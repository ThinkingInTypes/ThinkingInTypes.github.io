{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Thinking in Types","text":"<p>by Bruce Eckel</p>"},{"location":"#building-stubbornly-resilient-python-code","title":"Building Stubbornly Resilient Python Code","text":""},{"location":"01_Preface/","title":"Preface","text":""},{"location":"01_Preface/#strong-typing-vs-strong-testing","title":"Strong Typing vs. Strong Testing","text":""},{"location":"01_Preface/#tight-vs-permissive-type-systems","title":"Tight vs Permissive Type Systems","text":""},{"location":"01_Preface/#why-am-i-creating-this-book-in-the-open","title":"Why am I creating this book \"in the open\"?","text":"<ul> <li> <p>Thinking in C++ and Thinking in Java</p> </li> <li> <p>A \"Business Model\" can be about more than just money</p> </li> </ul>"},{"location":"01_Preface/#acknowledgements","title":"Acknowledgements","text":"<p>Most of the understanding I needed to explain this topic came from my attempts to help on the book by Bill Frasure and James Ward, titled \"Effect-Oriented Programming,\" that we worked on for over four years. I\u2019ve also learned a lot from some of the interviews that James and I have done for the Happy Path Programming podcast.</p>"},{"location":"02_Foundations/","title":"Foundations","text":"<p>Assumptions I make about your Python &amp; programming knowledge.</p>"},{"location":"02_Foundations/#your-python-knowlege","title":"Your Python Knowlege","text":"<ul> <li>You have intermediate-level understanding of the language, including a reasonable grasp of classes</li> <li>You understand core language features and know how to look up and learn features you haven't seen</li> <li>I will explain things I think are outside the core</li> </ul>"},{"location":"02_Foundations/#this-book-uses","title":"This book uses","text":"<ul> <li>Version control with github</li> <li>Project management with uv</li> <li>Testing with Pytest (noting that there are valid reasons to use other systems)</li> <li>Project organization (src directory)</li> </ul>"},{"location":"02_Foundations/#programming-philosophy","title":"Programming Philosophy","text":"<ul> <li>Build up from small testable pieces, balanced with simplicity and clarity.</li> <li>Use the most modern/elegant coding mechanisms available (latest Python)</li> <li>Classes are for creating types. As much as possible, pretend inheritance doesn't exist.</li> </ul>"},{"location":"02_Foundations/#examples","title":"Examples","text":"<ul> <li>Each example has a \"slug line\" which is simply the name of the file in a single-line comment as line one of the example.</li> <li>That example is in the Github repository in a subdirectory named for the chapter.</li> <li>The examples do not have <code>__main__</code>s; everything is at the top level.</li> <li>If a top-level-statement (TLS) produces output, that output will appear on the following line(s), commented with <code>##</code>.</li> <li>If a program does not run successfully, you will see a <code># R:</code> indicating an expected runtime error, typically followed by an explanation.</li> <li>Lines to be called out in text are marked with comments</li> <li>Black for consistent formatting</li> <li>Listings 47 Characters wide: readable on a phone</li> </ul>"},{"location":"03_What_is_a_Type/","title":"What is a Type?","text":"<p>This placeholder text was generated by ChatGPT 4.5. It will be significantly rewritten as the book is developed. In the meantime you can add comments to either https://bsky.app/bruceeckel or Github Issues.</p> <ul> <li>Types enable code generation tools, e.g. Typer, Cyclopts</li> </ul>"},{"location":"03_What_is_a_Type/#dynamic-vs-static-typing-definitions-pros-and-cons","title":"Dynamic vs. Static Typing: Definitions, Pros, and Cons","text":"<p>Python is traditionally known as a dynamically typed language. This means the types of variables are determined at runtime rather than explicitly declared. For example:</p> <pre><code># example_1.py\nx = 42  # x is dynamically assigned as an integer\ny = \"hello\"  # y is dynamically assigned as a string\n</code></pre> <p>In contrast, statically typed languages require explicit type declarations, and types are checked at compile time:</p> <pre><code>// int_and_string.cpp\n#include &lt;string&gt;\n\nint x = 42;               \nstd::string y = \"hello\";  \n</code></pre> <p>Pros of dynamic typing:</p> <ul> <li>Faster prototyping and development</li> <li>Greater flexibility in handling different types</li> <li>Easier learning curve for beginners</li> </ul> <p>Cons of dynamic typing:</p> <ul> <li>Runtime type errors can occur unexpectedly</li> <li>Less clarity on expected data types</li> <li>Reduced safety and predictability</li> </ul> <p>Pros of static typing:</p> <ul> <li>Type errors caught early at compile time</li> <li>Enhanced code clarity and readability</li> <li>Improved performance and optimization opportunities</li> </ul> <p>Cons of static typing:</p> <ul> <li>Verbose code with explicit declarations</li> <li>Potentially slower initial development</li> <li>Steeper learning curve for newcomers</li> </ul>"},{"location":"03_What_is_a_Type/#pythons-typing-evolution-from-duck-typing-to-type-annotations","title":"Python's Typing Evolution: From Duck Typing to Type Annotations","text":"<p>Python initially embraced the concept of \"duck typing,\" where the suitability of an object is determined by the presence of methods and properties, not by its explicit type. If it looks like a duck and quacks like a duck, it's treated as a duck:</p> <pre><code># example_2.py\nclass Duck:\n    def quack(self):\n        print(\"Quack!\")\n\n\ndef make_it_quack(bird):\n    bird.quack()\n\n\nmake_it_quack(Duck())  # works fine\n## Quack!\n</code></pre> <p>However, as Python projects grew in scale and complexity, the need for type safety and clearer documentation became apparent. Python 3.5 introduced type annotations, allowing developers to optionally specify expected types:</p> <pre><code># example_3.py\ndef greet(name: str) -&gt; str:\n    return f\"Hello, {name}!\"\n</code></pre> <p>This evolution combines the best of both worlds\u2014maintaining Python's flexibility while adding optional type safety.</p>"},{"location":"03_What_is_a_Type/#benefits-of-type-annotations-maintainability-readability-safety","title":"Benefits of Type Annotations: Maintainability, Readability, Safety","text":""},{"location":"03_What_is_a_Type/#maintainability","title":"Maintainability","text":"<ul> <li>Clearly defined types make code easier to refactor and maintain over time.</li> <li>Reduces uncertainty about the intended use of variables and functions.</li> </ul>"},{"location":"03_What_is_a_Type/#readability","title":"Readability","text":"<ul> <li>Type annotations serve as inline documentation.</li> <li>Quickly communicates developer intentions to other team members.</li> </ul>"},{"location":"03_What_is_a_Type/#safety","title":"Safety","text":"<ul> <li>Catch errors early, before the program runs.</li> <li>Reduces runtime exceptions due to unexpected types.</li> </ul>"},{"location":"03_What_is_a_Type/#type-checking-tools-overview-mypy-pyright-pycharm","title":"Type Checking Tools Overview (<code>mypy</code>, <code>pyright</code>, PyCharm)","text":"<p>Python\u2019s ecosystem provides robust tools to leverage type annotations:</p>"},{"location":"03_What_is_a_Type/#mypy","title":"mypy","text":"<ul> <li>One of the earliest static type checkers for Python.</li> <li>Highly configurable and widely adopted.</li> </ul> <pre><code>pip install mypy\nmypy your_script.py\n</code></pre>"},{"location":"03_What_is_a_Type/#pyright","title":"pyright","text":"<ul> <li>Developed by Microsoft, emphasizing performance and ease of use.</li> <li>Built into VSCode, offering real-time feedback.</li> </ul> <pre><code>npm install -g pyright\npyright your_script.py\n</code></pre>"},{"location":"03_What_is_a_Type/#pycharm","title":"PyCharm","text":"<ul> <li>Integrated IDE support for type checking.</li> <li>Provides immediate visual feedback as you write code.</li> </ul> <p>These tools allow developers to incrementally adopt static typing, improving code reliability without sacrificing Python's dynamic roots.</p>"},{"location":"03_What_is_a_Type/#understanding-runtime-vs-static-type-checking","title":"Understanding Runtime vs. Static Type Checking","text":""},{"location":"03_What_is_a_Type/#runtime-type-checking","title":"Runtime Type Checking","text":"<ul> <li>Types are validated as the program executes.</li> <li>Errors surface only when problematic code is executed.</li> </ul> <pre><code># example_4.py\ndef add(a, b):\n    return a + b\n\n\nadd(1, \"2\")  # raises runtime TypeError\n</code></pre>"},{"location":"03_What_is_a_Type/#static-type-checking","title":"Static Type Checking","text":"<ul> <li>Performed before the code runs, typically during development or as part of CI/CD pipelines.</li> <li>Prevents many type-related errors by analyzing code structure.</li> </ul> <pre><code># example_5.py\n\ndef add(a: int, b: int) -&gt; int:\n    return a + b\n\nadd(1, \"2\")  # R: Static type checker flags this\n</code></pre> <p>By combining runtime flexibility with static checking, Python provides a balanced approach that empowers developers to write safe, readable, and maintainable code.</p>"},{"location":"04_Predefined_Types/","title":"Predefined Types","text":"<p>This placeholder text was generated by ChatGPT 4.5. It will be significantly rewritten as the book is developed. In the meantime you can add comments to either https://bsky.app/bruceeckel or Github Issues.</p>"},{"location":"04_Predefined_Types/#built-in-types-int-str-float-bool-none","title":"Built-in Types (<code>int</code>, <code>str</code>, <code>float</code>, <code>bool</code>, <code>None</code>)","text":"<p>Python supports type annotations for its fundamental built-in types, allowing developers to clarify expected types of variables and function arguments explicitly:</p> <pre><code># example_1.py\nage: int = 25\nname: str = \"Alice\"\nsalary: float = 45000.50\nis_active: bool = True\nno_value: None = None\n</code></pre> <p>These annotations immediately communicate intent, simplifying code readability and maintainability.</p>"},{"location":"04_Predefined_Types/#variables-and-functions","title":"Variables and Functions","text":"<p>Type annotations can be added to variables and function parameters to indicate expected data types:</p>"},{"location":"04_Predefined_Types/#variables","title":"Variables","text":"<pre><code># example_2.py\nuser_id: int = 123\nusername: str = \"admin\"\n</code></pre>"},{"location":"04_Predefined_Types/#functions","title":"Functions","text":"<pre><code># example_3.py\ndef greet_user(username: str) -&gt; str:\n    return f\"Welcome, {username}!\"\n</code></pre> <p>Annotations clearly specify expected input and output types, helping prevent bugs and errors.</p>"},{"location":"04_Predefined_Types/#optional-types-and-default-values","title":"Optional Types and Default Values","text":"<p>Sometimes a variable or function argument can be a specific type or <code>None</code>. Python uses <code>Optional</code> from <code>typing</code> to indicate this:</p> <pre><code># example_4.py\nfrom typing import Optional\n\n\ndef find_user(user_id: int) -&gt; Optional[str]:\n    if user_id == 1:\n        return \"Alice\"\n    return None\n</code></pre> <p>Default values with optional annotations:</p> <pre><code># example_5.py\nfrom typing import Optional\n\n\ndef greet(name: Optional[str] = None) -&gt; str:\n    if name:\n        return f\"Hello, {name}!\"\n    return \"Hello!\"\n</code></pre>"},{"location":"04_Predefined_Types/#using-union-types-operator-vs-union","title":"Using Union Types (<code>|</code> operator vs. <code>Union</code>)","text":"<p>Python allows you to specify multiple acceptable types for variables or parameters. Traditionally, the <code>Union</code> type was used, but Python 3.10 introduced the <code>|</code> operator for readability:</p>"},{"location":"04_Predefined_Types/#using-union","title":"Using <code>Union</code>","text":"<pre><code># example_6.py\nfrom typing import Union\n\n\ndef process_value(value: Union[int, str]) -&gt; str:\n    return str(value)\n</code></pre>"},{"location":"04_Predefined_Types/#using-operator-python-310","title":"Using <code>|</code> operator (Python 3.10+)","text":"<pre><code># example_7.py\ndef process_value(value: int | str) -&gt; str:\n    return str(value)\n</code></pre> <p>The <code>|</code> operator provides clearer and more concise syntax.</p>"},{"location":"04_Predefined_Types/#defining-type-aliases","title":"Defining Type Aliases","text":"<p>Type aliases simplify complex annotations by providing a readable and reusable name for a type:</p> <pre><code># example_8.py\nfrom typing import List\n\nUserIDs = List[int]\n\n\ndef process_users(user_ids: UserIDs) -&gt; None:\n    for uid in user_ids:\n        print(f\"Processing user {uid}\")\n</code></pre> <p>Aliases improve code clarity, especially for complex types.</p>"},{"location":"04_Predefined_Types/#lists-tuples-sets-and-dictionaries","title":"Lists, Tuples, Sets and Dictionaries","text":"<p>Python provides built-in collection types such as lists, tuples, sets, and dictionaries. Annotating these clearly specifies their expected contents:</p>"},{"location":"04_Predefined_Types/#lists","title":"Lists","text":"<pre><code># example_9.py\nfrom typing import List\n\nscores: List[int] = [95, 85, 75]\n</code></pre>"},{"location":"04_Predefined_Types/#tuples","title":"Tuples","text":"<pre><code># example_10.py\nfrom typing import Tuple\n\ncoordinates: Tuple[float, float] = (23.5, 45.8)\n</code></pre>"},{"location":"04_Predefined_Types/#sets","title":"Sets","text":"<pre><code># example_11.py\nfrom typing import Set\n\nunique_ids: Set[str] = {\"abc\", \"xyz\", \"123\"}\n</code></pre>"},{"location":"04_Predefined_Types/#dictionaries","title":"Dictionaries","text":"<pre><code># example_12.py\nfrom typing import Dict\n\nuser_data: Dict[str, int] = {\"Alice\": 30, \"Bob\": 25}\n</code></pre> <p>These annotations enhance readability and help catch type-related errors early.</p>"},{"location":"04_Predefined_Types/#annotations-without-imports","title":"Annotations without Imports","text":"<p>Starting from Python 3.9, built-in collection types support direct annotations without importing from <code>typing</code>:</p> <pre><code># example_13.py\nscores: list[int] = [95, 85, 75]\nuser_data: dict[str, float] = {\"Alice\": 95.5, \"Bob\": 85.3}\n</code></pre> <p>This simplified syntax enhances readability and reduces verbosity.</p>"},{"location":"04_Predefined_Types/#specialized-annotations-sequence-mapping-iterable-iterator","title":"Specialized Annotations (<code>Sequence</code>, <code>Mapping</code>, <code>Iterable</code>, <code>Iterator</code>)","text":"<p>Python provides specialized annotations for greater flexibility:</p>"},{"location":"04_Predefined_Types/#sequence","title":"<code>Sequence</code>","text":"<ul> <li>For any ordered collection supporting indexing:</li> </ul> <pre><code># example_14.py\nfrom typing import Sequence\n\n\ndef average(numbers: Sequence[float]) -&gt; float:\n    return sum(numbers) / len(numbers)\n</code></pre>"},{"location":"04_Predefined_Types/#mapping","title":"<code>Mapping</code>","text":"<ul> <li>For dictionary-like objects:</li> </ul> <pre><code># example_15.py\nfrom typing import Mapping\n\n\ndef get_user_age(users: Mapping[str, int], username: str) -&gt; int:\n    return users.get(username, 0)\n</code></pre>"},{"location":"04_Predefined_Types/#iterable-and-iterator","title":"<code>Iterable</code> and <code>Iterator</code>","text":"<ul> <li>For looping over items:</li> </ul> <pre><code># example_16.py\nfrom typing import Iterable, Iterator\n\n\ndef print_items(items: Iterable[str]) -&gt; None:\n    for item in items:\n        print(item)\n\n\ndef generate_numbers(n: int) -&gt; Iterator[int]:\n    for i in range(n):\n        yield i\n</code></pre> <p>Specialized annotations enable broader compatibility with various collection types.</p>"},{"location":"04_Predefined_Types/#common-annotation-patterns-and-errors","title":"Common Annotation Patterns and Errors","text":""},{"location":"04_Predefined_Types/#common-patterns","title":"Common Patterns","text":"<ul> <li>Clearly annotate function parameters and return values.</li> <li>Use type aliases for complex or repetitive types.</li> <li>Use optional annotations when values can legitimately be <code>None</code>.</li> </ul>"},{"location":"04_Predefined_Types/#common-errors","title":"Common Errors","text":"<ul> <li>Incorrect annotations (e.g., annotating as <code>int</code> when the value might be <code>float</code>).</li> <li>Missing annotations on important public APIs or interfaces.</li> <li>Overuse of overly broad types like <code>Any</code>, reducing annotation benefits.</li> </ul> <p>Example error:</p> <pre><code># example_17.py\ndef calculate_area(radius: int) -&gt; float:\n    return 3.14 * radius**2\n\n\ncalculate_area(3.5)  # R: Flagged by static type checker\n</code></pre> <p>Careful use of annotations combined with static checking tools significantly enhances code robustness and readability.</p>"},{"location":"05_Custom_Types/","title":"Custom Types","text":"<ul> <li>Add variations: NamedTuple, Enum</li> <li>Incorporate examples from https://github.com/BruceEckel/DataClassesAsTypes</li> </ul> <p>This chapter began as a presentation at a Python conference, inspired by conversations with fellow programmers exploring functional programming techniques. Specifically, the idea arose from a podcast discussion about Scala's smart types. After extensive study of functional programming, several concepts coalesced into an approach that leverages Python\u2019s data classes effectively. This chapter aims to share those insights and illustrate the practical benefits of Python data classes, guiding you towards clearer, more reliable code.</p>"},{"location":"05_Custom_Types/#misunderstanding-class-attributes","title":"Misunderstanding Class Attributes","text":"<p>This chapter contains additional tools that modify the normal behavior of class attributes. It's important to understand that this behavior is created by the tool, and that ordinary classes do not behave this way. Read the [Class Attributes] appendix for deeper understanding.</p>"},{"location":"05_Custom_Types/#the-initial-problem-ensuring-correctness","title":"The Initial Problem: Ensuring Correctness","text":"<p>Imagine building a simple customer feedback system using a rating from one to ten stars. Traditionally, Python programmers use an integer type, checking its validity whenever it's used:</p> <pre><code># example_1.py\ndef rate_stars(stars: int):\n    assert 1 &lt;= stars &lt;= 10, \"Stars rating must be between 1 and 10.\"\n    # use stars safely\n</code></pre> <p>However, each time the integer is used, its validity must be rechecked, leading to duplicated logic, scattered validation, and potential mistakes.</p>"},{"location":"05_Custom_Types/#traditional-object-oriented-encapsulation","title":"Traditional Object-Oriented Encapsulation","text":"<p>Object-oriented programming (OOP) suggests encapsulating validation within the class. Python typically uses a private attribute to ensure encapsulation:</p> <pre><code># example_2.py\nclass Stars:\n    def __init__(self, stars: int):\n        assert 1 &lt;= stars &lt;= 10, \"Stars rating must be between 1 and 10.\"\n        self._stars = stars\n\n    @property\n    def stars(self):\n        return self._stars\n</code></pre> <p>This approach centralizes validation, yet remains cumbersome. Each method interacting with the attribute still requires pre- and post-condition checks, cluttering the code and potentially introducing errors if a developer neglects these checks.</p>"},{"location":"05_Custom_Types/#data-classes","title":"Data Classes","text":"<p>Data classes, introduced in Python 3.7, significantly streamline this process by generating essential methods automatically. They provide a structured, concise way to define data-holding objects:</p> <pre><code># example_3.py\nfrom dataclasses import dataclass\n\n\n@dataclass\nclass Stars:\n    stars: int\n\n    def __post_init__(self):\n        assert 1 &lt;= self.stars &lt;= 10, \"Stars rating must be between 1 and 10.\"\n</code></pre> <p>Here, validation logic resides exclusively in the <code>__post_init__</code> method, executed automatically after initialization. This guarantees that only valid <code>Stars</code> instances exist. Subsequent functions operating on <code>Stars</code> no longer require redundant checks:</p> <pre><code># example_4.py\ndef increase_stars(rating: Stars, increment: int) -&gt; Stars:\n    return Stars(rating.stars + increment)\n</code></pre> <p>If this function tries to create an invalid rating, the data class validation immediately raises an error. This greatly simplifies code maintenance and readability.</p>"},{"location":"05_Custom_Types/#immutable-data-classes-and-functional-programming","title":"Immutable Data Classes and Functional Programming","text":"<p>Functional programming strongly advocates immutability, preventing accidental changes and thus simplifying reasoning about your code. Python data classes support immutability through a <code>frozen=True</code> parameter:</p> <pre><code># example_5.py\nfrom dataclasses import dataclass\n\n\n@dataclass(frozen=True)\nclass Stars:\n    stars: int\n\n    def __post_init__(self):\n        assert 1 &lt;= self.stars &lt;= 10, \"Stars rating must be between 1 and 10.\"\n</code></pre> <p>Now, modifying a <code>Stars</code> instance after creation raises an error, further safeguarding the data integrity. Additionally, immutable objects can safely serve as keys in dictionaries, allowing reliable data lookups and caching.</p>"},{"location":"05_Custom_Types/#composing-data-classes","title":"Composing Data Classes","text":"<p>Composition, another functional programming cornerstone, allows building complex data types from simpler ones. Consider a <code>Person</code> object composed of <code>FullName</code>, <code>BirthDate</code>, and <code>Email</code> data classes:</p> <pre><code># example_6.py\nfrom dataclasses import dataclass\n\n\n@dataclass(frozen=True)\nclass FullName:\n    name: str\n\n    def __post_init__(self):\n        parts = self.name.split()\n        assert len(parts) &gt;= 2, \"Full name must include at least two parts.\"\n\n\n@dataclass(frozen=True)\nclass BirthDate:\n    year: int\n    month: int\n    day: int\n\n    def __post_init__(self):\n        assert 1900 &lt;= self.year &lt;= 2022, \"Year must be between 1900 and 2022.\"\n        assert 1 &lt;= self.month &lt;= 12, \"Month must be between 1 and 12.\"\n        assert 1 &lt;= self.day &lt;= 31, \"Day must be valid for given month.\"\n\n\n@dataclass(frozen=True)\nclass Email:\n    address: str\n\n    def __post_init__(self):\n        assert \"@\" in self.address, \"Invalid email address.\"\n\n\n@dataclass(frozen=True)\nclass Person:\n    name: FullName\n    birthdate: BirthDate\n    email: Email\n</code></pre> <p>This hierarchical validation structure ensures correctness and clarity at every composition level. Invalid data never propagates, vastly simplifying subsequent interactions.</p>"},{"location":"05_Custom_Types/#simple-type-aliasing-with-newtype","title":"Simple Type Aliasing with <code>NewType</code>","text":"<p><code>NewType</code> creates distinct types for stronger type checking without runtime overhead:</p> <pre><code># simple_type_aliasing.py\nfrom typing import NewType\n\nUserId = NewType(\"UserId\", int)\n\nuser_id = UserId(42)\n\n\ndef get_user(uid: UserId) -&gt; str:\n    return f\"User {uid}\"\n\n\n# get_user(42)  # type checker error\nget_user(user_id)  # correct usage\n</code></pre> <p><code>NewType</code> improves clarity, preventing accidental misuse of similar underlying types.</p>"},{"location":"05_Custom_Types/#literal-types","title":"Literal Types","text":"<p>Literal types allow specifying exact permissible values, enhancing type specificity and correctness:</p> <pre><code># literal_types.py\nfrom typing import Literal\n\n\ndef set_mode(mode: Literal[\"auto\", \"manual\"]) -&gt; None:\n    print(f\"Mode set to {mode}\")\n\n\nset_mode(\"auto\")  # valid\n## Mode set to auto\n# set_mode('automatic')  # invalid, detected by type checker\n</code></pre> <p>Literal types ensure values match expected exact constants, improving type safety.</p>"},{"location":"05_Custom_Types/#leveraging-enums-for-type-safety","title":"Leveraging Enums for Type Safety","text":"<p>Enums provide additional type safety for fixed-value sets, such as months:</p> <pre><code># example_7.py\nfrom enum import Enum\n\n\nclass Month(Enum):\n    JANUARY = (1, 31)\n    FEBRUARY = (2, 28)\n    # other months\n\n    @staticmethod\n    def validate(month_number: int, day: int) -&gt; bool:\n        month = Month(month_number)\n        return 1 &lt;= day &lt;= month.value[1]\n</code></pre> <p>Using enums makes code both readable and safely constrained, improving robustness. Enums clearly outperform data classes for fixed-value sets due to simplicity and compile-time definitions.</p>"},{"location":"05_Custom_Types/#specialized-tools","title":"Specialized Tools","text":""},{"location":"05_Custom_Types/#typed-namedtuples","title":"Typed NamedTuples","text":"<p>A typed <code>NamedTuple</code> combines tuple immutability with type annotations and named fields:</p> <pre><code># named_tuple.py\nfrom typing import NamedTuple\n\n\nclass Coordinates(NamedTuple):\n    latitude: float\n    longitude: float\n\n\ncoords = Coordinates(51.5074, -0.1278)\nprint(coords)\nprint(coords.latitude)\n# coords.latitude = 123.4567 # Runtime error\n</code></pre> <p><code>NamedTuple</code> provides clarity, immutability, and easy unpacking, ideal for simple structured data. For brevity and cleanliness, this book will used <code>NamedTuple</code>s instead of frozen <code>dataclass</code>es whenever possible.</p>"},{"location":"05_Custom_Types/#leveraging-typeddicts-for-structured-data","title":"Leveraging TypedDicts for Structured Data","text":"<p><code>TypedDict</code> is useful when defining dictionary structures with known keys and typed values:</p> <pre><code># typed_dict.py\nfrom typing import TypedDict\n\n\nclass UserProfile(TypedDict):\n    username: str\n    email: str\n    age: int\n\n\nuser: UserProfile = {\"username\": \"alice\", \"email\": \"alice@example.com\", \"age\": 30}\n</code></pre> <p><code>TypedDict</code> clarifies expected keys and types, providing type safety for dictionary data.</p>"},{"location":"05_Custom_Types/#optional-fields-in-typeddict","title":"Optional Fields in TypedDict","text":"<p>You can specify optional fields using <code>NotRequired</code> (Python 3.11+) or <code>total=False</code>:</p> <pre><code># optional_typed_dict_fields.py\nfrom typing import TypedDict, NotRequired\n\n\nclass UserSettings(TypedDict):\n    theme: str\n    notifications_enabled: NotRequired[bool]\n\n\nsettings: UserSettings = {\"theme\": \"dark\"}\n</code></pre> <p>This flexibility allows clear definitions for complex, partially-optional data structures.</p>"},{"location":"05_Custom_Types/#combining-dataclasses-and-enums","title":"Combining Dataclasses and Enums","text":"<pre><code># dataclasses_and_enums.py\nfrom dataclasses import dataclass\nfrom enum import Enum\n\n\nclass Status(Enum):\n    ACTIVE = \"active\"\n    INACTIVE = \"inactive\"\n\n\n@dataclass\nclass User:\n    id: int\n    name: str\n    status: Status\n\n\nuser = User(id=1, name=\"Alice\", status=Status.ACTIVE)\nprint(user)\n## User(id=1, name='Alice', status=&lt;Status.ACTIVE:\n## 'active'&gt;)\n</code></pre>"},{"location":"05_Custom_Types/#domain-driven-design-ddd","title":"Domain-Driven Design (DDD)","text":"<p>Strongly-typed domain models help clearly represent domain logic, improving robustness and maintainability. Define domain entities explicitly to enhance domain logic expressiveness:</p> <pre><code># ddd.py\nfrom dataclasses import dataclass\nfrom typing import List, NamedTuple\n\n\nclass Product(NamedTuple):\n    name: str\n    price: float\n\n\n@dataclass\nclass Order:\n    order_id: int\n    products: List[Product]\n\n    def total(self) -&gt; float:\n        return sum(product.price for product in self.products)\n</code></pre> <p>Strongly-typed domain models help catch issues early, facilitating clearer, safer, and more maintainable codebases.</p>"},{"location":"05_Custom_Types/#conclusion","title":"Conclusion","text":"<p>Python data classes simplify managing data integrity and composition, reducing repetitive checks and centralizing validation. Combined with functional programming principles like immutability and type composition, data classes significantly enhance the clarity, maintainability, and robustness of your code. Once you adopt this method, you'll find your development process smoother, more reliable, and enjoyable.</p>"},{"location":"05_Custom_Types/#generated-dataclass-intro-notes","title":"(Generated) Dataclass Intro Notes","text":"<p>Dataclasses simplify class definitions by automatically generating methods like <code>__init__</code>, <code>__repr__</code>, and <code>__eq__</code>:</p> <pre><code># generated_methods.py\nfrom dataclasses import dataclass\n\n\n@dataclass\nclass Product:\n    name: str\n    price: float\n    in_stock: bool = True\n\n\nproduct = Product(\"Laptop\", 999.99)\nprint(product)\n## Product(name='Laptop', price=999.99,\n## in_stock=True)\n</code></pre> <p>Dataclasses reduce boilerplate, ensuring concise and readable class definitions.</p> <p>Dataclasses support default factories, immutability, and more:</p> <pre><code># example_9.py\nfrom dataclasses import dataclass, field\nfrom typing import List\n\n\n@dataclass(frozen=True)\nclass Order:\n    order_id: int\n    items: List[str] = field(default_factory=list)\n\n\norder = Order(order_id=123)\n# order.order_id = 456  # Error: dataclass is frozen (immutable)\n</code></pre>"},{"location":"06_Pattern_Matching/","title":"Pattern Matching","text":"<p>This placeholder text was generated by ChatGPT 4.5. It will be significantly rewritten as the book is developed. In the meantime you can add comments to either https://bsky.app/bruceeckel or Github Issues.</p>"},{"location":"06_Pattern_Matching/#introduction-to-structural-pattern-matching-python-310","title":"Introduction to Structural Pattern Matching (Python 3.10+)","text":"<p>Python 3.10 introduced structural pattern matching, providing powerful and concise syntax to match objects against specific patterns:</p> <pre><code># example_1.py\ndef handle_command(command: str) -&gt; str:\n    match command:\n        case \"start\":\n            return \"Starting\"\n        case \"stop\":\n            return \"Stopping\"\n        case _:\n            return \"Unknown command\"\n</code></pre> <p>Pattern matching enhances readability and maintainability, reducing the complexity of conditional logic.</p>"},{"location":"06_Pattern_Matching/#annotating-code-with-pattern-matching","title":"Annotating Code with Pattern Matching","text":"<p>Annotations can clarify patterns used in structural matching, making code clearer and aiding static type checking:</p> <pre><code># example_2.py\nfrom typing import Union, NamedTuple\n\n\nclass Success(NamedTuple):\n    result: str\n\n\nclass Error(NamedTuple):\n    error: str\n\n\ndef process(response: Union[Success, Error]) -&gt; str:\n    match response:\n        case Success(result):\n            return f\"Success: {result}\"\n        case Error(error):\n            return f\"Error: {error}\"\n</code></pre> <p>This use of annotations and pattern matching simplifies complex decision-making logic.</p>"},{"location":"06_Pattern_Matching/#annotating-code-with-pattern-matching_1","title":"Annotating Code with Pattern Matching","text":"<p>When combining type annotations with pattern matching, carefully structuring types enhances type checker effectiveness:</p>"},{"location":"06_Pattern_Matching/#example-with-typeddict-and-pattern-matching","title":"Example with TypedDict and Pattern Matching","text":"<pre><code># example_3.py\nfrom typing import TypedDict\n\n\nclass Command(TypedDict):\n    action: str\n    payload: dict\n\n\ndef process_command(command: TypedDict) -&gt; None:\n    match command:\n        case {\"action\": \"create\", \"item\": item}:\n            print(f\"Creating {item}\")\n        case {\"action\": \"delete\", \"id\": int() as item_id}:\n            print(f\"Deleting item {item_id}\")\n        case _:\n            print(\"Unknown command\")\n</code></pre> <p>Annotations clearly define expected data shapes, improving readability and correctness.</p>"},{"location":"06_Pattern_Matching/#type-checking-considerations-with-match-statements","title":"Type Checking Considerations with <code>match</code> Statements","text":"<p>Static type checkers can analyze pattern matching effectively, but careful type design is essential:</p>"},{"location":"06_Pattern_Matching/#ensuring-consistent-patterns","title":"Ensuring Consistent Patterns","text":"<p>Pattern matching works best with clearly annotated and structurally consistent types:</p> <pre><code># example_4.py\nfrom typing import Union\n\n\nclass Cat:\n    def meow(self) -&gt; str:\n        return \"Meow\"\n\n\nclass Dog:\n    def bark(self) -&gt; str:\n        return \"Woof\"\n\n\ndef animal_sound(animal: Union[Cat, Dog]) -&gt; str:\n    match animal:\n        case Cat():\n            return animal.meow()\n        case Dog():\n            return animal.bark()\n</code></pre> <p>Properly annotated unions simplify handling of multiple types with clarity and safety.</p>"},{"location":"06_Pattern_Matching/#real-world-scenarios-for-pattern-matching","title":"Real-world Scenarios for Pattern Matching","text":"<p>Pattern matching is highly effective in real-world scenarios, such as:</p>"},{"location":"06_Pattern_Matching/#handling-api-responses","title":"Handling API Responses","text":"<pre><code># example_5.py\ndef process_response(response: dict) -&gt; str:\n    match response:\n        case {\"status\": \"success\", \"data\": data}:\n            return f\"Success: {data}\"\n        case {\"status\": \"error\", \"message\": error_msg}:\n            return f\"Error: {error}\"\n        case _:\n            return \"Unknown response format\"\n</code></pre>"},{"location":"06_Pattern_Matching/#parsing-complex-data-structures","title":"Parsing Complex Data Structures","text":"<pre><code># example_6.py\ndef parse_coordinates(coords: tuple) -&gt; str:\n    match coords := coords:\n        case (float(lat), float(lon)):\n            return f\"Latitude: {lat}, Longitude: {lon}\"\n        case _:\n            return \"Invalid coordinates\"\n</code></pre> <p>Pattern matching simplifies conditional logic, making code more maintainable.</p>"},{"location":"06_Pattern_Matching/#type-checking-considerations","title":"Type Checking Considerations","text":"<p>Ensure type annotations match patterns closely, as type checkers use them to validate correctness:</p> <ul> <li>Explicitly define type annotations for better static analysis.</li> <li>Carefully match patterns to annotated types for enhanced safety.</li> </ul> <p>Properly using pattern matching alongside type annotations helps catch potential runtime errors early, resulting in safer and more readable Python code.</p>"},{"location":"07_Immutability/","title":"Immutability","text":"<ul> <li>Benefits of immutability</li> <li>Historic immutability by convention with all caps</li> <li>Immutability with <code>Final</code></li> </ul> <p>Dataclasses support immutability with <code>frozen</code>:</p> <pre><code># example_2.py\nfrom dataclasses import dataclass, field\nfrom typing import List\n\n\n@dataclass(frozen=True)\nclass Order:\n    order_id: int\n    items: List[str] = field(default_factory=list)\n\n\norder = Order(order_id=123)\n# order.order_id = 456  # Error: dataclass is frozen (immutable)\n</code></pre> <ul> <li>show post_init with frozen</li> </ul>"},{"location":"08_Generics/","title":"Generics","text":"<p>This placeholder text was generated by ChatGPT 4.5. It will be significantly rewritten as the book is developed. In the meantime you can add comments to either https://bsky.app/bruceeckel or Github Issues.</p>"},{"location":"08_Generics/#defining-custom-generics-with-typevar-and-generic","title":"Defining Custom Generics with <code>TypeVar</code> and <code>Generic</code>","text":"<p>Custom generics allow functions and classes to handle various types flexibly:</p>"},{"location":"08_Generics/#using-typevar","title":"Using <code>TypeVar</code>","text":"<pre><code># example_1.py\nfrom typing import TypeVar, List\n\nT = TypeVar(\"T\")\n\n\ndef first_item(items: List[T]) -&gt; T:\n    return items[0]\n\n\nprint(first_item([1, 2, 3]))  # returns int\n## 1\nprint(first_item([\"a\", \"b\"]))  # returns str\n## a\n</code></pre>"},{"location":"08_Generics/#generic-classes","title":"Generic Classes","text":"<pre><code># example_2.py\nfrom dataclasses import dataclass\nfrom typing import Generic, TypeVar\n\nT = TypeVar(\"T\")  # Declare a type variable\n\n\n@dataclass\nclass Box(Generic[T]):\n    content: T\n\n\nbox_int = Box(123)  # Box[int]\nbox_str = Box(\"hello\")  # Box[str]\n</code></pre> <p>Custom generics enhance code reusability and type safety.</p>"},{"location":"08_Generics/#using-constraints-and-bounds-with-generics","title":"Using Constraints and Bounds with Generics","text":"<p>Generics can include constraints and bounds to restrict allowed types:</p>"},{"location":"08_Generics/#constraints","title":"Constraints","text":"<pre><code># example_3.py\nfrom typing import TypeVar\n\nU = TypeVar(\"U\", int, float)\n\n\ndef add(a: U, b: U) -&gt; U:\n    return a + b\n\n\nadd(1, 2)  # valid\nadd(1.5, 2.5)  # valid\n# add(\"a\", \"b\")  # invalid, detected by type checker\n</code></pre>"},{"location":"08_Generics/#bounds","title":"Bounds","text":"<pre><code># example_4.py\nfrom typing import TypeVar\n\n\nclass Animal:\n    def speak(self) -&gt; str:\n        return \"...\"\n\n\nA = TypeVar(\"A\", bound=Animal)\n\n\ndef animal_sound(animal: A) -&gt; str:\n    return animal.speak()\n\n\nclass Dog(Animal):\n    def speak(self) -&gt; str:\n        return \"Woof!\"\n\n\nprint(animal_sound(Dog()))  # \"Woof!\"\n## Woof!\n</code></pre> <p>Constraints and bounds improve specificity in generic type annotations, enhancing code clarity and correctness.</p>"},{"location":"08_Generics/#variance-covariance-and-contravariance-in-generics","title":"Variance, Covariance, and Contravariance in Generics","text":"<p>Variance controls type relationships between generic types:</p>"},{"location":"08_Generics/#covariance-covarianttrue","title":"Covariance (<code>covariant=True</code>)","text":"<p>Allows using subtypes in place of parent types:</p> <pre><code># example_7.py\nfrom typing import Generic, TypeVar\n\nT_co = TypeVar(\"T_co\", covariant=True)\n\n\nclass ReadOnlyList(Generic[T_co]):\n    def __init__(self, items: list[T_co]):\n        self.items = items\n\n\nints: ReadOnlyList[int] = ReadOnlyList([1, 2, 3])\nnumbers: ReadOnlyList[float] = ints  # Valid due to covariance\n</code></pre>"},{"location":"08_Generics/#contravariance-contravarianttrue","title":"Contravariance (<code>contravariant=True</code>)","text":"<p>Allows using parent types in place of subtypes, common in callbacks or consumers:</p> <pre><code># example_8.py\nfrom typing import TypeVar, Generic\n\nT_contra = TypeVar(\"T_contra\", contravariant=True)\n\n\nclass Processor(Generic[T_contra]):\n    def process(self, value: T_contra) -&gt; None:\n        print(value)\n\n\nint_processor: Processor[int] = Processor()\nnumber_processor: Processor[float] = int_processor  # Valid due to contravariance\n</code></pre> <p>Understanding variance ensures accurate type relationships, especially when designing flexible APIs or libraries.</p>"},{"location":"09_Callables/","title":"Callables","text":"<p>This placeholder text was generated by ChatGPT 4.5. It will be significantly rewritten as the book is developed. In the meantime you can add comments to either https://bsky.app/bruceeckel or Github Issues.</p>"},{"location":"09_Callables/#annotating-functions-and-lambdas","title":"Annotating Functions and Lambdas","text":"<p>Clearly annotating functions and lambda expressions improves readability and type safety:</p>"},{"location":"09_Callables/#function-annotations","title":"Function Annotations","text":"<pre><code># example_1.py\ndef add(x: int, y: int) -&gt; int:\n    return x + y\n</code></pre>"},{"location":"09_Callables/#lambda-annotations","title":"Lambda Annotations","text":"<p>Annotating lambdas directly isn't supported; however, annotations can be implied:</p> <pre><code># example_2.py\nfrom typing import Callable\n\nadder: Callable[[int, int], int] = lambda x, y: x + y\n</code></pre> <p>This explicit approach ensures that lambda behavior is type-checked properly.</p>"},{"location":"09_Callables/#using-callable-for-higher-order-functions","title":"Using <code>Callable</code> for Higher-Order Functions","text":"<p>The <code>Callable</code> type is essential for annotating functions that accept or return other functions:</p> <pre><code># example_3.py\nfrom typing import Callable\n\n\ndef operate(a: int, b: int, func: Callable[[int, int], int]) -&gt; int:\n    return func(a, b)\n\n\nresult = operate(5, 3, lambda x, y: x * y)  # returns 15\n</code></pre> <p>Using <code>Callable</code> clearly defines expected function signatures, enhancing maintainability and correctness.</p>"},{"location":"09_Callables/#advanced-function-annotations-with-paramspec","title":"Advanced Function Annotations with <code>ParamSpec</code>","text":"<p>Introduced in Python 3.10, <code>ParamSpec</code> allows annotating decorators and generic functions while preserving original function signatures:</p> <pre><code># example_4.py\nfrom typing import Callable, ParamSpec, TypeVar\n\nP = ParamSpec(\"P\")\nR = TypeVar(\"R\")\n\n\ndef logging_decorator(func: Callable[P, R]) -&gt; Callable[P, R]:\n    def wrapper(*args: P.args, **kwargs: P.kwargs) -&gt; R:\n        print(f\"Calling {func.__name__} with {args} and {kwargs}\")\n        return func(*args, **kwargs)\n\n    return wrapper\n\n\n@logging_decorator\ndef multiply(a: int, b: int) -&gt; int:\n    return a * b\n\n\nmultiply(2, 3)  # Output: Calling multiply with (2, 3) and {} then returns 6\n## Calling multiply with (2, 3) and {}\n</code></pre> <p><code>ParamSpec</code> helps decorators maintain accurate type information for wrapped functions.</p>"},{"location":"09_Callables/#implementing-function-overloading-with-overload","title":"Implementing Function Overloading with <code>@overload</code>","text":"<p>Python allows specifying multiple function signatures through the <code>@overload</code> decorator for better static type checking:</p> <pre><code># example_5.py\nfrom typing import overload, Union\n\n\n@overload\ndef double(value: int) -&gt; int: ...\n\n\n@overload\ndef double(value: str) -&gt; str: ...\n\n\ndef double(value: Union[int, str]) -&gt; Union[int, str]:\n    if isinstance(value, int):\n        return value * 2\n    return value + value\n\n\nprint(double(4))  # Output: 8\n## 8\nprint(double(\"Hi\"))  # Output: HiHi\n## HiHi\n</code></pre> <p><code>@overload</code> clearly defines each acceptable signature, providing strong typing and preventing misuse.</p>"},{"location":"09_Callables/#annotation-strategies-for-apis-and-libraries","title":"Annotation Strategies for APIs and Libraries","text":"<p>Clear annotations greatly enhance public API usability and reliability. Strategies include:</p>"},{"location":"09_Callables/#explicit-and-detailed-annotations","title":"Explicit and Detailed Annotations","text":"<ul> <li>Clearly annotate all public API interfaces and return types.</li> <li>Avoid overly broad types like <code>Any</code> unless necessary.</li> </ul>"},{"location":"09_Callables/#using-type-aliases-for-complex-signatures","title":"Using Type Aliases for Complex Signatures","text":"<pre><code># example_6.py\nfrom typing import Callable, TypeAlias\n\nRequestHandler: TypeAlias = Callable[[str, dict], dict]\n\n\ndef handle_request(path: str, handler: RequestHandler) -&gt; dict:\n    response = handler(path, {})\n    return response\n</code></pre>"},{"location":"09_Callables/#consistent-annotation-patterns","title":"Consistent Annotation Patterns","text":"<ul> <li>Follow consistent patterns for similar methods or functions within an API.</li> </ul>"},{"location":"09_Callables/#leveraging-protocols-and-callables","title":"Leveraging Protocols and Callables","text":"<p>Using <code>Protocol</code> for clearly defined callable behaviors:</p> <pre><code># example_7.py\nfrom typing import Protocol\n\n\nclass Handler(Protocol):\n    def __call__(self, request: dict) -&gt; dict: ...\n\n\ndef process_request(handler: Handler, request: dict) -&gt; dict:\n    return handler(request)\n</code></pre> <p>Following these strategies ensures type-safe, clear, and developer-friendly APIs and libraries.</p>"},{"location":"10_Structural_Typing/","title":"Structural Typing","text":"<p>This placeholder text was generated by ChatGPT 4.5. It will be significantly rewritten as the book is developed. In the meantime you can add comments to either https://bsky.app/bruceeckel or Github Issues.</p>"},{"location":"10_Structural_Typing/#introduction","title":"Introduction","text":"<p>In type systems, there are two fundamental ways to decide if one type is compatible with another: nominal typing and structural typing. Nominal typing (name-based typing) means type compatibility is determined by explicit declarations and the class hierarchy \u2013 an object\u2019s type is what its class name (or inheritance) says it is (Protocols and structural subtyping - mypy 1.15.0 documentation). For example, if class <code>Dog</code> inherits from class <code>Animal</code>, then <code>Dog</code> is-a* subtype of <code>Animal</code> by definition, and a <code>Dog</code> instance can be used wherever an <code>Animal</code> is expected (Protocols and structural subtyping - mypy 1.15.0 documentation). This is how traditional object-oriented languages like Java or C++ work, and it\u2019s also the primary mode in Python\u2019s type system by default.</p> <p>On the other hand, structural typing determines type compatibility by the actual structure or capabilities of the object, not its explicit inheritance. In a structural type system, if an object has all the required methods and attributes of a type, then it qualifies as that type, regardless of its class name or parent classes (Protocols and structural subtyping - mypy 1.15.0 documentation). In other words, if it \"walks like a duck and quacks like a duck, then it\u2019s treated as a duck\" \u2013 this is the essence of the famous duck typing principle. Duck typing is a runtime concept in Python: you invoke methods or attributes on an object, and as long as it supports those operations, things work (if a required method is missing, you get an <code>AttributeError</code> at runtime) (What's the Difference Between Nominal, Structural, and Duck Typing? - DEV Community) (Duck typing - Wikipedia). Structural typing can be seen as the static, compile-time equivalent of duck typing (Protocols and structural subtyping - mypy 1.15.0 documentation). Instead of waiting for a runtime error, a structural type system (with the help of a static type checker) can verify ahead of time* that an object has the necessary attributes to be used in a given context. This approach is more flexible than nominal typing because it doesn\u2019t require pre-planned inheritance relationships. It is also more explicit and safe than unguarded duck typing because the structure is checked (by a type checker) before the code runs.</p> <p>Python historically embraced duck typing at runtime \u2013 you just call methods on objects and trust they exist. Prior to Python 3.8, static type checking in Python (via tools like MyPy, PyRight, etc.) was largely nominal: you would use abstract base classes or concrete classes to hint the types, and an object\u2019s class had to match the annotation or inherit from a matching class. This could make it awkward to type-hint code that was written in a duck-typed style. For instance, if you had a function that worked with any object that had a <code>.read()</code> method, there wasn\u2019t a straightforward way to express that in a type hint without making all such objects share a common base class or using <code>typing.Any</code>. Python 3.8 remedied this by introducing protocols in the <code>typing</code> module (Python Protocols: Leveraging Structural Subtyping \u2013 Real Python). Protocols allow you to define a structural interface that other classes can fulfill just by having the right methods/attributes, without inheritance. This brings the flexibility of duck typing into the realm of static type checking \u2013 essentially formalizing \"If it quacks like a duck, it can be treated as a duck\" in the type system.</p> <p>In summary, nominal typing ties compatibility to declared relationships (e.g., subclassing an interface or abstract class), whereas structural typing ties compatibility to an object\u2019s actual shape (the presence of specific methods/attributes). Python\u2019s type system now supports both: use nominal typing for clarity and runtime consistency with class relationships, and use structural typing (via protocols) for flexibility and to more directly model Python\u2019s duck-typed nature (PEP 544 \u2013 Protocols: Structural subtyping (static duck typing) | peps.python.org).</p>"},{"location":"10_Structural_Typing/#defining-and-using-protocols","title":"Defining and Using Protocols","text":"<p>To leverage structural typing in Python\u2019s type hints, you define protocols. A protocol in Python is essentially an interface or template for a set of methods and attributes. It\u2019s defined by inheriting from <code>typing.Protocol</code> (available in the standard library <code>typing</code> module as of Python 3.8, or in <code>typing_extensions</code> for earlier versions). By creating a class that subclasses <code>Protocol</code>, you declare a group of methods and properties that form a \"protocol\" \u2013 any class that has those methods and properties (with compatible types) will be considered an implementation of that protocol by static type checkers, even if it doesn\u2019t formally inherit from the protocol.</p> <p>How to define a protocol: You simply create a class that inherits <code>Protocol</code> and define the method signatures (and any attribute types) that are required. Protocol methods typically have empty bodies (often using <code>...</code> or <code>pass</code>) because you\u2019re not providing an implementation, just a definition of the interface. For example, suppose we want a protocol for \"speaking\" creatures or objects: it should have a method <code>speak()</code> that returns a string. We can define:</p> <pre><code># speaker.py\nfrom typing import Protocol\n\n\nclass Speaker(Protocol):\n    def speak(self) -&gt; str: ...\n</code></pre> <p>Here, <code>Speaker</code> is a protocol that any \"speaker\" object should follow. Now, any class that defines a <code>speak(self) -&gt; str</code> method will be considered a <code>Speaker</code> for typing purposes. We can create two completely unrelated classes that fulfill this protocol without explicit inheritance:</p> <pre><code># announce.py\nfrom speaker import Speaker\n\n\nclass Dog:\n    def speak(self) -&gt; str:\n        return \"woof\"\n\n\nclass Robot:\n    def speak(self) -&gt; str:\n        return \"beep-boop\"\n\n\ndef announce(speaker: Speaker) -&gt; None:\n    # `speaker` can be any object that has .speak() returning str\n    print(\"Announcement:\", speaker.speak())\n\n\nannounce(Dog())  # OK, Dog has speak()\nannounce(Robot())  # OK, Robot has speak()\n</code></pre> <p>Even though <code>Dog</code> and <code>Robot</code> do not inherit from <code>Speaker</code> (and are not related to each other at all), the static type checker will accept them as valid arguments to <code>announce</code> because they structurally conform to the <code>Speaker</code> protocol by implementing the required method. This is the power of structural typing. In fact, the type checker treats <code>Dog</code> and <code>Robot</code> as subtypes of <code>Speaker</code> because they have the right <code>speak()</code> method signature (Protocols and structural subtyping - mypy 1.15.0 documentation). If we tried to pass an object that lacks a <code>speak()</code> method (or has an incompatible signature), the type checker would flag an error, ensuring type safety.</p> <p>It\u2019s important to note that protocols are primarily a static concept \u2013 they are enforced by type checkers, not by the Python runtime (by default). Unlike an abstract base class (ABC), a protocol doesn\u2019t actually require classes to formally subclass it, and Python won\u2019t automatically error at runtime if a required method is missing. For example, in the code above, if we call <code>announce(Dog())</code> and <code>Dog.speak</code> is missing or misnamed, we would only find out at runtime via an <code>AttributeError</code>. The protocol helps catch such issues before runtime by using tools like Mypy. The protocols defined in <code>typing</code> are optional and have no runtime effect on their own (PEP 544 \u2013 Protocols: Structural subtyping (static duck typing) | peps.python.org). This means you can use them freely for type hints without incurring runtime overhead or restrictions. Protocols do inherit from <code>abc.ABC</code> under the hood, but by default <code>isinstance()</code> and <code>issubclass()</code> checks against a protocol will not work without an explicit opt-in, as we\u2019ll discuss shortly.)</p> <p>Using a protocol in type hints: Once you have a protocol class, you use it as a type in annotations just like you would use an ABC or a concrete class. In the above example, the function <code>announce</code> was annotated to accept a <code>Speaker</code>. That tells readers and type checkers that any argument should \"speak\". This is more expressive than using a base class like <code>Animal</code> or a union of types \u2013 we directly specify the capability we need. Another example: Python\u2019s standard library defines an <code>Iterable[T]</code> protocol (in <code>collections.abc</code> or <code>typing</code>) that essentially says the object has an <code>__iter__</code> method returning an iterator. If you annotate a function parameter as <code>Iterable[str]</code>, any object that can be iterated over to yield strings will be accepted \u2013 whether it\u2019s a list, a tuple, a custom container class with an <code>__iter__</code>, etc. The type checker doesn\u2019t require them to inherit from <code>Iterable</code>; having the method is enough (Protocols and structural subtyping - mypy 1.15.0 documentation). This demonstrates that many idiomatic Python \"protocols\" (iteration, context managers, etc.) are recognized structurally. Python\u2019s typing module and static checkers come with several predefined protocols (either explicitly as in <code>typing.Protocol</code> classes or implicitly via ABCs with structural hooks) for common patterns.</p> <p>Let\u2019s look at a slightly more elaborate example of defining and using a protocol. Imagine we have objects that need to support a <code>close()</code> method (like files or network connections). We can define a protocol <code>Closable</code> and use it to write a function that closes a batch of resources:</p> <pre><code># example_3.py\nfrom typing import Protocol, Iterable\n\n\nclass Closable(Protocol):\n    def close(self) -&gt; None: ...\n\n\nclass FileResource:\n    def __init__(self, path: str):\n        self.file = open(path, \"w\")\n\n    def close(self) -&gt; None:\n        self.file.close()\n\n\nclass SocketResource:\n    def close(self) -&gt; None:\n        print(\"Socket closed\")\n\n\ndef close_all(resources: Iterable[Closable]) -&gt; None:\n    for res in resources:\n        res.close()\n\n\n# Using the close_all function with different resource types\nclosables = [FileResource(\"data.txt\"), SocketResource(), open(\"other.txt\", \"w\")]\nclose_all(\n    closables\n)  # OK: FileResource, SocketResource, and file objects all have close()\n## Socket closed\n</code></pre> <p>In this code, <code>Closable</code> is a protocol requiring a <code>.close()</code> method. We created a <code>FileResource</code> class and a <code>SocketResource</code> class that both implement <code>close()</code>. We also use a built-in file object from <code>open()</code>, which we know has a <code>close()</code> method. The <code>close_all</code> function is annotated to accept any iterable of <code>Closable</code> objects. Thanks to structural typing, it doesn\u2019t matter that these objects are of different types and don\u2019t share a common ancestor named <code>Closable</code> \u2013 as long as each has a callable <code>close()</code> method, the static type checker will be satisfied and, at runtime, the code will work. In fact, Mypy considers the built-in file object and our custom classes all as subtypes of <code>Closable</code> because they provide the required attribute (Protocols and structural subtyping - mypy 1.15.0 documentation).</p> <p>One thing to be aware of: protocols by default cannot be used with <code>isinstance()</code> or <code>issubclass()</code> checks at runtime. If you try <code>isinstance(some_obj, Closable)</code> in the above example, Python will raise a <code>TypeError</code> unless you take additional steps. This is because the protocol is not a real base class of those objects (they never inherited from it). However, Python\u2019s <code>typing</code> module provides a decorator <code>@runtime_checkable</code> that you can apply to a protocol to make runtime <code>isinstance</code> checks possible on it. Marking a protocol with <code>@runtime_checkable</code> means it gets a special <code>__instancecheck__</code> that will return True if the object has the required attributes (much like ABCs in <code>collections.abc</code> do with their <code>__subclasshook__</code>). For example:</p> <pre><code># example_4.py\nfrom typing import runtime_checkable, Protocol\n\n\n@runtime_checkable\nclass Closable(Protocol):\n    def close(self) -&gt; None: ...\n\n\nisinstance(FileResource(\"data.txt\"), Closable)  # True, because FileResource has close()\n</code></pre> <p>Now <code>Closable</code> can be used in <code>isinstance</code> and <code>issubclass</code> as a structural check (Abstract Base Classes and Protocols: What Are They? When To Use Them?? Lets Find Out! - Justin A. Ellis). Use this feature carefully \u2013 it\u2019s useful for type introspection in frameworks or for asserting an object meets an interface at runtime, but it only checks the presence of attributes and not their types, and could give false positives if an attribute name matches but semantics differ. In most cases, protocols are used purely for static checking and documentation.</p>"},{"location":"10_Structural_Typing/#practical-protocol-examples","title":"Practical Protocol Examples","text":"<p>Protocols shine in real-world scenarios where you want to decouple code and reduce dependencies on concrete classes. A common use case is dependency injection and testing. In Python, it\u2019s common to write functions or classes that operate on objects with a particular interface, without caring about the concrete implementation. Protocols let you formally capture that interface in the type system. This makes your code\u2019s expectations clear and allows static analysis to ensure you didn\u2019t violate those expectations. Let\u2019s discuss a few practical examples.</p> <p>1. Dependency injection and interchangeable components: Suppose you\u2019re writing a service that needs to log messages. You might want the ability to swap out the logger \u2013 sometimes logging to a file, sometimes to the console, or maybe collecting logs in memory for testing. You can define a protocol for the logger\u2019s interface and program against that. For instance:</p> <pre><code># example_5.py\nfrom typing import Protocol\n\n\nclass Logger(Protocol):\n    def log(self, message: str) -&gt; None: ...\n\n\nclass FileLogger:\n    \"\"\"Concrete logger that writes to a file.\"\"\"\n\n    def __init__(self, filename: str):\n        self.filename = filename\n\n    def log(self, message: str) -&gt; None:\n        with open(self.filename, \"a\") as f:\n            f.write(message + \"\\n\")\n\n\nclass ListLogger:\n    \"\"\"Concrete logger that stores messages in a list (e.g., for testing).\"\"\"\n\n    def __init__(self):\n        self.messages: list[str] = []\n\n    def log(self, message: str) -&gt; None:\n        self.messages.append(message)\n\n\ndef run_process(task_name: str, logger: Logger) -&gt; None:\n    logger.log(f\"Starting {task_name}\")\n    # Perform the task ...\n    logger.log(f\"Finished {task_name}\")\n\n\n# Using the run_process with different loggers\nrun_process(\"DataCleanup\", FileLogger(\"app.log\"))  # logs to file\ntest_logger = ListLogger()\nrun_process(\"DataCleanup\", test_logger)  # logs to list in memory\nprint(\"Captured logs:\", test_logger.messages)\n## Captured logs: ['Starting DataCleanup',\n## 'Finished DataCleanup']\n</code></pre> <p>In <code>Logger(Protocol)</code>, we specify that a logger must have a <code>.log(str)</code> method. Our <code>run_process</code> function doesn\u2019t care how the logging is done, just that the object passed in can <code>.log</code> a message. FileLogger<code>and</code>ListLogger<code>are two implementations \u2013 one writes to a file, the other stores messages in a Python list. Notice that neither</code>FileLogger<code>nor</code>ListLogger<code>subclasses</code>Logger<code>; they don\u2019t need to. They implicitly satisfy the protocol by having the correct</code>log<code>method. This design is very flexible: you can add new logger classes later (say, a</code>DatabaseLogger<code>that writes to a database, or reuse Python\u2019s built-in</code>logging.Logger<code>by writing an adapter that has a</code>log<code>method) without changing the code that uses the logger. During testing, as shown, we can use</code>ListLogger<code>to capture logs and make assertions on them. The static type checker will ensure that any object we pass as a</code>logger<code>to</code>run_process<code>has a</code>log(str)<code>method. In a nominal type system, you might have to define an abstract base class</code>Logger` and make every logger inherit it. With protocols, you get the benefit of an interface without the inheritance \u2013 this reduces coupling and makes it easier to integrate third-party classes that weren\u2019t written with your ABC in mind (Python Protocols: Leveraging Structural Subtyping \u2013 Real Python) (Abstract Base Classes and Protocols: What Are They? When To Use Them?? Lets Find Out! - Justin A. Ellis).</p> <p>2. Testing with fake or mock objects: Building on the above example, protocols are extremely handy for unit testing. In tests, we often use fake objects or mocks to simulate real components (like databases, web services, etc.) without having to perform the real operations. With protocols, you can give those test doubles a clear interface. For example, if you have a function that fetches data from an API, you could define a protocol for the fetcher. In production you pass a real HTTP client, in tests you pass a dummy object that returns predetermined data. The protocol assures the dummy has the same method signature as the real client. This avoids type checker warnings and makes tests cleaner. It\u2019s essentially the static typing analog of using an interface in other languages for dependency injection in tests.) Many testing libraries (like <code>unittest.mock</code>) create dynamic mocks that can be configured with attributes on the fly; to type-annotate those, you can either cast them to a Protocol or use a Protocol as a base for a dummy implementation. Using protocols in this way documents exactly what methods a mock is expected to provide. This can prevent situations where your test double is missing a method or has a typo that wouldn\u2019t be caught until runtime. In short, whenever you say \"I need an object that can do X in my code, and I might swap different implementations of it,\" that\u2019s a cue to define a protocol for X.</p> <p>3.Interface design and third-party integration: Protocols can serve as interfaces in your application design. Even if you\u2019re not writing multiple implementations immediately, defining a protocol for a role in your system can clarify the design. For example, you might define a <code>DataStore</code> protocol with methods like <code>save(item)</code> and <code>load(id)</code> that any storage backend should implement. Today you only have a database implementation, but tomorrow you might add an in-memory or file-based implementation \u2013 the protocol makes the contract clear. Moreover, if you want to accept objects from a third-party library that already have the necessary methods, protocols let you do so without subclassing or modifying those classes (Abstract Base Classes and Protocols: What Are They? When To Use Them?? Lets Find Out! - Justin A. Ellis). Suppose you\u2019re writing a function that can output data to any \"file-like\" object (something with a <code>.write()</code> method). The <code>io.TextIOBase</code> abstract class in Python is nominal, but not every file-like object will inherit it. By defining your own protocol with a <code>write(str)</code> method, your function can accept a wide range of objects (actual file handles, <code>io.StringIO</code> instances, custom writer objects) as long as they implement <code>write</code>. This is especially useful when working with libraries that weren\u2019t built with your interfaces; you can adapt them via protocols instead of being forced into their class hierarchy. Protocols thus increase reusability and extensibility of your code by focusing on what an object can do rather than what it is.</p> <p>It\u2019s worth mentioning that Python\u2019s standard library and frameworks have embraced the concept of protocols (even before the formal <code>Protocol</code> type existed) by using \"duck typing\" and abstract base classes. For instance, the act of iterating in Python checks for an <code>__iter__</code> method \u2013 any object that has <code>__iter__</code> is iterable. The static typing system knows this too: you don\u2019t have to explicitly register your class as an <code>Iterable</code> ABC; if it has the right method, tools like Mypy will treat it as iterable (Protocols and structural subtyping - mypy 1.15.0 documentation). With <code>Protocol</code>, we can create our own such abstractions. In modern Python, the combination of protocols and <code>@runtime_checkable</code> even lets us approximate some features of a language with a built-in interface system.</p> <p>4. Composition and adapters using protocols: Another practical pattern is using protocols to enable composition and decorators. Because protocols don\u2019t require inheritance, you can make wrapper classes that add functionality while still conforming to an interface. For example, you might have a basic service class and then a logging wrapper class that takes a service and also implements the same service protocol to proxy calls and add logging. As long as both implement the protocol, code using the protocol can accept either the plain or the wrapped version. This was illustrated by defining an <code>AddServiceProtocol</code> for an addition service and creating both a normal implementation and a logging decorator implementation that forwards calls (Protocols and Composition in Python - DEV Community). The key takeaway is that structural typing focuses on the behavior, so even objects that don\u2019t share a lineage can work together if they fulfill the same behavioral contract.</p>"},{"location":"10_Structural_Typing/#combining-dataclasses-with-protocols","title":"Combining Dataclasses with Protocols","text":"<pre><code># dataclasses_and_protocols.py\nfrom dataclasses import dataclass\nfrom typing import Protocol\n\n\nclass Identifiable(Protocol):\n    id: int\n\n\n@dataclass\nclass User:\n    id: int\n    name: str\n\n\n@dataclass\nclass Product:\n    id: int\n    price: float\n\n\ndef print_id(entity: Identifiable) -&gt; None:\n    print(f\"ID: {entity.id}\")\n\n\nprint_id(User(1, \"Alice\"))\n## ID: 1\nprint_id(Product(101, 19.99))\n## ID: 101\n</code></pre>"},{"location":"10_Structural_Typing/#combining-protocols-with-generics","title":"Combining Protocols with Generics","text":"<p>Just like classes and functions can be generic (using <code>TypeVar</code> to operate over a range of types), protocol classes can be generic as well. A generic protocol allows you to define a protocol that is parameterized by a type (or multiple types), enabling more precise typing of method arguments and return values. Many built-in protocols are generic \u2013 for example, <code>Iterable[T]</code> is a protocol that can be <code>Iterable[int]</code>, <code>Iterable[str]</code>, etc., depending on what type it yields. We can do the same with our own protocols.</p> <p>To define a generic protocol, we use <code>TypeVar</code> and put the type variable in brackets after <code>Protocol</code> when defining the class (Python Protocols: Leveraging Structural Subtyping \u2013 Real Python). Let\u2019s say we want to define a simple container protocol that yields items of some type. We can make it generic so that a <code>Container[int]</code> will be a protocol for \"container of ints\" and <code>Container[str]</code> for \"container of strings,\" but both are based on the same generic interface. For example:</p> <pre><code># example_6.py\nfrom typing import Protocol, TypeVar\n\nT = TypeVar(\"T\")\n\n\nclass Container(Protocol[T]):\n    def get_item(self) -&gt; T: ...\n</code></pre> <p>Here, <code>Container[T]</code> is a generic protocol with a single type variable <code>T</code>. It specifies one method <code>get_item</code> that returns an object of type <code>T</code>. Now we can implement this protocol for different types by providing concrete type parameters. For instance, a container of strings and a container of integers:</p> <pre><code># example_7.py\nclass StringContainer:\n    def __init__(self, value: str):\n        self.value = value\n\n    def get_item(self) -&gt; str:\n        return self.value\n\n\nclass IntContainer:\n    def __init__(self, value: int):\n        self.value = value\n\n    def get_item(self) -&gt; int:\n        return self.value\n</code></pre> <p><code>StringContainer</code> and <code>IntContainer</code> each implement <code>get_item</code> returning the appropriate type. They don\u2019t subclass <code>Container</code>, but structurally they match <code>Container[str]</code> and <code>Container[int]</code> respectively. We can write functions that use the generic protocol to accept any kind of container and preserve the type information of the contained item:</p> <pre><code># example_8.py\nfrom typing import Container\n\n\ndef print_item_and_return[C](container: Container[C]) -&gt; C:\n    item = container.get_item()\n    print(\"Got:\", item)\n    return item  # The type of item is inferred as C\n\n\n# Using the generic function with different container types:\nx = print_item_and_return(StringContainer(\"hello\"))  # prints \"hello\", x is str\ny = print_item_and_return(IntContainer(42))  # prints \"42\", y is int\n</code></pre> <p>In the function <code>print_item_and_return</code>, we used <code>C</code> (could also use <code>T</code> again) as a type variable for the container\u2019s item type. When we call this function with a <code>StringContainer</code>, the type checker knows <code>C</code> is <code>str</code> in that call, so it infers that the function returns a <code>str</code>. Similarly, with <code>IntContainer</code>, <code>C</code> becomes <code>int</code>. This is the benefit of generic protocols: they let you write flexible code that is still type-safe and retains specific type information. In other words, one protocol can work for many types without losing the ability to distinguish those types when it matters. The syntax we used (<code>Container[C]</code> inside the function annotation) leverages Python\u2019s ability to support generics in type hints. Under the hood, <code>Container[int]</code> is a parameterized protocol instance, but conceptually you can think of it like an interface template.)</p> <p>Keep in mind that user-defined generic protocols follow the same rules as normal generic classes for type checking (PEP 544 \u2013 Protocols: Structural subtyping (static duck typing) | peps.python.org). You can declare variance for type variables if needed (covariant, contravariant) using <code>typing.Final</code> or by special syntax in <code>TypeVar</code>, although if you don\u2019t declare, the type checker will assume invariance (meaning <code>Container[SubClass]</code> is not a subtype of <code>Container[BaseClass]</code> unless you marked variance). In our container example, this is not an issue because we\u2019re primarily using it to carry the exact type.</p> <p>Another scenario for combining protocols with generics is when you want to put protocols as bounds on <code>TypeVar</code>s. For instance, you can declare <code>T = TypeVar('T', bound=SomeProtocol)</code> to indicate that a type variable must satisfy a certain protocol. This is analogous to saying \"T must be a subtype of this Protocol,\" except since protocols aren\u2019t part of the class hierarchy, it really means any type used for T must structurally implement the protocol. For example, if we have:</p> <pre><code># example_9.py\nfrom typing import TypeVar\n\nT = TypeVar(\"T\", bound=Logger)  # using our Logger protocol from earlier\n</code></pre> <p>This means any type filling in for T must have a <code>.log(str) -&gt; None</code> method. You could use such a bound in a generic function or class to ensure the operations you perform on T (like calling <code>log</code>) are valid. This is a powerful way to write generic algorithms that operate on any objects meeting a certain interface, without tying them to a base class.</p> <p>It\u2019s also worth noting that Python 3.12 introduced an even more concise way to define generic protocols (and generic classes in general) by allowing type variables in the definition of methods directly (PEP 695 \u2013 Type Parameter Syntax). For instance, one could write something like:</p> <pre><code># example_10.py\nfrom typing import Protocol\n\n\nclass Container(Protocol):\n    def get_item[T](self) -&gt; T: ...\n</code></pre> <p>to define a generic method <code>get_item</code> in a protocol. However, under the hood this still creates a generic protocol with a type variable <code>T</code>. Most code at the time of writing still uses the earlier syntax with explicit <code>TypeVar</code> declarations, which is what we\u2019ve shown above.</p> <p>In summary, combining protocols with generics lets you express very flexible and reusable type relationships. You can create protocols that work over a family of types while still preserving type information. Many of Python\u2019s built-in protocols are generic (for example, an iterator protocol <code>Iterator[T]</code> yields items of type T), and you can do the same in your own designs (Python Protocols: Leveraging Structural Subtyping \u2013 Real Python) (Python Protocols: Leveraging Structural Subtyping \u2013 Real Python). This enables things like container types, numeric operations, or callback interfaces to be both generic and structural. When designing a generic protocol, think about what parts of the interface should change with the type (those become type variables) and which are fixed. The result is a very powerful abstraction that remains easy to use.</p>"},{"location":"10_Structural_Typing/#when-to-choose-structural-typing-over-nominal-typing","title":"When to Choose Structural Typing Over Nominal Typing","text":"<p>Now that we\u2019ve explored what structural typing (via protocols) and nominal typing (via concrete classes or ABCs) offer, a natural question arises: When should you use one over the other? The answer often depends on the context and goals. Both approaches have their strengths, and in Python they complement each other rather than one completely replacing the other (PEP 544 \u2013 Protocols: Structural subtyping (static duck typing) | peps.python.org). Here are some guidelines, pros and cons, and best practices to help decide:</p> <p>Use nominal typing (classes/ABCs) when:</p> <ul> <li> <p>You want to reuse code via inheritance. If you have default method implementations or shared attributes that can be defined in a base class, an abstract base class can provide that. Inheritance isn\u2019t the only way to reuse code, but when it makes sense (e.g. a base class providing common functionality), nominal typing naturally goes along with it because subclasses inherit from the base.</p> </li> <li> <p>You need a strict class hierarchy or runtime type information. If it\u2019s important in your design to maintain actual subclass relationships (perhaps for identity checks, <code>isinstance</code> checks, or because you rely on Python\u2019s method resolution order and <code>super()</code> calls), then using nominal types is appropriate. For example, if you have a plugin system where all plugins must register as subclasses of <code>BasePlugin</code> to be discovered, that\u2019s a nominal approach.</p> </li> <li> <p>The interface is large or complex, with many methods, and tightly coupled to an implementation. While you could model this with a protocol, it may be clearer to use an abstract class to group behavior. If multiple methods are meant to be overridden together, an ABC can enforce that at instantiation time (trying to instantiate a subclass that hasn\u2019t implemented all abstract methods raises an error). In short, for class designs that naturally form an \"is-a\" hierarchy and possibly share some code, nominal typing fits well.</p> </li> </ul> <p>Use structural typing (protocols) when:</p> <ul> <li> <p>You want to keep it lightweight and focused purely on the method/attribute requirements. Protocols are great for defining a narrow interface that multiple disparate classes can implement without formal coupling. If you only care about one or a few methods on an object (and not about its exact type), a protocol lets you specify just that. This is especially useful for function parameters: you can annotate a function to accept any object that has a <code>.close()</code> method, or a <code>.write()</code> method, etc., without forcing a common base class (Abstract Base Classes and Protocols: What Are They? When To Use Them?? Lets Find Out! - Justin A. Ellis).</p> </li> <li> <p>You are working with third-party or existing classes that you can\u2019t modify to fit into your class hierarchy. Structural typing shines here because you can define a protocol that matches the external class\u2019s capabilities. For example, if a 3rd-party library gives you objects that have a <code>.to_json()</code> method, and you want to treat those objects uniformly in your code, you can create a <code>ToJsonable</code> protocol with <code>to_json(self) -&gt; str</code> and use that in your type hints. Any object from the library will satisfy the protocol if it has the method, without you needing to make it inherit from anything (Abstract Base Classes and Protocols: What Are They? When To Use Them?? Lets Find Out! - Justin A. Ellis). This decoupling is very powerful in a language as dynamic as Python, where often we \"duck type\" through frameworks \u2013 now you can put an actual type hint on it.</p> </li> <li> <p>You need generic interfaces or extension of existing ones. Protocols are useful for creating ad-hoc interfaces that might not have been foreseen initially. For instance, you might realize that two classes in different parts of your system happen to have similar methods for, say, resetting their state. You could retroactively define a <code>Resettable</code> protocol and update type hints to use it, without touching the classes themselves. If later you make those classes formally implement an ABC, fine \u2013 but the protocol gave you an immediate way to express the concept in types and check it. Additionally, if you\u2019re designing a library and want to allow users to plug in their own objects (as long as they have certain methods), providing a protocol in your public API documentation is a nice way to communicate that. Users can either implement that Protocol (statically) or just ensure their classes match the signature.</p> </li> </ul> <p>Pros and Cons Summary: Nominal typing (using concrete classes and ABCs) offers clarity in terms of design \u2013 it\u2019s very clear that ClassX is a kind of InterfaceY because it explicitly inherits it. It also allows enforcement: abstract base classes can ensure at runtime that certain methods are implemented (attempting to instantiate a subclass that hasn\u2019t implemented an abstract method will error out). They can also provide default behavior. However, nominal typing is less flexible \u2013 everything must be planned or adapted to fit the hierarchy. If you want an external class to be treated as an InterfaceY, you might have to write an adapter or subclass it, which could be clunky or impossible (if you don\u2019t control that class). Structural typing (using protocols) is extremely flexible and mirrors Python\u2019s dynamic nature \u2013 you get to \"write the interface after the fact.\" It encourages designing for capabilities rather than inheritance. The downside is that protocols are primarily static \u2013 they rely on the developer running a type checker. Python won\u2019t stop you from passing an object that doesn\u2019t fulfill the protocol (until you call a missing method and get an error at runtime, just like normal duck typing). So if you need guaranteed enforcement in a running program, protocols alone won\u2019t give you that (they are optional). That said, in a team or project using type checks as part of CI, protocols can prevent a lot of mistakes. Another minor con is that protocols, if overused, could make it less obvious which classes actually implement which interface; with nominal typing you can always search for subclasses of an ABC. In practice, a mix is often best: use protocols for the broad \"this is what we expect\" contracts especially for external boundaries and flexible APIs, and use concrete classes or ABCs internally when you want more structure or reuse.</p> <p>Best practices: It\u2019s not an either/or choice \u2013 you can use both in the same codebase. For example, you might define an ABC with some default methods for a complex interface, but also define a protocol for a subset of that interface for use in a more generic function. Choose structural typing when you want minimal coupling and maximum flexibility, especially at boundaries of your system or for \"pluggable\" functionality. Choose nominal typing when you want an explicit, enforced contract and possibly to leverage inheritance of code. Remember that protocols are most valuable when you are using static type checking; if your project doesn\u2019t use type checks, then a protocol is simply a <code>abc.ABC</code> with no abstract methods \u2013 it won\u2019t enforce anything by itself at runtime. In such cases, if enforcement is needed, an ABC with abstract methods (or even just documentation) might be better. However, even in purely dynamic contexts, many developers find protocols useful as documentation: by reading the Protocol class, you know what an object is expected to do.</p> <p>In Python\u2019s type system evolution, protocols were introduced to complement nominal typing, not to replace it (PEP 544 \u2013 Protocols: Structural subtyping (static duck typing) | peps.python.org). They give you the freedom to write code in the Pythonic duck-typed style while still reaping the benefits of static analysis. A good guideline is to use protocols to describe roles that can be played by objects of different class hierarchies, and use nominal typing for relationships within a class hierarchy. By following these practices, you can make your code both flexible and robust, leveraging the best of both worlds in Python\u2019s type system.</p>"},{"location":"11_Make_Illegal_Types_Unrepresentable/","title":"Make Illegal Types Unrepresentable","text":"<p>A common strategy for preventing problems is to check values after arguments are passed to functions. This spreads validation code across functions, producing maintenance problems. This chapter moves validation into custom types that make invalid data impossible. In addition, data is checked when you create an instance, rather than when data is passed to a function. With this approach, you:</p> <ol> <li>Discover problems sooner.</li> <li>Clarify the meaning of your code.</li> <li>Share custom type benefits across all functions that use those types.</li> <li>Eliminate duplicate validation checks and their associated maintenance.</li> <li>Make changes easier by localizing validation to a single point.</li> <li>Eliminate the need for techniques such as Design By Contract (DBC).</li> <li>Enable more focused testing with finer granularity.</li> </ol>"},{"location":"11_Make_Illegal_Types_Unrepresentable/#stringly-typed","title":"\"Stringly Typed\"","text":"<p>Years ago I came across some research looking at the way generic components like <code>List</code>, <code>Set</code> and <code>Map</code> were being used in Java. Only a tiny percentage of the code reviewed used anything except strings as type parameters. This study suggested that the vast majority of systems were using strings as their primary data type.</p> <p>Because you can put any characters in any format into a string, such \"stringly typed\" systems (an ironic play on \"strongly typed\") may be the worst of all possible worlds. Unless it's actually text, classifying something as a string says virtually nothing about it. When a function receives a string that is meant to represent a type, that function can assume precisely nothing about it. Every such function must start from scratch and analyze that string to see if it conforms to what that function needs.</p> <p>If you ever change the meaning of that stringly-typed item, you have a daunting job ahead of you: to look through every function that uses it and ensure that your change is reflected in the validations in every single function.</p> <p>[[Stringly typed example, possibly telephone numbers]]</p>"},{"location":"11_Make_Illegal_Types_Unrepresentable/#design-by-contract","title":"Design by Contract","text":"<p>The argument-validation problem was observed by Bertrand Meyer and introduced as a core concept in his Eiffel programming language, described in the book Object-Oriented Software Construction (1988). Design By Contract (DbC) tried to reduce errors by treating the interaction between software components as a formal agreement:</p> <ul> <li>Preconditions: What must be true before a function/method runs.</li> <li>Postconditions: What must be true after the function completes.</li> <li>Invariants: What must always be true about the object state.</li> </ul> <p>Eiffel provided explicit keywords to make DbC a first-class citizen in the language:</p> Keyword Purpose <code>require</code> Preconditions <code>ensure</code> Postconditions <code>invariant</code> Class-wide conditions <code>old</code> Refers to previous state in postconditions <p>The idea was that each function you wrote would use these to ensure the correctness of the inputs and outputs of that function. In particular, <code>require</code> typically checks the argument values for correctness. For preconditions in Python, we can create a <code>requires</code> decorator to check argument values:</p> <pre><code># require.py\nfrom typing import Callable, NamedTuple\nfrom functools import wraps\n\n\nclass Condition(NamedTuple):\n    check: Callable[..., bool]\n    message: str\n\n\ndef requires(*conditions: Condition):\n    def decorator(func: Callable):\n        @wraps(func)\n        def wrapper(*args, **kwargs):\n            for condition in conditions:\n                if not condition.check(*args, **kwargs):\n                    # Do something like this:\n                    # raise ValueError(condition.message)\n                    # We'll just:\n                    print(condition.message)\n            return func(*args, **kwargs)\n        return wrapper\n    return decorator\n</code></pre> <p>Now we can apply <code>require</code> to validate function arguments:</p> <pre><code># bank_account.py\nfrom require import requires, Condition\n\nPOSITIVE_AMOUNT = Condition(\n    check=lambda self, amount: amount &gt; 0,\n    message=\"Amount must be positive\"\n)\n\nSUFFICIENT_BALANCE = Condition(\n    check=lambda self, amount: self.balance &gt;= amount,\n    message=\"Insufficient balance\"\n)\n\nclass BankAccount:\n    def __init__(self, balance: float):\n        self.balance = balance\n\n    @requires(POSITIVE_AMOUNT, SUFFICIENT_BALANCE)\n    def withdraw(self, amount: float) -&gt; None:\n        self.balance -= amount\n        print(f\"Withdrew {amount}, new balance: {self.balance}\")\n\n    @requires(POSITIVE_AMOUNT)\n    def deposit(self, amount: float) -&gt; None:\n        self.balance += amount\n        print(f\"Deposited {amount}, new balance: {self.balance}\") \n\naccount = BankAccount(100)\naccount.deposit(50)\naccount.withdraw(30)\naccount.withdraw(200)\naccount.deposit(-10) \n</code></pre> <p>This is an improvement over placing the testing code at the beginning of each function, as Eiffel does and as traditional Python functions do--assuming they test their arguments. The <code>@require</code> clearly shows that constraints have been placed on the arguments. <code>Condition</code> reduces duplicated code.</p> <p>DbC definitely helps, but it has limitations:</p> <ol> <li>A programmer can forget to use <code>requires</code>, or simply choose to perform argument checks by hand if DbC doesn't make sense to them.</li> <li>The tests are spread throughout your system. Using <code>Condition</code> centralizes the test logic but making changes still risks missing updates on functions.</li> </ol>"},{"location":"12_Errors_as_Values/","title":"Errors as Values","text":"<p>Most of what we've been working towards in programming\u2014whether we are aware of it or not\u2014is composability.</p> <p>Discovering the meaning of composability is part of this path\u2014there are different definitions depending on the programming language paradigm under scrutiny. Here\u2019s my definition:</p> <p>The ability to assemble bigger pieces from smaller pieces.</p> <p>This is less-precise than some definitions. For example, composition in object-oriented programming means \u201cputting objects inside other objects.\u201d When dealing with functions, composability means \u201ccalling functions within other functions.\u201d Both definitions fit my overall definition; they achieve the same goal but in different specific ways.</p> <p>To enable the easy construction of programs, we need to be able to effortlessly assemble components in the same way that a child assembles Legos\u2014by simply sticking them together, without requiring extra activities. On top of that, such assemblages become their own components that can be stuck together just as easily. This composability scales up regardless of the size of the components.</p> <p>Over the years we have encountered numerous roadblocks to this goal.</p>"},{"location":"12_Errors_as_Values/#goto-considered-harmful","title":"Goto Considered Harmful","text":"<p>Djikstra\u2019s 1968 note had quite an impact on the programming community, which at the time consisted largely of assembly-language programmers. For these, the goto statement was foundational, and denigrating it was a shock. Although he never explicitly mentioned functions in his note, the effect was to push programmers towards functions. The creator of Structured Concurrency provides a clear description of this.</p> <p>Rather than jumping about within a limited program, functions present the caller with a single entry and exit point. This dramatically improves composability because you can no longer leave a section of code at any point using a goto. Within a function scope you cannot know what\u2019s outside that scope, thus you can\u2019t jump somewhere because you don\u2019t know a destination to jump to.</p> <p>My programming training was primarily as a computer engineer and I spent the first few years of my career programming in assembly. Assembly supports subroutine calls and returns, but not the loading of arguments on the stack and passing results back out\u2014the programmer must write this error-prone code by hand.</p> <p>Higher-level languages handle function arguments and returns for you, which made them a very desirable improvement as the size and complexity of programs grew beyond what the assembly programmer was able to hold in their head.</p>"},{"location":"12_Errors_as_Values/#modules","title":"Modules","text":"<p>Tim Peters\u2019 observation of the value of namespaces (see The Zen of Python) is the core of the idea of modules, which more modern languages incorporate (unfortunately C++ had to inherit C\u2019s messy system, for backwards compatibility). In Python, files are automatically modules, which is certainly one of the easiest solutions.</p> <p>It wasn\u2019t always this way. Breaking assembly-language programs into pieces was not easy, and early higher-level languages tended to be single-file programs and did not consider modularity. When the idea began to surface it was incorporated as a main feature of the Modula-2 language (a descendent of Pascal). The name tells you what a significant shift it was considered at the time.</p> <p>Modula-2 and similar languages required an explicit declaration of a module:</p> <pre><code>MODULE Hello;\nFROM STextIO IMPORT WriteString;\nBEGIN\n  WriteString(\"Hello World!\")\nEND Hello.\n</code></pre> <p>This allowed complete granularity independent of file organization; perhaps this was because programmers were used to thinking in terms of one big file-per-program. Python\u2019s merging of modules with files makes more sense in hindsight and has the benefit of eliminating the (significant) extra verbiage, only a portion of which is shown here.</p> <p>The main benefit of modules is name control\u2014each module creates a scope for names (a namespace) which allows programmers the freedom to choose any name at will within a module. This prevents name collisions across a project and reduces the cognitive load on the programmer. Prior to this, programs reached scaling limits as they grew larger. Program size in assembly language programs was limited by many different factors, so the need for modules was not seen until systems were able to grow larger because higher-level languages solved enough of these other factors.</p> <p>In modern languages, modularity is part of the background of a language and we don\u2019t think much about it. At one time, however, the lack of modularity was a significant roadblock to code composability.</p>"},{"location":"12_Errors_as_Values/#inheritance","title":"Inheritance","text":"<p>Object-oriented programming has a bit of a tortured history. Although the first OO language was Simula-67 (a compiled language), OO found its first real success with Smalltalk. But Smalltalk might be the most dynamic language you\u2019ll ever encounter\u2014literally everything is evaluated at runtime. While this worked well for the kinds of problems Smalltalk was good at solving, it turned out that taking the ideas of Smalltalk and imprinting them into a statically-typed language lost a lot in translation.</p>"},{"location":"12_Errors_as_Values/#error-handling","title":"Error Handling","text":"<p>Error reporting and handling has been a significant impediment to composability.</p>"},{"location":"12_Errors_as_Values/#history","title":"History","text":"<p>Original programs were small (by present-day standards), written in assembly language (machine code quickly became too unwieldy), and tightly coupled to the underlying hardware. If something went wrong, the only way to report it was to change the output on a wire, to turn on a light or a buzzer. If you had one, you put a message on the console\u2014this might as simple as a dot-matrix display. Such an error message probably wasn\u2019t friendly to the end-user of the system and usually required a tech support call to the manufacturer.</p> <p>Two of my first jobs were building embedded systems that controlled hardware. These systems had to work right. There was no point in reporting most errors because  an error normally meant the software was broken.</p> <p>For business and scientific programming, Fortran and Cobol were batch processed on punch cards. If something went wrong, either the compilation failed or the resulting data was bad. No real-time error-handling was necessary because the program didn\u2019t run in real time.</p> <p>As time-sharing operating systems like Unix became a common way to distribute computing resources, program execution became more immediate. Users began to expect more interactive experiences, so programmers had to begin thinking about how to report and handle errors during the execution of a program, and in ideal cases recovering from those errors so the program could continue without shutting down.</p> <p>Programmers produced a scattered collection of solutions to the reporting problem:</p> <ul> <li> <p>Indicate failure by returning a special value from a function call. This only works when the special value doesn't occur from an ordinary call to that function. For example, if your function returns any <code>int</code>, you can't use <code>0</code> or <code>-1</code> to report an error. A bigger problem is that you rely on the client programmer to pay attention to the return value and know what to do about errors.</p> </li> <li> <p>Indicate failure by setting a global flag. This is a single flag shared by all functions in the program. The client programmer must know to watch that flag. If the flag isn't checked right away, it might get overwritten by a different function call in which case the error is lost.</p> </li> <li> <p>Use signals if the operating system supports it.</p> </li> </ul> <p>The operating system was something that needed to be discovered. As programmers found themselves rewriting the same basic code over and over again, and much of that repeated code involved manipulating hardware and the attendant specialized knowledge required, it became clear that we needed a layer to eliminate this extra work, work that to some degree every program required.</p> <p>A fundamental question that designers were trying to understand during this evolution was:</p> <p>Who is responsible for error handling, the OS or the language?</p> <p>Since every program has the potential for errors, it initially seemed obvious that this activity should be the domain of the operating system. Some early operating systems allowed the program to invoke an error which would then jump to the operating system, and a few OSes even experimented with the ability to \u201cresume\u201d back to the point where the error occurred, so the handler could fix the problem and continue processing. Notably, these systems did not find success and resumption was removed.</p> <p>Further experiments eventually made it clear that the language needed primary responsibility for error reporting and handling (there are a few special cases, such as out-of-memory errors, which must still be handled by the OS). This is because an OS is designed to be general-purpose, and thus cannot know the specific situation that caused an error, whereas language code can be close to the problem. Customization is normally the domain of the language. You could imagine calling the OS to install custom error-handling routines, and you can also imagine how quickly that would become overwhelmingly messy.</p> <p>If errors are in the language domain, the next question is how to report and handle them.</p>"},{"location":"12_Errors_as_Values/#exceptions","title":"Exceptions","text":"<p>Unifying error reporting and recovery</p> <p>There were different language implementations of exceptions:</p> <ul> <li>Lisp (was this the origin of language-based exceptions?). Possibly ironic as Lisp is the first functional language.</li> <li>BASIC had \u201cOn Error Go To\u201d (and \u201cresume\u201d?)</li> <li>Pascal</li> <li>C++</li> <li>Java created checked exceptions, which must be explicitly dealt with in your code, and runtime exceptions, which could be ignored.</li> <li>Python has exceptions but doesn\u2019t provide any type annotation or other mechanism to indicate what exceptions might emerge from a function call.</li> </ul> <p>Exceptions seemed like a great idea:</p> <ol> <li>A standardized way to correct problems so that an operation can recover and retry.</li> <li>There's only one way to report errors.</li> <li>Errors cannot be ignored\u2014they flow upward until caught or displayed on the console with program termination.</li> <li>Errors can be handled close to the origin, or generalized by catching them \"further out\" so that multiple error sources can be managed with a single handler.</li> <li>Exception hierarchies allow more general exception handlers to handle multiple exception subtypes.</li> </ol> <p>To be clear, exceptions were a big improvement over all of the previous (non) solutions to the error reporting problem. Exceptions moved us forward for awhile (and became entrenched in programming culture) until folks started discovering pain points. As is often the case, this happened as we tried to scale up to create larger and more complex systems. And once again, the underlying issue was composability.</p>"},{"location":"12_Errors_as_Values/#problems-with-exceptions","title":"Problems with Exceptions","text":"<p>In the small (and especially when teaching them), exceptions seem to work quite well. It's hard to prove during language design; things work in the small but don't scale. We only figure it out when scaling composability.</p>"},{"location":"12_Errors_as_Values/#1-the-two-kinds-of-errors-are-conflated","title":"1. The Two Kinds of Errors are Conflated","text":"<p>Recoverable vs panic (Recovering/Retrying requires programming) With exceptions, the two types are conflated. (Link to Error handling article)</p>"},{"location":"12_Errors_as_Values/#2-not-part-of-the-type-system","title":"2. Not Part of the Type System","text":"<p>If the type system doesn\u2019t include exceptions as part of a function signature, you can\u2019t know what exceptions you must handle when calling other functions (i.e.: composing). Even if you track down all the possible exceptions thrown explicitly in the code (by hunting for them in their source code!), built-in exceptions can still happen without evidence in the code: divide-by-zero is a great example of this.</p> <p>You can be using a library and handling all the exceptions from it (or perhaps just the ones you found in the documentation), and a newer version of that library can quietly add a new exception, and suddenly you are no longer detecting and/or handling all the exceptions. Even though you made no changes to your code.</p> <p>Languages like C++ and Java attempted to solve this problem by adding exception specifications, a notation that allows you to add the exception types that may be thrown, as part of the function\u2019s type signature.</p> <p>Object-oriented languages that enforce exception specifications (C++, Java) and create exception hierarchies introduce another problem. Exception hierarchies allow the library programmer to use an exception base type in the exception specification. This obscures important details; if the exception specification just uses a base type, there\u2019s no way for the compiler to enforce coverage of specific exceptions.</p> <p>When errors are included in the type system, you can know all the errors that can occur just by looking at the type information. If a library component adds a new error then that must be reflected in that component\u2019s type signature, which means that the code using it immediately knows that it is no longer covering all the error conditions, and will produce type errors until it is fixed.</p>"},{"location":"12_Errors_as_Values/#3-exception-specifications-create-a-shadow-type-system","title":"3. Exception Specifications Create a \u201cShadow Type System\u201d","text":"<p>Languages like C++ and Java attempted to add notation indicating the exceptions that might emerge from a function call. This was well-intentioned and seems to produce the necessary information the client programmer needs to handle errors. The fundamental problem was that this created an alternate or \u201cshadow\u201d type system that doesn\u2019t follow the same rules as the primary type system. To make the shadow type system work, its rules were warped to the point where it became effectively useless (a discovery that has taken years to realize).</p> <p>C++ exception specifications were originally optional and not statically type-checked. After many years these were deprecated in favor of the statically-typed <code>expected</code> specification (which takes the functional approached described in this paper).</p> <p>Java created checked exceptions, which must be explicitly dealt with in your code, and runtime exceptions, which could be ignored. Eventually they added a feature that allows checked exceptions to be easily converted into runtime exceptions. Java functions can always return <code>null</code> without any warning.</p> <p>Both systems (the original C++ dynamic exception specifications, and Java exception specifications) had too many holes, and it was too difficult to effectively support both the main and shadow type systems.</p>"},{"location":"12_Errors_as_Values/#4-exceptions-destroy-partial-calculations","title":"4. Exceptions Destroy Partial Calculations","text":"<p>Let\u2019s start with a simple example where we populate a <code>List</code> with the results of a sequence of calls to the function <code>func_a</code>:</p> <pre><code># discarded_state.py\n# Exception throws everything away\n\n\ndef func_a(i: int) -&gt; int:\n    if i == 1:\n        raise ValueError(f\"func_a({i})\")\n    return i\n\n\nresult = [func_a(i) for i in range(3)]\nprint(result)\n\"\"\"\nTraceback (most recent call last):\n  ...\nValueError: func_a(1)\n\"\"\"\n</code></pre> <p><code>func_a</code> throws a <code>ValueError</code> if its argument is <code>1</code>. The <code>range(3)</code> is 0, 1, and 2; only one of these values causes the exception. So <code>result</code> contains only one problem; the other two values are fine. However, we lose everything that we were calculating when the exception is thrown. This:</p> <ol> <li>Is computationally wasteful, especially with large calculations.</li> <li>Makes debugging harder. It would be quite valuable to see in <code>result</code> the parts that succeeded and those that failed.</li> </ol>"},{"location":"12_Errors_as_Values/#the-functional-solution","title":"The Functional Solution","text":"<p>Instead of creating a complex implementation to report and handle errors, the functional approach creates a \u201creturn package\u201d containing the answer along with the (potential) error information. Instead of only returning the answer, we return this package from the function.</p> <p>This package is a new type, with operations that prevent the programmer from simply plucking the result from the package without dealing with error conditions (a failing of the Go language approach).</p> <p>A first attempt uses type unions to create a nameless return package:</p> <pre><code># return_union.py\n# Type union aka Sum Type\n# Success vs error is not clear\n\n\ndef func_a(i: int) -&gt; int | str:  # Sum type\n    if i == 1:\n        return f\"func_a({i})\"\n    return i\n\n\nprint(outputs := [(i, func_a(i)) for i in range(5)])\n\nfor i, r in outputs:\n    match r:\n        case int(answer):\n            print(f\"{i}: {answer = }\")\n        case str(error):\n            print(f\"{i}: {error = }\")\n</code></pre> <p><code>func_a</code> returns a <code>str</code> to indicate an error, and an <code>int</code> answer if there is no error. In the pattern match, we are forced to check the result type to determine whether an error occurs; we cannot just assume it is an <code>int</code>.</p> <p>An important problem with this approach is that it is not clear which type is the success value and which type represents the error condition\u2014because we are trying to repurpose existing built-in types to represent new meanings.</p> <p>In hindsight, it might seem like this \u201creturn package\u201d approach is much more obvious than the elaborate exception-handling scheme that was adopted for C++, Java and other languages, but at the time the apparent overhead of returning extra bytes seemed unacceptable (I don\u2019t know of any comparisons between that and the overhead of exception-handling mechanisms, but I do know that the goal of C++ exception handling is to have zero execution overhead if no exceptions occur).</p> <p>Note that in the definition of <code>composed</code>, the type checker requires that you return <code>int | str</code> because <code>func_a</code> returns those types. Thus, when composing, type-safety is preserved. This means you won\u2019t lose error type information during composition, so composability automatically scales.</p>"},{"location":"12_Errors_as_Values/#creating-a-new-return-type","title":"Creating a New Return Type","text":"<p>We now have the unfortunate situation that <code>outputs</code> contains multiple types: both <code>int</code> and <code>str</code>. The solution is to create a new type that unifies the \u201canswer\u201d and \u201cerror\u201d types. We\u2019ll call this <code>Result</code> and define it using generics to make it universally applicable:</p> <pre><code># result.py\n# Generic Result with Success &amp; Failure subtypes\nfrom dataclasses import dataclass\nfrom typing import Generic, TypeVar, NamedTuple\n\nANSWER = TypeVar(\"ANSWER\")  # Generic parameters\nERROR = TypeVar(\"ERROR\")\n\n\nclass Result(Generic[ANSWER, ERROR]):\n    pass\n\n\nclass Success(NamedTuple, Result[ANSWER, ERROR]):\n    answer: ANSWER  # Usage: return Success(answer)\n\n    def unwrap(self) -&gt; ANSWER:\n        return self.answer\n\n\nclass Failure(NamedTuple, Result[ANSWER, ERROR]):\n    error: ERROR  # Usage: return Failure(error)\n</code></pre> <p>A <code>TypeVar</code> defines a generic parameter. We want <code>Result</code> to contain a type for an <code>ANSWER</code> when the function call is successful, and an <code>ERROR</code> to indicate how the function call failed. Each subtype of <code>Result</code> only holds one field: <code>answer</code> for a successful <code>Success</code> calculation, and <code>error</code> for a <code>Failure</code>. Thus, if a <code>Failure</code> is returned, the client programmer cannot simply reach in and grab the <code>answer</code> field because it doesn\u2019t exist. The client programmer is forced to properly analyze the <code>Result</code>.</p> <p>We could use a frozen <code>dataclass</code> instead of a <code>NamedTuple</code> here, but the latter is more concise.</p> <p>To use <code>Result</code>, you <code>return Success(answer)</code> when you\u2019ve successfully created an answer, and <code>return Failure(error)</code> to indicate a failure. <code>unwrap</code> is a convenience method which is only available for a <code>Success</code>.</p> <p>The modified version of the example using <code>Result</code> is now:</p> <pre><code># return_result.py\n# Result type returns Success/Failure\n# Using https://github.com/dry-python/returns\nfrom pprint import pprint\n\nfrom returns.result import Failure, Result, Success\n\n\ndef func_a(i: int) -&gt; Result[int, str]:\n    if i == 1:\n        return Failure(f\"func_a({i})\")\n    return Success(i)\n\n\npprint([(i, func_a(i)) for i in range(5)])\n</code></pre> <p>Now <code>func_a</code> returns a single type, <code>Result</code>. The first type parameter to <code>Result</code> is the type returned by <code>Success</code> and the second type parameter is the type returned by <code>Failure</code>. The <code>outputs</code> from the comprehension are all of type <code>Result</code>, and we have preserved the successful calculations even though there is a failing call. We can also pattern-match on the outputs, and it is crystal-clear which match is for the success and which is for the failure.</p> <p>The <code>returns</code> library has been slipped in here, but its basic form is that of <code>result.py</code>.</p>"},{"location":"12_Errors_as_Values/#composing-with-result","title":"Composing with <code>Result</code>","text":"<p>The previous examples included very simple composition in the <code>composed</code> functions which just called a single other function. What if you need to compose a more complex function from multiple other functions? The <code>Result</code> type ensures that the <code>composed</code> function properly represents both the <code>Answer</code> type but also the various different errors that can occur:</p> <pre><code># composing_functions.py\nfrom pprint import pprint\n\nfrom return_result import func_a\nfrom returns.result import Failure, Result, Success, safe\n\n\n# Use an exception as info (but don't raise it):\ndef func_b(i: int) -&gt; Result[int, ValueError]:\n    if i == 2:\n        return Failure(ValueError(f\"func_b({i})\"))\n    return Success(i)\n\n\n# Convert exception to Failure:\ndef func_c(i: int) -&gt; Result[int, ZeroDivisionError]:\n    try:\n        1 / (i - 3)\n    except ZeroDivisionError as e:\n        return Failure(\n            ZeroDivisionError(f\"func_c({i}): {e}\")\n        )\n    return Success(i)\n\n\n@safe  # Convert existing function\ndef func_d(i: int) -&gt; str:  # Result[str, ZeroDivisionError]\n    1 / i\n    return f\"func_d({i})\"\n\n\ndef composed(\n    i: int,\n) -&gt; Result[str, str | ValueError | ZeroDivisionError]:\n    result_a = func_a(i)\n    if isinstance(result_a, Failure):\n        return result_a\n\n    # unwrap() gets the answer from Success:\n    result_b = func_b(result_a.unwrap())\n    if isinstance(result_b, Failure):\n        return result_b\n\n    result_c = func_c(result_b.unwrap())\n    if isinstance(result_c, Failure):\n        return result_c\n\n    return func_d(result_c.unwrap())\n\n\npprint([(i, composed(i)) for i in range(5)])\n</code></pre> <p>The <code>a</code>, <code>b</code> and <code>c</code> functions each have argument values that are unacceptable. Notice that <code>b</code> and <code>c</code> both use built-in exception types as arguments to <code>Failure</code>, but those exceptions are never raised\u2014they are simply used to convey information, just like the <code>str</code> in <code>a</code>.</p> <p>In <code>composed</code>, we call <code>a</code>, <code>b</code> and <code>c</code> in sequence. After each call, we check to see if the result type is <code>Failure</code>. If so, the calculation has failed and we can\u2019t continue, so we return the current result, which is a <code>Failure</code> object containing the reason for the failure. If it succeeds, it is a <code>Success</code> which contains an <code>unwrap</code> method that is used to extract the answer from that calculation\u2014if you look back at <code>Result</code>, you\u2019ll see that it returns the <code>ANSWER</code> type so its use can be properly type-checked.</p> <p>This means that any failure during a sequence of composed function calls will short-circuit out of <code>composed</code>, returning a <code>Failure</code> that tells you exactly what happened, and that you must decide what to do with. You can\u2019t just ignore it and assume that it will \u201cbubble up\u201d until it finds an appropriate handler. You are forced to deal with it at the point of origin, which is typically when you know the most about an error.</p>"},{"location":"12_Errors_as_Values/#simplifying-composition-with-bind","title":"Simplifying Composition with <code>bind</code>","text":"<p>There\u2019s still a problem that impedes our ultimate goal of composability: every time you call a function within a composed function, you must write code to check the <code>Result</code> type and extract the <code>answer</code> with <code>unwrap</code>. This is extra repetitive work that interrupts the flow and readability of the program. We need some way to reduce or eliminate the extra code.</p> <p>Lets modify <code>Result</code> to add a new member function, <code>bind</code>:</p> <pre><code># result_with_bind.py\nfrom dataclasses import dataclass\nfrom typing import Callable, Generic, TypeVar\n\nANSWER = TypeVar(\"ANSWER\")\nERROR = TypeVar(\"ERROR\")\n\n\n@dataclass(frozen=True)\nclass Result(Generic[ANSWER, ERROR]):\n    def bind(\n        self, func: Callable[[ANSWER], \"Result\"]\n    ) -&gt; \"Result[ANSWER, ERROR]\":\n        if isinstance(self, Success):\n            return func(self.unwrap())\n        return self  # Pass the Failure forward\n\n\n@dataclass(frozen=True)\nclass Success(Result[ANSWER, ERROR]):\n    answer: ANSWER\n\n    def unwrap(self) -&gt; ANSWER:\n        return self.answer\n\n\n@dataclass(frozen=True)\nclass Failure(Result[ANSWER, ERROR]):\n    error: ERROR\n</code></pre> <p><code>bind</code> removes the duplicated code:</p> <pre><code># composing_with_bind.py\nfrom pprint import pprint\n\nfrom composing_functions import func_a, func_b, func_c, func_d\nfrom returns.result import Result\n\n\ndef composed(\n    i: int,\n) -&gt; Result[str, str | ZeroDivisionError | ValueError]:\n    # fmt: off\n    return (\n        func_a(i)\n        .bind(func_b)\n        .bind(func_c)\n        .bind(func_d)\n    )\n\n\npprint([(i, composed(i)) for i in range(5)])\n</code></pre> <p>In <code>composed</code>, we call <code>func_a(i)</code> which returns a <code>Result</code>. The <code>bind</code> method is called on that <code>Result</code>, passing it the next function we want to call (<code>func_b</code>) as an argument. The return value of <code>bind</code> is also a <code>Result</code>, so we can call <code>bind</code> again upon that <code>Result</code>, passing it the third function we want to call (<code>func_c</code>), and so on.</p> <p>At each \u201cchaining point\u201d in <code>func_a(i).bind(func_b).bind(func_c).bind(func_d)</code>, <code>bind</code> checks the <code>Result</code> type to see if it <code>Success</code>. If so, it passes the result <code>answer</code> from that call as the argument to the next function in the chain. If not, that means <code>self</code> is a <code>Failure</code> object (containing specific error information), so all it needs to do is <code>return self</code>. The next call in the chain sees that the returned type is <code>Failure</code>, so it doesn\u2019t try to apply the next function but just (again) returns the <code>Failure</code>. Once you produce a <code>Failure</code>, no more function calls occur (that is, it short-circuits) and the <code>Failure</code> result gets passed all the way out of the composed function so the caller can deal with that specific failure.</p>"},{"location":"12_Errors_as_Values/#handling-multiple-arguments","title":"Handling Multiple Arguments","text":"<p>We could continue adding features to our <code>Result</code> library until it becomes a complete solution. However, others have worked on this problem so it makes more sense to reuse their libraries. The most popular Python library that includes this extra functionality is Returns. <code>Returns</code> includes other features, but we will only focus on  <code>Result</code>.</p> <p>What if you need to create a <code>composed</code> function that takes multiple arguments? For this, we use something called \u201cdo notation,\u201d which you access using <code>Result.do</code>:</p> <pre><code># multiple_arguments.py\nfrom pprint import pprint\n\nfrom composing_functions import func_a, func_b, func_c\nfrom returns.result import Result\n\n\ndef add(first: int, second: int, third: int) -&gt; str:\n    return (\n        f\"add({first} + {second} + {third}):\"\n        f\" {first + second + third}\"\n    )\n\n\ndef composed(\n    i: int, j: int\n) -&gt; Result[str, str | ZeroDivisionError | ValueError]:\n    # fmt: off\n    return Result.do(\n        add(first, second, third)\n        for first in func_a(i)\n        for second in func_b(j)\n        for third in func_c(i + j)\n    )\n\n\ninputs = [(1, 5), (7, 2), (2, 1), (7, 5)]\npprint([(args, composed(*args)) for args in inputs])\n</code></pre> <p><code>Returns</code> provides a <code>@safe</code> decorator that you see applied to the \u201cplain\u201d function <code>func_b</code>. This changes the normal <code>int</code> return type into a <code>Result</code> that includes <code>int</code> for the <code>Success</code> type but is also somehow able to recognize that the division might produce a <code>ZeroDivisionError</code> and include that in the <code>Failure</code> type. In addition, <code>@safe</code> is apparently catching the exception and converting it to the <code>ZeroDivisionError</code> returned as the information object in the <code>Failure</code> object. <code>@safe</code> is a helpful tool when converting exception-throwing code into error-returning code.</p> <p><code>func_c</code> adds some variety by rejecting <code>-1</code> and producing a <code>str</code> result. We can now produce <code>composed</code> using a <code>pipe</code> and <code>bind</code>. All the previous error-checking and short-circuiting behaviors happen as before, but the syntax is now more straightforward and readable.</p> <p>Notice that when the <code>outputs</code> list is created, the output from <code>reject0</code> only happens for the values <code>-1</code> and <code>2</code>, because the other values cause errors in the <code>composed</code> chain of operations. The value <code>1</code> never gets to <code>func_b</code> because it is intercepted by the prior <code>composed</code> call to <code>func_a</code>. The value <code>0</code> causes <code>func_b</code> to produce a <code>ZeroDivisionError</code> when it tries to perform the division inside the <code>print</code>.</p> <p>[Explain rest of example]</p> <p>Note that there may be an issue with the <code>Returns</code> library, which is that for proper type checking it requires using a MyPy extension. So far I have been unable to get that extension to work (however, I have no experience with MyPy extensions).</p>"},{"location":"12_Errors_as_Values/#functional-error-handling-is-happening","title":"Functional Error Handling is Happening","text":"<p>Functional error handling has already appeared in languages like Rust, Kotlin, and recent versions of C++ support these combined answer-error result types, with associated unpacking operations. In these languages, errors become part of the type system and it is far more difficult for an error to \u201cslip through the cracks.\u201d</p> <p>Python has only been able to support functional error handling since the advent of typing and type checkers, and it doesn\u2019t provide any direct language or library constructs for this. The benefits of better error handling and robust composability make it worth adopting a library like <code>Results</code>.</p>"},{"location":"13_Advanced_Concepts/","title":"Advanced Concepts","text":"<p>[[Distribute these ideas as appropriate]]</p> <p>This placeholder text was generated by ChatGPT 4.5. It will be significantly rewritten as the book is developed. In the meantime you can add comments to either https://bsky.app/bruceeckel or Github Issues.</p>"},{"location":"13_Advanced_Concepts/#annotated-types-annotated-for-metadata","title":"Annotated Types (<code>Annotated[...]</code>) for Metadata","text":"<p><code>Annotated</code> provides metadata for types, useful in documentation, validation, or frameworks:</p> <pre><code># example_2.py\nfrom typing import Annotated\n\nUserID = Annotated[int, \"Database primary key\"]\n\n\ndef fetch_user(user_id: UserID) -&gt; dict:\n    return {\"id\": user_id, \"name\": \"Alice\"}\n</code></pre> <p>Metadata within <code>Annotated</code> helps convey additional context beyond simple type hints.</p>"},{"location":"13_Advanced_Concepts/#advanced-type-narrowing-techniques","title":"Advanced Type Narrowing Techniques","text":"<p>Type narrowing refines a variable's type within conditional checks:</p>"},{"location":"13_Advanced_Concepts/#using-isinstance","title":"Using <code>isinstance</code>","text":"<pre><code># example_4.py\nfrom typing import Union\n\n\ndef process(value: Union[int, str]) -&gt; None:\n    if isinstance(value, int):\n        print(value + 1)\n    else:\n        print(value.upper())\n</code></pre>"},{"location":"13_Advanced_Concepts/#using-assertions","title":"Using assertions","text":"<pre><code># example_5.py\nfrom typing import Optional\n\n\ndef greet(name: Optional[str]) -&gt; None:\n    assert name is not None, \"Name cannot be None\"\n    print(f\"Hello, {name}\")\n</code></pre> <p>Type narrowing helps write precise, safe, and understandable code.</p>"},{"location":"13_Advanced_Concepts/#type-guards-isinstance-custom-type-guards-assertions","title":"Type Guards (<code>isinstance</code>, custom type guards, assertions)","text":"<p>Custom type guards offer explicit ways to narrow types more clearly:</p>"},{"location":"13_Advanced_Concepts/#custom-type-guard-functions-python-310","title":"Custom type guard functions (Python 3.10+)","text":"<pre><code># example_6.py\nfrom typing import TypeGuard\n\n\nclass Cat:\n    def meow(self):\n        print(\"Meow!\")\n\n\ndef is_cat(animal: object) -&gt; TypeGuard[Cat]:\n    return hasattr(animal, \"meow\")\n\n\nanimal = Cat()\nif is_cat(animal):\n    animal.meow()  # Safe to call\n## Meow!\n</code></pre> <p>Type guards enhance type narrowing accuracy, making code safer and cleaner.</p>"},{"location":"A1_Quick_Reference/","title":"Quick Reference","text":"Annotation Description Example <code>int</code>, <code>str</code>, <code>float</code>, <code>bool</code> Basic built-in types <code>age: int = 25</code> <code>List[T]</code>, <code>list[T]</code> List containing items of type <code>T</code> <code>scores: list[int]</code> <code>Tuple[T, ...]</code> Tuple with specified item types <code>coords: tuple[float, float]</code> <code>Dict[K, V]</code>, <code>dict[K, V]</code> Dictionary with keys <code>K</code>, values <code>V</code> <code>user_data: dict[str, int]</code> <code>Set[T]</code>, <code>set[T]</code> Set containing items of type <code>T</code> <code>tags: set[str]</code> <code>Optional[T]</code> Type <code>T</code> or <code>None</code> <code>name: Optional[str]</code> <code>Union[T1, T2]</code> or <code>T1 | T2</code> Either type <code>T1</code> or <code>T2</code> <code>value: int | str</code> <code>Callable[[Args], ReturnType]</code> Function types <code>adder: Callable[[int, int], int]</code> <code>Literal[\"value\"]</code> Specific literal values <code>mode: Literal[\"auto\", \"manual\"]</code> <code>Annotated[T, metadata]</code> Type <code>T</code> with additional metadata <code>UserID = Annotated[int, \"primary key\"]</code> <code>NewType('Name', T)</code> New distinct type based on type <code>T</code> <code>UserId = NewType('UserId', int)</code> <code>Protocol</code> Structural typing protocol <code>class Speaker(Protocol): ...</code>"},{"location":"A2_Glossary/","title":"Glossary","text":"Term Definition Annotation Explicit type declaration for variables, functions, or classes. Duck Typing Determining an object's suitability based on presence of methods/attributes Generics Type annotations parameterized by type variables. Literal Types Types representing specific literal values. Protocol Interface defined by structural compatibility, rather than explicit inheritance. Stub Files Files (<code>.pyi</code>) containing type annotations without implementations. Type Alias Simplified or descriptive alias for complex type annotations. Type Checking Verification of type consistency either statically or at runtime. Type Narrowing Refining variable types within specific control-flow branches. Variance Rules describing subtype relationships between generic types (covariant, contravariant). Static Typing Types checked before execution (compile-time). Dynamic Typing Types determined and checked during execution (runtime). Covariance Generic type that accepts subtypes as substitutes for its type parameter. Contravariance Generic type that accepts supertypes as substitutes for its type parameter. Invariant Generic type that requires exact type matches for its type parameters."},{"location":"A3_Guidelines/","title":"Guidelines","text":"<p>[[Needs lots of work]]</p> <p>This placeholder text was generated by ChatGPT 4.5. It will be significantly rewritten as the book is developed. In the meantime you can add comments to either https://bsky.app/bruceeckel or Github Issues.</p>"},{"location":"A3_Guidelines/#effective-patterns-for-clear-and-maintainable-annotations","title":"Effective Patterns for Clear and Maintainable Annotations","text":"<p>Clear type annotations significantly improve code quality and maintainability:</p>"},{"location":"A3_Guidelines/#consistent-type-annotation-style","title":"Consistent Type Annotation Style","text":"<ul> <li>Standardize type annotations across your project.</li> <li>Clearly annotate function signatures, class attributes, and return types.</li> </ul> <pre><code># example_1.py\ndef calculate_area(width: float, height: float) -&gt; float:\n    return width * height\n</code></pre>"},{"location":"A3_Guidelines/#use-type-aliases-for-complex-types","title":"Use Type Aliases for Complex Types","text":"<p>Simplify repetitive or complex annotations:</p> <pre><code># example_2.py\nfrom typing import Dict, List\n\nUserData = Dict[str, List[int]]\n\n\ndef process_data(data: UserData) -&gt; None:\n    pass\n</code></pre> <p>Type aliases enhance readability, making complex types easier to understand.</p>"},{"location":"A3_Guidelines/#leverage-dataclasses-and-typeddicts","title":"Leverage Dataclasses and TypedDicts","text":"<ul> <li>Dataclasses simplify structured data definitions.</li> <li>TypedDicts clarify expected dictionary structures.</li> </ul> <pre><code># example_3.py\nfrom dataclasses import dataclass\n\n\n@dataclass\nclass User:\n    id: int\n    name: str\n</code></pre> <p>These patterns improve explicitness and reduce boilerplate code.</p>"},{"location":"A3_Guidelines/#common-pitfalls-and-how-to-avoid-them","title":"Common Pitfalls and How to Avoid Them","text":""},{"location":"A3_Guidelines/#overusing-any","title":"Overusing <code>Any</code>","text":"<p>Overuse of <code>Any</code> defeats the purpose of type annotations:</p> <ul> <li>Pitfall:</li> </ul> <pre><code># example_4.py\nfrom typing import Any\n\n\ndef process(data: Any) -&gt; Any:\n    pass\n</code></pre> <ul> <li>Solution:   Provide specific type annotations whenever possible.</li> </ul>"},{"location":"A3_Guidelines/#missing-or-inconsistent-annotations","title":"Missing or Inconsistent Annotations","text":"<p>Incomplete annotations lead to confusion:</p> <ul> <li>Always annotate public APIs clearly.</li> <li>Regularly review annotations during code reviews.</li> </ul>"},{"location":"A3_Guidelines/#complex-union-types","title":"Complex Union Types","text":"<p>Avoid overly complex union types:</p> <ul> <li>Pitfall:</li> </ul> <pre><code># example_5.py\nfrom typing import Union\n\n\ndef handle(value: Union[int, str, None, float]) -&gt; None:\n    pass\n</code></pre> <ul> <li>Solution:   Refactor to simplify or use custom types.</li> </ul>"},{"location":"A3_Guidelines/#balancing-simplicity-readability-and-explicitness","title":"Balancing Simplicity, Readability, and Explicitness","text":""},{"location":"A3_Guidelines/#simplicity","title":"Simplicity","text":"<ul> <li>Aim for the simplest annotation that accurately represents the type.</li> </ul>"},{"location":"A3_Guidelines/#readability","title":"Readability","text":"<ul> <li>Ensure annotations improve, rather than obscure, readability.</li> </ul>"},{"location":"A3_Guidelines/#explicitness","title":"Explicitness","text":"<ul> <li>Favor explicit annotations that clarify intent, especially at API boundaries.</li> </ul> <p>Striking the right balance ensures maintainable and understandable code.</p>"},{"location":"A3_Guidelines/#strategies-for-large-scale-typed-codebases","title":"Strategies for Large-Scale Typed Codebases","text":"<p>Managing large-scale typed codebases requires strategic approaches:</p>"},{"location":"A3_Guidelines/#incremental-adoption","title":"Incremental Adoption","text":"<ul> <li>Gradually introduce type annotations to existing codebases.</li> <li>Prioritize critical and frequently changed components.</li> </ul>"},{"location":"A3_Guidelines/#automate-type-checking","title":"Automate Type Checking","text":"<ul> <li>Integrate tools like <code>mypy</code> and <code>pyright</code> into CI/CD.</li> <li>Regularly enforce type checking to maintain standards.</li> </ul>"},{"location":"A3_Guidelines/#continuous-review-and-improvement","title":"Continuous Review and Improvement","text":"<ul> <li>Regularly review annotations during code reviews.</li> <li>Address inconsistencies and improve clarity over time.</li> </ul>"},{"location":"A3_Guidelines/#comprehensive-documentation","title":"Comprehensive Documentation","text":"<ul> <li>Document type annotation standards and best practices.</li> <li>Ensure all team members follow consistent annotation strategies.</li> </ul> <p>Implementing these strategies helps sustain clarity, maintainability, and robustness in large, typed Python projects.</p>"},{"location":"A4_Type_Checkers/","title":"Type Checkers","text":"<p>This placeholder text was generated by ChatGPT 4.5. It will be significantly rewritten as the book is developed. In the meantime you can add comments to either https://bsky.app/bruceeckel or Github Issues.</p>"},{"location":"A4_Type_Checkers/#getting-started-with-mypy-installation-and-basic-use","title":"Getting Started with <code>mypy</code>: Installation and Basic Use","text":"<p><code>mypy</code> is a popular static type checker for Python that validates type annotations:</p>"},{"location":"A4_Type_Checkers/#installation","title":"Installation","text":"<pre><code>pip install mypy\n</code></pre>"},{"location":"A4_Type_Checkers/#basic-use","title":"Basic Use","text":"<p>Run <code>mypy</code> on your script or module to identify type errors:</p> <pre><code>mypy your_script.py\n</code></pre> <p>Example:</p> <pre><code># script.py\ndef greet(name: str) -&gt; str:\n    return f\"Hello, {name}!\"\n\n\ngreet(123)  # R: Incorrect type\n</code></pre> <p>Running <code>mypy script.py</code> outputs:</p> <pre><code>script.py:4: error: Argument 1 to \"greet\" has incompatible type \"int\"; expected \"str\"\n</code></pre>"},{"location":"A4_Type_Checkers/#advanced-configuration-and-fine-tuning-of-mypy","title":"Advanced Configuration and Fine-tuning of <code>mypy</code>","text":"<p>Customize <code>mypy</code> behavior using a <code>mypy.ini</code> or <code>pyproject.toml</code> file:</p>"},{"location":"A4_Type_Checkers/#example-mypyini","title":"Example <code>mypy.ini</code>","text":"<pre><code>[mypy]\nignore_missing_imports = True\nstrict = True\ncheck_untyped_defs = True\n</code></pre>"},{"location":"A4_Type_Checkers/#example-pyprojecttoml","title":"Example <code>pyproject.toml</code>","text":"<pre><code>[tool.mypy]\nignore_missing_imports = true\nstrict = true\n</code></pre> <p>Advanced configuration allows precise control over type-checking behavior and strictness levels.</p>"},{"location":"A4_Type_Checkers/#exploring-pyright-and-ide-integration-vscode-pycharm","title":"Exploring <code>pyright</code> and IDE Integration (VSCode, PyCharm)","text":"<p><code>pyright</code>, developed by Microsoft, offers high-performance static type checking, integrated seamlessly with popular IDEs.</p>"},{"location":"A4_Type_Checkers/#using-pyright-cli","title":"Using <code>pyright</code> (CLI)","text":"<p>Install globally using npm:</p> <pre><code>npm install -g pyright\npyright your_script.py\n</code></pre>"},{"location":"A4_Type_Checkers/#vscode-integration","title":"VSCode Integration","text":"<p><code>pyright</code> powers VSCode's built-in Python type checking, providing immediate feedback:</p> <ul> <li>Install the Python extension in VSCode.</li> <li>Real-time inline error highlighting and suggestions.</li> </ul>"},{"location":"A4_Type_Checkers/#pycharm-integration","title":"PyCharm Integration","text":"<p>PyCharm supports built-in type checking:</p> <ul> <li>Provides live error detection, highlighting, and quick-fix suggestions.</li> <li>Navigate to <code>Preferences &gt; Editor &gt; Inspections</code> to configure type-checking rules.</li> </ul>"},{"location":"A4_Type_Checkers/#incremental-typing-strategies-gradual-adoption","title":"Incremental Typing Strategies: Gradual Adoption","text":"<p>Adopt typing gradually, focusing first on critical paths:</p> <ul> <li>Annotate high-risk or frequently changing modules first.</li> <li>Enable type checking incrementally to avoid overwhelming your team:</li> </ul> <pre><code>[mypy]\nfiles = core/, utils/\n</code></pre> <p>Incremental typing balances immediate benefits with manageable adoption efforts.</p>"},{"location":"A4_Type_Checkers/#integrating-type-checking-into-continuous-integration","title":"Integrating Type Checking into Continuous Integration","text":"<p>Automate type checking within your CI/CD pipeline to enforce consistency and catch errors early:</p>"},{"location":"A4_Type_Checkers/#example-github-actions-workflow","title":"Example GitHub Actions Workflow","text":"<pre><code>name: Type Check\n\non: [push, pull_request]\n\njobs:\n  type-check:\n    runs-on: ubuntu-latest\n\n    steps:\n      - uses: actions/checkout@v3\n      - uses: actions/setup-python@v3\n        with:\n          python-version: '3.11'\n\n      - run: pip install mypy\n      - run: mypy .\n</code></pre> <p>Automated checks ensure ongoing compliance with typing standards and maintain high code quality.</p>"},{"location":"A4_Type_Checkers/#handling-and-resolving-common-errors","title":"Handling and Resolving Common Errors","text":"<p>Common type-checking errors and their resolutions:</p>"},{"location":"A4_Type_Checkers/#incorrect-type-annotation","title":"Incorrect Type Annotation","text":"<pre><code># example_2.py\n# Error: Incompatible types in assignment (expression has type \"int\", variable has type \"str\")\nname: str = 123  # fix: name = \"Alice\"\n</code></pre>"},{"location":"A4_Type_Checkers/#missing-imports","title":"Missing Imports","text":"<p>Use <code>ignore_missing_imports</code> or install type stubs:</p> <pre><code>[mypy]\nignore_missing_imports = True\n</code></pre> <p>Or install stubs:</p> <pre><code>pip install types-requests\n</code></pre>"},{"location":"A4_Type_Checkers/#union-and-optional-errors","title":"Union and Optional Errors","text":"<p>Resolve ambiguity clearly:</p> <pre><code># example_3.py\nfrom typing import Optional\n\n\n# Error: Incompatible return value type (got \"None\", expected \"int\")\ndef find_index(item: str, items: list[str]) -&gt; Optional[int]:\n    try:\n        return items.index(item)\n    except ValueError:\n        return None\n</code></pre> <p>Effectively handling and resolving these errors leads to clearer, more reliable, and maintainable codebases.</p>"},{"location":"A5_Automatic_Annotations/","title":"Automatic Annotations","text":"<p>[[Too specific to mypy -- should cover other tools]]</p> <p>This placeholder text was generated by ChatGPT 4.5. It will be significantly rewritten as the book is developed. In the meantime you can add comments to either https://bsky.app/bruceeckel or Github Issues.</p>"},{"location":"A5_Automatic_Annotations/#introduction-to-pyi-stub-files","title":"Introduction to <code>.pyi</code> Stub Files","text":"<p><code>.pyi</code> stub files provide type annotations for Python modules, especially useful when source code lacks annotations or is unavailable:</p> <ul> <li>Contains type definitions without actual implementations.</li> <li>Enables static type checking for third-party libraries.</li> </ul> <p>Example:</p> <pre><code># math.pyi\ndef sqrt(x: float) -&gt; float: ...\n</code></pre> <p>Stub files clearly document expected types, significantly improving interoperability.</p>"},{"location":"A5_Automatic_Annotations/#generating-stubs-automatically-with-stubgen","title":"Generating Stubs Automatically with <code>stubgen</code>","text":"<p><code>stubgen</code> is a tool included with <code>mypy</code> to automatically generate stub files from existing Python code:</p>"},{"location":"A5_Automatic_Annotations/#installation-and-basic-use","title":"Installation and Basic Use","text":"<pre><code>pip install mypy\nstubgen -m your_module\n</code></pre> <p>Generates a <code>.pyi</code> file with inferred annotations, saving manual effort:</p> <pre><code># generated_example.pyi\ndef greet(name: str) -&gt; str: ...\n</code></pre> <p>Auto-generated stubs provide a starting point for type annotations.</p>"},{"location":"A5_Automatic_Annotations/#writing-effective-stubs-manually","title":"Writing Effective Stubs Manually","text":"<p>Manual stub writing is essential when automatic inference is insufficient:</p>"},{"location":"A5_Automatic_Annotations/#example-stub-file","title":"Example Stub File","text":"<pre><code># custom_module.pyi\nclass User:\n    id: int\n    name: str\n\n\ndef fetch_user(user_id: int) -&gt; User: ...\n</code></pre>"},{"location":"A5_Automatic_Annotations/#best-practices","title":"Best Practices","text":"<ul> <li>Clearly annotate arguments and return types.</li> <li>Use ellipsis (<code>...</code>) to indicate stub implementation.</li> <li>Reflect original module's behavior accurately.</li> </ul> <p>Manual stub files enhance readability and ensure accurate type definitions.</p>"},{"location":"A5_Automatic_Annotations/#distributing-and-versioning-typing-stubs","title":"Distributing and Versioning Typing Stubs","text":"<p>Typing stubs can be distributed independently or alongside the original package:</p>"},{"location":"A5_Automatic_Annotations/#bundled-with-package","title":"Bundled with Package","text":"<p>Include stubs directly in your package:</p> <pre><code>your_package/\n\u251c\u2500\u2500 __init__.py\n\u2514\u2500\u2500 __init__.pyi\n</code></pre>"},{"location":"A5_Automatic_Annotations/#separate-distribution","title":"Separate Distribution","text":"<p>Publish stubs as standalone packages:</p> <pre><code>pip install types-requests\n</code></pre> <p>Use semantic versioning aligned with the original package for clarity and compatibility:</p> <pre><code>types-requests==2.25.1\n</code></pre> <p>Effective versioning ensures seamless integration and updates.</p>"},{"location":"A5_Automatic_Annotations/#typing-third-party-libraries-without-native-annotations","title":"Typing Third-party Libraries without Native Annotations","text":"<p>When third-party libraries lack native annotations:</p>"},{"location":"A5_Automatic_Annotations/#use-third-party-typing-packages","title":"Use Third-party Typing Packages","text":"<p>Install existing typing packages from PyPI:</p> <pre><code>pip install types-requests\n</code></pre>"},{"location":"A5_Automatic_Annotations/#custom-stubs","title":"Custom Stubs","text":"<p>Write custom stub files within your project:</p> <pre><code>stubs/\n\u251c\u2500\u2500 requests.pyi\n</code></pre>"},{"location":"A5_Automatic_Annotations/#ignoring-missing-annotations","title":"Ignoring Missing Annotations","text":"<p>Temporarily ignore missing annotations with <code>mypy</code> configuration:</p> <pre><code>[mypy-requests]\nignore_missing_imports = True\n</code></pre> <p>Using stubs significantly improves type checking for libraries without built-in annotations, maintaining robust and reliable codebases.</p>"},{"location":"A6_Class_Attributes/","title":"Class Attributes","text":"<p>A number of type tools use a syntax that hacks class attribute syntax; the most obvious is dataclasses but there are others. It's important to understand that this is special behavior created by the tool, and that ordinary classes do not behave this way.</p> <p>While contributing to an open-source project, I was stopped short by this (names have been changed):</p> <pre><code># data_point.py\nclass DataPoint:\n    measurement1 = None\n    measurement2 = None\n    measurement3 = None\n\n\nd = DataPoint()\nd.measurement1 = 100\nd.measurement2 = 200\nd.measurement3 = 300\n</code></pre> <p>Why give names and initialization values to <code>class</code> attributes, then when you make an object, immediately create and initialize instance variables with the same names as the class attributes? I began to suspect a misunderstanding about class attributes.</p> <p>I asked one of the coaches of the project (not the original author). They explained that this was the way you provide default values for Python objects. When I attempted to disagree, the effects were demonstrated using a debugger. The argument looked something like this:</p> <pre><code># like_default_values.py\n\n\nclass A:\n    x: int = 100\n\n\na = A()\nprint(f\"{a.x = }\")\n# a.x = 100\na.x = -1\nprint(f\"{a.x = }\")\n# a.x = -1\na2 = A()\nprint(f\"{a2.x = }\")\n# a2.x = 100\n</code></pre> <p>(<code>f\"{a.x = }\"</code> is an f-string feature that eliminates the redundancy of displaying a variable.)</p> <p>Sure enough, if I create an <code>A</code> object called <code>a</code> and ask for <code>a.x</code>, it looks like <code>x</code> has the \"default value\" of <code>100</code>. I can set <code>a.x</code> to <code>-1</code> and create a second <code>A</code> object <code>a2</code> which once again is given the \"default value\" of 100---separate storage appears to have been created and initialized for the <code>x</code> in both <code>a</code> and <code>a2</code>. Based on this simple example, Python class attributes seem to produce default value behavior.</p>"},{"location":"A6_Class_Attributes/#where-did-this-idea-come-from","title":"Where Did This Idea Come From?","text":"<p>Because of the way class attributes are defined, someone coming from either C++ or Java might assume they work the same as in C++ or Java: Storage for those variables is allocated and initialized before the constructor[^1] is called. Indeed, the first time I saw class attributes used for automated constructor generation (a trick we shall visit later in this article), I wondered if I had previously missed something magical about class attributes.</p> <p>Here's a Java example exploring the same ideas:</p> <pre><code>// DefaultValues.java\n// Java automatically initializes from defaults\n\nclass A {\n  int x = 100;\n  public A() {\n    // x is already initialized:\n    System.out.println(\"In A constructor: \" + this);\n  }\n  @Override\n  public String toString() {\n    return \"x = \" + x;\n  }\n}\n\nclass B {\n  static int x = 100;\n  @Override\n  public String toString() {\n    // Accessing static via instance:\n    return \"x = \" + x;\n    // Same as \"x = \" + this.x;\n  }\n  static public String statics() {\n    return \"B.statics(): B.x = \" + B.x;\n  }\n  // Cannot shadow identifier names:\n  // int x = -1;\n  // Variable 'x' is already defined in the scope\n}\n\npublic class DefaultValues {\n  public static void main(String[] args) {\n    A a = new A();\n    // In A constructor: x = 100\n    System.out.println(\"a: \" + a);\n    // a: x = 100\n    a.x = -1;\n    System.out.println(\"a: \" + a);\n    // a: x = -1\n    System.out.println(\"new A(): \" + new A());\n    // In A constructor: x = 100\n    // new A(): x = 100\n\n    B b = new B();\n    System.out.println(\"b: \" + b);\n    // b: x = 100\n    System.out.println(B.statics());\n    // B.statics(): B.x = 100\n    // Accessing static via class:\n    B.x = -1;\n    System.out.println(\"b: \" + b);\n    // b: x = -1\n    System.out.println(B.statics());\n    // B.statics(): B.x = -1\n    B b2 = new B();\n    System.out.println(\"b2: \" + b2);\n    // b2: x = -1\n  }\n}\n</code></pre> <p>Inside the constructor <code>A()</code>, the storage for <code>x</code> has already been allocated and initialized. Changing the value of <code>a.x</code> doesn't influence further new <code>A</code> objects, which are initialized to <code>100</code>.</p> <p>In <code>class B</code>, <code>x</code> is changed to a <code>static</code> variable. This means there is only a single piece of <code>x</code> storage for the class---no matter how many instances of that class you create. This is how Python class attributes work: they are <code>static</code> variables without using the <code>static</code> keyword.</p> <p>In <code>B</code>'s <code>toString()</code>, notice that <code>B</code>'s <code>x</code> is accessed the same way it is in <code>Class A</code>'s <code>toString()</code>: as if it were an ordinary object field rather than a <code>static</code> field. When you do this, Java automatically uses the <code>static</code> <code>x</code> even though you are syntactically treating it like the object's <code>x</code>.</p> <p>In <code>statics()</code>, <code>x</code> is accessed through the class by saying <code>B.x</code>. If <code>x</code> were not a <code>static</code> you couldn't do this.</p> <p>At the end of <code>class B</code>, notice that we cannot \"shadow\" an identifier name like we can in Python: we cannot have both an ordinary and a <code>static</code> variable of the same name. <code>main()</code> demonstrates that the <code>static x</code> in <code>B</code> is indeed associated with the class, and there's only one piece of storage shared by all objects of <code>class B</code>.</p> <p>C++ has virtually identical behavior, although <code>static</code> initialization syntax is different for variables:</p> <pre><code>// default_values.cpp\n// C++ automatically initializes from defaults\n// Tested on http://cpp.sh\n#include &lt;iostream&gt;\n\nclass A {\n    public:\n    int x = 100;\n    A() { // x is already initialized:\n        std::cout &lt;&lt; \"constructor: \" &lt;&lt; x &lt;&lt; std::endl;\n    }\n};\n\nclass B {\n    public:\n    static int x;\n    B() { // x has been initialized:\n        std::cout &lt;&lt; \"constructor: \" &lt;&lt; x &lt;&lt; std::endl;\n    }\n    // Cannot shadow identifier name:\n    // int x = 1;\n    // 'int B::x' conflicts with a previous declaration\n};\n\n// Static variables must be initialized outside the class:\nint B::x = 100;\n\n// Static consts are initialized inline:\nclass C {\n    public:\n    static const int x = 100;\n};\n\nint main() {\n    A a;\n    // constructor: 100\n    std::cout &lt;&lt; a.x &lt;&lt; std::endl;\n    // 100\n    a.x = -1;\n    std::cout &lt;&lt; a.x &lt;&lt; std::endl;\n    // -1\n\n    B b;\n    // constructor: 100\n    std::cout &lt;&lt; b.x &lt;&lt; std::endl;\n    // 100\n    // Accessing static via instance:\n    b.x = -1;\n    std::cout &lt;&lt; b.x &lt;&lt; std::endl;\n    // -1\n    // Accessing static via class:\n    B::x = -99;\n    std::cout &lt;&lt; b.x &lt;&lt; std::endl;\n    // -99\n\n    C c;\n    std::cout &lt;&lt; c.x &lt;&lt; std::endl;\n    // 100\n    // Cannot assign to const:\n    // c.x = -1;\n}\n</code></pre> <p>Just like Java, storage is allocated and initialized for <code>x</code> by the time the <code>A()</code> constructor is called.</p> <p>In <code>class B</code>, the <code>static int x</code> definition only indicates that <code>x</code> exists for <code>B</code>. To allocate and initialize static variable storage, the external definition <code>int B::x = 100</code> is required. If, however, the <code>static</code> is <code>const</code>, the initialization value is included in the definition as seen in <code>class C</code>. The compiler is able to inline <code>const</code> values where they are used, so no storage is required.</p> <p>In <code>class B</code>, you see that, like Java, C++ also disallows name shadowing. <code>main()</code> shows that <code>static x</code> can be accessed either through the class or using an instance of the class.</p> <p>Notice that both Java and C++ have explicit <code>static</code> keywords, whereas Python does not. This adds to the confusion, so when a Java or C++ programmer (who has not learned about class attributes) sees something of the form:</p> <pre><code># no_static_keyword.py\nclass X:\n    a = 1\n    b = 2\n    c = 3\n</code></pre> <p>It is quite reasonable to expect the same results as from similar-looking C++ or Java code. After doing a few simple experiments as in <code>like_default_values.py</code>, a C++ or Java programmer might well conclude that Python does indeed work that way. And, because a class attribute is a single variable that is \"global to the class,\" it can be mistaken for a default value.</p>"},{"location":"A6_Class_Attributes/#how-things-break","title":"How Things Break","text":"<p>The worst thing about this is that code written with the assumption that class attributes are just default initialization values seems to work most of the time for simple situations like the one I encountered. The code passes its tests, so how can I call it \"wrong?\"</p> <p>The problem occurs when you're least expecting it. Here is just one configuration that produces a surprise:</p> <pre><code># it_all_goes_wrong.py\n\nclass A:\n    x: int = 100\n    y: int = 200\n\n    @classmethod\n    def change_x(cls):\n        cls.x = 999\n\n    @classmethod\n    def change_y(cls):\n        cls.y = 313\n\n\ndef reset():\n    A.x = 100\n    A.y = 200\n\n\na1: A = None\na2: A = None\na3: A = None\n\n\ndef display(counter: int):\n    print(f\"display({counter})\")\n    if a1:\n        print(f\"{a1.x = }, {a1.y = }\")\n    if a2:\n        print(f\"{a2.x = }, {a2.y = }\")\n    if a3:\n        print(f\"{a3.x = }, {a3.y = }\")\n\n\na1 = A()\ndisplay(1)\na1.x = -1\na1.y = -2\ndisplay(2)\na1.change_x()\ndisplay(3)\na2 = A()\ndisplay(4)\na2.y = 17\ndisplay(5)\nA.change_y()\na3 = A()\ndisplay(6)\nreset()\ndisplay(7)\n</code></pre> <p>Every object instance has its own dictionary. When you assign to an instance variable, you add a binding to the instance dictionary. But a class definition creates a (class) object, which also has its own dictionary. When you define a class attribute, you add a binding to the class dictionary.</p> <p>When Python looks up an attribute, it (generally) starts at the instance and if it doesn't find the attribute there, falls back to looking it up in the associated class/type dictionary (the same way that C++ and Java do).</p> <p><code>class A</code> contains two class attributes. <code>change_x()</code> and <code>change_y()</code> are \"class methods,\" which mean they operate on the class object, and not a particular instance of that class. The first parameter of a <code>classmethod</code> is thus not <code>self</code> (the instance reference) but instead <code>cls</code> (the class reference). <code>change_x()</code> and <code>change_y()</code> modify the class attributes, and <code>reset()</code> sets both class attributes back to their original values.</p> <p>The main code starts by creating three <code>A</code> references initialized to <code>None</code>, and a <code>display()</code> function that shows the <code>x</code> and <code>y</code> values for each non-<code>None</code> object.</p> <p>Everything looks like it exhibits \"default value\" behavior until we call <code>change_x()</code> and <code>change_y()</code>, then things get strange. The original <code>a1</code> produces the same results as before, but <code>a2</code> is partially affected (<code>x</code> changes but not <code>y</code>) and the new <code>a3</code> has different \"default values.\" Calling <code>reset()</code> modifies <code>a2</code> (partially) and <code>a3</code> (completely), but not <code>a1</code>.</p> <p><code>reset()</code> changes objects it has no direct connection with. The changes themselves are inconsistent across the different objects. Imagine these kinds of errors appearing in your code base, and trying to track them down based on the varying behavior of these so-called \"default values.\"</p>"},{"location":"A6_Class_Attributes/#class-attributes_1","title":"Class Attributes","text":"<p>The source of confusion is twofold:</p> <ol> <li> <p>Python's dynamic nature. Instance variables are not automatically created,    not even in the constructor. They are created the first time they are assigned to, which can happen just about anywhere.</p> </li> <li> <p>Unlike C++ and Java, Python allows instance variables to shadow (have the    same name as) class attributes. This feature gets significant use in    libraries that simplify configuration by using class attributes to    automatically generate constructors and other methods.</p> </li> </ol> <p>The two confusions compound, because if you ask for an uncreated instance variable with the same name as a class attribute, Python quietly returns the class attribute. If at some later point the instance variable of the same name is created (by assigning something to its identifier), the object will from then on produce the instance variable instead of the class attribute. The same behavior that makes a class attribute look like a default value can cause subtle bugs.</p> <p>To see this in action, we need a function that displays the inside of classes and objects:</p> <pre><code># look_inside.py\n\n\ndef attributes(d: object) -&gt; str:\n    return (\n        \", \".join([f\"{k}: {v}\" for k, v in vars(d).items() if not k.startswith(\"__\")])\n        or \"Empty\"\n    )\n\n\ndef show(obj: object, obj_name: str) -&gt; None:\n    klass: type = obj.__class__\n    print(f\"[Class {klass.__name__}] {attributes(klass)}\")\n    print(f\"[Object {obj_name}] {attributes(obj)}\")\n</code></pre> <p><code>attributes()</code> can be applied to either a class or an object. It uses the builtin <code>vars()</code> function to produce the dictionary, skips dunder functions, and produces names and values or <code>\"Empty\"</code> if there are none. <code>attributes()</code> is used in <code>show()</code> to display both the class and an object of that class. Now we can see the details when using class attributes:</p> <pre><code># class_attributes.py\nfrom look_inside import show\n\n\nclass A:\n    x: int = 100\n\n\nclass B:\n    x: int = 100\n\n    def __init__(self, x_init: int):\n        # Shadows the class attribute name:\n        self.x = x_init\n\n\na = A()\nshow(a, \"a\")\na.x = 1\nshow(a, \"a\")\nb = B(-99)\nshow(b, \"b\")\n</code></pre> <p>Creating an <code>A</code> requires no constructor arguments (because there is no constructor). There are no instance variables for <code>a</code> until after the assignment <code>a.x = 1</code>. <code>B</code>'s constructor requires an argument and uses it to assign to an instance variable (thus creating it).</p> <p>Let's look at the original example using <code>show()</code>:</p> <pre><code># like_default_values_shown.py\nfrom look_inside import show\n\n\nclass A:\n    x: int = 100\n\n\na = A()\nshow(a, \"a\")\nprint(f\"{a.x = }\")\na.x = -1\nshow(a, \"a\")\nprint(f\"{a.x = }\")\na2 = A()\nshow(a2, \"a2\")\nprint(f\"{a2.x = }\")\n</code></pre> <p>In the first <code>print()</code>, the instance variable <code>x</code> has not yet been created, so Python helpfully produces the class attribute of the same name. But the assignment <code>a.x = -1</code> creates an instance variable, and so the second <code>print()</code> sees that instance variable. When we create a new <code>A</code> for <code>a2</code>, we're back to a new object without an instance variable so it once again produces the class attribute, making it look like a default value.</p> <p>If you never do anything more complex than this, you won't know there are lurking problems.</p>"},{"location":"A6_Class_Attributes/#the-class-attribute-trick","title":"The Class Attribute Trick","text":"<p>Name shadowing is an intentional part of Python's design, and has become an integral part of the way some libraries provide easy class configuration. The first time I saw it was in Django:</p> <pre><code># example_9.py\nclass Blog(models.Model):\n    name = models.CharField(max_length=100)\n    tagline = models.TextField()\n\n    def __str__(self):\n        return self.name\n</code></pre> <p>This seemed magical and confusing. There's no visible constructor but somehow <code>__str__</code> can access <code>self.name</code>. Presumably the base-class constructor creates the instance variables by using the class attributes as a template.</p> <p>Python's <code>dataclasses</code> use a decorator to generate code for the constructor and other methods using class attributes as a template. Simply adding <code>dataclasses</code> to <code>it_all_goes_wrong.py</code> fixes the problem:</p> <pre><code># example_10.py\nfrom dataclasses import dataclass\n\n\n@dataclass\nclass A:\n    x: int = 100\n    y: int = 200\n</code></pre> <p>I suspect that the use of class attributes as code-generation templates will continue.</p>"},{"location":"A6_Class_Attributes/#recommendations","title":"Recommendations","text":"<p>The solution is to not make class attributes seem like default values. Instead, write proper constructors with default arguments, as you see in <code>class A</code>:</p> <pre><code># choices.py\nfrom look_inside import show\nfrom dataclasses import dataclass\n\n\nclass A:\n    def __init__(self, x: int = 100, y: int = 200, z: int = 300):\n        self.x = x\n        self.y = y\n        self.z = z\n\n\n# OR:\n\n\n@dataclass\nclass AA:\n    x: int = 100\n    y: int = 200\n    z: int = 300\n\n\na = A()\nshow(a, \"a\")\na.x = -1\na.y = -2\na.z = -3\nshow(a, \"a\")\n\naa = AA()\nprint(aa)\nshow(aa, \"aa\")\naa.x = -1\naa.y = -2\naa.z = -3\nshow(aa, \"aa\")\naa2 = AA(-4, -5, -6)\nshow(aa2, \"aa2\")\n\n# Even if we modify the class attributes, the\n# constructor default arguments stay the same:\nAA.x = 42\nAA.y = 74\nAA.z = 22\naa3 = AA()\nshow(aa3, \"aa3\")\n</code></pre> <p>You can also use a <code>dataclass</code> as seen in <code>class AA</code>. Notice the result of <code>print(aa)</code> produces a useful description of the object because the <code>dataclass</code> automatically generates a <code>__repr__()</code>.</p> <p>The <code>dataclass</code> decorator generates a constructor with default arguments that match the class attributes. After that you can modify the class attributes and it has no effect on the constructed objects. It seems like <code>dataclasses</code> are what the original author of the code I encountered was hoping for.</p> <p>Although Python's syntax can make it look like other languages, its dynamic nature strongly influences the language's semantics. Assumptions that it works like C++ or Java will generally produce incorrect results.</p> <p>You can learn more about <code>dataclasses</code> from my Pycon 2022 presentation Making Dataclasses Work for You, on YouTube (not yet available at this writing).</p> <p>Thanks to Barry Warsaw for reviewing and giving feedback.</p> <p>[^1]: Languages like C++ and Java use constructor to mean \"activities performed after storage allocation and basic initialization.\" C++ also has a <code>new()</code> for controlling memory allocation, calling it \"operator new\" rather than \"constructor.\" In contrast, Python's constructor is usually defined as the <code>__new__()</code> function, and <code>__init__()</code> is called the initializer. C++'s operator <code>new()</code> and Python's <code>__new__()</code> are almost never overridden, and are rarely even mentioned (The common usage for Python's <code>__new__()</code> seems to be to create Factory functions). To keep things simple I just say \"constructor\" when referring to <code>__init__()</code>.</p>"},{"location":"A7_Book_Notes/","title":"Book Notes","text":"<p>Resources and Ideas for eventual inclusion in the book.</p> <ul> <li>https://github.com/BruceEckel/RethinkingObjects (code from Pycon presentation, youtube video is not comprehensible)</li> <li>https://github.com/BruceEckel/RethinkingObjects-book</li> </ul>"},{"location":"A7_Book_Notes/#ai-generated-topic-list","title":"AI-Generated Topic List","text":"<p>Created by ChatGPT 4o.</p>"},{"location":"A7_Book_Notes/#part-i-the-basics-of-typing-in-python","title":"\ud83d\udcd8 Part I: The Basics of Typing in Python","text":""},{"location":"A7_Book_Notes/#introduction-to-static-typing","title":"Introduction to Static Typing","text":"<ul> <li>Why type your code?</li> <li>Benefits of types in Python (readability, tooling, correctness)</li> </ul>"},{"location":"A7_Book_Notes/#basic-type-annotations","title":"Basic Type Annotations","text":"<ul> <li>Built-in types: <code>int</code>, <code>str</code>, <code>float</code>, <code>bool</code></li> <li>Variable annotations</li> <li>Function argument and return types</li> </ul>"},{"location":"A7_Book_Notes/#optional-and-union-types","title":"Optional and Union Types","text":"<ul> <li><code>Optional[T]</code> / <code>T | None</code></li> <li><code>Union</code> / <code>T1 | T2</code></li> <li>When and why to use</li> </ul>"},{"location":"A7_Book_Notes/#any-and-noreturn","title":"Any and NoReturn","text":"<ul> <li>When to use <code>Any</code></li> <li>Risks of <code>Any</code></li> <li>Meaning and use of <code>NoReturn</code></li> </ul>"},{"location":"A7_Book_Notes/#type-aliases","title":"Type Aliases","text":"<ul> <li>Creating and using <code>type MyAlias = ...</code></li> <li>Organizing complex types</li> </ul>"},{"location":"A7_Book_Notes/#part-ii-collections-and-generics","title":"\ud83d\udcd8 Part II: Collections and Generics","text":""},{"location":"A7_Book_Notes/#typing-built-in-collections","title":"Typing Built-in Collections","text":"<ul> <li><code>List</code>, <code>Dict</code>, <code>Tuple</code>, <code>Set</code></li> <li>Homogeneous vs heterogeneous types</li> <li>Variadic tuples</li> </ul>"},{"location":"A7_Book_Notes/#generic-types","title":"Generic Types","text":"<ul> <li>Understanding <code>TypeVar</code> and generic functions</li> <li>Creating generic classes</li> </ul>"},{"location":"A7_Book_Notes/#callable-and-lambdas","title":"Callable and Lambdas","text":"<ul> <li>Typing functions as values</li> <li>Callable signatures</li> </ul>"},{"location":"A7_Book_Notes/#iterables-and-iterators","title":"Iterables and Iterators","text":"<ul> <li><code>Iterable</code>, <code>Iterator</code>, <code>Generator</code></li> <li>Typing generators and coroutines</li> </ul>"},{"location":"A7_Book_Notes/#literal-types","title":"Literal Types","text":"<ul> <li>Restricting to fixed string or numeric values</li> <li>Using <code>Literal</code> for flags and enums</li> </ul>"},{"location":"A7_Book_Notes/#part-iii-advanced-concepts","title":"\ud83d\udcd8 Part III: Advanced Concepts","text":""},{"location":"A7_Book_Notes/#protocols-and-structural-typing","title":"Protocols and Structural Typing","text":"<ul> <li>Introduction to duck typing</li> <li><code>Protocol</code> classes and <code>@runtime_checkable</code></li> </ul>"},{"location":"A7_Book_Notes/#new-in-python-10","title":"New in Python 10+","text":"<ul> <li><code>|</code> syntax for unions</li> <li><code>match</code> statement and typing with pattern matching</li> <li><code>ParamSpec</code> and <code>Concatenate</code></li> </ul>"},{"location":"A7_Book_Notes/#annotated-and-metadata-types","title":"Annotated and Metadata Types","text":"<ul> <li>Using <code>Annotated</code> for richer metadata</li> <li>Use in CLI tools, validation, etc.</li> </ul>"},{"location":"A7_Book_Notes/#self-type-and-recursive-types","title":"Self Type and Recursive Types","text":"<ul> <li>Typing methods that return <code>self</code></li> <li>Recursive types like nested JSON</li> </ul>"},{"location":"A7_Book_Notes/#dataclasses-and-typing","title":"Dataclasses and Typing","text":"<ul> <li>Typing fields with and without defaults</li> <li><code>InitVar</code>, <code>field</code>, <code>kw_only</code>, etc.</li> </ul>"},{"location":"A7_Book_Notes/#part-iv-runtime-typing-and-validation","title":"\ud83d\udcd8 Part IV: Runtime Typing and Validation","text":""},{"location":"A7_Book_Notes/#type-checking-at-runtime","title":"Type Checking at Runtime","text":"<ul> <li><code>isinstance</code> and <code>typing.get_type_hints()</code></li> <li>Runtime enforcement libraries (e.g. Pydantic, Enforce)</li> </ul>"},{"location":"A7_Book_Notes/#validating-with-decorators","title":"Validating with Decorators","text":"<ul> <li>Type validation decorators</li> <li>Enforcing types in dynamic code</li> </ul>"},{"location":"A7_Book_Notes/#typeddict-and-json-like-structures","title":"TypedDict and JSON-like Structures","text":"<ul> <li>Using <code>TypedDict</code> for structured data</li> <li>Migration from <code>dict[str, Any]</code></li> </ul>"},{"location":"A7_Book_Notes/#enums-and-custom-types","title":"Enums and Custom Types","text":"<ul> <li>Strongly typed enums</li> <li>Creating domain-specific types</li> </ul>"},{"location":"A7_Book_Notes/#dynamic-typing-interop","title":"Dynamic Typing Interop","text":"<ul> <li>Working with untyped or partially typed code</li> <li>Handling <code>Any</code> gracefully</li> </ul>"},{"location":"A7_Book_Notes/#part-v-tooling-and-practices","title":"\ud83d\udcd8 Part V: Tooling and Practices","text":""},{"location":"A7_Book_Notes/#static-type-checkers","title":"Static Type Checkers","text":"<ul> <li>Using <code>mypy</code>, <code>pyright</code>, <code>pyre</code>, <code>pytype</code></li> <li>Configuration and workflows</li> </ul>"},{"location":"A7_Book_Notes/#ide-and-editor-support","title":"IDE and Editor Support","text":"<ul> <li>VS Code, PyCharm, etc.</li> <li>Type hinting with LSPs and plugins</li> </ul>"},{"location":"A7_Book_Notes/#refactoring-with-types","title":"Refactoring with Types","text":"<ul> <li>Incremental typing strategies</li> <li>Using types to guide refactoring</li> </ul>"},{"location":"A7_Book_Notes/#testing-and-typing","title":"Testing and Typing","text":"<ul> <li>Typing test code</li> <li>Type-aware mocking and fixtures</li> </ul>"},{"location":"A7_Book_Notes/#types-in-documentation","title":"Types in Documentation","text":"<ul> <li>Sphinx and autodoc with type hints</li> <li>Docstrings vs annotations</li> </ul>"},{"location":"A7_Book_Notes/#part-vi-real-world-applications","title":"\ud83d\udcd8 Part VI: Real-World Applications","text":""},{"location":"A7_Book_Notes/#typing-apis-and-libraries","title":"Typing APIs and Libraries","text":"<ul> <li>Public API surfaces</li> <li>Library development with types</li> </ul>"},{"location":"A7_Book_Notes/#using-types-in-frameworks","title":"Using Types in Frameworks","text":"<ul> <li>Django/Pydantic/FastAPI with typing</li> <li>Typing decorators and middleware</li> </ul>"},{"location":"A7_Book_Notes/#typing-concurrency","title":"Typing Concurrency","text":"<ul> <li><code>async def</code>, <code>Awaitable</code>, <code>Coroutine</code></li> <li><code>Thread</code>, <code>Process</code>, <code>Queue</code></li> </ul>"},{"location":"A7_Book_Notes/#cross-version-compatibility","title":"Cross-Version Compatibility","text":"<ul> <li>Using <code>typing_extensions</code></li> <li>Supporting older Python versions</li> </ul>"},{"location":"A7_Book_Notes/#common-pitfalls-and-anti-patterns","title":"Common Pitfalls and Anti-Patterns","text":"<ul> <li>Misusing <code>Any</code></li> <li>Over-annotating</li> <li>Annotations that hinder readability</li> </ul>"}]}