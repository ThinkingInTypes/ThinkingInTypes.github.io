{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"Thinking in Types   Building Stubbornly Resilient Python Code     by Bruce Eckel  <p>This is a work in progress. It is in early, rough form, especially the prose. However, the book development tooling is in place, so all examples are tested (If something doesn't work, please report it). My hope is that even during development, you will find the material useful. Pull requests welcome.</p> <p> \ud83d\udcd6 Table of Contents </p> <ul> <li>        Example Repository      </li> <li>        Issues &amp; Suggestions      </li> <li>        Pull Requests      </li> </ul> <p> \ud83e\udd8b Contact me on Bluesky</p>"},{"location":"C01_Preface/","title":"Preface","text":"<p>This is a work in progress. A lot of the material is rough and in early form, especially the prose. However, the book development tooling is in place, so all the examples are tested (If something doesn't work, I'll know about it). My hope is that even during development, you will find the material useful.</p> <p>At the beginning of the book Alice in Wonderland, Alice sees a white rabbit wearing clothing and holding a watch. The rabbit runs off, very concerned about being late for something, and Alice follows him. She falls down a rabbit hole, and this leads to many bizarre and complicated adventures. The story ends when she wakes up and realizes it was all a dream.</p> <p>This is the origin of the phrase \"going down a rabbit hole.\" I feel silly explaining it, but I've begun having getting-old experiences where I realize that something that was common earlier in my life has become so obsolete that all we are left with is obscure references--which I understand but younger people don't.</p> <p>A young friend rescued a typewriter from a dumpster, fascinated with all the physical mechanisms for stamping letters onto paper. But they were completely baffled by the way that paper got moved forward so you could start typing the next line. I demonstrated pushing the arm attached to the paper carriage; it not only advances the roller--that is, performs a \"line feed\"--but it also moves the carriage back to the starting position--a \"carriage return.\" I've seen the expressions in younger programmers when they realize that those words came from physical typewriters and that we still carry the terms in programming today despite there being no physical analogue anymore.</p> <p>At the beginning of my career, a huge portion of the programming world went down a rabbit hole called Object-Oriented Programming (OOP). That particular Wonderlandian dream has lasted for decades, but in recent years we've finally started waking up from it. I've had a number of conversations with fellow OOP teachers, and all of us are beginning to feel quite foolish that we didn't see the illusions earlier. But those illusions were both complex and compelling.</p> <p>This book is one attempt to help undo the damage produced by the illusion of OOP.</p>"},{"location":"C01_Preface/#whats-wrong-with-objects","title":"What's Wrong with Objects?","text":"<p>My first experience with OO programming was during the infancy of C++ in the mid-1980s. I was working in the School of Oceanography at the University of Washington under Tom Keffer, who had gotten a research grant to explore making programming easier. Our target audience was scientists and engineers, who were still primarily using Fortran, an acronym for FORmula TRANslation. Translating formulas into Fortran was an onerous process, and we hoped to create a system where the resulting code looked like the original math equations. The ability to create objects and to combine them with operators seemed very promising, so we settled on C++, even though it was in its infancy.</p> <p>The C++ compiler had to be physically mailed to us from Bell Labs; it might even have been Bjarne Stroustrup or Andrew Koenig who did the mailing. It arrived on a big tape reel, containing a C program that we had to compile with our local C compiler. The standardization of the C language was years away, and every machine had their own variant of C, so the C++ compiler had to be written in a common subset that would work with most C compilers.</p> <p>Compiling this program produced <code>cfront</code> which takes your C++ code and translates it into C code. You passed this generated C to your local C compiler to produce the resulting executable. This approach was brilliant because it worked atop the diaspora of C compilers available at that time.</p> <p>The language itself was brilliant because it was an evolution of the dominant C language. These days we are comfortable learning new and different languages. Back then, people were still getting comfortable with C--many had been assembly programmers, so the idea of a compiler was still strange. They had little interest in taking a chance on something that didn't feel like C.</p> <p>As I burrowed my way into this new language, I came across a mystery: the keyword <code>virtual</code>. Because <code>cfront</code> emitted C code, I was able to sleuth my way through the convoluted process of dynamic binding in a statically compiled language. Although this seemed like a weird thing to do, I reasoned that this very weirdness meant it must be especially important. And I, along with everyone else, began trying to understand what we were supposed to do with this new feature.</p> <p>This lead to writing books, teaching, and consulting about OOP. An industry grew up around it, and the reign of OOP influenced new languages--you had to have it.</p> <p>Teaching it was tough because you had to come up with introductory examples that made some kind of sense. If a class solved a problem but had no possibilities for inheritance, it didn't make the case for OOP, so we didn't use it. Shapes and pets and colors were repeated again and again.</p> <p>I still remember Bjarne Stroustrup saying \"user-defined types,\" and how powerful that sounded. He also made the distinction between object-based and object-oriented. The former turned out to be the very problem we wanted to solve, to liberate ourselves from the limitations of the language's built-in types. The latter turned out to be a huge distraction.</p> <p>The book Design Patterns: Elements of Reusable Object-Oriented Software appeared in 1994 and answered the question, \"what are we supposed to do with OOP?\" It was such a success that its four primary authors garnered the nickname Gang of Four, and \"GoF\" became the shorthand way to refer to the book.</p> <p>The GoF book showed that there were indeed many interesting ways to apply OOP to design problems. The question felt answered. However, upon closer inspection the design examples given in the book turned out to be rather obscure. And the most confounding thing was in the preface [check this] of the book, where they said \"Prefer composition to inheritance.\" After writing this complicated tome about OOP, they tried to convince us, right at the beginning, to avoid it.</p> <p>No one noticed the admonishment for many years because that was not the answer we were looking for. Asking \"how do I do this?\" and being answered \"don't\" is one of the more common jokes, and frustrating things, about programmers. So we forged ahead and dutifully struggled to understand the GoF patterns and how they might be applied to everyday software designs.</p> <p>I remember older programmers trying to point out that \"you don't really need that.\" Often I assumed they were just curmudgeons stuck in the past. But occasionally I wondered if they somehow saw or something that I was somehow missing.</p>"},{"location":"C01_Preface/#strong-typing-vs-strong-testing","title":"Strong Typing vs. Strong Testing","text":""},{"location":"C01_Preface/#tight-vs-permissive-type-systems","title":"Tight vs. Permissive Type Systems","text":""},{"location":"C01_Preface/#why-is-this-book-free","title":"Why is This Book Free?","text":"<p>When I began writing about programming, there were user manuals, but these weren't very good. Magazine articles and books were the primary way people found information. The demand was high, so it was relatively easy to become a book author. I'm sure I could have made a lot more money in computing in some other way, but:</p> <ol> <li>I enjoyed the process of discovery and of writing about it.</li> <li>I had convinced myself that this was a good path to becoming a consultant.</li> </ol> <p>Many years later, I've come to ponder point two and realized that I had jumped to a convenient conclusion based on point one. If I was starting out now to pursue consulting, I would instead ask a lot of questions, probably starting with an AI. I would then talk to individual consultants and small consulting firms, and maybe even work for one. Most importantly, I would try to get to the bottom of why I wanted to be a consultant; what need does it satisfy (other than making a living).</p> <p>In my case, the \"why\" is the need for connection and community and the need to be helpful. In the last 15 years, I've studied this thing called Nonviolent Communication (NVC) and taken a lot of enjoyable workshops on the subject. After becoming better at communicating, the biggest benefit of NVC is discovering your true needs. Once you know those, you can distinguish between needs and strategies--a strategy is one way to meet a need. We humans tend to get attached to strategies and often assume that the strategy is the need. However, if you can discover and focus on your needs, it opens possibilities. Paying attention to needs allows you to look at multiple strategies instead of getting stuck on the first one that pops into your head. You can evaluate strategies to see which ones are more or less possible, and which ones might meet your needs better.</p> <p>I've had some very enjoyable consulting experiences, but I wonder what things might have been like if I had seen and understood the difference between needs and strategies sooner.</p> <p>If you do want to contribute financially to the book, there are ways:</p> <ol> <li>Although the lowest price on Leanpub is <code>0$</code> and you are encouraged to use that, it's also possible to raise that    number.</li> <li>[Other ways? Contribute to the nonprofit? TBD]</li> </ol>"},{"location":"C01_Preface/#creating-this-book-in-the-open","title":"Creating This Book \"In The Open\"","text":"<p>A very significant benefit of giving the book away is that I can build it \"in the open.\" That is, I can publish it on the web as I'm creating it. This produces:</p> <ol> <li>Feedback. My most successful books, Thinking in C++ and Thinking in Java, were both tested on audiences many    times before they were published in print.    Getting feedback as early as possible, and as the book evolved, was essential in making them what they were.</li> <li>Promotion. People are happy to tell other people about something they like that is free. There's no way to corrupt    recommendations if there's no cost.</li> <li> <p>Availability. Giving away Thinking in Java in the late 90's meant that anyone in the world who had an internet    connection could get it,    especially countries where books were expensive or prohibited in some way. And this produced more feedback.</p> </li> <li> <p>A \"Business Model\" can be about more than just money</p> </li> <li>My goal is to create experiences. I'm not sure what form they might take, but perhaps it will be helping teams design   types and architect their software.</li> </ol>"},{"location":"C01_Preface/#yes-i-used-ai","title":"Yes, I Used AI","text":"<p>This is the first book I've written with AI, and it's been massively helpful. I've used it every way that I can. It has dramatically sped up the development of the book and my understanding of the material.</p> <p>AI has been a tremendously useful assistant, far better than what we've had in the past, but:</p> <ol> <li>I've still had to come up with the questions.</li> <li>I've had to check, correct, and rewrite everything it's produced.</li> </ol> <p>To create this book, I've been as lazy as I've known how. But as with any book, I've developed a deep understanding of the topic by writing it. And if I've \"cheated\" by using AI, well, you can use the book for free, so it doesn't bother me.</p> <p>The Jevons Paradox, named after the English economist William Stanley Jevons, who identified it in 1865. Jevons observed that as coal use became more efficient, particularly with the invention of the Watt steam engine. Coal consumption increased rather than decreased. Increased efficiency in using a resource tends to increase (rather than decrease) the total consumption of that resource. Rebound effects: expected gains from efficiency are offset by behavioral or economic responses. As AI makes programmers more efficient in creating systems, the demand for programmers will increase.</p> <p>I used to have a bookcase full of computer programming books. Then it became much easier to search the internet for answers than look at books. Eventually, I got rid of most of my books. It's now become much easier to ask questions of an AI and have it generate examples and prose (although both must be rewritten). So I will tend to use AI more than other resources, still verifying as I did with those other resources. Using the AI has taught me to be better at asking questions, and I hope this book might do the same for you.</p> <p>I've enjoyed writing books, but perhaps because of AI, this will be my last one. Perhaps I will hand over the teaching of programming to AI. If that happens, it means that I will have moved on to building tools for programmers and building systems for non-programmers. Ultimately, that will be more useful than writing books about programming. I look forward to it.</p>"},{"location":"C01_Preface/#acknowledgements","title":"Acknowledgements","text":"<p>Most of the understanding I needed to explain this topic came from my attempts to help on the book Effect-Oriented Programming with Bill Frasure and James Ward, that we worked on for over four years. I\u2019ve also learned a lot from some of the interviews that James and I have done for the Happy Path Programming podcast.</p>"},{"location":"C02_Foundations/","title":"Foundations","text":"<p>[Primarily notes at this point; I find that the introduction doesn't usually emerge until later in the book writing process]</p> <p>In the before times, programming is like playing a kart-racing game. You hop in your cart and drive as fast as you can, controlling the kart with the steering wheel and brakes. Crashes are spectacular, spewing parts across the landscape. You figure out what went wrong by hunting through the remnants of the crash, but it's more common to make a guess as to what happened, adjust something and go back to the starting line.</p> <p>A new breed of racers show up. They carry helmets and install three-point seat belts. They add bumpers and turn signals and even radios to communicate with each other. Their carts become cars, filled with devices that make it look like they don't plan to crash, but to finish the course without a scratch. The occasional crash does happen. They add even more devices to their cars.</p> <p>They start driving in teams, and those teams get bigger as they use their mechanisms to cooperate. They start building bigger cars out of smaller cars, and eventually outgrow the original track with the size and complexity of what they can create.</p> <p>Not all the original cart racers see value in all this gadgetry. Some prefer the danger of driving all-out without safety features and guardrails, and the thrill of the crash. These racers are limited to a smaller track.</p>"},{"location":"C02_Foundations/#the-evolution-of-complex-systems","title":"The Evolution of Complex Systems","text":"<p>Starting with assembly language. Subroutines to save space, no intrinsic arguments and returns. C was more than high-level assembly because it automated function arguments and returns.</p> <p>\"Goto Considered Harmful\" and the transition to functions as independent packages of code.</p> <p>Other code management developments: scoping in general, namespaces, exceptions.</p>"},{"location":"C02_Foundations/#object-oriented-programming","title":"Object-Oriented Programming","text":"<p>User-defined types plus the huge distraction of inheritance. GoF was so popular because it finally showed people what to do with inheritance, although most cases were rather specialized solutions to non-mainstream problems. Ultimately, inheritance creates more problems than solutions; it is occasionally helpful but usually not more than one level; deeper inheritance designs are challenging to use and maintain, and rarely provide enough benefits to justify their use.</p> <p>Domain-Driven Design was an early step away from inheritance and towards types, but it has been a slow process.</p> <p>Objects are useful as, to quote Stroustrup, \"user-defined types,\" but as the GoF say in their introduction, \"prefer composition to inheritance.\" In this book, Python's Objects will be used as types and not base classes. Anything that looks like inheritance will only be to create a type of something. For example, the syntax of creating an enumeration looks like inheritance:</p> <pre><code># enumeration_definition.py\nprint(\"Can you inherit from an Enum?\")\n## Can you inherit from an Enum?\n</code></pre> <p>A NamedTuple is also defined in a way that looks like inheritance (other examples).</p>"},{"location":"C02_Foundations/#the-wall-we-keep-hitting","title":"The Wall We Keep Hitting","text":"<p>Putting small pieces together into larger pieces. Sticking lumps of modeling clay together vs. assembling Legos.</p>"},{"location":"C02_Foundations/#strong-typing-vs-strong-testing","title":"\"Strong Typing vs. Strong Testing\"","text":"<p>What is strong typing?</p>"},{"location":"C02_Foundations/#scalability","title":"Scalability","text":"<p>The Scala language: a research project into type systems. Scala: \"Scalability\" It seems like Python's type system is primarily inspired by Scala. Scala leverages the JVM, which was a smart way to rapidly create an implementation of a language. Being backwards compatible with Java, however, constrained Scala's design. As strange as it sounds, Python doesn't have those constraints because its type system is optional. Because of this optionality, Python's type system can effectively start from nothing and go anywhere it needs to, unhindered by the constraints of compatibility with an existing language.</p> <p>Path as an example of a type (you don't typically inherit it)</p>"},{"location":"C02_Foundations/#who-this-book-is-for","title":"Who This Book Is For","text":"<p>Assumptions I make about your Python &amp; programming knowledge.</p>"},{"location":"C02_Foundations/#your-python-knowledge","title":"Your Python Knowledge","text":"<ul> <li>You have intermediate-level understanding of the language, including a reasonable grasp of classes</li> <li>You understand core language features and know how to look up and learn features you haven't seen</li> <li>I will explain things I think are outside the core</li> </ul>"},{"location":"C02_Foundations/#this-book-uses","title":"This book uses","text":"<ul> <li>Version control with GitHub</li> <li>Project management with uv</li> <li>Testing with Pytest (noting that there are valid reasons to use other systems)</li> <li>Project organization (flat directory for examples distro)</li> <li>Standard tools for code consistency, such as <code>ruff</code></li> <li>Tested against multiple type checkers: Pycharm (builtin), PyRight, Mypy, Pyre, (Astral one when available)</li> <li>Invoke as a build system</li> <li>Developed on Windows, tested on Windows/Linux (should work fine on Mac)</li> </ul>"},{"location":"C02_Foundations/#programming-philosophy","title":"Programming Philosophy","text":"<ul> <li>Build up from small testable pieces, balanced with simplicity and clarity.</li> <li>Use the most modern/elegant coding mechanisms available (latest Python)</li> <li>Classes are for creating types.   As much as possible, pretend inheritance doesn't exist.</li> <li>Performance issues can be solved (sometimes by converting types or functions to Rust)</li> <li>Minimize Hungarian notation: a typed identifier name does not need to include the type information in its name.</li> </ul>"},{"location":"C02_Foundations/#examples","title":"Examples","text":"<ul> <li>Each example has a slug line: the name of the file in a single-line comment as line one of the example.</li> <li>That example is in the GitHub repository in a subdirectory named for the chapter.</li> <li>The examples do not have <code>__main__</code>s; everything is at the top level.</li> <li>If a top-level-statement (TLS) produces output, that output will appear on the following line(s), commented with <code>##</code>.</li> <li>Lines to be called out in text are marked with comments</li> <li>Black or Ruff for consistent formatting</li> <li>Listings 47 Characters wide: readable on a phone</li> </ul>"},{"location":"C03_What_is_a_Type/","title":"What is a Type?","text":"<p>A type is a set of values. It classifies and categorizes data. It can also define operations.</p> <p>One reason we define types is to ensure correctness of what those types hold. A type creates its own namespace and scope, which makes it easier to reason about your code.</p>"},{"location":"C03_What_is_a_Type/#defining-type-in-programming","title":"Defining \"Type\" in Programming","text":"<p>The <code>int</code> type allows arithmetic operations like addition or subtraction, while the <code>str</code> type supports operations like concatenation. Types give meaning to data and inform the program (and the programmer) what kinds of behavior are valid for that data. If a piece of data is labeled as an <code>int</code>, the language knows it can perform numerical calculations on it; if it's a <code>str</code>, operations like splitting or joining make sense.</p> <p>In Python, types are associated with values, not with variables. You don't explicitly declare variable types; instead, any variable can reference any object, and that object carries its type with it.</p> <p>In Python, an object knows its type. You can always check that type at runtime using the built-in <code>type()</code> function or <code>isinstance()</code> function:</p> <pre><code># example_1.py\nprint(type(42))\n## &lt;class 'int'&gt;\nprint(type(\"Hello\"))\n## &lt;class 'str'&gt;\nprint(isinstance(42, int))\n## True\nprint(isinstance(\"Hello\", int))\n## False\n</code></pre> <p>The calls to <code>isinstance</code> confirm that 42 is indeed an <code>int</code> and that the string <code>\"Hello\"</code> is not an <code>int</code>. Types determine what operations are allowed; for instance, you can multiply integers, but multiplying two strings is not defined (except to repeat the string).</p> <p>Types act as a contract or promise about data. If a function expects a certain type, providing data of the wrong type can lead to errors. For example, giving a text string to a mathematical formula that expects a number will cause problems. In short, a type defines both a set of values and the permitted operations on those values, setting the stage for how data is used in a program.</p> <p>Python comes with a rich set of built-in types (numbers, strings, lists, dictionaries, etc.). You can also define custom types (classes) for more complex data. This chapter focuses on what a \"type\" means and how Python's approach to types influences how we write and maintain code.</p>"},{"location":"C03_What_is_a_Type/#dynamic-vs-static-typing","title":"Dynamic vs. Static Typing","text":"<p>One of the core distinctions in programming language type systems is dynamic typing vs. static typing. Python is a dynamically typed language, whereas languages like C++ or Java are typically statically typed. Let's unpack what that means and the pros and cons of each approach.</p> <ul> <li> <p>Statically Typed Languages: In a statically typed language, the type of each variable and expression is determined at compile time (before the program runs).   You usually must declare the types of your variables (e.g., in Java: <code>int count = 5;</code>).   The compiler uses these declarations to verify that you are using variables in a type-safe way.   If you attempt an invalid operation, like adding a number to a string, a compile-time error is raised and the program won't run until the error is fixed.   In short, static type checking finds type errors by analyzing the program's source code before execution.   This early detection can prevent many runtime errors.   Static typing can also enable performance optimizations, since knowing the types in advance allows the compiler to produce more efficient machine code (for example, it doesn't need to check types   during each operation at runtime).</p> </li> <li> <p>Dynamically Typed Languages: In a dynamically typed language, the variable type is allowed to change over its lifetime, and type checks are done at runtime.   You do not have to declare types explicitly.   For example, in Python you can do:</p> </li> </ul> <pre><code># example_2.py\nx = 10  # x is an int\n# Reassign to a different type (str):\nx = \"hello\"  # type: ignore\nprint(x)  # Output: hello\n## hello\n</code></pre> <p>Python will infer the type of <code>x</code> from whatever value it's holding at the moment. Here <code>x</code> started as an integer and later became a string. This is perfectly valid in Python. The flexibility of dynamic typing makes it easy to write quick scripts and prototypes because you don't have to constantly specify types--the interpreter figures it out as the program runs.</p> <p>The example above shows Python's dynamic nature: you can assign a value of any type to <code>x</code>, and later even assign a value of a different type to the same <code>x</code>. However, this flexibility comes at a price. Because type checks are done as the code runs, if you perform an operation that the data type doesn't support, you'll only find out at runtime (perhaps causing your program to crash if not handled). For instance:</p> <pre><code># example_3.py\nfrom book_utils import Catch\n\nx = 10\nwith Catch():\n    # Can't add a str to an int:\n    result = x + \"world\"  # type: ignore\n</code></pre> <p>We attempted to \"add\" <code>\"world\"</code>, a <code>str</code>, to <code>x</code>, an <code>int</code>. Python only discovers the problem while running the line: realizing it can't add an <code>int</code> and <code>str</code>, it throws a <code>TypeError</code> exception. In a statically typed language, such an error would be caught before running the program (the code wouldn't compile).</p> <p>To summarize the difference:</p> <ul> <li>In static typing, type errors are caught early--before the program runs--which can make debugging easier and programs more reliable.   You also get better documentation from explicit type annotations in code.   But static typing requires more upfront work: declaring types and sometimes contending with more rigid code, which can slow down initial development or make code less flexible to change.</li> <li>In dynamic typing, you get more flexibility--you can write code faster without specifying types everywhere, and the same variable can hold different types of data over its lifetime.   This is great for quick iterations and when you want to write generic code.   The downside is that type-related mistakes are only caught when that line of code runs, which might be far into a program's execution.   This can lead to runtime errors and sometimes makes large codebases harder to reason about (you have to remember or check what type a variable might be at a given point).</li> </ul> <p>It's important to note that dynamic vs. static is about when type checking happens (at runtime vs. compile time). It's independent of strong vs. weak typing; Python is strongly typed--it won't implicitly convert types for you in unchecked ways (except for truthiness, which can be disallowed). Trying to add a number to a string is not permitted, as Python won't guess that maybe you meant <code>\"10\" + \"world\"</code>. In Python, values have a definite type, and you can't treat a value as a different type without an explicit conversion. Many static languages are also strongly typed, but some languages are weakly typed (they might, for instance, automatically convert strings to numbers in certain contexts, which can lead to subtle bugs). The key takeaway is that Python is dynamically and strongly typed: type checks happen at runtime, and the interpreter will raise an error if you attempt an operation on incompatible types.</p>"},{"location":"C03_What_is_a_Type/#duck-typing-in-python","title":"Duck Typing in Python","text":"<p>Python's dynamic typing is closely related to the idea of duck typing. The name comes from the phrase \"If it looks like a duck and quacks like a duck, it must be a duck.\" In programming, duck typing means that an object's suitability for an operation is determined by the presence of certain methods or properties, rather than the type of the object itself. In other words, \"an object is considered compatible with a given type if it has all the methods and attributes that the type requires.\" The class or inheritance of the object is less important than whether it implements the interface. This is a very Pythonic idea: \"don't check an object's type to determine if it has the right interface; just try to use it, and it will either work or fail.\"</p> <p>Duck typing means you often write functions that work on any object that supports the operations you need, rather than only working on specific classes. For example, consider a function that makes an object quack:</p> <pre><code># duck_typing.py\nclass Duck:\n    def quack(self):\n        print(\"Quack!\")\n\n\nclass Car:\n    def quack(self):\n        print(\"I can quack, too!\")\n\n\ndef quacks(entity):\n    entity.quack()\n</code></pre> <pre><code># duck_typing_demo.py\nfrom duck_typing import Duck, Car, quacks\n\ndonald = Duck()\nstudebaker = Car()\nquacks(donald)\n## Quack!\nquacks(studebaker)\n## I can quack, too!\n</code></pre> <p><code>Duck</code> and <code>Car</code> each have a <code>quack()</code> method. The function <code>quacks(entity)</code> calls <code>entity.quack()</code> without caring what type <code>entity</code> is. Thanks to duck typing, both a <code>Duck</code> instance and a <code>Car</code> instance can be passed to <code>quacks</code> and it will work, as long as they implement <code>quack()</code>. The <code>quacks(donald)</code> call prints \"Quack!\", and <code>quacks(studebaker)</code> prints \"I can quack, too!\", even though <code>studebaker</code> is not a Duck--it's a Car that happens to know how to quack. The function didn't check types; it just invoked the method.</p> <p>But what if we call <code>quacks(42)</code> (an integer)? An int has no <code>quack()</code> method, so Python will raise an <code>AttributeError</code> at runtime (e.g., \"<code>'int' object has no attribute 'quack'</code>\"). This demonstrates duck typing's approach: \"it's better to ask for forgiveness than permission.\" We just try to use the object in a duck-like way. If it quacks, great. If not, Python throws an error, and we handle that (or let it propagate). In code, you might handle this with try/except:</p> <pre><code># example_5.py\nfrom duck_typing import quacks\n\ntry:\n    quacks(42)\nexcept AttributeError as e:\n    print(f\"Oops: {e = }\")\n## Oops: e = AttributeError(\"'int' object has no attribute 'quack'\")\n</code></pre> <p>In Python, it's idiomatic to write code that assumes objects have the right methods (duck typing) and deal with exceptions if they don't, rather than explicitly checking types upfront.</p> <p>Duck-typed functions are extremely flexible. Many Python libraries and built-in functions use duck typing so that they can work with a variety of object types as long as those objects support the expected interface. For example, Python's file-handling functions don't require an object to be a specific \"File\" class--they just require an object that implements the file interface (methods like <code>.read()</code> or <code>.write()</code>). As long as the object passed in has those methods, the function will work.</p> <p>However, duck typing can sometimes make it harder to reason about code in large projects--because any object with a <code>quack</code> method will do, you might accidentally pass the wrong object to a function and only find out at runtime. This is where the balance between flexibility and safety comes into play, which leads us to the evolution of Python's type system in recent years.</p>"},{"location":"C03_What_is_a_Type/#from-duck-typing-to-type-annotations","title":"From Duck Typing to Type annotations","text":"<p>Historically, Python has been a dynamically typed language. The language didn't have a way to explicitly declare the type of variable or function parameter in code. Developers used documentation or naming conventions to indicate expected types (for example, a comment like <code># param x is an int</code>), but these were not enforced. As codebases grew, this lack of explicit type information started to become a pain point for some projects. It's easy to lose track of what types are flowing through the code, which can lead to bugs or make the code harder to maintain.</p> <p>Python 3.5 introduced optional syntax for adding type annotations to your code. These are optional annotations that you can add to function definitions, variables, and class attributes to declare what type they are supposed to be. Crucially, these type annotations do not change how the code runs; Python remains dynamically typed at runtime. The annotations are mainly for the benefit of the developers and tooling.</p> <p>For example, here's a function without type annotations, and then with type annotations:</p> <pre><code># example_6.py\n# Without type annotations:\ndef greet1(name):\n    return \"Hello, \" + name\n\n\n# With type annotations:\ndef greet2(name: str) -&gt; str:\n    return \"Hello, \" + name\n</code></pre> <p>In the second version, the <code>str</code> in <code>name: str</code> and <code>-&gt; str</code> is a type annotation. It indicates that <code>name</code> should be a string, and that the function returns a string. If you run this code, Python will not enforce that <code>name</code> is a string--if you pass an integer, it will still run, and likely error out only when it tries to do <code>\"Hello, \" + 5</code>. In other words, type annotations don't make Python statically typed. They are metadata attached to the functions and variables. The official Python documentation makes this clear: the Python runtime does not enforce function and variable type annotations; they are meant to be used by third-party tools (like type checkers, IDEs, linters).</p> <p>The benefits of type annotations are seen during development: they serve as documentation and enable static analysis tools to catch errors before running the code. By reading the annotated <code>greet</code> function, a developer (or an IDE) immediately knows that <code>name</code> is expected to be a string, which improves readability. If somewhere else in the code we call <code>greet(123)</code>, a type-checking tool can warn us that we're calling <code>greet</code> with the wrong type of argument.</p> <p>A type checker will catch this:</p> <pre><code># example_7.py\nfrom book_utils import Catch\n\n\ndef add(a: int, b: int) -&gt; int:\n    return a + b\n\n\nprint(add(10, 5))\n## 15\nwith Catch():\n    add(10, \"5\")  # type: ignore\n</code></pre> <p>The second call <code>add(10, \"5\")</code> is a mistake: we intended both arguments to be <code>int</code>s. Running this code would produce a runtime error when trying to add an integer to a string (<code>TypeError: unsupported operand type(s) for +: 'int' and 'str'</code>). A static type checker, however, would catch this before running the program. For instance, Mypy (one of the most popular Python type checkers) would emit an error like: <code>error: Argument 2 to \"add\" has incompatible type \"str\"; expected \"int\"</code>. This early detection of the bug can save you from having to debug a runtime crash.</p> <p>Python's adoption of type annotations has been gradual and very much optional. You can start adding types to a few functions, or even one variable at a time. This approach is sometimes called gradual typing or optional static typing. The designers of Mypy describe it as an attempt to \"combine the benefits of dynamic (or 'duck') typing and static typing.\" You don't have to choose one or the other for the whole program; you can get the flexibility of dynamic typing where needed, and the safety/net of static typing where it helps. Python will happily run code with or without type annotations, and you can mix annotated and unannotated code freely. This means you can adopt type annotations in a legacy codebase incrementally or use them only for the trickiest parts of a new project.</p> <p>Over the past several Python releases (3.5 through 3.13), the type annotation syntax and capabilities have expanded significantly. For instance, you can annotate variables (since Python 3.6) in addition to function params and returns:</p> <pre><code># example_8.py\ncount: int = 0\n# list[str] instead of typing.List:\ntexts: list[str] = [\"hello\", \"world\"]\n</code></pre> <p>You can use union types with nice shorthand. Python 3.10 introduced the <code>|</code> operator for types, so instead of writing <code>typing.Union[str, bytes]</code> you can just write <code>str | bytes</code>:</p> <pre><code># example_9.py\nfrom pathlib import Path\n\nfrom book_utils import Catch\n\n\ndef is_file(file: str | Path) -&gt; bool:\n    # Converts string or Path to a Path object:\n    p = Path(file)\n    return p.exists() and p.is_file()\n\n\n# Works with a string path:\nprint(is_file(\"nonexistent.txt\"))\n## False\n# Works with a Path object:\nprint(is_file(Path(\"nonexistent.txt\")))\n## False\nwith Catch():\n    # Raises TypeError, static checker flags it:\n    is_file(12345)  # type: ignore\n</code></pre> <p>The function <code>is_file</code> can accept either a file path as a normal string or a <code>Path</code> object (from the <code>pathlib</code> module)--thanks to the union type <code>str | Path</code>. Inside the function we convert whatever it is to a <code>Path</code> for uniform processing. Passing an integer produces an error when trying to make a <code>Path(12345)</code>, because an <code>int</code> isn't a valid path. The type checker tells us about this right away, and very specifically. Waiting until runtime produces errors that take time and effort to untangle.</p> <p>The standard library <code>typing</code> module provides many advanced types and constructs, which we cover in later chapters:</p> <ul> <li>Generics (like <code>list[int]</code> or <code>dict[str, int]</code>)</li> <li><code>Optional[X]</code> (shorthand for <code>X | None</code> in newer Python versions)</li> <li><code>Literal</code> types (specific allowed values)</li> <li><code>TypedDict</code> (dicts with specific shape)</li> <li>protocols (PEP 544) static duck typing (you can define an interface that says \"this type must have methods X, Y, Z\" without caring about inheritance).</li> </ul>"},{"location":"C03_What_is_a_Type/#typing-is-optional","title":"Typing is Optional","text":"<p>Python's type annotations are optional and ignored at runtime. They are a developer tool. The interpreter will not refuse to run your program if the types don't match:</p> <pre><code># example_10.py\nvalue: float = 3.14159\n# Reassign to str:\nvalue = \"Pi\"  # type: ignore\nprint(value)\n## Pi\n</code></pre> <p>We annotated <code>value</code> as a float, but then assigned a string to it. Python does not enforce the annotation--the code runs and <code>value</code> ends up as <code>\"Pi\"</code>. A type checker warns about that reassignment, but Python itself doesn't mind. Adding type annotations doesn't change Python's runtime behavior unless you use additional frameworks or decorators to enforce types at runtime.</p>"},{"location":"C03_What_is_a_Type/#why-use-type-annotations","title":"Why Use Type Annotations?","text":"<p>If type annotations are optional, why bother with them? They produce significant benefits, especially for larger projects:</p> <ul> <li> <p>Clarity and Readability: Type annotations serve as documentation.   When you see a function signature <code>def process(data: list[str]) -&gt; bool</code>, it's immediately clear what is expected: a list of strings goes in, and a boolean comes out.   You don't have to read through the function body or comments to guess the types.   This makes it easier for others (and yourself, in the future) to understand the code's intent.   Type annotations are a form of documentation.</p> </li> <li> <p>Early Error Detection: Perhaps the biggest practical advantage is catching bugs before running the code.   Type checkers catch mistakes while you're coding.   This is especially useful in large codebases where you might change something in one module and inadvertently break an assumption in another.   A type checker can often catch such issues at build time or in your editor, rather than letting them slip into runtime.   This early detection of type errors significantly improves code reliability.</p> </li> <li> <p>Better IDE/Editor Support: Modern editors and IDEs (like VSCode, PyCharm, etc.) use type information to provide features like autocompletion, jump-to-definition, and inline error highlighting.   If you declare types, the IDE can help you more.   For instance, if a function returns an <code>Employee</code> object, and you've annotated that, the IDE can auto-suggest <code>employee.</code> methods and attributes when you use the result, because it knows the type.   It can also immediately warn you if you try to call a list method on something that's annotated as a string, for example.   Type information makes tooling smarter and developer experience better.</p> </li> <li> <p>Refactoring and Maintenance: When you or someone else needs to modify code, type annotations act as a safety net.   They make it harder to misuse a function or variable inadvertently.   If you change a function's expected types, all the callers that pass the wrong type will light up in your type checker.   This makes large-scale refactoring more manageable--you can confidently change the internals of a function or module and rely on the type system to tell you if something incompatible is being done   somewhere else.   This leads to more maintainable code in the long run.</p> </li> <li> <p>Communication of Intent: Sometimes you might intentionally allow multiple types (using a union) or a very generic type (like <code>Any</code> or a base class).   Other times you expect a very specific protocol.   Writing that down in code via annotations communicates your intent to anyone reading it.   It also communicates to static analysis: \"I intend this to be of type X,\" so if later the code violates that intent, it can be flagged.</p> </li> </ul> <p>That said, there are some downsides or challenges with type annotations to be aware of:</p> <ul> <li> <p>Initial Overhead: Writing annotations means more typing (pun intended).   It can slow down the speed of writing code, especially for quick scripts or one-off tasks where the overhead might not be worth it.   However, many find that for anything beyond small scripts, the time spent adding type annotations is paid back in time saved debugging.</p> </li> <li> <p>Learning Curve: Python's typing system has grown quite rich, with generics, protocols, type variables, etc.   Using these effectively may require learning new concepts.   For intermediate Python programmers, there's a learning curve to understanding things like <code>Optional</code>, <code>Union</code>, or generics.   The good news is you can start annotating basic types and only delve into advanced typing features as needed.</p> </li> <li> <p>Runtime Overhead: By default, there is virtually no runtime overhead for having type annotations (since Python ignores them at runtime).   However, if you use certain libraries or decorators to enforce type checking at runtime, those will add overhead.   Also, importing the <code>typing</code> module historically had some minor import-time cost (which has been reduced in recent Python versions), but generally this is not a big issue.</p> </li> <li> <p>False Sense of Security: It's worth remembering that type annotations are not a cure-all.   You can annotate everything and have a clean bill of health from the type checker, and your program can still have bugs (logic errors, runtime issues unrelated to types, etc.).   Also, if you're interfacing with dynamic parts of Python (like using <code>hasattr</code> or doing dynamic attribute setting, or dealing with JSON data), the type checker might not catch misuse because you   might be using <code>Any</code> or ignoring types in those spots.   So, use type annotations as a helpful tool but still test and validate your code.</p> </li> </ul> <p>Overall, the Python community has increasingly embraced type annotations because the benefits (especially for larger projects) have proven valuable: fewer bugs, easier collaboration, improved code quality. It's a way to get some advantages of statically typed languages without giving up Python's dynamic flexibility entirely.</p>"},{"location":"C03_What_is_a_Type/#static-type-checkers-mypy-pyright-and-friends","title":"Static Type Checkers: <code>mypy</code>, <code>PyRight</code>, and Friends","text":"<p>Type annotations by themselves do nothing unless you use a tool to check those annotations against your code. While you might visually inspect code and spot a type mismatch, it's much more reliable to use automated tools. Two of the most popular type checking tools for Python are MyPy and PyRight.</p> <ul> <li> <p>Mypy: Mypy has been around since the early days of Python's gradual typing experiment (it was developed alongside PEP 484).   It's a command-line tool (and a library) that you run on your Python code (or integrate into your editor/IDE) to static-check the types.   Mypy reads your <code>.py</code> files, interprets the type annotations, and reports any inconsistencies or errors.   For example, if you have <code>def func(x: int) -&gt; None:</code> and somewhere you call <code>func(\"hello\")</code>, mypy will catch that and report an error.   Mypy aims to be strict and thorough, catching subtle issues (it even tries to infer types of variables where possible and can warn if you, say, add a string and int without any annotations given, etc.).   The philosophy of mypy is to let you start with little to no annotations and gradually add them--it will treat unannotated code as basically <code>Any</code> types by default (which don't produce errors), and   as you add annotations, it will enforce them.   As the official mypy documentation states, it \"is an optional static type checker for Python that aims to combine the benefits of dynamic (or 'duck') typing and static typing.\"   You can run mypy as part of your development or CI (Continuous Integration) to prevent type regressions in a codebase.</p> </li> <li> <p>PyRight: PyRight is a newer type checker, open-sourced by Microsoft.   It is known for speed and is designed to handle large projects efficiently.   PyRight powers the Python type checking in Microsoft's VSCode editor (the PylLance extension).   PyRight is written in TypeScript (running on Node.js), which might sound unusual, but it means it's optimized for speed and can do things like watch files and re-check only what changed, etc.   PyRight is also fully aware of all the latest PEPs and typing features.   According to its documentation, \"PyRight is a full-featured, standards-based static type checker for Python.   It is designed for high performance and can be used with large Python source bases.\"   Many developers use PyRight via their editor for instant feedback as they code (and/or in CI as well).   For instance, as you're coding, PyRight can underline an inconsistent call in red immediately.   PyRight is also available as a command-line tool (via npm) if you prefer that route.   One of its selling points is performance--it's been noted to be much faster than mypy on large codebases, though for small-to-medium projects both tools run quickly enough.</p> </li> </ul> <p>Both mypy and PyRight adhere to Python's typing rules (PEP 484 and successors) pretty closely. There are some minor differences and configuration options (for example, how strict they are about certain default behaviors, or handling of untyped code). Some teams use one, some use the other, and some even use both (one as an editor linter for speed, another as a final check in CI for thoroughness). The good news is you don't need to lock yourself in--you can try them out and see which fits your workflow.</p> <p>Aside from mypy and PyRight, there are other tools worth mentioning:</p> <ul> <li>PyCharm and Other IDEs: PyCharm has its own built-in type checker that uses the same type annotation information to warn about issues.   It's not as configurable as mypy/PyRight, but it often catches many of the same things in real-time.</li> <li>Pylint and Flake8: These are linters that primarily focus on code style issues, but they have basic type checking rules or plugins (e.g., Pylint can catch some obvious type errors, though it's   not as comprehensive as a dedicated type checker).</li> <li>Pyre: A type checker from Facebook (written in OCaml).   It's also fast and aimed at large applications.   Its usage is less widespread in the community compared to mypy/PyRight, but it's an alternative.</li> <li>TypeGuard, Enforce, etc.: These are runtime type checking helpers.   For example, TypeGuard is a library that can be used to enforce type annotations at runtime by wrapping functions (so if someone calls <code>func(\"hello\")</code> when it expects an int, it will raise an error at   call time).   These can be useful in specific scenarios, but generally static checkers are more common in Python since runtime checks negate some of the performance benefits of dynamic typing.</li> </ul> <p>As an example of using a type checker, imagine we save the earlier <code>add</code> function example in a file and run a checker:</p> <pre><code># example_11.py\nfrom book_utils import Catch\n\n\ndef add(a: int, b: int) -&gt; int:\n    return a + b\n\n\nprint(add(10, 5))\n## 15\nwith Catch():\n    # Second arg is not an int:\n    add(10, \"5\")  # type: ignore\n</code></pre> <p>If we run mypy on this file, we might get an output like:</p> <pre><code>error: Argument 2 to \"add\" has incompatible type \"str\"; expected \"int\"\nFound 1 error in 1 file (checked 1 source file)\n</code></pre> <p>This tells us what and where the problem is. We can then fix the code (e.g., by converting <code>\"5\"</code> to an integer, or by correcting the input).</p> <p>The use of these tools ties back to the earlier benefits. By acting as an automated guardrail, they produce overall code quality improvement through:</p> <ul> <li>maintainability</li> <li>readability</li> <li>safety</li> <li>early error detection</li> <li>enhanced tooling support</li> <li>better documentation</li> </ul>"},{"location":"C03_What_is_a_Type/#runtime-vs-static-type-checking","title":"Runtime vs. Static Type Checking","text":"<p>Let's clearly distinguish between runtime type checking and static type checking, because this is crucial to understanding Python's type system:</p> <ul> <li> <p>Runtime Type Checking: This is what Python does natively.   The interpreter checks types on the fly as operations are executed.   If you try to do something invalid (like call a method that doesn't exist or use an operator on incompatible types), Python will raise an error at that moment.   For example, if you do <code>3 + \"3\"</code>, Python immediately raises a <code>TypeError</code> when it hits that line, because it finds an integer and a string and doesn't know how to add them.   Another example: calling <code>quacks(42)</code> in the earlier duck typing example raised an <code>AttributeError</code> at runtime, because 42 didn't have the required method.   Runtime type checking is built into the language's operations.   When you do something with an object, the object's type (or more precisely, its capabilities) determines what happens.   Python will never silently do the wrong thing with a wrong type; it will error out (that's part of being strongly typed).   But the key is, these errors happen during execution.</p> </li> <li> <p>Static Type Checking: This does not happen by default in Python--it's something you opt into by writing type annotations and using external tools.   Static checking means examining the code without running it and ensuring that, according to the type annotations and language rules, the operations make sense.   It's like a dry run of the program in terms of types.   If you say a function returns an <code>int</code> but you return a <code>str</code> somewhere, a static checker can catch that.   If you pass the wrong type to a function, it's caught before running.   This is what mypy, PyRight, etc., do.   They look at your code as data, not as a running program.   The Python interpreter itself does not do static analysis--it doesn't look at annotations and refuses to run the program.   You (or your development environment) have to invoke a tool to get static checking.   This is why we call Python's type system \"gradual\" or \"optional static typing\"--the static part is bolted on by tools, not enforced by the language runtime.</p> </li> </ul> <p>One consequence of this design is that you can have a program that passes all static type checks but still crashes or behaves incorrectly at runtime if you made an assumption that wasn't guaranteed by the language. Conversely, you might have a program that does something tricky that the static checker flags as a possible type issue, but at runtime it never fails because of the particular way you use it. In those cases, you can often adjust your type annotations or use casts/<code># type: ignore</code> comments to tell the checker \"trust me, I know what I'm doing here.\" This disconnect between static analysis and running code is something to be aware of--it's the price of keeping the type system optional. A quote from Python's documentation highlights this separation: _\"The Python runtime does not enforce function and variable type annotations. They can be used by third party tools such as type checkers, IDEs, linters, etc.\" In other words, if you want enforcement of those annotations, you need to use a tool (or implement your own checks).</p> <p>Consider:</p> <pre><code># example_12.py\ndef f(x: int) -&gt; int:\n    return x * 2\n\n\nprint(f(5))  # Correct type\n## 10\n# Expected type 'int', got 'str' instead:\nprint(f(\"hi\"))  # type: ignore\n## hihi\n# Strings can be \"multiplied\"\n</code></pre> <p>This example is a bit tricky--Python will not error on <code>f(\"hi\")</code> because <code>\"hi\" * 2</code> in Python is valid (it repeats the string, resulting in <code>\"hihi\"</code>). So our type annotation said <code>x</code> should be an int, but we passed a str, and Python didn't crash--it did something that perhaps we did not intend. A static type checker would have warned us that <code>f(\"hi\")</code> is not consistent with the annotation. If this were a bug (say we truly only wanted numbers there), the static check catches it, whereas at runtime Python happily did something else. If we had a case where passing a wrong type would crash (e.g., <code>f(None)</code> fails since <code>None * 2</code> is invalid), a static checker warns you.</p> <p>Static type checks are a complement to Python's dynamic checks. The dynamic runtime checks will catch issues when the code runs, but you want to catch as many issues as possible earlier. Static typing tools help find mistakes without having to run every possible code path.</p>"},{"location":"C03_What_is_a_Type/#the-benefits-of-types","title":"The Benefits of Types","text":"<p>A type is a fundamental attribute of data that constrains what you can do with that data. Python's is dynamically typed, meaning you don't have to declare types and can freely mix and change them at runtime. This provides a lot of power and agility at the cost of potential runtime type errors. Python emphasizes duck typing, relying on the capabilities of objects rather than explicit type declarations, which makes code very flexible and reusable.</p> <p>Type annotations provide the best of both worlds: dynamic behavior plus tools to catch mistakes early. Type annotations improve code clarity and maintainability and act as a safety net, catching errors while coding. This can dramatically increase confidence in code, especially as codebases grow.</p> <p>The type system is there to help developers, not to make the language strict or verbose by force. You can adopt it gradually and use it to the degree that it adds value for your projects.</p> <p>Embracing Python's type system--both its dynamic nature and its optional static features--will make you a more effective Python programmer, writing code that is clear, correct, and robust.</p>"},{"location":"C03_What_is_a_Type/#references","title":"References","text":"<ol> <li>Data type - Wikipedia</li> <li>Comparison of programming languages by type system--Wikipedia</li> <li>Precision Python</li> <li>Static vs. Dynamic Typing: Pros, Cons, and Key Differences</li> <li>Python's \"Type Hints\" are a bit of a disappointment to me</li> <li>Duck Typing in Python: Writing Flexible and Decoupled Code--Real Python</li> <li>PEP 484</li> <li>What Are Python Type-Hints and How to Use Them?--Andres Berejnoi</li> <li>mypy--Optional Static Typing for Python</li> <li>microsoft/PyRight: Static Type Checker for Python--GitHub</li> <li>Statically type checking Python code using PyRight--DEV Community</li> </ol>"},{"location":"C04_Using_Types/","title":"Using Types","text":"<p>This chapter looks at Python's <code>typing</code> module and applies type annotations to variables, functions, and data structures.</p>"},{"location":"C04_Using_Types/#built-in-types-int-str-float-bool-none","title":"Built-in Types (<code>int</code>, <code>str</code>, <code>float</code>, <code>bool</code>, <code>None</code>)","text":"<p>Annotating variables with <code>int</code>, <code>str</code>, <code>float</code>, <code>bool</code>, or <code>None</code> communicates the expected data types, makes code more readable, and catches mistakes via type checkers. For example:</p> <pre><code># basic_types.py\nage: int = 25\nname: str = \"Alice\"\nsalary: float = 45000.50\nis_active: bool = True\nno_value: None = None\n</code></pre> <p>Each variable's type is clearly stated. A reader can immediately see that <code>age</code> should be an integer, <code>name</code> a string, and so on. Type annotations do not change the runtime behavior of the code--Python will not enforce them at runtime. They provide documentation and enable static type checkers and IDEs to detect errors (for instance, if you later try to treat <code>age</code> as a string, a type checker warns you).</p> <p>Annotating with <code>None</code> as a type (as shown for <code>no_value</code>) indicates that the variable should hold no value. It's equivalent to saying the variable's type is <code>NoneType</code>. Using built-in type names in annotations is straightforward and is the foundation for more complex types.</p>"},{"location":"C04_Using_Types/#variables-and-functions","title":"Variables and Functions","text":"<p>Type annotations can be applied to both variables and function definitions. In both cases, they clarify what type of data is expected, which helps in reasoning about the code.</p>"},{"location":"C04_Using_Types/#variables","title":"Variables","text":"<p>To annotate variables at the time of assignment, place a colon after the variable name, followed by the type, and then the assignment:</p> <pre><code># example_2.py\nuser_id: int = 123\nusername: str = \"admin\"\nlevel: float\n</code></pre> <p>Even if we don't immediately assign a value, as in <code>level</code>, we can still provide a type annotation to indicate the intended usage of that variable.</p>"},{"location":"C04_Using_Types/#functions","title":"Functions","text":"<p>Using annotations for functions makes code self-explanatory. We annotate each function parameter as well as the return type of the function, after an <code>-&gt;</code> arrow:</p> <pre><code># example_3.py\ndef greet_user(username: str) -&gt; str:\n    return f\"Welcome, {username}!\"\n</code></pre> <p>Here the parameter <code>username</code> expects a <code>str</code>, and <code>greet_user</code> returns a string (the greeting message). The annotation <code>-&gt; str</code> after the parentheses indicates the return type. These annotations serve as both documentation and a contract: anyone reading the code can see what type <code>greet_user</code> expects and returns. A type checker flags calls like <code>greet_user(123)</code> as errors because <code>123</code> is not a <code>str</code>.</p> <p>Imagine a function with multiple parameters or a complex return type--having those types explicitly stated can prevent misuse.</p> <p>If a function does not return anything, you can annotate its return type as <code>None</code>, or omit the return annotation, which implies <code>None</code>. For instance, <code>def log_message(msg: str) -&gt; None:</code> tells you the function is only called to perform side effects.</p>"},{"location":"C04_Using_Types/#optional-types-and-default-values","title":"Optional Types and Default Values","text":"<p>If a variable or a function argument is optional, it can either hold a value of a certain type or be <code>None</code> to indicate the absence of a value. To represent this in type annotations, Python provides <code>Optional</code> in the <code>typing</code> module. <code>Optional[T]</code> is shorthand for \"either type <code>T</code> or <code>None</code>\".</p> <p>For example, consider a function that tries to find a user by ID and returns the user's name if found, or <code>None</code> if not found:</p> <pre><code># example_4.py\nfrom typing import Optional\n\n\ndef find_user(user_id: int) -&gt; Optional[str]:\n    if user_id == 1:\n        return \"Alice\"\n    return None\n</code></pre> <p>The return type of <code>Optional[str]</code> means the function returns either a string (the user's name) or <code>None</code> (if no user was found for that ID). A <code>user_id</code> of <code>1</code> produces a string <code>\"Alice\"</code>, otherwise it returns <code>None</code>. Without the <code>Optional</code>, someone looking at the function signature might assume it always returns a string. The type annotation makes it clear that <code>None</code> is a possible outcome.</p> <p><code>Optional</code> types are useful with default arguments that can be <code>None</code>:</p> <pre><code># example_5.py\nfrom typing import Optional\n\n\ndef greet(name: Optional[str] = None) -&gt; str:\n    if name:\n        return f\"Hello, {name}!\"\n    return \"Hello!\"\n</code></pre> <p>The use of <code>Optional[str]</code> clearly communicates that you can call <code>greet()</code> without an argument (treating <code>name</code> as <code>None</code>), or call <code>greet(\"Bob\")</code> with a string. The function returns a string either way--if a name is given, it includes the name in the greeting; if not, it returns a generic greeting.</p> <p>You can also write the above annotation as <code>Union[str, None]</code> or <code>str | None</code>; <code>Optional</code> is preferred because it is more and descriptive.</p>"},{"location":"C04_Using_Types/#todo-sort-out-whether-to-prefer-optional-or-t-none","title":"TODO: sort out whether to prefer Optional or T | None","text":""},{"location":"C04_Using_Types/#union-types","title":"Union Types","text":"<p>A union type indicates that a variable or function parameter can accept several different types instead of just one. The <code>typing</code> module provides <code>Union</code> for this purpose, and in more recent versions of Python you can use the <code>|</code> operator.</p>"},{"location":"C04_Using_Types/#union","title":"<code>Union</code>","text":"<p>Before Python 3.10, the typical way to declare a union of types was to use <code>typing.Union</code>, like this:</p> <pre><code># example_6.py\nfrom typing import Union\n\n\ndef process_value(value: Union[int, str]) -&gt; str:\n    return str(value)\n</code></pre> <p>The parameter <code>value</code> can be either an <code>int</code> or a <code>str</code>. The function converts <code>value</code> to a string (using the built-in <code>str()</code> constructor). The annotation <code>Union[int, str]</code> makes it clear that both types are acceptable, and the type checker will flag an attempt to use any other type.</p> <p>Unions can include more than two types. <code>Union[int, str, float]</code> means a value can be an <code>int</code> or a <code>str</code> or a <code>float</code>. However, if you write union that includes <code>None</code> (like <code>Union[X, None]</code>), remember that you can simplify it using <code>Optional[X]</code>.</p>"},{"location":"C04_Using_Types/#the-union-operator","title":"The <code>|</code> Union Operator","text":"<p>Python 3.10 introduced a more concise syntax for union types using the <code>|</code> operator. Unions written this way indicate use the idea of the logical \"OR\" to combine the different types. This rewritten <code>process_value</code> definition is equivalent to the previous one using <code>Union[int, str]</code>:</p> <pre><code># example_7.py\n\n\ndef process_value(value: int | str) -&gt; str:\n    return str(value)\n</code></pre> <p>This syntax is shorter and often clearer--you can read it as, \"value is an <code>int</code> or <code>str</code>\".</p> <p>You can chain the <code>|</code> operator to include multiple types (e.g., <code>int | str | float</code>), and you can use it with <code>None</code>: <code>str | None</code> is the same as <code>Optional[str]</code>:</p> <pre><code># union_plus_optional.py\nfrom typing import Optional\n\n\ndef f1(value: int | str | None) -&gt; str:\n    return str(value)\n\n\nprint(f1(42), f1(\"forty-two\"), f1(None))\n## 42 forty-two None\n\n\ndef f2(value: Optional[int | str]) -&gt; str:\n    return str(value)\n\n\nprint(f2(42), f2(\"forty-two\"), f2(None))\n## 42 forty-two None\n</code></pre> <p>If you must support older Python versions, use <code>Union</code>.</p>"},{"location":"C04_Using_Types/#lists-tuples-sets-and-dicts","title":"<code>List</code>s, <code>Tuple</code>s, <code>Set</code>s, and <code>Dict</code>s","text":"<p>Python's built-in collection types are generic, meaning they can hold items of any type. With type annotations, we can specify what type of items a particular collection is supposed to contain. This makes our intentions clear (e.g., a list of integers vs. a list of strings) and helps catch errors such as accidentally putting the wrong type of item in a collection.</p> <p>The <code>typing</code> module provides specialized generic classes for common collections: <code>List</code>, <code>Tuple</code>, <code>Set</code>, and <code>Dict</code> (note: in Python 3.9+, you can use the built-in class names with brackets, which we will discuss in the next section). We use these to annotate collections with their element types.</p>"},{"location":"C04_Using_Types/#lists","title":"Lists","text":"<p>A list is an ordered collection of items. When annotating a list, we specify the type of its elements inside square brackets:</p> <pre><code># example_9.py\nfrom typing import List\n\nscores: List[int] = [95, 85, 75]\n</code></pre> <p>Here, <code>scores</code> is declared to be a list of integers. The annotation <code>List[int]</code> tells us and the type checker that every element of <code>scores</code> should be an <code>int</code>. If somewhere else in the code we mistakenly append a string to <code>scores</code>, a type checker would complain. The benefit is clear: by reading the annotation, we know what <code>scores</code> contains, and we get early warnings if we misuse it.</p>"},{"location":"C04_Using_Types/#tuples","title":"<code>Tuple</code>s","text":"<p><code>Tuple</code>s are fixed-size sequences, often used for grouping heterogeneous data. Unlike lists, where all elements are usually of one type, <code>Tuple</code>s often have a fixed structure (e.g., a pair of a <code>float</code> and a <code>float</code> for coordinates). We can annotate <code>Tuple</code>s by listing the types of each position:</p> <pre><code># example_10.py\nfrom typing import Tuple\n\ncoordinates: Tuple[float, float] = (23.5, 45.8)\n</code></pre> <p>The annotation <code>Tuple[float, float]</code> means: a <code>Tuple</code> with two elements, the first a <code>float</code> and the second a <code>float</code>. If we tried to assign <code>coordinates = (23.5, \"north\")</code>, a static checker would flag it, because the second element isn't a <code>float</code> as expected.</p> <p>For <code>Tuple</code>s of variable length where all elements are the same type, you can use an ellipsis in the annotation (e.g., <code>Tuple[int, ...]</code> for \"a <code>Tuple</code> of <code>int</code> of any length\"). However, in many cases where you have a sequence of varying length, a list might be more appropriate. Use the <code>Tuple</code> annotation when the position and count of elements are fixed and meaningful.</p>"},{"location":"C04_Using_Types/#sets","title":"Sets","text":"<p>To annotate a set, we specify the type of its elements:</p> <pre><code># example_11.py\nfrom typing import Set\n\nunique_ids: Set[str] = {\"abc\", \"xyz\", \"123\"}\n</code></pre> <p>The annotation <code>Set[str]</code> indicates that every element of the set should be a string. If code later tries to add a non-string to <code>unique_ids</code>, a type checker will report an error. As with lists, specifying the element type as <code>Set</code> makes the intended content clear. It also helps readers understand what kind of data <code>unique_ids</code> holds (e.g., user identifiers, in this case represented as strings).</p>"},{"location":"C04_Using_Types/#dictionaries","title":"Dictionaries","text":"<p>When annotating dictionaries, we must specify two types: one for keys and one for values:</p> <pre><code># example_12.py\nfrom typing import Dict\n\nuser_data: Dict[str, int] = {\"Alice\": 30, \"Bob\": 25}\n</code></pre> <p>The annotation tells us that <code>user_data</code> maps names (<code>str</code>) to ages (<code>int</code>). The type annotation ensures that someone doesn't accidentally pass in, say, a dict mapping names to something else like phone numbers (unless it matches the specified types).</p> <p>Using these collection type annotations (<code>List</code>, <code>Tuple</code>, <code>Set</code>, <code>Dict</code>) greatly enhances code documentation. They specify not just that a variable is a list or dict, but what's inside it. This is crucial for writing correct code--many bugs come from misunderstanding data types. Next, we will see that Python has even more convenient ways to write these annotations, especially in newer versions.</p>"},{"location":"C04_Using_Types/#annotations-without-imports","title":"Annotations without Imports","text":"<p>Starting with Python 3.9, Python allows the direct use of built-in collection type names. This means you can write <code>list[int]</code> instead of importing <code>List</code> from <code>typing</code>, and similarly for <code>dict</code>, <code>tuple</code>, and <code>set</code>.</p> <p>This removes the extra imports and makes the syntax more natural:</p> <pre><code># example_13.py\nscores: list[int] = [95, 85, 75]\nuser_data: dict[str, float] = {\n    \"Alice\": 95.5,\n    \"Bob\": 85.3,\n}\n</code></pre> <p>You can do the same for <code>tuple</code> and <code>set</code> (e.g., <code>coordinates: tuple[float, float] = (23.5, 45.8)</code> or <code>unique_ids: set[str] = {\"a\", \"b\"}</code>), and the other standard library collection types.</p> <p>To support Python versions earlier than 3.9, use <code>typing.List</code> / <code>typing.Dict</code> style, because bracketed syntax for built-in types won't be recognized in older versions. This book will use the built-in names whenever possible</p> <p>There is also a mechanism called <code>from __future__ import annotations</code> that can ease adoption of newer annotation features by treating annotations as strings (to avoid evaluation issues), but that is an advanced detail beyond our current scope. TODO: Add an example</p>"},{"location":"C04_Using_Types/#specialized-annotations-sequence-mapping-iterable-iterator","title":"Specialized Annotations (<code>Sequence</code>, <code>Mapping</code>, <code>Iterable</code>, <code>Iterator</code>)","text":"<p>Sometimes you want a more abstract concept of a type. For example, suppose you write a function that takes anything you can iterate over, rather than a specific type like <code>list</code> or <code>tuple</code> or <code>set</code>. Or a function that can accept any kind of mapping; not just a built-in <code>dict</code>, but maybe an <code>OrderedDict</code> or a custom mapping type. For such cases, the <code>typing</code> module provides specialized abstract types: <code>Sequence</code>, <code>Mapping</code>, <code>Iterable</code>, <code>Iterator</code>, and others.</p> <p>These abstract annotations allow broader compatibility. They indicate the function or variable isn't tied to one specific implementation, but rather to a category of types that share certain behavior.</p>"},{"location":"C04_Using_Types/#sequence","title":"<code>Sequence</code>","text":"<p>A <code>Sequence</code> represents any ordered collection that supports element access by index and has a length. This includes Python's <code>list</code>, <code>tuple</code>, <code>range</code>, and even <code>str</code> (a string can be seen as a sequence of characters).</p> <pre><code># example_14.py\nfrom typing import Sequence\n\n\ndef average(numbers: Sequence[float]) -&gt; float:\n    return sum(numbers) / len(numbers)\n</code></pre> <p>In <code>average</code>, we accept <code>numbers</code> as a <code>Sequence[float]</code>. This means you can pass in a list of floats, a <code>tuple</code> of floats, or any sequence (ordered collection) of <code>float</code>s, and the function will calculate the average. If we annotate <code>numbers</code> as <code>List[float]</code>, the type checker complains if you pass anything that's not explicitly a <code>list</code>. By using the broader <code>Sequence</code> type, we allow any suitable container, which makes the function more flexible while still ensuring the elements are <code>float</code>s.</p>"},{"location":"C04_Using_Types/#mapping","title":"<code>Mapping</code>","text":"<p>A <code>Mapping</code> represents an object with key-value pairs, like dictionaries. It is an abstract supertype of <code>dict</code> and other mappings. A <code>Mapping[K, V]</code> has keys of type <code>K</code> and values of type <code>V</code>.</p> <pre><code># example_15.py\nfrom typing import Mapping\n\n\ndef get_user_age(users: Mapping[str, int], username: str) -&gt; int:\n    return users.get(username, 0)\n</code></pre> <p><code>get_user_age</code> takes a <code>users</code> argument annotated as <code>Mapping[str, int]</code>. This accepts any mapping from <code>str</code> to <code>int</code>. It can be anything from a normal <code>dict</code> to something like <code>collections.UserDict</code> or any custom object that implements the mapping protocol. The function body uses <code>users.get(username, 0)</code> to retrieve an integer age, defaulting to 0 if the username is not found. By annotating with <code>Mapping[str, int]</code> instead of <code>Dict[str, int]</code>, we are not forcing the caller to provide a built-in <code>dict</code>--any mapping will do. This gives the function flexibility; for example, it could work with an <code>os.environ</code> mapping, which behaves like a dict for environment variables, or a database proxy that implements the mapping interface.</p>"},{"location":"C04_Using_Types/#iterable-and-iterator","title":"<code>Iterable</code> and <code>Iterator</code>","text":"<p>An <code>Iterable</code> describes any object that you can loop over (using a <code>for</code> loop or other iteration contexts). If the object has an <code>__iter__()</code> method, it implements the <code>Iterable</code> protocol. Examples include <code>list</code>s, <code>set</code>s, <code>tuple</code>s, <code>dict</code>s (iterating over keys), file objects (iterating over lines), and more.</p> <p>An <code>Iterator</code> is a subtype of <code>Iterable</code> that represents the <code>Iterator</code> object returned by calling <code>iter()</code> on an <code>Iterable</code>. It implements a <code>__next__()</code> method that returns the next item or raises <code>StopIteration</code> when there are no more items. Generator functions (functions using the <code>yield</code> keyword) produce iterators.</p> <pre><code># example_16.py\nfrom typing import Iterable, Iterator\n\n\ndef print_items(items: Iterable[str]) -&gt; None:\n    for item in items:\n        print(item)\n\n\ndef generate_numbers(n: int) -&gt; Iterator[int]:\n    for i in range(n):\n        yield i\n</code></pre> <p><code>items</code> can be any iterable of strings. This means you can pass a <code>list</code>, a <code>set</code>, a <code>tuple</code>, or any object that yields strings when iterated. <code>print_items</code> does not care about the concrete type that holds the <code>str</code>s. Restricting <code>items</code> to, say, <code>list[str]</code>, means we wouldn't be able to pass a <code>set</code> of strings, even though you can print each item of a <code>set</code>. <code>Iterable[str]</code> makes the function more general purpose.</p> <p><code>generate_numbers</code> is an example of a generator. It uses <code>yield</code> to produce a sequence of integers from 0 up to <code>n-1</code>. The return type is annotated as <code>Iterator[int]</code> because calling <code>generate_numbers(5)</code> will produce an iterator of integers. Annotating this helps users of <code>generate_numbers</code> know what to expect: they will get an iterator (which they might loop over or convert to a list, etc.) rather than, say, a fully realized list. Also, it signals that the function uses <code>yield</code> internally. As a side note, if a function is meant to never return normally (for instance, one that enters an infinite loop or always raises an exception), you could use the special return type <code>NoReturn</code> from <code>typing</code>, but such cases are rare and beyond our current scope.</p> <p>Specialized annotations like <code>Sequence</code>, <code>Mapping</code>, <code>Iterable</code>, and <code>Iterator</code> let you capture the interface or behavior you require, rather than a specific concrete type. They are especially useful in library or API design, where over-specifying types can needlessly limit the utility of a function or class. By using these abstract collection types, you make your code flexible while still retaining the benefits of type checking.</p>"},{"location":"C04_Using_Types/#t-strings","title":"T-Strings","text":"<p>https://davepeck.org/2025/04/11/pythons-new-t-strings/</p> <p>Also custom f string format specifiers</p>"},{"location":"C04_Using_Types/#faster-development-clearer-results","title":"Faster Development, Clearer Results","text":"<p>Type annotations make intentions explicit. This produces code that is easier to understand and maintain. Type checkers catch type mismatches early in development. The type system in Python is gradually typed and opt-in. You can use as much or as little as makes sense for your project. Using types effectively is a powerful skill.</p>"},{"location":"C05_Custom_Types_Data_Classes/","title":"Custom Types: Data Classes","text":"<p>Built-in types are extremely useful (I'm including all the types in the standard Python library), but the real programming power comes by creating user-defined types, which we shall call custom types. The remainder of this book will primarily focus on various ways to create and use custom types.</p> <p>One of the biggest benefits of custom types is that they allow you to create types that reflect entities in your problem domain. The book Domain-Driven Design by Eric Evans explores problem-domain modeling to discover the types in your system.</p>"},{"location":"C05_Custom_Types_Data_Classes/#ensuring-correctness","title":"Ensuring Correctness","text":"<p>Imagine building a customer feedback system using a rating from one to ten stars. Traditionally, Python programmers use an <code>int</code> to represent <code>stars</code>, checking arguments to ensure validity:</p> <pre><code># int_stars.py\n# Using 1-10 stars for customer feedback.\nfrom book_utils import Catch\n\n\ndef f1(stars: int) -&gt; int:\n    # Must check argument...\n    assert 1 &lt;= stars &lt;= 10, f\"f1: {stars}\"\n    return stars + 5\n\n\ndef f2(stars: int) -&gt; int:\n    # ...each place it is used.\n    assert 1 &lt;= stars &lt;= 10, f\"f2: {stars}\"\n    return stars * 5\n\n\nstars1 = 6\nprint(stars1)\n## 6\nprint(f1(stars1))\n## 11\nprint(f2(stars1))\n## 30\nstars2 = 11\nwith Catch():\n    print(f1(stars2))\n## Error: f1: 11\nstars3 = 99\nwith Catch():\n    print(f2(stars3))\n## Error: f2: 99\n</code></pre> <p>Each function that takes a <code>stars</code> must validate that argument, leading to duplicated logic, scattered validation, and potential mistakes.</p>"},{"location":"C05_Custom_Types_Data_Classes/#traditional-object-oriented-encapsulation","title":"Traditional Object-Oriented Encapsulation","text":"<p>Object-oriented programming (OOP) suggests encapsulating validation within the class. Python typically uses a private attribute (indicated with a single leading underscore) for encapsulation:</p> <pre><code># stars_class.py\nfrom typing import Optional\nfrom book_utils import Catch\n\n\nclass Stars:\n    def __init__(self, n_stars: int):\n        self._number = n_stars  # Private by convention\n        self.validate()\n\n    def validate(self, s: Optional[int] = None):\n        if s:\n            assert 1 &lt;= s &lt;= 10, f\"{self}: {s}\"\n        else:\n            assert 1 &lt;= self._number &lt;= 10, f\"{self}\"\n\n    # Prevent external modification:\n    @property\n    def number(self):\n        return self._number\n\n    def __str__(self) -&gt; str:\n        return f\"Stars({self._number})\"\n\n    # Every member function must validate the private variable:\n    def f1(self, n_stars: int) -&gt; int:\n        self.validate(n_stars)  # Precondition\n        self._number = n_stars + 5\n        self.validate()  # Postcondition\n        return self._number\n\n    def f2(self, n_stars: int) -&gt; int:\n        self.validate(n_stars)  # Precondition\n        self._number = n_stars * 5\n        self.validate()  # Postcondition\n        return self._number\n\n\nstars1 = Stars(4)\nprint(stars1)\n## Stars(4)\nprint(stars1.f1(3))\n## 8\nwith Catch():\n    print(stars1.f2(stars1.f1(3)))\n## Error: Stars(40)\nwith Catch():\n    stars2 = Stars(11)\n## Error: Stars(11)\nstars3 = Stars(5)\nprint(stars3.f1(4))\n## 9\nwith Catch():\n    print(stars3.f2(22))\n## Error: Stars(9): 22\n# @property without setter prevents mutation:\nwith Catch():\n    stars1.number = 99  # type: ignore\n</code></pre> <p>This approach centralizes validation yet remains cumbersome. Each method interacting with the attribute still requires pre-and post-condition checks, cluttering the code and potentially introducing errors if a developer neglects these checks.</p>"},{"location":"C05_Custom_Types_Data_Classes/#type-aliases-newtype","title":"Type Aliases &amp; <code>NewType</code>","text":"<p>Suppose you have a <code>dict</code> with nested structures or a <code>tuple</code> with many elements. Writing out these types every time is unwieldy. Type aliases assign a name to a type to make annotations cleaner and more maintainable.</p> <p>A type alias is a name assignment at the top level of your code. We normally name type aliases with CamelCase to indicate they are types:</p> <pre><code># simple_type_aliasing.py\nfrom typing import get_type_hints, NewType\n\ntype Number = int | float | str\n# Runtime-safe distinct type for measurement lists\nMeasurements = NewType(\"Measurements\", list[Number])\n\n\ndef process(data: Measurements) -&gt; None:\n    print(get_type_hints(process))\n    for n in data:\n        print(f\"{n = }, {type(n) = }\")\n\n\nprocess(Measurements([11, 3.14, \"1.618\"]))\n## {'data': __main__.Measurements, 'return': &lt;class 'NoneType'&gt;}\n## n = 11, type(n) = &lt;class 'int'&gt;\n## n = 3.14, type(n) = &lt;class 'float'&gt;\n## n = '1.618', type(n) = &lt;class 'str'&gt;\n</code></pre> <p>Using <code>Number</code> and <code>Measurements</code> is functionally identical to writing the annotation as <code>int | float</code> or <code>list[Number]</code>. The aliases:</p> <ul> <li>Gives a meaningful name to the type, indicating what the <code>list</code> of <code>Number</code>s represents--in this case,   a collection called <code>Measurements</code>.</li> <li>Avoids repeating a complex type annotation in multiple places.</li> <li>Improves readability by abstracting away the details of the type structure.</li> <li>If the definition of <code>Measurements</code> changes (if we use a different type to represent <code>Number</code>),   we can update the alias in one place.</li> </ul> <p>You can see from the output that type aliases do not create new types at runtime; they are purely for the benefit of the type system and the developer.</p>"},{"location":"C05_Custom_Types_Data_Classes/#newtype","title":"<code>NewType</code>","text":"<p>A type alias is a notational convenience, but it doesn't create a new type recognized by the type checker. <code>NewType</code> creates a new, distinct type, preventing accidental misuse of similar underlying types. You'll often want to use <code>NewType</code> instead of type aliasing:</p> <pre><code># new_type.py\nfrom typing import NewType, get_type_hints\n\ntype Number = int | float | str  # Static union alias\n\n# Runtime-safe distinct type:\nMeasurements = NewType(\"Measurements\", list[Number])\n\n\ndef process(data: Measurements) -&gt; None:\n    print(get_type_hints(process))\n    for n in data:\n        print(f\"{n = }, {type(n) = }\")\n\n\nprocess(Measurements([11, 3.14, \"1.618\"]))\n## {'data': __main__.Measurements, 'return': &lt;class 'NoneType'&gt;}\n## n = 11, type(n) = &lt;class 'int'&gt;\n## n = 3.14, type(n) = &lt;class 'float'&gt;\n## n = '1.618', type(n) = &lt;class 'str'&gt;\n</code></pre> <p><code>get_type_hints</code> produces information about the function.</p> <p><code>NewType</code> is intended to create a distinct type based on another type. Its primary goal is to help prevent the mixing of semantically different values that are represented by the same underlying type; for example, differentiating <code>UserID</code> from <code>ProductID</code>, even though both are <code>int</code>s:</p> <pre><code># new_type_users.py\nfrom typing import NewType\n\nUserID = NewType(\"UserID\", int)\nProductID = NewType(\"ProductID\", int)\nUsers = NewType(\"Users\", list[UserID])\n\nusers = Users([UserID(2), UserID(5), UserID(42)])\n\n\ndef increment(uid: UserID) -&gt; UserID:\n    # Transparently access underlying value:\n    return UserID(uid + 1)\n\n\n# increment(42)  # Type check error\n\n# Access underlying list operation:\nprint(increment(users[-1]))\n## 43\n\n\ndef increment_users(users: Users) -&gt; Users:\n    return Users([increment(uid) for uid in users])\n\n\nprint(increment_users(users))\n## [3, 6, 43]\n</code></pre> <p>Notice that <code>Users</code> uses <code>UserID</code> in its definition. The type checker requires <code>UserID</code> for <code>increment</code> and <code>Users</code> for <code>increment_users</code>, even though we can transparently access the underlying elements of each type (<code>int</code> and <code>list[UserID]</code>).</p>"},{"location":"C05_Custom_Types_Data_Classes/#creating-a-newtype-from-a-newtype","title":"Creating a <code>NewType</code> from a <code>NewType</code>","text":"<p>You cannot subclass a <code>NewType</code>:</p> <pre><code># newtype_subtype.py\nfrom typing import NewType\n\nStars = NewType(\"Stars\", int)\n\n# Fails type check and at runtime:\n# class GasGiants(Stars): pass\n</code></pre> <p>However, it is possible to create a <code>NewType</code> based on a <code>NewType</code>:</p> <pre><code># newtype_based_type.py\nfrom typing import NewType\n\nStars = NewType(\"Stars\", int)\n\nGasGiants = NewType(\"GasGiants\", Stars)\n</code></pre> <p>Typechecking for <code>GasGiants</code> works as expected.</p>"},{"location":"C05_Custom_Types_Data_Classes/#newtype-stars","title":"<code>NewType</code> Stars","text":"<p><code>NewType</code> will provide some benefit to the <code>Stars</code> problem by going from an <code>int</code> to a specific type:</p> <pre><code># newtype_stars.py\nfrom typing import NewType\n\nStars = NewType(\"Stars\", int)\n\n\ndef f1(stars: Stars) -&gt; Stars:\n    assert 1 &lt;= stars &lt;= 10, f\"f1: {stars}\"\n    return Stars(stars + 5)\n\n\ndef f2(stars: Stars) -&gt; Stars:\n    assert 1 &lt;= stars &lt;= 10, f\"f2: {stars}\"\n    return Stars(stars * 5)\n</code></pre> <p>Now <code>f1</code> and <code>f2</code> will produce an error if you try to pass them an <code>int</code>; they only accept <code>Stars</code>. Note that <code>NewType</code> generates a constructor for <code>Stars</code>, which we need to return <code>Stars</code> objects. The validation code remains the same, because <code>Stars</code> is an <code>int</code>. However, we still need the validation code. To improve the design, we require a more powerful technique.</p>"},{"location":"C05_Custom_Types_Data_Classes/#data-classes","title":"Data Classes","text":"<p>Data classes provide a structured, concise way to define data-holding types. Many languages have similar constructs under different names: Scala has <code>case class</code>, Kotlin has <code>data class</code>, Java has <code>record</code>, Rust has <code>struct</code>, etc. Data classes streamline the process of creating types by generating essential methods automatically.</p> <pre><code># messenger.py\nfrom dataclasses import dataclass, replace\n\n\n@dataclass\nclass Messenger:\n    name: str\n    number: int\n    depth: float = 0.0  # Default argument\n\n\nx = Messenger(name=\"x\", number=9, depth=2.0)\nm = Messenger(\"foo\", 12, 3.14)\nprint(m)\n## Messenger(name='foo', number=12, depth=3.14)\nprint(m.name, m.number, m.depth)\n## foo 12 3.14\nmm = Messenger(\"xx\", 1)  # Uses default argument\nprint(mm == Messenger(\"xx\", 1))  # Generated __eq__()\n## True\nprint(mm == Messenger(\"xx\", 2))\n## False\n\n# Make a copy with a different depth:\nmc = replace(m, depth=9.9)\nprint(m, mc)\n## Messenger(name='foo', number=12, depth=3.14)\n## Messenger(name='foo', number=12, depth=9.9)\n\n# Mutable:\nm.name = \"bar\"\nprint(m)\n## Messenger(name='bar', number=12, depth=3.14)\n# d = {m: \"value\"}\n# TypeError: unhashable type: 'Messenger'\n</code></pre> <p><code>Messenger</code> is defined with three fields: <code>name</code> and <code>number</code>, which are required, and <code>depth</code>, which has a default value of <code>0.0</code>. The <code>@dataclass</code> decorator automatically generates an <code>__init__</code>, <code>__repr__</code>, <code>__eq__</code>, among others. We see several ways to instantiate <code>Messenger</code> objects, demonstrating that the default for <code>depth</code> is used when not provided. It also shows that two instances with the same field values are equal, and how to create a modified copy of an instance using <code>replace()</code>. It highlights mutability: <code>Messenger</code> instances can be modified unless marked as <code>frozen=True</code> (a feature covered in [C06_Immutability]). Finally, it demonstrates that <code>Messenger</code> instances cannot be used as dictionary keys by default because they are not hashable, a feature that can be enabled via <code>@dataclass(unsafe_hash=True)</code> or by making the class immutable with <code>frozen=True</code>.</p>"},{"location":"C05_Custom_Types_Data_Classes/#generated-methods","title":"Generated Methods","text":"<p>Using the standard library <code>inspect</code> module, we can display the type signatures of the methods in a class:</p> <pre><code># class_methods.py\nimport inspect\n\n\ndef show_methods(cls: type) -&gt; None:\n    print(f\"class {cls.__name__}:\")\n    for name, member in cls.__dict__.items():\n        if callable(member):\n            sig = inspect.signature(member)\n            print(f\"  {name}{sig}\")\n</code></pre> <p>The function iterates through the class dictionary and uses <code>inspect.signature()</code> to display the type signatures of callable members. Here is <code>show_methods</code> applied to an ordinary class:</p> <pre><code># point_methods.py\nfrom class_methods import show_methods\n\n\nclass Klass:\n    def __init__(self, val: str):\n        self.val = val\n\n\nshow_methods(Klass)\n## class Klass:\n##   __init__(self, val: str)\n</code></pre> <p>Here are different configurations of <code>@dataclass</code>:</p> <pre><code># point_dataclasses.py\nfrom dataclasses import dataclass\n\n\n@dataclass\nclass Point:\n    x: int = 1\n    y: int = 2\n\n\n@dataclass(order=True)\nclass OrderedPoint:\n    x: int = 1\n    y: int = 2\n\n\n@dataclass(frozen=True)\nclass FrozenPoint:\n    x: int = 1\n    y: int = 2\n\n\n@dataclass(order=True, frozen=True)\nclass OrderedFrozenPoint:\n    x: int = 1\n    y: int = 2\n</code></pre> <p>Now we can see the methods generated by these variations:</p> <pre><code># dataclass_generated_methods.py\nfrom point_dataclasses import (\n    Point,\n    OrderedPoint,\n    FrozenPoint,\n    OrderedFrozenPoint,\n)\nfrom class_methods import show_methods\n\nshow_methods(Point)\n## class Point:\n##   __annotate_func__(format, /)\n##   __replace__(self, /, **changes)\n##   __init__(self, x: int = 1, y: int = 2) -&gt; None\n##   __repr__(self)\n##   __eq__(self, other)\nshow_methods(OrderedPoint)\n## class OrderedPoint:\n##   __annotate_func__(format, /)\n##   __replace__(self, /, **changes)\n##   __init__(self, x: int = 1, y: int = 2) -&gt; None\n##   __repr__(self)\n##   __eq__(self, other)\n##   __lt__(self, other)\n##   __le__(self, other)\n##   __gt__(self, other)\n##   __ge__(self, other)\nshow_methods(FrozenPoint)\n## class FrozenPoint:\n##   __annotate_func__(format, /)\n##   __replace__(self, /, **changes)\n##   __hash__(self)\n##   __init__(self, x: int = 1, y: int = 2) -&gt; None\n##   __repr__(self)\n##   __eq__(self, other)\n##   __setattr__(self, name, value)\n##   __delattr__(self, name)\nshow_methods(OrderedFrozenPoint)\n## class OrderedFrozenPoint:\n##   __annotate_func__(format, /)\n##   __replace__(self, /, **changes)\n##   __hash__(self)\n##   __init__(self, x: int = 1, y: int = 2) -&gt; None\n##   __repr__(self)\n##   __eq__(self, other)\n##   __lt__(self, other)\n##   __le__(self, other)\n##   __gt__(self, other)\n##   __ge__(self, other)\n##   __setattr__(self, name, value)\n##   __delattr__(self, name)\n</code></pre> <p>The different forms of data class all have a set of methods in common:</p> <ul> <li><code>__init__</code> constructs a new instance by initializing the instance attributes according to the defined class attributes.</li> <li><code>__replace__</code> is used by the <code>replace()</code> function, shown earlier, to create a new instance from an existing instance, changing one or more attributes.</li> <li><code>__repr__</code> creates a readable representation produced by <code>repr()</code> or any operation that needs a <code>str</code>.</li> <li><code>__eq__</code> defines equivalence between two instances of the data class.</li> <li><code>__annotate_func__</code> is a utility function used internally by the dataclass.</li> </ul> <p>Adding <code>order=True</code> to the dataclass adds the full suite of comparison methods: <code>__lt__</code>, <code>__le__</code>, <code>__gt__</code>, and <code>__ge__</code>.</p> <p>Adding <code>frozen=True</code> produces immutability by preventing instance mutation; this also enables hashability. The definitions of <code>__setattr__</code> and <code>__delattr__</code> prevent modification at runtime.</p> <p>Adding <code>order=True</code> together with <code>frozen=True</code> produces the sum of all generated methods.</p>"},{"location":"C05_Custom_Types_Data_Classes/#sorting-and-hashing","title":"Sorting and Hashing","text":"<p>// Describe</p> <pre><code># sortable_points.py\nfrom point_dataclasses import OrderedPoint\n\nordered_points: list[OrderedPoint] = [\n    OrderedPoint(3, 4),\n    OrderedPoint(1, 9),\n    OrderedPoint(1, 2),\n]\nprint(sorted(ordered_points))\n## [OrderedPoint(x=1, y=2), OrderedPoint(x=1, y=9),\n## OrderedPoint(x=3, y=4)]\n</code></pre> <pre><code># hashable_points.py\nfrom point_dataclasses import FrozenPoint\n\npoint_set: set[FrozenPoint] = {\n    FrozenPoint(1, 2),\n    FrozenPoint(3, 4),\n}\nprint(FrozenPoint(1, 2) in point_set)\n## True\npoint_dict: dict[FrozenPoint, str] = {\n    FrozenPoint(1, 2): \"first\",\n    FrozenPoint(3, 4): \"second\",\n}\nprint(point_dict[FrozenPoint(3, 4)])\n## second\n</code></pre>"},{"location":"C05_Custom_Types_Data_Classes/#default-factories","title":"Default Factories","text":"<p>A default factory is a function that creates a default value for a field. Here, <code>next_ten</code> is a custom default factory; it's a function that produces a value:</p> <pre><code># default_factory.py\nfrom dataclasses import dataclass, field\nfrom typing import List, Dict\n\n_n = 0\n\n\ndef next_ten() -&gt; int:\n    global _n\n    _n += 10\n    return _n\n\n\n@dataclass\nclass UserProfile:\n    username: str\n    # Built-in factory: each instance gets a new empty list\n    strlist: List[str] = field(default_factory=list)\n    # Custom default factories:\n    n1: int = field(default_factory=next_ten)\n    data: Dict[str, str] = field(\n        default_factory=lambda: {\"A\": \"B\"}\n    )\n    n2: int = field(default_factory=next_ten)\n\n\nprint(user1 := UserProfile(\"Alice\"))\n## UserProfile(username='Alice', strlist=[], n1=10, data={'A': 'B'},\n## n2=20)\nprint(user2 := UserProfile(\"Bob\"))\n## UserProfile(username='Bob', strlist=[], n1=30, data={'A': 'B'},\n## n2=40)\n\n# Modify mutable fields to verify they don't share state\nuser1.strlist.append(\"dark_mode\")\nuser2.strlist.append(\"notifications\")\nuser2.data[\"C\"] = \"D\"\nprint(f\"{user1 = }\")\n## user1 = UserProfile(username='Alice', strlist=['dark_mode'],\n## n1=10, data={'A': 'B'}, n2=20)\nprint(f\"{user2 = }\")\n## user2 = UserProfile(username='Bob', strlist=['notifications'],\n## n1=30, data={'A': 'B', 'C': 'D'}, n2=40)\n</code></pre> <p>// Describe</p>"},{"location":"C05_Custom_Types_Data_Classes/#post-initialization","title":"Post-Initialization","text":"<p>In a typical data class, validation logic resides in the <code>__post_init__</code> method. This is executed automatically after initialization. With <code>__post_init__</code>, you can guarantee that only valid instances of your type can be created. Here, <code>__post_init__</code> initializes the <code>area</code> attribute:</p> <pre><code># post_init.py\nfrom dataclasses import dataclass\nfrom math import pi\n\n\n@dataclass\nclass Circle:\n    radius: float\n    area: float = 0.0\n\n    def __post_init__(self):\n        self.area = pi * self.radius**2\n\n\nprint(Circle(radius=5))\n## Circle(radius=5, area=78.53981633974483)\n</code></pre> <p>Here's a slightly more complex example:</p> <pre><code># team_post_init.py\nfrom dataclasses import dataclass, field\nfrom typing import List\n\n\n@dataclass\nclass Team:\n    leader: str\n    members: List[str] = field(default_factory=list)\n\n    def __post_init__(self):\n        self.leader = self.leader.capitalize()\n        if self.leader not in self.members:\n            self.members.insert(0, self.leader)\n\n\nprint(Team(\"alice\", [\"bob\", \"carol\", \"ted\"]))\n## Team(leader='Alice', members=['Alice', 'bob', 'carol', 'ted'])\n</code></pre> <p>We can use <code>__post_init__</code> to solve the <code>Stars</code> validation problem:</p> <pre><code># stars_dataclass.py\nfrom dataclasses import dataclass\n\nfrom book_utils import Catch\n\n\n@dataclass\nclass Stars:\n    number: int\n\n    def __post_init__(self) -&gt; None:\n        assert 1 &lt;= self.number &lt;= 10, f\"{self}\"\n\n\ndef f1(stars: Stars) -&gt; Stars:\n    return Stars(stars.number + 5)\n\n\ndef f2(stars: Stars) -&gt; Stars:\n    return Stars(stars.number * 5)\n\n\nstars1 = Stars(6)\nprint(stars1)\n## Stars(number=6)\nwith Catch():\n    print(f1(stars1))\n## Error: Stars(number=11)\nwith Catch():\n    print(f2(stars1))\n## Error: Stars(number=30)\nwith Catch():\n    print(f1(Stars(22)))\n## Error: Stars(number=22)\nwith Catch():\n    print(f2(Stars(99)))\n## Error: Stars(number=99)\n</code></pre> <p>Now <code>f1</code> and <code>f2</code> no longer need to do any validation testing on <code>Stars</code>, because it is impossible to create an invalid <code>Stars</code> object. Note that you can still take a <code>Stars</code> and modify it so it becomes invalid; we shall address this in the next chapter.</p>"},{"location":"C05_Custom_Types_Data_Classes/#initializers","title":"Initializers","text":"<p>Normally you'll define a <code>__post_init__</code> to perform validation. Sometimes, you'll need an <code>__init__</code> to customize the way fields are initialized.</p> <p>A custom <code>__init__</code> makes sense primarily for different initialization logic than the field-based constructor allows. You need a completely alternative interface, such as parsing inputs from a different format (e.g., strings, dictionaries, files) and then assigning to fields. For example, consider parsing two pieces of <code>float</code> data from a single <code>str</code> argument:</p> <pre><code># point.py\nfrom dataclasses import dataclass\n\n\n@dataclass\nclass Point:\n    x: float\n    y: float\n\n    def __init__(self, coord: str):\n        x_str, y_str = coord.split(\",\")\n        self.x = float(x_str.strip())\n        self.y = float(y_str.strip())\n</code></pre> <p>Notice the extra space in the string argument to <code>Point</code>:</p> <pre><code># point_demo.py\nfrom point import Point\n\nprint(Point(\" 10.5 , 20.3 \"))\n## Point(x=10.5, y=20.3)\n</code></pre> <p>Here, the custom <code>__init__</code> provides a simpler API. You retain data class features like <code>__repr__</code>, <code>__eq__</code>, and automatic field handling.</p> <p>Data classes auto-generate an <code>__init__</code> unless you explicitly define one. If you provide a custom <code>__init__</code>, the automatic one is replaced. You can still use <code>__post_init__</code>, but must call it explicitly from your custom <code>__init__</code>.</p> <p>Prefer <code>__post_init__</code> for basic validation, transformation, or default adjustments after standard field initialization. Use a custom <code>__init__</code> if you require fundamentally different or more complex input logic that's incompatible with the autogenerated initializer.</p>"},{"location":"C05_Custom_Types_Data_Classes/#composing-data-classes","title":"Composing Data Classes","text":"<p>Composition creates complex data types from simpler ones. Consider a <code>Person</code> object composed of <code>FullName</code>, <code>BirthDate</code>, and <code>Email</code> data classes:</p> <pre><code># dataclass_composition.py\nfrom dataclasses import dataclass\n\n\n@dataclass\nclass FullName:\n    name: str\n\n    def __post_init__(self) -&gt; None:\n        print(f\"FullName checking {self.name}\")\n        assert len(self.name.split()) &gt; 1, (\n            f\"'{self.name}' needs first and last names\"\n        )\n\n\n@dataclass\nclass BirthDate:\n    dob: str\n\n    def __post_init__(self) -&gt; None:\n        print(f\"BirthDate checking {self.dob}\")\n\n\n@dataclass\nclass EmailAddress:\n    address: str\n\n    def __post_init__(self) -&gt; None:\n        print(f\"EmailAddress checking {self.address}\")\n\n\n@dataclass\nclass Person:\n    name: FullName\n    date_of_birth: BirthDate\n    email: EmailAddress\n\n\nperson = Person(\n    FullName(\"Bruce Eckel\"),\n    BirthDate(\"7/8/1957\"),\n    EmailAddress(\"mindviewinc@gmail.com\"),\n)\n## FullName checking Bruce Eckel\n## BirthDate checking 7/8/1957\n## EmailAddress checking mindviewinc@gmail.com\nprint(person)\n## Person(name=FullName(name='Bruce Eckel'),\n## date_of_birth=BirthDate(dob='7/8/1957'),\n## email=EmailAddress(address='mindviewinc@gmail.com'))\n</code></pre> <p>This hierarchical validation structure ensures correctness and clarity at every composition level. Invalid data never propagates, vastly simplifying subsequent interactions.</p>"},{"location":"C05_Custom_Types_Data_Classes/#initvar","title":"<code>InitVar</code>","text":"<p><code>dataclasses.InitVar</code> allows you to define fields that are only used during initialization but are not stored as attributes of the data class object. <code>InitVar</code> fields are passed as parameters to the <code>__init__</code> method and can be used within the <code>__post_init__</code> method for additional initialization logic. They are not considered regular fields of the data class and are not included in the output of functions like <code>fields()</code>.</p> <pre><code># dataclass_initvar.py\nfrom dataclasses import dataclass, InitVar\n\n\n@dataclass\nclass Book:\n    title: str\n    author: str\n    condition: InitVar[str]\n    shelf_id: int | None = None\n\n    def __post_init__(self, condition):\n        if condition == \"Unacceptable\":\n            self.shelf_id = None\n\n\nb = Book(\"Emma\", \"Austen\", \"Good\", 11)\nprint(b.__dict__)\n## {'title': 'Emma', 'author': 'Austen', 'shelf_id': 11}\n</code></pre> <p>In this example, <code>condition</code> is an <code>InitVar</code>. It is used to conditionally set the <code>shelf_id</code> in <code>__post_init__</code>, but we can see from displaying the <code>__dict__</code> that it is not stored as an attribute of the <code>Book</code> instance.</p>"},{"location":"C05_Custom_Types_Data_Classes/#dataclass-as-dictionary","title":"Dataclass as Dictionary","text":"<p>The <code>dataclasses.asdict</code> function can seem confusing at first:</p> <pre><code># dataclass_as_dict.py\nfrom dataclasses import dataclass, asdict\nfrom point_dataclasses import Point\n\np = Point(7, 9)\nprint(asdict(p))\n## {'x': 7, 'y': 9}\nprint(p.__dict__)\n## {'x': 7, 'y': 9}\n# Unpacking:\nx, y = tuple(asdict(p).values())\nprint(x, y)\n## 7 9\n# Or:\nx1, y1 = tuple(p.__dict__.values())\nprint(x1, y1)\n## 7 9\n</code></pre> <p>The result of <code>asdict(p)</code> and <code>p.__dict__</code> appear to be the same. To see the effect of <code>asdict()</code> we need a more complicated example:</p> <pre><code># asdict_behavior.py\nfrom dataclasses import dataclass, asdict\n\nfrom point_dataclasses import Point\n\n\n@dataclass\nclass Line:\n    p1: Point\n    p2: Point\n\n\n@dataclass\nclass Shape:\n    lines: list[Line]\n\n\n@dataclass\nclass Image:\n    shapes: list[Shape]\n\n\nshape1 = Shape(\n    [\n        Line(Point(0, 0), Point(10, 4)),\n        Line(Point(10, 4), Point(16, 8)),\n    ]\n)\n\nimage = Image([shape1, shape1])\nprint(image.__dict__)\n## {'shapes': [Shape(lines=[Line(p1=Point(x=0, y=0), p2=Point(x=10,\n## y=4)), Line(p1=Point(x=10, y=4), p2=Point(x=16, y=8))]),\n## Shape(lines=[Line(p1=Point(x=0, y=0), p2=Point(x=10, y=4)),\n## Line(p1=Point(x=10, y=4), p2=Point(x=16, y=8))])]}\nprint(asdict(image))\n## {'shapes': [{'lines': [{'p1': {'x': 0, 'y': 0}, 'p2': {'x': 10,\n## 'y': 4}}, {'p1': {'x': 10, 'y': 4}, 'p2': {'x': 16, 'y': 8}}]},\n## {'lines': [{'p1': {'x': 0, 'y': 0}, 'p2': {'x': 10, 'y': 4}},\n## {'p1': {'x': 10, 'y': 4}, 'p2': {'x': 16, 'y': 8}}]}]}\n</code></pre> <p>Notice how easily we produce a sophisticated type like <code>Image</code>. Now you can see the difference: <code>__dict__</code> recursively produces the <code>repr()</code>s of all the components, while <code>asdict()</code> creates <code>dict</code>s and <code>list</code>s as you would need for a JSON representation. In addition, <code>__dict__</code> shows you the dictionary for the object, while <code>asdict()</code> creates a new object.</p>"},{"location":"C05_Custom_Types_Data_Classes/#class-attributes","title":"Class Attributes","text":"<p>Sometimes people get confused and mistakenly believe that a class attribute defines an instance attribute:</p> <pre><code># a_with_x.py\nclass A:\n    # Does this create instance attributes?\n    x: int = 1\n    y: int = 2\n\n\na = A()\nprint(f\"{a.x = }, {a.y = }\")\n## a.x = 1, a.y = 2\n</code></pre> <p>Creating <code>A()</code> appears to automatically produce instance attributes <code>x</code> and <code>y</code>. This happens because of the lookup rules: when <code>a.x</code> or <code>a.y</code> can't find an instance attribute, it looks for a class attribute with the same name.</p> <p>The confusion is understandable because in languages like C++ and Java, similar class definitions do produce instance attributes.</p> <p>The key is to understand the difference between class attributes and instance attributes. Both are stored in dictionaries; <code>show_dicts</code> compares the attributes in both dictionaries:</p> <pre><code># class_and_instance.py\n\n\ndef show_dicts(obj: object, obj_name: str):\n    cls = obj.__class__\n    cls_name = cls.__name__\n\n    cls_dict = {\n        k: v\n        for k, v in cls.__dict__.items()\n        if not k.startswith(\"__\")\n    }\n    obj_dict = obj.__dict__\n\n    print(f\"{cls_name}.__dict__ (class attributes):\")\n    for attr in cls_dict.keys():\n        value = cls_dict[attr]\n        note = \"\"\n        if attr in obj_dict and obj_dict[attr] != value:\n            note = \"  # Hidden by instance attribute\"\n        print(f\"  {attr}: {value}{note}\")\n\n    print(f\"{obj_name}.__dict__ (instance attributes):\")\n    for attr in cls_dict.keys():\n        if attr in obj_dict:\n            print(f\"  {attr}: {obj_dict[attr]}\")\n        else:\n            print(f\"  {attr}: &lt;not present&gt;\")\n\n    for attr in cls_dict.keys():\n        print(f\"{obj_name}.{attr} is {getattr(obj, attr)}\")\n</code></pre> <p>Python stores class attributes in the class <code>__dict__</code> and instance attributes in the instance <code>__dict__</code>. When you access <code>a.x</code>, Python first looks in <code>a.__dict__</code>. If the name isn't found there, it continues the search in <code>A.__dict__</code>. This fallback behavior makes class attributes appear to be instance attributes, but they aren't.</p> <p><code>show_dicts</code> clarifies this by listing the class attributes, instance attributes, and the result of accessing the attribute (<code>getattr(obj, attr)</code>), which follows Python's lookup rules.</p> <p>Here's an example proving that class attributes do not create instance attributes:</p> <pre><code># class_attribute_proof.py\nfrom class_and_instance import show_dicts\n\n\nclass A:\n    x: int = 1\n    y: int = 2\n\n\na = A()\nshow_dicts(a, \"a\")\n## A.__dict__ (class attributes):\n##   x: 1\n##   y: 2\n## a.__dict__ (instance attributes):\n##   x: &lt;not present&gt;\n##   y: &lt;not present&gt;\n## a.x is 1\n## a.y is 2\na.x = 99\nshow_dicts(a, \"a\")\n## A.__dict__ (class attributes):\n##   x: 1  # Hidden by instance attribute\n##   y: 2\n## a.__dict__ (instance attributes):\n##   x: 99\n##   y: &lt;not present&gt;\n## a.x is 99\n## a.y is 2\na.y = 111\nshow_dicts(a, \"a\")\n## A.__dict__ (class attributes):\n##   x: 1  # Hidden by instance attribute\n##   y: 2  # Hidden by instance attribute\n## a.__dict__ (instance attributes):\n##   x: 99\n##   y: 111\n## a.x is 99\n## a.y is 111\n</code></pre> <p>After creating <code>a</code>, we see class attribute of <code>x</code> and <code>y</code> with values <code>1</code> and <code>2</code>, respectively. However, the instance dictionary is empty--there are no instance attributes. Thus, when we access <code>a.x</code> and <code>b.x</code>, Python doesn't find those instance attributes and continues to search, displaying the class attributes instead.</p> <p>The act of assigning <code>a.x = 99</code> and <code>a.y = 111</code> creates new instance attributes <code>x</code> and <code>y</code>. Note that the class attributes <code>A.x</code> and <code>A.y</code> remain unchanged.</p> <p>Let's perform the same experiment with a data class:</p> <pre><code># dataclass_attribute.py\nfrom dataclasses import dataclass\nfrom class_and_instance import show_dicts\n\n\n@dataclass\nclass D:\n    x: int = 1\n    y: int = 2\n\n\nd = D()\nshow_dicts(d, \"d\")\n## D.__dict__ (class attributes):\n##   x: 1\n##   y: 2\n## d.__dict__ (instance attributes):\n##   x: 1\n##   y: 2\n## d.x is 1\n## d.y is 2\nd.x = 99\nshow_dicts(d, \"d\")\n## D.__dict__ (class attributes):\n##   x: 1  # Hidden by instance attribute\n##   y: 2\n## d.__dict__ (instance attributes):\n##   x: 99\n##   y: 2\n## d.x is 99\n## d.y is 2\nd.y = 111\nshow_dicts(d, \"d\")\n## D.__dict__ (class attributes):\n##   x: 1  # Hidden by instance attribute\n##   y: 2  # Hidden by instance attribute\n## d.__dict__ (instance attributes):\n##   x: 99\n##   y: 111\n## d.x is 99\n## d.y is 111\n</code></pre> <p>After initialization, there are class attributes <code>x</code> and <code>y</code>, and instance attributes <code>x</code> and <code>y</code>. The <code>@dataclass</code> decorator looks at the class attributes and generates an <code>__init__</code> that creates the corresponding instance attributes. Note that after assigning to the instance attributes with <code>d.x = 99</code> and <code>d.y = 111</code>, the class attributes are unchanged.</p> <p>What happens if you define your own <code>__init__</code> for a data class?</p> <pre><code># dataclass_with_init.py\nfrom dataclasses import dataclass\nfrom class_and_instance import show_dicts\nfrom class_methods import show_methods\n\n\n@dataclass\nclass DI:\n    x: int = 1\n    y: int = 2\n\n    def __init__(self):\n        pass\n\n\nshow_methods(DI)\n## class DI:\n##   __init__(self)\n##   __annotate_func__(format, /)\n##   __replace__(self, /, **changes)\n##   __repr__(self)\n##   __eq__(self, other)\ndi = DI()\nshow_dicts(di, \"di\")\n## DI.__dict__ (class attributes):\n##   x: 1\n##   y: 2\n## di.__dict__ (instance attributes):\n##   x: &lt;not present&gt;\n##   y: &lt;not present&gt;\n## di.x is 1\n## di.y is 2\ndi.x = 99\nshow_dicts(di, \"di\")\n## DI.__dict__ (class attributes):\n##   x: 1  # Hidden by instance attribute\n##   y: 2\n## di.__dict__ (instance attributes):\n##   x: 99\n##   y: &lt;not present&gt;\n## di.x is 99\n## di.y is 2\ndi.y = 111\nshow_dicts(di, \"di\")\n## DI.__dict__ (class attributes):\n##   x: 1  # Hidden by instance attribute\n##   y: 2  # Hidden by instance attribute\n## di.__dict__ (instance attributes):\n##   x: 99\n##   y: 111\n## di.x is 99\n## di.y is 111\n</code></pre> <p>The generated <code>__init__</code> is suppressed. That means your <code>__init__</code> is responsible for setting up the instance attributes; if you don't, they won't be created. As a result, even though <code>x</code> and <code>y</code> are still listed as data class attributes, the instance starts out with no <code>x</code> or <code>y</code> in its <code>__dict__</code>. Accessing <code>di.x</code> and <code>di.y</code> falls back to the class attributes, just like in a regular class. Only when you assign new values to <code>di.x</code> and <code>di.y</code> do they become instance attributes and override the class-level defaults.</p>"},{"location":"C05_Custom_Types_Data_Classes/#the-power-of-custom-types","title":"The Power of Custom Types","text":"<p>Creating custom types simplifies managing data integrity and composition, reduces repetitive checks, and centralizes validation. Combined with functional programming principles like immutability and type composition, custom types significantly enhance the clarity, maintainability, and robustness of your code. Once you adopt this approach, you'll find your development process smoother, more reliable, and far more enjoyable.</p> <ul> <li>Incorporate examples from https://github.com/BruceEckel/DataClassesAsTypes</li> </ul>"},{"location":"C06_Custom_Types_Enums/","title":"Custom Types: Enums","text":"<p>An <code>Enum</code> type is preferable when you have a smaller set of values. <code>Enum</code>s provide additional type safety for fixed-value sets such as months:</p> <pre><code># birth_date.py\n# \"Leap years are left as an exercise.\"\nfrom dataclasses import dataclass\nfrom enum import Enum\n\nfrom book_utils import Catch\n\n\n@dataclass\nclass Day:\n    n: int\n\n    def __post_init__(self) -&gt; None:\n        assert 1 &lt;= self.n &lt;= 31, f\"{self}\"\n\n\n@dataclass\nclass Year:\n    n: int\n\n    def __post_init__(self) -&gt; None:\n        assert 1900 &lt; self.n &lt;= 2022, f\"{self}\"\n\n\nclass Month(Enum):\n    JANUARY = (1, 31)\n    FEBRUARY = (2, 28)\n    MARCH = (3, 31)\n    APRIL = (4, 30)\n    MAY = (5, 31)\n    JUNE = (6, 30)\n    JULY = (7, 31)\n    AUGUST = (8, 31)\n    SEPTEMBER = (9, 30)\n    OCTOBER = (10, 31)\n    NOVEMBER = (11, 30)\n    DECEMBER = (12, 31)\n\n    @staticmethod\n    def number(month_number: int):\n        assert 1 &lt;= month_number &lt;= 12, f\"Month({month_number})\"\n        return list(Month)[month_number - 1]\n\n    def check_day(self, day: Day):\n        assert day.n &lt;= self.value[1], f\"{self} {day}\"\n\n    def __repr__(self):\n        return self.name\n\n\n@dataclass\nclass BirthDate:\n    m: Month\n    d: Day\n    y: Year\n\n    def __post_init__(self):\n        self.m.check_day(self.d)\n\n\nfor date in [\n    (7, 8, 1957),\n    (0, 32, 1857),\n    (2, 31, 2022),\n    (9, 31, 2022),\n    (4, 31, 2022),\n    (6, 31, 2022),\n    (11, 31, 2022),\n    (12, 31, 2022),\n]:\n    with Catch():\n        print(date)\n        print(\n            BirthDate(\n                Month.number(date[0]),\n                Day(date[1]),\n                Year(date[2]),\n            )\n        )\n        print(\"-\" * 30)\n## (7, 8, 1957)\n## BirthDate(m=JULY, d=Day(n=8), y=Year(n=1957))\n## ------------------------------\n## (0, 32, 1857)\n## Error: Month(0)\n## (2, 31, 2022)\n## Error: Month.FEBRUARY Day(n=31)\n## (9, 31, 2022)\n## Error: Month.SEPTEMBER Day(n=31)\n## (4, 31, 2022)\n## Error: Month.APRIL Day(n=31)\n## (6, 31, 2022)\n## Error: Month.JUNE Day(n=31)\n## (11, 31, 2022)\n## Error: Month.NOVEMBER Day(n=31)\n## (12, 31, 2022)\n## BirthDate(m=DECEMBER, d=Day(n=31), y=Year(n=2022))\n## ------------------------------\n</code></pre> <p><code>Month</code> can be a data class, but it's more complicated than using <code>Enum</code>, and with questionable benefits:</p> <pre><code># month_data_class.py\nfrom dataclasses import dataclass, field\n\nfrom book_utils import Catch\n\n\n@dataclass\nclass Day:\n    n: int\n\n    def __post_init__(self) -&gt; None:\n        assert 1 &lt;= self.n &lt;= 31, f\"Day({self.n})\"\n\n\n@dataclass\nclass Year:\n    n: int\n\n    def __post_init__(self) -&gt; None:\n        assert 1900 &lt; self.n &lt;= 2022, f\"Year({self.n})\"\n\n\n@dataclass\nclass Month:\n    name: str\n    n: int\n    max_days: int\n\n    def __post_init__(self):\n        assert 1 &lt;= self.n &lt;= 12, f\"Month({self.n})\"\n        assert self.max_days in [28, 30, 31], (\n            f\"Month max_days {self.max_days}\"\n        )\n\n    def check_day(self, day: Day):\n        assert day.n &lt;= self.max_days, f\"{self} {day}\"\n\n    @staticmethod\n    def make_months():\n        return [\n            Month(m[0], m[1], m[2])\n            for m in [\n                (\"January\", 1, 31),\n                (\"February\", 2, 28),\n                (\"March\", 3, 31),\n                (\"April\", 4, 30),\n                (\"May\", 5, 31),\n                (\"June\", 6, 30),\n                (\"July\", 7, 31),\n                (\"August\", 8, 31),\n                (\"September\", 9, 30),\n                (\"October\", 10, 31),\n                (\"November\", 11, 30),\n                (\"December\", 12, 31),\n            ]\n        ]\n\n\n@dataclass\nclass Months:\n    months: list[Month] = field(\n        default_factory=Month.make_months\n    )\n\n    def number(self, month_number: int):\n        assert 1 &lt;= month_number &lt;= 12, f\"Month({month_number})\"\n        return self.months[month_number - 1]\n\n\n@dataclass\nclass BirthDate:\n    m: Month\n    d: Day\n    y: Year\n\n    def __post_init__(self):\n        self.m.check_day(self.d)\n\n\nmonths = Months()\nfor date in [\n    (7, 8, 1957),\n    (0, 32, 1857),\n    (2, 31, 2022),\n    (9, 31, 2022),\n    (4, 31, 2022),\n    (6, 31, 2022),\n    (11, 31, 2022),\n    (12, 31, 2022),\n]:\n    with Catch():\n        print(date)\n        print(\n            BirthDate(\n                months.number(date[0]),\n                Day(date[1]),\n                Year(date[2]),\n            )\n        )\n        print(\"-\" * 30)\n## (7, 8, 1957)\n## BirthDate(m=Month(name='July', n=7, max_days=31), d=Day(n=8),\n## y=Year(n=1957))\n## ------------------------------\n## (0, 32, 1857)\n## Error: Month(0)\n## (2, 31, 2022)\n## Error: Month(name='February', n=2, max_days=28) Day(n=31)\n## (9, 31, 2022)\n## Error: Month(name='September', n=9, max_days=30) Day(n=31)\n## (4, 31, 2022)\n## Error: Month(name='April', n=4, max_days=30) Day(n=31)\n## (6, 31, 2022)\n## Error: Month(name='June', n=6, max_days=30) Day(n=31)\n## (11, 31, 2022)\n## Error: Month(name='November', n=11, max_days=30) Day(n=31)\n## (12, 31, 2022)\n## BirthDate(m=Month(name='December', n=12, max_days=31),\n## d=Day(n=31), y=Year(n=2022))\n## ------------------------------\n</code></pre> <p>Here are all the ways you can use <code>Enum</code>s:</p> <pre><code># enum_examples.py\n\"\"\"\nComprehensive demonstration of Enum capabilities.\n\"\"\"\n\nfrom enum import (\n    Enum,\n    auto,\n    unique,\n    IntEnum,\n    StrEnum,\n    Flag,\n    IntFlag,\n)\n\n\n# 1. Basic Enum definition\nclass Color(Enum):\n    RED = 1\n    GREEN = 2\n    BLUE = 3\n\n\nprint(Color.RED)\n## Color.RED\nprint(Color.RED.name, Color.RED.value)\n## RED 1\n\n\n# 2. Enum with auto values\nclass Status(Enum):\n    PENDING = auto()\n    RUNNING = auto()\n    DONE = auto()\n\n\nprint(list(Status))\n## [&lt;Status.PENDING: 1&gt;, &lt;Status.RUNNING: 2&gt;, &lt;Status.DONE: 3&gt;]\n\n\n# 3. Custom values and types\nclass HttpStatus(IntEnum):\n    OK = 200\n    NOT_FOUND = 404\n    INTERNAL_ERROR = 500\n\n\nprint(\n    f\"HttpStatus.OK = {HttpStatus.OK}, as int: {int(HttpStatus.OK)}\"\n)\n## HttpStatus.OK = 200, as int: 200\n\n# 4. Iteration and comparison\nfor color in Color:\n    print(f\"Color: {color.name} = {color.value}\")\n## Color: RED = 1\n## Color: GREEN = 2\n## Color: BLUE = 3\n\nprint(Color.RED == Color.RED)\n## True\nprint(Color.RED is Color.RED)\n## True\nprint(Color.RED == Color.GREEN)\n## False\n\n# 5. Access by name and value\nprint(Color[\"BLUE\"])\n## Color.BLUE\nprint(Color(2))  # GREEN\n## Color.GREEN\n\n\n# 6. Unique constraint\n@unique\nclass Direction(Enum):\n    NORTH = 1\n    SOUTH = 2\n    EAST = 3\n    WEST = 4\n    # UP = 1  # Uncommenting this raises ValueError\n\n\n# 7. Subclassing str or int for JSON-friendliness\nclass Fruit(StrEnum):\n    APPLE = \"apple\"\n    BANANA = \"banana\"\n\n\nprint(Fruit.APPLE.upper())\n## APPLE\nprint(f\"JSON-ready: {Fruit.BANANA!r}\")\n## JSON-ready: &lt;Fruit.BANANA: 'banana'&gt;\n\n\n# 8. Methods and properties on Enums\nclass Shape(Enum):\n    CIRCLE = auto()\n    SQUARE = auto()\n\n    def sides(self) -&gt; int:\n        return {\n            Shape.CIRCLE: 0,\n            Shape.SQUARE: 4,\n        }[self]\n\n\nprint(f\"Shape.CIRCLE has {Shape.CIRCLE.sides()} sides\")\n## Shape.CIRCLE has 0 sides\n\n\n# 9. Aliases\nclass Mood(Enum):\n    HAPPY = 1\n    JOYFUL = 1  # Alias\n    SAD = 2\n\n\nprint(\n    f\"Members: {[m for m in Mood]}\"\n)  # Only one member per value\n## Members: [&lt;Mood.HAPPY: 1&gt;, &lt;Mood.SAD: 2&gt;]\nprint(f\"Alias: {Mood.JOYFUL is Mood.HAPPY}\")\n## Alias: True\n\n\n# 10. Bitwise Flags\nclass Permission(Flag):\n    READ = auto()\n    WRITE = auto()\n    EXECUTE = auto()\n\n\nuser_perm = Permission.READ | Permission.WRITE  # type: ignore\nprint(f\"User permissions: {user_perm}\")\n## User permissions: Permission.READ|WRITE\nprint(f\"Can execute? {Permission.EXECUTE in user_perm}\")\n## Can execute? False\n\n\n# IntFlag for bitwise checks with ints\nclass Access(IntFlag):\n    NONE = 0\n    READ = 1\n    WRITE = 2\n    EXECUTE = 4\n\n\nperm = Access.READ | Access.EXECUTE\nprint(f\"perm &amp; Access.WRITE: {perm &amp; Access.WRITE}\")\n## perm &amp; Access.WRITE: 0\nprint(f\"perm has EXECUTE: {bool(perm &amp; Access.EXECUTE)}\")\n## perm has EXECUTE: True\n\n# 11. Pattern matching\nstatus = Status.DONE\nmatch status:\n    case Status.PENDING:\n        print(\"Job is pending\")\n    case Status.RUNNING:\n        print(\"Job is in progress\")\n    case Status.DONE:\n        print(\"Job completed\")\n## Job completed\n</code></pre> <p><code>Enum</code>s improve robustness by making code both readable and safely constrained. For simplicity and IDE interactivity, choose <code>Enum</code>s over data classes for fixed-value sets.</p> <p>TODO: Can enum names be brought into scope?</p>"},{"location":"C06_Custom_Types_Enums/#enum-mixins","title":"Enum Mixins","text":"<p>An <code>Enum</code> defines a closed set of named values. Allowing inheritance conflicts with the meaning of \"the set of valid members.\" Thus, Python forbids subclassing a concrete <code>Enum</code> class to make a new <code>Enum</code>.</p> <p>The only thing you can inherit when dealing with <code>Enum</code>s is mixins, like adding methods:</p> <pre><code># enum_mixins.py\nfrom enum import Enum\n\n\nclass StrMixin(str):\n    pass\n\n\nclass Color(StrMixin, Enum):\n    RED = \"red\"\n    GREEN = \"green\"\n</code></pre> <p>Here, Color mixes in <code>str</code> behavior. Because it's an <code>Enum</code>, you can't inherit from <code>Color</code>.</p>"},{"location":"C06_Custom_Types_Enums/#enums-and-exhaustivity","title":"Enums and Exhaustivity","text":"<p>Because you can't inherit from an <code>Enum</code>, an <code>Enum</code> can be included in exhaustivity analysis during pattern matching:</p> <pre><code># enum_exhaustivity.py\nfrom enum import Enum\n\n\nclass Status(Enum):\n    OPEN = \"open\"\n    CLOSED = \"closed\"\n    PENDING = \"pending\"\n\n    def handle(self) -&gt; str:\n        match self:\n            case Status.OPEN:\n                return f\"open: {self}\"\n            case Status.CLOSED:\n                return f\"closed: {self}\"\n            case Status.PENDING:\n                return f\"pending: {self}\"\n            # Not possible, but some type checkers\n            # haven't caught up yet:\n            case _:\n                return f\"Unhandled: {self}\"\n\n\nprint(Status.OPEN.handle())\n## open: Status.OPEN\nprint(Status.CLOSED.handle())\n## closed: Status.CLOSED\nprint(Status.PENDING.handle())\n## pending: Status.PENDING\n</code></pre> <p>Because <code>Enum</code>s are closed, you know all possible <code>Status</code> members: <code>OPEN</code>, <code>CLOSED</code>, <code>PENDING</code>. The type checker warns you if you forget to handle a case. No \"unknown\" cases can sneak in later because <code>Enum</code>s can't be subclassed.</p> <p>// What different types can Enum members be? Can you mix types within a single Enum? // Can you provide type annotations to Enum members?</p>"},{"location":"C06_Custom_Types_Enums/#attaching-functionality-to-enum-members","title":"Attaching Functionality to Enum Members","text":"<pre><code># state_machine.py\nfrom __future__ import annotations\nfrom enum import Enum\nfrom typing import Callable\n\n\ndef open_next(self: Status) -&gt; Status:\n    _ = self  # Silence unused variable warning.\n    print(\"Moving from OPEN to PENDING.\")\n    return Status.PENDING\n\n\ndef pending_next(self: Status) -&gt; Status:\n    _ = self\n    print(\"Moving from PENDING to CLOSED.\")\n    return Status.CLOSED\n\n\ndef closed_next(self: Status) -&gt; Status:\n    _ = self\n    print(\"CLOSED is a final state. Staying put.\")\n    return Status.CLOSED\n\n\nclass Status(Enum):\n    OPEN = (\"open\", open_next)\n    PENDING = (\"pending\", pending_next)\n    CLOSED = (\"closed\", closed_next)\n\n    def __init__(\n        self,\n        label: str,\n        next_handler: Callable[[Status], Status],\n    ) -&gt; None:\n        self._label = label\n        self._next_handler = next_handler\n\n    def next(self) -&gt; Status:\n        return self._next_handler(self)\n\n    @property\n    def label(self) -&gt; str:\n        return self._label\n\n\nstate = Status.OPEN\nwhile state != Status.CLOSED:\n    print(state.label)\n    state = state.next()\n## open\n## Moving from OPEN to PENDING.\n## pending\n## Moving from PENDING to CLOSED.\n</code></pre> <p>Each <code>Enum</code> member (<code>Status.OPEN</code>, etc.) carries two pieces of information:</p> <ol> <li> <p>A label: \"open\" or \"pending\" or \"closed\"</p> </li> <li> <p>A handler function <code>_next_handler</code></p> </li> </ol> <p>In the <code>__init__</code>, we capture these and assign to instance attributes (<code>_label</code>, <code>_next_handler</code>). The <code>next()</code> method calls the stored function.</p>"},{"location":"C06_Custom_Types_Enums/#a-finite-state-machine","title":"A Finite State Machine","text":"<p>A Finite State Machine (FSM) chooses its next state based on the current state and one or more inputs. All the information of an FSM is initialized in the state transition table, so we want that to be fully typed and as clean as possible. Here's a way to do that:</p> <pre><code># finite_state_machine.py\nfrom __future__ import annotations\nfrom enum import Enum\nfrom typing import Dict\n\n\nclass Event(Enum):\n    SUBMIT = \"submit\"\n    APPROVE = \"approve\"\n    REJECT = \"reject\"\n    REOPEN = \"reopen\"\n\n\nclass Status(Enum):\n    OPEN = \"open\"\n    PENDING = \"pending\"\n    CLOSED = \"closed\"\n\n    def __init__(self, label: str) -&gt; None:\n        self._label = label\n\n    def on_event(self, event: Event) -&gt; Status:\n        mapping = _TRANSITIONS.get(self, {})\n        next_state = mapping.get(event)\n        if next_state is None:\n            print(f\"Invalid {self.name} &amp; {event.name}\")\n            return self\n        print(f\"{self.name} + {event.name} -&gt; {next_state.name}\")\n        return next_state\n\n    @property\n    def label(self) -&gt; str:\n        return self._label\n\n\n# Mapping of transitions: {current_status: {event: next_status}}\n_TRANSITIONS: Dict[Status, Dict[Event, Status]] = {\n    Status.OPEN: {Event.SUBMIT: Status.PENDING},\n    Status.PENDING: {\n        Event.APPROVE: Status.CLOSED,\n        Event.REJECT: Status.OPEN,\n    },\n    Status.CLOSED: {Event.REOPEN: Status.OPEN},\n}\n\n\ndef run(initial: Status, events: list[Event]) -&gt; None:\n    \"\"\"\n    Execute a sequence of events starting from the given initial status.\n    \"\"\"\n    state = initial\n    print(f\"Starting at {state.label}\")\n    for event in events:\n        state = state.on_event(event)\n        print(f\"Now at {state.label}\")\n\n\nworkflow = [\n    Event.SUBMIT,\n    Event.REOPEN,\n    Event.REJECT,\n    Event.SUBMIT,\n    Event.APPROVE,\n    Event.REOPEN,\n]\nrun(Status.OPEN, workflow)\n## Starting at open\n## OPEN + SUBMIT -&gt; PENDING\n## Now at pending\n## Invalid PENDING &amp; REOPEN\n## Now at pending\n## PENDING + REJECT -&gt; OPEN\n## Now at open\n## OPEN + SUBMIT -&gt; PENDING\n## Now at pending\n## PENDING + APPROVE -&gt; CLOSED\n## Now at closed\n## CLOSED + REOPEN -&gt; OPEN\n## Now at open\n</code></pre>"},{"location":"C06_Custom_Types_Enums/#literal-the-lightweight-enum","title":"<code>Literal</code>: The Lightweight <code>Enum</code>","text":"<p><code>Literal</code> types specify a set of permissible values to ensure values match expected exact constants:</p> <pre><code># literal_types.py\nfrom typing import Literal\n\n\ndef set_mode(mode: Literal[\"auto\", \"manual\"]) -&gt; None:\n    print(f\"Mode set to {mode}\")\n\n\nset_mode(\"auto\")  # valid\n## Mode set to auto\n# set_mode('automatic')  # invalid, detected by type checker\n</code></pre> <p><code>Literal</code>s can serve as a lightweight substitute for <code>Enum</code>s when you only need to restrict values at the type level and do not require the additional runtime features of <code>Enum</code>s. This makes <code>Literal</code>s attractive for scenarios like defining a parameter that only accepts a small set of constant values without adding extra code complexity.</p> <p>// What types can a Literal contain? // Sequence of small examples showing everything you can do with Literals</p>"},{"location":"C06_Custom_Types_Enums/#pattern-matching-on-literals","title":"Pattern Matching on Literals","text":"<pre><code># literal_pattern_matching.py\nfrom typing import Literal\n\nCommand = Literal[\"start\", \"stop\", \"pause\"]\n\n\ndef run_command(cmd: Command) -&gt; str:\n    match cmd:\n        case \"start\":\n            return \"System starting...\"\n        case \"stop\":\n            return \"System stopping...\"\n        case \"pause\":\n            return \"System pausing...\"\n        # Should not need this; some type checkers\n        # require it anyway:\n        case _:  # Unreachable\n            raise ValueError(f\"Unhandled command: {cmd}\")\n\n\ndef run_string(cmd: str) -&gt; str | None:\n    match cmd:\n        case \"start\":\n            return \"System starting...\"\n        case \"stop\":\n            return \"System stopping...\"\n        case \"pause\":\n            return \"System pausing...\"\n    return None\n</code></pre> <p>In <code>run_command</code>, the <code>cmd</code> parameter is restricted to the values <code>\"start\"</code>, <code>\"stop\"</code>, or <code>\"pause\"</code>. The <code>match</code> statement uses pattern matching on these <code>Literal</code> values. A type checker will warn you if a branch is missing. This is called <code>exhaustiveness checking</code>.</p> <p>However, with the <code>match</code> in <code>run_string</code> there's no way to know what the legal cases are, so exhaustiveness checking is not possible.</p> <p>[Example of exhaustiveness checking with subclasses]</p>"},{"location":"C06_Custom_Types_Enums/#examples","title":"Examples","text":"<p>Can literals be created dynamically? Probably not. Example of Country with states, states with counties, counties with towns and cities, How far can <code>Literal</code> go? Is there a limit to the number of Literals in a single element? Compare that with the same example using Enums. Perhaps an example that mixes <code>Literal</code>s and <code>Enum</code>s</p>"},{"location":"C06_Custom_Types_Enums/#similarities","title":"Similarities","text":"<ul> <li>Value Restriction:   Both <code>Literal</code>s and <code>Enum</code>s let you restrict a variable to a fixed set of values.   For example, <code>ParamType = Union[float, Literal[\"MIN\", \"MAX\", \"DEF\"]]</code>   tells a type checker that only these string values are allowed (aside from floats),   similar to how an <code>Enum</code> restricts possible members.</li> </ul>"},{"location":"C06_Custom_Types_Enums/#differences","title":"Differences","text":"<ul> <li> <p>Type Checking vs. Runtime Behavior:</p> <ul> <li><code>Literal</code>: <code>Literal</code>s are a static type annotation introduced in PEP 586.   They exist solely for type checking and do not create a distinct runtime type.   The type checker (and your IDE) knows that only those exact values are allowed, but at runtime,   they are ordinary values (e.g., ordinary strings).</li> <li><code>Enum</code>: An <code>Enum</code> is a real class (inheriting from <code>enum.Enum</code>) that creates distinct runtime objects. <code>Enum</code>s   provide additional functionality like iteration over members, comparison, and custom methods. They work both at   runtime and during static type checking.</li> </ul> </li> <li> <p>Overhead and Simplicity:</p> <ul> <li><code>Literal</code>: Using <code>Literal</code>s is easy and lightweight if you just want to specify allowed constant values. There\u2019s   no additional boilerplate, so it\u2019s a good choice when you only need type constraints.</li> <li><code>Enum</code>: <code>Enum</code>s come with more structure and can encapsulate behavior. However, they require defining a class and   are slightly heavier in terms of syntax and runtime footprint.</li> </ul> </li> </ul>"},{"location":"C06_Custom_Types_Enums/#choosing-between-literal-and-enum","title":"Choosing between <code>Literal</code> and <code>Enum</code>","text":"<ul> <li> <p>Use <code>Literal</code>s if:</p> <ul> <li>You need a simple, compile-time constraint on allowed values without extra runtime behavior.</li> <li>You want minimal boilerplate and are comfortable relying on your static type checker and IDE for guidance.</li> </ul> </li> <li> <p>Use <code>Enum</code>s if:</p> <ul> <li>You need runtime features, such as iterating over allowed values, custom methods, or more semantic richness (e.g.,   when each value might need its own behavior or additional attributes).</li> <li>You want a self-documenting interface that clearly models a set of related constants as a distinct type.</li> </ul> </li> </ul> <p>Both approaches improve type safety, but if you need more robust functionality or runtime introspection, an <code>Enum</code> might be the better choice.</p>"},{"location":"C06_Custom_Types_Enums/#literal-support-for-enums","title":"Literal Support for Enums","text":"<p>The type checker knows the exact value of an <code>Enum</code> member and can narrow types accordingly. Because of this, type checkers can treat <code>Enum</code> values as <code>Literal</code>s.</p> <pre><code># enum_exhaustiveness.py\nfrom enum import Enum\n\n\nclass Color(Enum):\n    RED = \"red\"\n    GREEN = \"green\"\n    BLUE = \"blue\"\n\n\n# Did you intentionally leave out Color.BLUE?\ndef paint1(color: Color) -&gt; str:\n    if color == Color.RED:\n        return \"You chose red\"\n    elif color == Color.GREEN:\n        return \"You chose green\"\n    else:\n        return \"Something else\"\n\n\nprint(paint1(Color.BLUE))\n## Something else\n\n\n# Exhaustiveness checking:\ndef paint2(color: Color) -&gt; str:\n    match color:\n        case Color.RED:\n            return \"You chose red\"\n        case Color.GREEN:\n            return \"You chose green\"\n        case Color.BLUE:\n            return \"You chose blue\"\n</code></pre> <p>The type checker warns you if a branch is missing. This is essentially <code>Literal</code>-style exhaustiveness for <code>Enum</code>s.</p>"},{"location":"C06_Custom_Types_Enums/#converting-a-literal-to-a-set","title":"Converting a <code>Literal</code> to a <code>Set</code>","text":"<p>You can write an expression that looks like it's checking for membership in a <code>Literal</code> but it won't work:</p> <pre><code># literal_to_set.py\nfrom typing import Literal\n\nParamVal = Literal[\"DEF\", \"MIN\", \"MAX\"]\nprint(ParamVal)\n## typing.Literal['DEF', 'MIN', 'MAX']\nprint(\"MIN\" in ParamVal)  # type: ignore\n## False\nprint(\"NOPE\" in ParamVal)  # type: ignore\n## False\n\n# Convert literal values to a set:\nallowed_set = set(ParamVal.__args__)  # type: ignore\nprint(allowed_set)\n## {'MIN', 'MAX', 'DEF'}\nprint(\"MIN\" in allowed_set)\n## True\nprint(\"NOPE\" in allowed_set)\n## False\n</code></pre> <p>To check for membership, you must convert it to a <code>set</code> using the <code>__args__</code> property, as seen in <code>allowed_set</code>.</p>"},{"location":"C06_Custom_Types_Enums/#choosing-between-enum-literal-and-set","title":"Choosing Between <code>Enum</code>, <code>Literal</code>, and <code>Set</code>","text":"<p>Each approach has its strengths and trade-offs. The best choice depends on your requirements for type safety, runtime behavior, and code clarity.</p>"},{"location":"C06_Custom_Types_Enums/#literal","title":"<code>Literal</code>","text":"<p>Pros:</p> <ul> <li>Static Type Safety: Type checkers can enforce that only the allowed constant values appear in your code.</li> <li>Minimal Overhead: <code>Literal</code>s have no runtime cost; they serve solely as type annotations.</li> <li>Simplicity: Using literals is straightforward and requires no extra boilerplate code.</li> </ul> <p>Cons:</p> <ul> <li>No Runtime Distinction: At runtime, <code>\"MIN\"</code>, <code>\"MAX\"</code>, and <code>\"DEF\"</code> are ordinary strings.   You lose benefits like custom methods or iteration over members.</li> <li>Limited Expressiveness: <code>Literal</code>s only provide type-checking constraints and no additional behavior beyond that.</li> </ul> <p>When to Use:</p> <ul> <li>Use <code>Literal</code>s when you need to enforce a small set of constant values at the type level, and you are comfortable   relying on static type checkers and IDEs for guidance.</li> <li>They are ideal for simple cases where you want to ensure that only a few specific string values (alongside other   types, like numbers) are accepted.</li> </ul>"},{"location":"C06_Custom_Types_Enums/#enum","title":"<code>Enum</code>","text":"<p><code>Enum</code>s create a distinct type at runtime and define a collection of symbolic names bound to constant values. For example:</p> <p>Pros:</p> <ul> <li>Runtime Features: <code>Enum</code>s are real classes at runtime, so they support iteration, comparison, and custom methods.</li> <li>Clarity and Self-Documentation: Using an <code>Enum</code> clearly signals that the parameter is one of a predetermined, fixed   set.   IDE autocompletion can also list the valid members.</li> <li>Extra Functionality: You can add methods or properties to an <code>Enum</code> if the values need to carry extra meaning (for   instance, mapping to specific instrument settings).</li> </ul> <p>Cons:</p> <ul> <li>Additional Overhead: <code>Enum</code>s require a bit more code and syntax compared to <code>Literal</code>s.</li> <li>Slightly Heavier: While typically negligible, there is a bit more runtime overhead as <code>Enum</code>s are objects.</li> </ul> <p>When to Use:</p> <ul> <li>Use <code>Enum</code>s when you need not only type safety at the static level but also runtime assurance--such as when you need   to iterate over allowed options or attach extra behavior.</li> <li><code>Enum</code>s are excellent for cases where the set of allowed values is fixed, and you might want to use them throughout   your codebase in a uniform, well-documented manner.</li> </ul>"},{"location":"C06_Custom_Types_Enums/#set","title":"<code>Set</code>","text":"<p>A set is a built-in Python data structure that holds unique elements. In the context of allowed values, you might define <code>ALLOWED_KEYWORDS = {\"MIN\", \"MAX\", \"DEF\"}</code></p> <p>Pros:</p> <ul> <li>Dynamic Membership Testing: <code>Set</code>s check if a given value is in the allowed collection using the <code>in</code> operator.</li> <li>Runtime Flexibility: You can modify the set at runtime if needed (though for constants this might not be necessary).</li> <li>Simplicity in Validation: When writing custom validation code, a set easily confirms membership.</li> </ul> <p>Cons:</p> <ul> <li>Not a Type Annotation: <code>Set</code>s do not integrate with static type checkers. They only serve at runtime to check if a   value belongs to the allowed set.</li> <li>No Static Safety: Unlike <code>Literal</code>s or <code>Enum</code>s, sets don\u2019t give you compile-time guarantees or IDE autocompletion for   allowed values.</li> </ul> <p>When to Use:</p> <ul> <li>Use sets for runtime validation where you need a simple way to confirm membership (e.g., inside a helper function that   checks if a value is valid).</li> <li>They are ideal when the allowed values are defined once and only used for dynamic checks, not for type annotations.</li> </ul>"},{"location":"C06_Custom_Types_Enums/#choosing","title":"Choosing","text":"<p>Each approach has its specific use cases:</p> <ul> <li><code>Literal</code>s provide a quick and easy way to inform static type checkers without extra runtime behavior.</li> <li><code>Enum</code>s add clarity and runtime functionality at the cost of a little extra complexity.</li> <li><code>Set</code>s work well if your validation is purely runtime-oriented, and you don\u2019t need the additional benefits of static   type restrictions.</li> </ul> <p>Choosing between them depends on whether you prioritize compile-time type checking and better IDE support (favoring <code>Literal</code>s or <code>Enum</code>s) or need flexible, dynamic validation (favoring <code>set</code>s). In many cases, combining these approaches can be effective--for example, using <code>Literal</code>s in type annotations and a <code>set</code> for quick runtime membership checks in helper functions.</p>"},{"location":"C06_Custom_Types_Enums/#typeddicts-for-structured-data","title":"TypedDicts for Structured Data","text":"<p><code>TypedDict</code> is useful when defining dictionary structures with known keys and typed values.</p> <pre><code># typed_dict.py\nfrom typing import TypedDict\n\n\nclass UserProfile(TypedDict):\n    username: str\n    email: str\n    age: int\n\n\nuser: UserProfile = {\n    \"username\": \"alice\",\n    \"email\": \"alice@example.com\",\n    \"age\": 30,\n}\n</code></pre> <p><code>TypedDict</code> clarifies expected keys and types, providing type safety for dictionary data.</p>"},{"location":"C06_Custom_Types_Enums/#optional-fields","title":"Optional Fields","text":"<p>You can specify optional fields using <code>NotRequired</code> (Python 3.11+) or <code>total=False</code>:</p> <pre><code># optional_typed_dict_fields.py\nfrom typing import TypedDict, NotRequired\n\n\nclass UserSettings(TypedDict):\n    theme: str\n    notifications_enabled: NotRequired[bool]\n\n\n# Only the required field is provided:\ntettings: UserSettings = {\"theme\": \"dark\"}\n</code></pre> <p>This flexibility allows clear definitions for complex, partially optional data structures.</p>"},{"location":"C06_Custom_Types_Enums/#combining-dataclasses-and-enums","title":"Combining Dataclasses and <code>Enum</code>s","text":"<pre><code># dataclasses_and_enums.py\nfrom dataclasses import dataclass\nfrom enum import Enum\n\n\nclass Status(Enum):\n    ACTIVE = \"active\"\n    INACTIVE = \"inactive\"\n\n\n@dataclass\nclass User:\n    id: int\n    name: str\n    status: Status\n\n\nprint(User(id=1, name=\"Alice\", status=Status.ACTIVE))\n## User(id=1, name='Alice', status=&lt;Status.ACTIVE: 'active'&gt;)\n</code></pre>"},{"location":"C06_Custom_Types_Enums/#domain-driven-design-ddd","title":"Domain-Driven Design (DDD)","text":"<p>Strongly typed domain models help clearly represent domain logic, improving robustness and maintainability. Define domain entities explicitly to enhance domain logic expressiveness:</p> <pre><code># ddd.py\nfrom dataclasses import dataclass\n\n\n@dataclass\nclass Product:\n    name: str\n    price: float\n\n\n@dataclass\nclass Order:\n    order_id: int\n    products: list[Product]\n\n    def total(self) -&gt; float:\n        return sum(product.price for product in self.products)\n</code></pre> <p>Strongly typed domain models help catch issues early, facilitating clearer, safer, and more maintainable codebases.</p>"},{"location":"C07_Immutability/","title":"Immutability","text":"<p>Immutability--the inability to change an object or variable after its creation--offers several key benefits in software design. By making data immutable, we greatly simplify the mental model needed to understand program state. In particular, immutability makes programs easier to reason about by eliminating the possibility of unexpected changes to data. This reduction in \"the realm of possibility\" for how data can evolve means fewer potential bugs and side effects in our code. An immutable variable gives us one less thing to worry about when tracing through a program's logic, because once it's set, it won't arbitrarily change under us.</p> <p>Another major benefit is safety in concurrent contexts. In multithreaded code, shared mutable state is a common source of issues like data races. Immutability helps prevent these by ensuring that once a shared object is created, threads can read it without needing locks or fear of one thread modifying it out from under another. Even in single-threaded programs, immutability prevents accidental modifications that could lead to corrupted state. With mutable state, a stray assignment or method call can silently alter data and introduce bugs that are hard to track down. In contrast, if you attempt to modify an immutable piece of state, it will typically fail fast--either with a clear error at runtime or (ideally) an error caught by a static analysis tool before the code even runs. This fail-fast behavior makes bugs much easier to detect and fix.</p> <p>Some concrete advantages of embracing immutability:</p> <ul> <li>Easier Reasoning: You can trust that values won't change unexpectedly, making functions behave more predictably.</li> <li>Thread-Safety: Immutable objects can be freely shared between threads without synchronization, since no thread can   alter them and cause race conditions.</li> <li>Avoiding Bugs: Accidental mutations are caught early--either by a runtime exception or by a type checker--instead   of silently corrupting state.</li> <li>Safe Sharing and Caching: You can safely reuse or cache immutable objects (even as keys in dictionaries or members   of sets) since their hash or contents won't change after creation.   This aligns with Python's rule that objects used as dictionary keys must be immutable (e.g., using a tuple instead of   a list for a key).</li> </ul> <p>Functional programming strongly advocates immutability, preventing accidental changes and thus simplifying reasoning about your code. Designing with immutability leads to code that is safer, more robust in concurrent environments, and easier to understand. As a dynamic language, Python doesn't enforce immutability by default, but it provides patterns and tools to achieve immutable-like behavior where beneficial.</p>"},{"location":"C07_Immutability/#immutability-by-convention-in-python","title":"Immutability by Convention in Python","text":"<p>Python does not have a built-in <code>const</code> declaration to make a variable truly immutable, nor does it allow truly unchangeable user-defined objects in all cases. Instead, Python developers have traditionally relied on conventions and certain immutable built-in types to signal that something should not be changed.</p> <p>One common convention is the use of ALL_CAPS names for constants. According to PEP 8 (Python's style guide), \"constants are usually defined on a module level and written in all capital letters with underscores separating words.\" For example, one might write:</p> <pre><code># example_1.py\nMAX_OVERFLOW = 1000  # intended to be a constant\nDATABASE_URL = (\n    \"postgres://localhost/db\"  # constant configuration\n)\n</code></pre> <p>By writing these names in uppercase, we indicate to other developers (and ourselves) that these values should be treated as immutable constants. The Python interpreter won't stop you from reassigning <code>MAX_OVERFLOW</code> to a different value--this is purely a human convention--but following this naming scheme makes the code's intent clear. Many linters will flag reassignment of all-caps \"constant\" variables as a potential issue, reinforcing the convention.</p> <p>Another historical approach is to leverage Python's immutable built-in types. Python itself has immutable types like <code>int</code>, <code>float</code>, <code>str</code>, <code>tuple</code>, and <code>frozenset</code>. When you want to prevent modifications to a collection of values, you might use a tuple instead of a list, or a <code>frozenset</code> instead of a set. For instance, if you have a fixed set of options, using a tuple (<code>options = (\"red\", \"green\", \"blue\")</code>) conveys that this sequence is not to be altered. This isn't enforced by syntax, but the type's lack of mutating methods provides some safety. Trying to call a mutating method on an immutable type will result in an <code>AttributeError</code> or a runtime error (for example, attempting to append to a tuple will fail since tuples have no <code>append</code> method).</p> <p>Before formal language support for immutability, Python developers used naming conventions and choice of immutable types to signal immutability. This approach relies on discipline: the interpreter won't stop someone from breaking the rules, but clear conventions help maintain correctness. Python's philosophy has long been \"we are all consenting adults here\"--meaning if someone really wants to mutate something, the language lets them, but by following conventions like all-caps constants and using immutable data types, you can largely avoid accidental mutations.</p> <p>Modern Python, however, has introduced better ways to enforce immutability or at least catch mutations early. The two main tools we'll discuss are the <code>Final</code> type annotation (for variables and attributes that shouldn't be reassigned) and frozen dataclasses (for creating immutable data objects). These provide a more formal way to achieve immutability beyond just convention.</p>"},{"location":"C07_Immutability/#using-final-for-constants-and-immutable-references","title":"Using <code>Final</code> for Constants and Immutable References","text":"<p>Python 3.8 introduced the <code>Final</code> qualifier. <code>Final</code> allows you to declare that a name--whether a module-level variable, a class attribute, or an instance attribute--cannot be reassigned after initialization. This is a purely static indication; it's enforced by the type checker but not by the Python runtime.</p>"},{"location":"C07_Immutability/#declaring-final-variables","title":"Declaring Final Variables","text":"<p>To use it, import <code>Final</code> from <code>typing</code> and annotate your constant definitions. For example:</p> <pre><code># example_2.py\nfrom typing import Final\n\nPI: Final[float] = 3.14159\nMAX_CONNECTIONS: Final = 100  # type inferred as int\n</code></pre> <p>Here, <code>PI</code> and <code>MAX_CONNECTIONS</code> are marked as <code>Final</code>, signaling that these names should never be re-bound to a new value. A type checker will enforce this. If later in the code you attempt to do <code>PI = 3.14</code> (reassigning the constant), the type checker will emit an error, e.g. \"Error: can't assign to final attribute.\" The same goes for changing <code>MAX_CONNECTIONS</code>. The Python interpreter itself will not stop you from doing this reassignment, but using <code>Final</code> elevates the constant from a mere convention to something that static analysis tools can verify.</p> <p>According to the Python typing documentation, \"Final names cannot be reassigned in any scope. Final names declared in class scopes cannot be overridden in subclasses.\" In other words, marking a variable as <code>Final</code> means:</p> <ul> <li>No rebinding: You can assign to it only once; the type checker flags any further assignments.</li> <li>No override in subclass: If you mark a class attribute as <code>Final</code>, a subclass cannot override that attribute with   a new value.</li> </ul> <p>Let's illustrate this with a quick example:</p> <pre><code># example_3.py\nfrom typing import Final\n\nRATE: Final = 3000\n\n\nclass BaseConfig:\n    TIMEOUT: Final[int] = 60\n\n\nclass SubConfig(BaseConfig):\n    # Error: can't override a final attribute in BaseConfig\n    TIMEOUT = 30  # type: ignore\n</code></pre> <p>In the above code, <code>RATE</code> is a module-level constant. If somewhere else we had <code>RATE = 2500</code>, a tool like mypy would report an error (\"can't assign to final name 'RATE'\"). Similarly, <code>BaseConfig.TIMEOUT</code> is a constant class attribute; attempting to override it in <code>SubConfig</code> would be flagged (\"can't override a final attribute\"). This helps maintain invariants in class hierarchies.</p> <p>It's important to note that <code>Final</code> can also be used for instance attributes in <code>__init__</code>. If you have an instance attribute that should only be set once (in the initializer) and never changed, you can annotate it with <code>Final</code> in the class body and then assign it in the constructor. For example:</p> <pre><code># example_4.py\nfrom typing import Final\nfrom dataclasses import dataclass\n\n\n@dataclass\nclass User:\n    name: Final[str] = \"Uninitialized\"\n    id: Final[int] = -1\n\n    def __init__(self, name: str, id: int):\n        object.__setattr__(self, \"name\", name)\n        object.__setattr__(self, \"id\", id)\n</code></pre> <p>Here, <code>User.name</code> and <code>User.id</code> are intended to never change after the object is created. We use <code>Final[str]</code> and <code>Final[int]</code> in the annotation. The <code>__init__</code> uses <code>object.__setattr__</code> to bypass immutability enforcement (more on that technique in the next section about frozen dataclasses). A type checker would ensure that no code later tries to reassign <code>user.name</code> or <code>user.id</code>. For dataclasses, it's more idiomatic to use the <code>frozen=True</code> parameter (discussed below) rather than manually handling <code>Final</code> on instance attributes, but this example shows it's possible.</p> <p>Runtime behavior of Final: At runtime, <code>Final</code> does not truly \"freeze\" the value. It does not make the object itself immutable--it only prevents the name from being rebound in type-checked code. For instance, if you declare <code>numbers: Final[list[int]] = [1, 2, 3]</code>, you are not supposed to reassign <code>numbers</code> to a new list, but you can still mutate the list itself (e.g. <code>numbers.append(4)</code> will succeed) because the list object is still mutable. The type checker might warn you if the type is <code>Final[Sequence[int]]</code> instead (since <code>Sequence</code> has no <code>append</code> method), but with <code>Final[list[int]]</code> the list methods are available. In short, marking something <code>Final</code> guarantees that the name won't be re-bound to a different object, but it does not magically make the object's contents immutable. If true immutability of the content is needed, combine <code>Final</code> with an immutable type (e.g., use a tuple or use an immutable interface like <code>Sequence</code> instead of <code>list</code>). For example:</p> <pre><code># example_5.py\nfrom typing import Final, Sequence\n\ndata1: Final = [\n    1,\n    2,\n    3,\n]  # `data1` won't be re-assigned, but list can mutate\ndata2: Final[Sequence[int]] = [\n    1,\n    2,\n    3,\n]  # `data2` treated as Sequence, so no mutation methods\n</code></pre> <p>In the above, <code>data1.append(4)</code> is allowed by the type system (though <code>data1</code> name can't be re-bound), whereas <code>data2.append(4)</code> would be rejected by a type checker because a <code>Sequence[int]</code> is assumed to be immutable (it lacks an <code>append</code> method). This demonstrates the difference between preventing reassignment of a variable and ensuring true immutability of the object.</p> <p>Finally, note that Python also provides a <code>@final</code> decorator in <code>typing</code> which can be applied to classes or methods. This is related to immutability in the sense of preventing changes in inheritance. Decorating a class with <code>@final</code> means you intend it not to be subclassed, and a type checker will flag any subclass attempt as an error. Similarly, marking a method with <code>@final</code> means it should not be overridden in any subclass. This is more about preventing behavioral modification via inheritance rather than value mutation. It can be useful in design to ensure certain classes remain closed for extension (similar to <code>final</code> classes in Java). At runtime, as of Python 3.11, the <code>@final</code> decorator sets a <code>__final__ = True</code> attribute on the class or function to help introspection, but it doesn't enforce anything on its own. Like the <code>Final</code> annotation, <code>@final</code> is a tool for communicating intent and catching errors early with the help of static analysis.</p> <p><code>Final</code> in Python typing is a lightweight way to get the benefits of immutability by preventing reassignments. It formalizes the \"ALL_CAPS means constant\" convention into something a type checker can understand. Combined with immutable types or interfaces, it can help you create APIs that promise not to mutate state. However, for more complex state (especially when you want to bundle multiple values), Python's dataclasses offer another approach to enforce immutability at runtime.</p>"},{"location":"C07_Immutability/#immutable-data-classes","title":"Immutable Data Classes","text":"<p>By default, dataclass instances are mutable (their fields can be assigned to freely). However, <code>dataclasses</code> support an immutability feature: if you specify <code>frozen=True</code> in the <code>@dataclass</code> decorator, the resulting class will prevent any assignment to its fields after object creation. In other words, a frozen dataclass instance is effectively immutable (or \"frozen\") once it's constructed.</p> <pre><code># example_6.py\nfrom dataclasses import dataclass\n\nfrom book_utils import Catch\n\n\n@dataclass(frozen=True)\nclass Point:\n    x: int\n    y: int\n\n\np = Point(x=1, y=2)\nprint(p.x, p.y)  # Outputs: 1 2\n## 1 2\n\nwith Catch():\n    # Attempting to modify a field produces an error:\n    p.x = 5  # type: ignore\n\np.__dict__[\"x\"] = 5  # Bypassing 'frozen'\n</code></pre> <p>Running this code will result in a runtime error at the line <code>p.x = 5</code>. Specifically, Python will raise a <code>dataclasses.FrozenInstanceError</code> with the message \"cannot assign to field 'x'\". The dataclass machinery has made the <code>Point</code> class's instances immutable by overriding the attribute-setting behavior: any attempt to set an attribute on a frozen instance triggers that exception.</p> <p>When you use <code>@dataclass(frozen=True)</code>, Python generates an <code>__setattr__</code> method (and a <code>__delattr__</code> method) for your class that intercepts all attempts to set or delete attributes and immediately throws a <code>FrozenInstanceError</code>. This effectively locks down the instance after <code>__init__</code> finishes. The exception <code>FrozenInstanceError</code> is a subclass of <code>AttributeError</code>, consistent with what Python throws for assignment to a read-only attribute.</p> <p>Because of this, frozen dataclasses give you runtime enforcement of immutability. A <code>Final</code> type annotation is only checked by static analyzers, but a frozen dataclass will actively prevent mutation in a running program. This can be a powerful tool for ensuring certain objects remain constant. It's especially handy for value objects (like points, coordinates, config objects, etc.) where you want to make sure their state doesn't change once created.</p>"},{"location":"C07_Immutability/#example-frozen-dataclass-in-action","title":"Example: Frozen Dataclass in Action","text":"<p>Let's illustrate with a more detailed example and show what happens if we attempt to mutate a frozen <code>dataclass</code>:</p> <pre><code># frozen_person.py\nfrom dataclasses import dataclass\n\nfrom book_utils import Catch\n\n\n@dataclass(frozen=True)\nclass Person:\n    name: str\n    age: int\n\n\nperson = Person(name=\"Alice\", age=30)\nprint(person.name)  # \"Alice\"\n## Alice\nwith Catch():\n    # Trying to modify a frozen dataclass field:\n    person.age = 31  # type: ignore\n\nperson.__dict__[\"age\"] = 31  # Disable 'frozen'\n</code></pre> <p>The auto-generated <code>__setattr__</code> method of the dataclass raises an error. This demonstrates that our <code>Person</code> instance is effectively read-only.</p> <p>True immutability in Python can't be enforced; if you go out of your way to subvert immutability, you can. The goal of frozen dataclasses is to protect against accidental or careless mutations, not to provide an unbreakable security boundary. In normal usage, you would treat the frozen instance as completely immutable.</p> <p>Because instances of frozen dataclasses are immutable (by design and by behavior), they are also hashable by default, provided the class is comparable. The dataclass decorator, by default, will generate an <code>__eq__</code> method for you (unless you opt out). If you set <code>frozen=True</code> (and do not disable equality), it will also generate a <code>__hash__</code> method so that instances can be used in sets or as dictionary keys. Specifically, if <code>eq=True</code> and <code>frozen=True</code>, Python will automatically add a <code>__hash__</code> method for the class based on its fields. This makes sense: an object that is equal based on its field values and cannot change those values can safely be hashed. Conversely, a mutable dataclass (eq=True, frozen=False) gets a <code>__hash__ = None</code> by default, marking it as unhashable ( since its hash could change if fields changed). This is an example of how immutability (or lack thereof) interacts with Python's runtime behavior.</p> <pre><code># frozen_data_classes.py\nfrom dataclasses import dataclass\nfrom book_utils import Catch\n\n\n@dataclass(frozen=True)\nclass Messenger:\n    name: str\n    number: int\n    depth: float = 0.0  # Default\n\n\nprint(messenger := Messenger(\"foo\", 12, 3.14))\n## Messenger(name='foo', number=12, depth=3.14)\n# Frozen dataclass is immutable:\nwith Catch():\n    messenger.name = \"bar\"  # type: ignore\n\n# Automatically creates __hash__():\nd = {messenger: \"value\"}\nprint(d[messenger])\n## value\n</code></pre> <p>We can apply this approach to the <code>Stars</code> example:</p> <pre><code># stars.py\nfrom dataclasses import dataclass\n\n\n@dataclass(frozen=True)\nclass Stars:\n    number: int\n\n    def __post_init__(self) -&gt; None:\n        assert 1 &lt;= self.number &lt;= 10, f\"{self}\"\n</code></pre> <pre><code># star_demo.py\nfrom stars import Stars\nfrom book_utils import Catch\n\n\ndef f1(s: Stars) -&gt; Stars:\n    return Stars(s.number + 5)\n\n\ndef f2(s: Stars) -&gt; Stars:\n    return Stars(s.number * 5)\n\n\nstars1 = Stars(4)\nprint(stars1)\n## Stars(number=4)\n\nprint(f1(stars1))\n## Stars(number=9)\nwith Catch():\n    print(f2(f1(stars1)))\n## Error: Stars(number=45)\nwith Catch():\n    stars2 = Stars(11)\n## Error: Stars(number=11)\nwith Catch():\n    print(f1(Stars(11)))\n## Error: Stars(number=11)\n</code></pre> <p>Subsequent functions operating on <code>Stars</code> no longer require redundant checks. Modifying a <code>Stars</code> instance after creation raises an error, further safeguarding the data integrity:</p> <pre><code># modify_stars.py\nfrom stars import Stars\n\n\ndef increase_stars(rating: Stars, increment: int) -&gt; Stars:\n    return Stars(rating.number + increment)\n</code></pre> <p>If this function tries to create an invalid rating, the data class validation immediately raises an error. This greatly simplifies code maintenance and readability.</p> <p>Additionally, immutable objects can safely serve as keys in dictionaries, allowing reliable data lookups and caching.</p>"},{"location":"C07_Immutability/#how-final-and-frozen-work","title":"How <code>Final</code> and <code>frozen</code> Work","text":"<p>Understanding how these features are implemented gives insight into their guarantees and limitations.</p>"},{"location":"C07_Immutability/#final","title":"<code>Final</code>","text":"<p>This is entirely a compile-time (static) concept. When you declare a variable or attribute with <code>Final</code>, the Python interpreter records that in the <code>__annotations__</code> of the module or class, but it does not prevent assignments at runtime. The enforcement comes from type checkers. Tools like mypy will scan your code and, if you try to reassign a <code>Final</code> variable, they will emit an error and refuse to consider the code type-safe. As of Python 3.11, marking classes or methods with the <code>@final</code> decorator sets a <code>__final__ = True</code> attribute on the object, mostly for introspection or tooling--Python won't stop you from subclassing a <code>@final</code> class or overriding a <code>@final</code> method at runtime, but doing so would likely cause your type checker to complain or your linter to warn you. One key thing to remember is that <code>Final</code> is about the name binding, not the object's mutability: a <code>Final</code> list can still be changed in content, and <code>Final</code> doesn't make a dataclass frozen or anything of that sort. It's a tool for design-by-contract: signaling intent and catching mistakes early.</p>"},{"location":"C07_Immutability/#frozen-dataclass","title":"Frozen dataclass","text":"<p>This provides runtime enforcement by generating code. When you use <code>frozen=True</code>, the dataclass decorator modifies your class definition. It creates a custom <code>__setattr__</code> and <code>__delattr__</code> on the class that will raise <code>FrozenInstanceError</code> whenever someone tries to set or delete an attribute on an instance. During object creation, the dataclass-generated <code>__init__</code> uses <code>object.__setattr__</code> internally for each field to bypass the restriction while initializing values. Once construction is done, any further attribute setting goes through the overridden <code>__setattr__</code> and is blocked. It's not unbreakable; a savvy user could call <code>object.__setattr__</code> themselves, or manipulate low-level object state. Although you cannot create truly immutable Python objects, <code>frozen=True</code> emulates immutability. In day-to-day practice, a frozen dataclass is as good as immutable.</p>"},{"location":"C07_Immutability/#performance-considerations","title":"Performance considerations","text":"<p>The convenience of frozen dataclasses comes with a minor cost. As noted, setting attributes in <code>__init__</code> uses a slightly slower path (calling <code>object.__setattr__</code> for each field). In the vast majority of cases this overhead is negligible (a few extra function calls during object creation). It's rare to create so many objects that this becomes a bottleneck, but it's something to be aware of. Accessing attributes and all other operations on a frozen dataclass are just as fast as on a regular class; it's only the initialization that's marginally slower. For <code>Final</code> type annotations, there is virtually no runtime cost at all, since it doesn't inject any checking--it's purely a compile-time concept.</p>"},{"location":"C07_Immutability/#combining-final-and-frozen-dataclasses","title":"Combining <code>Final</code> and frozen dataclasses","text":"<p>You generally don't need <code>Final</code> annotations inside a frozen dataclass. If a dataclass is frozen, all its fields are effectively final by design; you can't rebind them after construction. For example, if you have <code>@dataclass(frozen=True) class C: x: int</code>, a type checker will treat <code>c.x</code> as a read-only property.</p> <p>Note that in a dataclass, a bare <code>x: Final[int] = 3</code> is treated as an instance field default, whereas normally a <code>Final</code> at class level means a class variable. You can use <code>Final</code> to indicate a class-level constant inside a dataclass. However, it doesn't make sense to use <code>Final</code> on fields (instance attributes), because <code>frozen=True</code> already makes those fields immutable.</p>"},{"location":"C07_Immutability/#using-__post_init__-in-frozen-dataclasses","title":"Using <code>__post_init__</code> in Frozen Dataclasses","text":"<p>One challenge with frozen dataclasses is that you cannot assign to fields outside the initializer--but what if you need to compute one field based on others? In a regular (mutable) dataclass, it's common to use a <code>__post_init__</code> method to perform additional initialization or validation after the auto-generated <code>__init__</code> has run. With frozen dataclasses, however, you must be careful: by the time <code>__post_init__</code> executes, the <code>__setattr__</code> override that enforces immutability is already in place. Any attempt to do <code>self.field = value</code> in <code>__post_init__</code> will trigger a <code>FrozenInstanceError</code> just like an outside assignment would (because internally it uses the same attribute-setting mechanism).</p> <p>So how can we set up derived fields or perform adjustments in <code>__post_init__</code> for a frozen class? The answer is to bypass the frozen <code>__setattr__</code> using the base class (<code>object</code>) method. Python lets us call the underlying <code>object.__setattr__</code> method directly, which sets the attribute. This is how dataclasses themselves initialize fields for frozen instances. The dataclass documentation notes: \"There is a tiny performance penalty when using <code>frozen=True</code>: <code>__init__</code> cannot use assignment to initialize fields, and must use <code>object.__setattr__</code>.\". The dataclass-generated <code>__init__</code> knows to do this for the fields that are set in the constructor. We can apply the same technique in <code>__post_init__</code>.</p> <p>Correct approach: Use <code>object.__setattr__(self, 'field_name', value)</code> in your <code>__post_init__</code> for any field that needs to be set on a frozen dataclass. This calls the built-in <code>object</code> class's <code>__setattr__</code> implementation, which writes to the instance's <code>__dict__</code>.</p> <p>Let's demonstrate this with an example. Suppose we want to have a <code>Rectangle</code> dataclass that stores width and height, and we also want to store the area as a field for quick access. We want the class to be frozen (immutable). We can declare <code>area</code> as a field with <code>init=False</code> (so it's not passed to the constructor), and then compute it in <code>__post_init__</code> as follows:</p> <pre><code># example_8.py\nfrom dataclasses import dataclass, field\n\n\n@dataclass(frozen=True)\nclass Rectangle:\n    width: float\n    height: float\n    area: float = field(\n        init=False\n    )  # area will be computed, not passed by caller\n\n    def __post_init__(self):\n        # Bypass immutability to set the derived field\n        object.__setattr__(\n            self, \"area\", self.width * self.height\n        )\n</code></pre> <p>Here, <code>area</code> is intended to be a derived attribute (width _ height). We marked it with <code>field(init=False)</code> so that dataclasses knows not to expect it as a parameter. In <code>__post_init__</code>, we calculate the area and assign it using <code>object.__setattr__</code>. This is the crucial step to avoid the <code>FrozenInstanceError</code>. We could also use <code>super.setattr('area', self.width _ self.height)</code>--since the immediate base class is<code>object</code>, this has the same effect. After <code>__post_init__</code> the <code>Rectangle</code>instance will a correct <code>area</code> but be frozen for further modifications.</p> <p>Let's test this behavior:</p> <pre><code># example_9.py\nfrom book_utils import Catch\nfrom example_8 import Rectangle\n\nr = Rectangle(3.0, 4.0)\nprint(r.area)  # Outputs: 12.0\n## 12.0\n# Try to modify attributes (should fail)\nwith Catch():\n    # 'Rectangle' object attribute 'width' is read-only:\n    # r.width = 5.0\n    r.__dict__[\"width\"] = 5.0  # Cheat to change\n</code></pre> <p>As expected, printing <code>r.area</code> gives 12.0, which means our <code>__post_init__</code> successfully set the value. And attempting to assign <code>r.width</code> after creation raises an error, confirming the instance is immutable. We have effectively created an immutable data object with some logic in its initialization.</p> <p>A word of caution: using <code>object.__setattr__</code> is a bit of a loophole--it's meant to be used only during object initialization. You wouldn't normally call <code>object.__setattr__</code> on a frozen instance outside of <code>__init__</code>/<code>__post_init__</code> because that would defeat the point of immutability. (If someone is determined to bypass immutability, they can, but that's not normal usage.) If you find yourself needing to change a frozen object after creation via such tricks, it may be a sign that the design should be reconsidered (maybe that piece of data shouldn't be frozen). Generally, use this technique only to set up derived fields or cached values at construction time.</p>"},{"location":"C07_Immutability/#namedtuple","title":"NamedTuple","text":"<p>In many cases, a <code>NamedTuple</code> can be used in lieu of a frozen <code>dataclass</code>. A <code>NamedTuple</code> combines <code>tuple</code> immutability with type annotations and named fields:</p> <pre><code># named_tuple.py\nfrom typing import NamedTuple\n\n\nclass Coordinates(NamedTuple):\n    latitude: float\n    longitude: float\n\n\ncoords = Coordinates(51.5074, -0.1278)\nprint(coords)\n## Coordinates(latitude=51.5074, longitude=-0.1278)\nprint(coords.latitude)\n## 51.5074\n# coords.latitude = 123.4567 # Runtime error\n</code></pre> <p><code>NamedTuple</code> provides clarity, immutability, and easy unpacking, ideal for structured data. Their simplicity makes them ideal for simple, lightweight, immutable record types. For brevity and cleanliness, this book will use <code>NamedTuple</code>s instead of frozen <code>dataclass</code>es whenever possible.</p> <p>Both <code>NamedTuple</code> and <code>dataclass</code> automate the creation of common methods (such as constructors, <code>repr</code>, equality, and sometimes hash methods), but they do so in different ways and with different design goals in mind.</p> <p>Rather than generating an <code>__init__</code>, a <code>NamedTuple</code> is a subclass of <code>tuple</code> and uses a generated <code>new</code> method to create instances. Customization of construction logic is limited because you cannot define an init but must instead override <code>new</code>. <code>NamedTuple</code> instances are immutable since they are <code>tuple</code> subclasses, so you cannot assign to their fields after creation. A <code>NamedTuple</code> automatically generates a <code>repr</code> that prints the field names along with their values (e.g., Point(x=1, y=2)) in a manner similar to a standard <code>tuple</code> representation. An <code>__eq__</code> is generated based on the <code>tuple</code>\u2019s content, and <code>__hash__</code> is automatically defined (since <code>tuple</code>s are immutable). <code>NamedTuple</code>s inherit <code>tuple</code> ordering (lexicographical order) by default. <code>NamedTuple</code> is a subclass of <code>tuple</code>, which means all <code>tuple</code> operations (indexing, iteration, etc.) work as expected. Since a <code>NamedTuple</code> is implemented as a <code>tuple</code> (with immutability and slots by default), it is memory efficient.</p> <p>A <code>dataclass</code> generates an <code>__init__</code> that assigns the provided arguments to instance attributes. By default, <code>dataclass</code> instances are mutable; however, you can set <code>frozen=True</code> to make them immutable. This causes the generated <code>__init__</code> to assign to immutable fields. The <code>repr</code> method is automatically generated to include the field names and their current values. It is highly customizable via the <code>repr</code> parameter on fields. By default, <code>dataclass</code> automatically generates an eq method that compares instances based on their fields. The default <code>dataclass</code> is mutable (<code>frozen=False</code>); this generates no hash unless you specify <code>unsafe_hash=True</code>. Mutable objects of any kind should generally not be hashed because the hash can change from one access to another. If the <code>dataclass</code> is frozen (immutable), then a hash method is automatically provided. You can add ordering methods (e.g., lt, le, etc.) by setting <code>order=True</code> when declaring the <code>dataclass</code>. Otherwise, no ordering is generated. Dataclasses provide a post_init method that runs immediately after the generated init method. This is a convenient place for additional initialization or validation. Dataclasses offer per-field customization (default values, default_factory, comparison options, etc.) that allows fine-tuning of instances behavior.</p> <p>Python's approach to immutability is a mix of convention, static assurance, and runtime enforcement:</p> <ul> <li>Use <code>Final</code> (and <code>@final</code>) to convey and enforce via static analysis that certain variables or attributes shouldn't   change or be overridden.</li> <li>Use <code>@dataclass(frozen=True)</code> (or other techniques like <code>NamedTuple</code>s or custom <code>__setattr__</code> overrides) to prevent   changes to object state at runtime.</li> </ul>"},{"location":"C07_Immutability/#namedtuple-capabilities","title":"NamedTuple Capabilities","text":"<p>Here's an example showing everything you can do with <code>NamedTuple</code>s:</p> <pre><code># namedtuple_capabilities.py\nfrom collections import namedtuple\nfrom typing import NamedTuple, Optional\n\n# 1. Dynamically generating a NamedTuple:\nPoint1 = namedtuple(\"Point1\", [\"x\", \"y\"])\np1 = Point1(10, 20)\nprint(f\"{p1 = }, {type(p1) = }\")\n## p1 = Point1(x=10, y=20), type(p1) = &lt;class '__main__.Point1'&gt;\n\n\n# 2. A basic immutable type:\nclass Point2(NamedTuple):\n    x: int\n    y: int\n\n\nprint(p2 := Point2(30, 40))\n## Point2(x=30, y=40)\n\n\n# 3. Default values:\nclass Employee(NamedTuple):\n    name: str\n    id: int = 0\n    department: Optional[str] = None\n\n\nprint(f\"Defaulted: {Employee('Alice')}\")\n## Defaulted: Employee(name='Alice', id=0, department=None)\nprint(f\"Full: {Employee('Bob', 123, 'Engineering')}\")\n## Full: Employee(name='Bob', id=123, department='Engineering')\n\n\n# 4. Methods:\nclass Circle(NamedTuple):\n    radius: float | int\n\n    def area(self) -&gt; float:\n        from math import pi\n\n        return pi * (self.radius**2)\n\n\nprint(f\"{(c := Circle(5))} {c.area():.2f}\")\n## Circle(radius=5) 78.54\n\n# 5. NamedTuple utilities: _replace, _asdict, _fields:\nprint(f\"Original Circle: {c}\")\n## Original Circle: Circle(radius=5)\nc2 = c._replace(radius=10)\nprint(f\"{c2 = }, {c = }\")\n## c2 = Circle(radius=10), c = Circle(radius=5)\nprint(f\"Fields: {Circle._fields}\")\n## Fields: ('radius',)\nprint(f\"As dict: {c2._asdict()}\")\n## As dict: {'radius': 10}\n\n# 6. Sequence unpacking:\nx_val, y_val = p2\nprint(f\"{x_val = }, {y_val = }\")\n## x_val = 30, y_val = 40\n\n\n# 7. Pattern matching\ndef describe_point(pt: Point2) -&gt; str:\n    match pt:\n        case Point2(x, y) if x == y:\n            return f\"Diagonal point at ({x}, {y})\"\n        case Point2(x, y):\n            return f\"Point at x={x}, y={y}\"\n        case _:\n            return \"Unknown point\"\n\n\nprint(describe_point(Point2(1, 1)))\n## Diagonal point at (1, 1)\nprint(describe_point(Point2(2, 3)))\n## Point at x=2, y=3\n\n\n# 8. Nested NamedTuples:\nclass Address(NamedTuple):\n    street: str\n    city: str\n\n\nclass Person(NamedTuple):\n    name: str\n    age: int\n    address: Address\n\n\naddr = Address(\"123 Maple St\", \"Springfield\")\nperson = Person(\"Carol\", 29, addr)\nprint(\n    f\"{person.name = }, {person.age = }, {person.address.city = }\"\n)\n## person.name = 'Carol', person.age = 29, person.address.city =\n## 'Springfield'\n\n\n# Nested pattern match:\ndef location_info(p: Person) -&gt; str:\n    match p:\n        case Person(_, _, Address(_, city=\"Springfield\")):\n            return f\"Resident of Springfield\"\n        case Person(name, _, Address(street, city)):\n            return f\"{name} lives at {street}, {city}\"\n        case _:\n            return \"Unknown location\"\n\n\nprint(location_info(person))\n## Resident of Springfield\n</code></pre>"},{"location":"C07_Immutability/#what-frozen-dataclasses-can-do-that-namedtuple-cannot","title":"What Frozen Dataclasses can do that NamedTuple Cannot","text":"<pre><code># frozen_dataclass_vs_namedtuple.py\nfrom dataclasses import dataclass, field\nfrom typing import NamedTuple, Any\n\n\n# 1. Per-instance mutable default values via default_factory\n@dataclass(frozen=True)\nclass Config:\n    options: list[str] = field(default_factory=list)\n\n\nc1 = Config()\nc2 = Config()\nc1.options.append(\"x\")\nprint(f\"c1.options={c1.options}\")  # ['x']\n## c1.options=['x']\nprint(f\"c2.options={c2.options}\")  # []\n## c2.options=[]\n\n# NamedTuple cannot use default_factory; defaults share same object\n# This must use a single default list if provided, and no factory.\nPointNT = NamedTuple(\"PointNT\", [(\"tags\", list[str])])\n\n\n# 2. Validation and invariants via __post_init__\n@dataclass(frozen=True)\nclass Person:\n    name: str\n    age: int\n\n    def __post_init__(self) -&gt; None:\n        if self.age &lt; 0:\n            raise ValueError(\n                f\"Age must be non-negative: {self.age}\"\n            )\n\n\ntry:\n    Person(\"Eve\", -5)\nexcept ValueError as e:\n    print(f\"Validation: {e}\")\n## Validation: Age must be non-negative: -5\n\n\n# 3. Computed/derived fields with init=False\n@dataclass(frozen=True)\nclass Rectangle:\n    width: float\n    height: float\n    area: float = field(init=False)\n\n    def __post_init__(self) -&gt; None:\n        object.__setattr__(\n            self, \"area\", self.width * self.height\n        )\n\n\nrect = Rectangle(3.0, 4.0)\nprint(f\"Rectangle area={rect.area}\")  # 12.0\n## Rectangle area=12.0\n\n\n# 4. Hiding sensitive fields via repr\n@dataclass(frozen=True)\nclass Credentials:\n    username: str\n    password: str = field(repr=False)\n\n\ncred = Credentials(\"user1\", \"s3cr3t\")\nprint(f\"Credentials repr: {cred}\")\n## Credentials repr: Credentials(username='user1')\n\n\n# 5. Keyword-only fields enforcement:\n@dataclass(frozen=True)\nclass Point:\n    x: int\n    y: int\n    z: int = field(init=False)\n\n    def __post_init__(self) -&gt; None:\n        object.__setattr__(self, \"z\", self.x + self.y)\n\n\n# Positional-only: x, y; z computed\np = Point(1, 2)\nprint(f\"Point(z computed): {p}\")\n## Point(z computed): Point(x=1, y=2, z=3)\n\n\n# 6. Automatic ordering methods\n@dataclass(order=True, frozen=True)\nclass Version:\n    major: int\n    minor: int\n    patch: int\n\n\nv1 = Version(1, 0, 0)\nv2 = Version(1, 1, 0)\nprint(f\"v1 &lt; v2: {v1 &lt; v2}\")\n## v1 &lt; v2: True\n\n\n# 7. Customizing equality/hash behavior\n@dataclass(frozen=True, eq=False, unsafe_hash=True)\nclass IDWrapper:\n    id_value: Any\n\n    def __eq__(self, other: object) -&gt; bool:\n        if isinstance(other, IDWrapper):\n            return self.id_value == other.id_value\n        return NotImplemented\n\n\nw1 = IDWrapper(10)\nw2 = IDWrapper(10)\nprint(\n    f\"Custom eq w1 == w2: {w1 == w2}, hash(w1)==hash(w2): {hash(w1) == hash(w2)}\"\n)\n## Custom eq w1 == w2: True, hash(w1)==hash(w2): True\n\n\n# 8. Using slots for memory optimization:\n@dataclass(frozen=True, slots=True)\nclass Point3D:\n    x: int\n    y: int\n    z: int\n\n\npt = Point3D(0, 0, 0)\nprint(f\"Point3D slots: {pt}\")  # No __dict__, uses slots\n## Point3D slots: Point3D(x=0, y=0, z=0)\n</code></pre>"},{"location":"C07_Immutability/#prefer-immutability","title":"Prefer Immutability","text":"<p>With immutability, you get clarity, safety, and bug prevention--while still working within Python's flexible and dynamic nature. Immutability in Python is ultimately a matter of developer intent supported by language features that make it easier to achieve and maintain. With <code>Final</code> and frozen dataclasses, we now have the means to clearly communicate and enforce that intent, leading to more robust and maintainable codebases.</p>"},{"location":"C07_Immutability/#references","title":"References","text":"<ol> <li>Mimicking Immutability in Python with Type Hints | Justin Austin</li> <li>dataclasses--Data Classes--Python 3.13.3 documentation</li> <li>PEP 8--Style Guide for Python Code | peps.python.org</li> <li>PEP 591</li> <li>Type qualifiers--typing documentation</li> <li>typing--Support for type hints--Python 3.13.3 documentation</li> <li>Customizing dataclass initialization--Python Morsels</li> <li>python--How to set the value of a dataclass field in post_init when frozen=True?--Stack Overflow</li> </ol>"},{"location":"C08_Pattern_Matching/","title":"Pattern Matching","text":"<p>Python 3.10 added structural pattern matching via the <code>match...case</code> statement. Pattern matching compares a value (the subject) against a series of patterns, and executes code based on the pattern that fits. Unlike a basic switch on a single value, structural pattern matching destructures complex data and tests for conditions in one expressive syntax.</p> <p>A <code>match</code> statement looks similar to a switch/case from other languages, but Python's patterns can match structure (like the shape of a sequence or the attributes of an object) and bind variables. Python tries each <code>case</code> in order and executes the first one that matches, with a wildcard <code>_</code> as a catch-all default. Patterns can include literals, names, and even nested sub-patterns to unpack data.</p>"},{"location":"C08_Pattern_Matching/#literal-patterns","title":"Literal Patterns","text":"<p>A literal pattern specifies a concrete value that the subject must equal. These are most akin to classic switch-case constants. Literal patterns can be numbers, strings, booleans, <code>None</code>, or even singleton objects. The pattern matches if the subject is equal to that value (using <code>==</code> comparison for most types). For example, consider matching an HTTP status code to a message:</p> <pre><code># literal_patterns.py\nstatus = 404\nmatch status:\n    case 200:\n        result = \"OK\"\n    case 404:\n        result = \"Not Found\"\n    case _:\n        result = \"Unknown status\"\n</code></pre> <p>The cases <code>200</code> and <code>404</code> are literal patterns. The <code>match</code> compares <code>status</code> against each literal in turn. Because <code>status == 404</code>, the second case matches and <code>result</code> becomes <code>\"Not Found\"</code>. If <code>status</code> had been something else, the wildcard <code>_</code> would catch it as a default.</p> <p>Most literal constants match by equality. However, Python's three singletons--<code>True</code>, <code>False</code>, and <code>None</code>--are matched by identity (i.e., the subject is that object). This distinction rarely matters in practice (since there's only one <code>True</code> etc.), but it's a defined part of the rules. You can also combine multiple literals in one pattern using the OR operator <code>|</code> to match any of several constants (e.g., <code>case 401 | 403 | 404:</code> to handle multiple error codes in one branch).</p> <p>You'll often want to match against a constant defined elsewhere, such as an enumeration member or a module-level constant. In pattern matching, a bare name is treated as a capture variable, not a constant. To use a named value as a literal pattern, you must qualify it so that it's not seen as a new variable. Named constants must appear as dotted names (or attributes) in patterns. For example, to match an <code>Enum</code> member:</p> <pre><code># colors.py\nfrom enum import Enum\n\n\nclass Color(Enum):\n    RED = 1\n    GREEN = 2\n    BLUE = 3\n</code></pre> <pre><code># color_match.py\nfrom colors import Color\n\ncolor = Color.GREEN\nmatch color:\n    case Color.RED:\n        print(\"color is red!\")\n    case Color.GREEN:\n        print(\"color is green!\")\n    case Color.BLUE:\n        print(\"color is blue!\")\n## color is green!\n</code></pre> <p>Here <code>Color.RED</code> etc. are dotted names, so the pattern treats them as specific constant values rather than capturing new variables named <code>RED</code>, <code>GREEN</code>, <code>BLUE</code>. This will correctly match the enum value in <code>color</code>. Using the un-dotted <code>RED</code> instead of <code>Color.RED</code> makes it a capture pattern.</p> <p>Literal patterns work well with type annotations for <code>Literal</code> types and <code>Enum</code>s. If a variable is annotated with a union of literal values or an <code>Enum</code> type, a series of literal <code>case</code> clauses can cover all possibilities.</p> <p>Static type checkers can perform exhaustiveness checking on <code>match</code> statements. This means if you forget to handle one of the specified values, the type checker can warn you. For instance, if <code>status</code> was of type <code>Literal[200, 404]</code>, the checker would expect all those values to be matched. With the <code>Color</code> enum, checkers know there are three members and can report an error if you omit a case.</p>"},{"location":"C08_Pattern_Matching/#capture-patterns","title":"Capture Patterns","text":"<p>Capture patterns let you extract pieces of data for use in the body of the case. A capture pattern is an identifier used in a pattern to \"capture\" the value from the subject if that pattern position matches. Instead of testing for a specific value, a capture pattern matches anything and binds a variable to the subject (or subcomponent of the subject).</p> <p>Writing a bare name in a pattern creates a capture. For example, <code>case x:</code> will match any subject value and assign it to the variable <code>x</code>. Capture patterns can also appear inside compound patterns (like inside a sequence or mapping), where they bind a part of the structure.</p> <p>The <code>_</code> (underscore) is not a capture; it's a special wildcard pattern that discards the value. Any other name will be treated as a capture. If the name wasn't already defined in the surrounding scope, it will be a new variable set in that case. (If it was defined outside, pattern matching will not automatically compare against it--it still creates a new binding shadowing the outer variable. As mentioned, to match an existing variable's value, use a literal or value pattern with a dotted name.)</p> <p>In this example, the second case uses <code>other</code> as a capture pattern:</p> <pre><code># example_3.py\ncommand = \"hello\"\nmatch command:\n    case \"quit\":\n        print(\"Quitting...\")\n    case other:\n        print(f\"Received unknown command: {other!r}\")\n## Received unknown command: 'hello'\n</code></pre> <p>If the first case (<code>\"quit\"</code>) doesn't match, the second case will match anything. The subject <code>\"hello\"</code> is not <code>\"quit\"</code>, so it falls to <code>case other:</code>. This pattern matches unconditionally and binds the name <code>other</code> to the value of <code>command</code> (<code>\"hello\"</code>, in this case). The result is that it prints: <code>Received unknown command: 'hello'</code>. Essentially, <code>other</code> serves as a catch-all variable for \"anything else.\" In this role, a capture is similar to the wildcard <code>_</code> (which also matches anything) except that we can use the captured value in the code.</p> <p>Capture patterns are extremely useful when you need to extract parts of a structure. For example, matching a tuple <code>case (x, y):</code> uses two capture sub-patterns <code>x</code> and <code>y</code> to pull out the elements of the tuple. Similarly, <code>case {\"user\": name, \"id\": id}:</code> on a dictionary captures the values of the <code>\"user\"</code> and <code>\"id\"</code> keys into the variables <code>name</code> and <code>id</code> respectively. We will show more of these in Sequence and Mapping patterns.</p> <p>Irrefutable patterns: A capture pattern (on its own) always matches because it imposes no conditions on the value. Patterns that always succeed are called irrefutable. If an irrefutable pattern is used as a top-level case (like <code>case x:</code> at the same indent as case), it matches everything and typically must be the last case (otherwise it would prevent any subsequent cases from ever running). Using a capture as the last case is one way to handle \"default\" scenarios while still naming the value. A wildcard <code>_</code> provides a default case when the value itself doesn't need to be referenced.</p>"},{"location":"C08_Pattern_Matching/#wildcard-patterns-_","title":"Wildcard Patterns (<code>_</code>)","text":"<p>The wildcard pattern is written as a single underscore <code>_</code>. It matches anything, just like a capture pattern does, but it does not bind any variable. It means, \"I don't care what's here.\" It's typically used to ignore certain values or as a catch-all default case. Since <code>_</code> is not a valid variable name (in pattern context it's special-cased), you can use it freely without worrying about collisions or overwriting.</p> <p>Common uses of the wildcard pattern include:</p> <ul> <li>The final case of a match (default case) to catch all situations not handled by earlier cases:</li> </ul> <pre><code># wildcard_final_case.py\ndef wildcard(status):\n    match status:\n        case 200:\n            message = \"OK\"\n        case 404:\n            message = \"Not Found\"\n        case _:\n            message = \"Unknown\"  # `_` matches anything not matched above\n</code></pre> <ul> <li>Ignoring one or more elements in a sequence pattern:</li> </ul> <pre><code># wildcard_ignore_elements.py\nfrom typing import Any\n\n\ndef wildcard_ignore(\n    point: tuple[float, Any, Any],\n) -&gt; None:\n    match point:\n        case (x, _, _):\n            print(f\"x-coordinate is {x}\")\n</code></pre> <p>The pattern <code>(x, _, _)</code> binds the first element to <code>x</code> and ignores the second and third elements. The underscores indicate we do not need those values. (If the sequence had a different length or structure, this pattern would fail to match.)</p> <ul> <li>Ignoring a value in a class or mapping pattern:</li> </ul> <pre><code># wildcard_ignore_value.py\nfrom typing import NamedTuple\n\n\nclass Player(NamedTuple):\n    name: str\n    score: int\n\n\ndef player_score(player: Player):\n    match player:\n        case Player(name=_, score=s):\n            print(f\"Player has score {s}\")\n</code></pre> <p>This matches a <code>Player</code> object of any name, capturing only the <code>score</code> attribute into <code>s</code>. The name attribute is ignored.</p> <p>You can use multiple wildcards in a single pattern if needed (each <code>_</code> is independent and just means \"ignore this part\"). All <code>_</code> in a pattern are effectively the same anonymous throwaway--none of them create variables. This makes <code>_</code> safe to use in any number of places in the pattern.</p> <p>Wildcard patterns are a convenient way to say \"match anything here, and I don't intend to use it.\" They improve readability by explicitly marking unneeded parts of the structure and are essential for default cases. Every <code>match</code> statement should usually end with either a wildcard case or otherwise guarantee that all possibilities are handled (to avoid falling through with no match).</p>"},{"location":"C08_Pattern_Matching/#sequence-patterns","title":"Sequence Patterns","text":"<p>Sequence patterns let you match sequence types (like lists, tuples, etc.) by their contents. They look much like unpacking assignments. By placing subpatterns in square brackets <code>[...]</code> or parentheses <code>(...)</code>, you can match on the length of the sequence and the patterns of each element. This is a powerful way to destructure sequence data.</p> <p>Suppose we want to categorize a 2D point given as a tuple <code>(x, y)</code>:</p> <pre><code># example_7.py\npoint = (0, 5)\nmatch point:\n    case (0, 0):\n        print(\"Origin\")\n    case (0, y):\n        print(f\"On the Y-axis at y={y}\")\n    case (x, 0):\n        print(f\"On the X-axis at x={x}\")\n    case (x, y):\n        print(f\"Point at ({x}, {y})\")\n## On the Y-axis at y=5\n</code></pre> <p>This match has four sequence patterns, each a tuple of two elements:</p> <ul> <li><code>(0, 0)</code> is a sequence pattern of two literals, matching only the point <code>(0, 0)</code>.</li> <li><code>(0, y)</code> matches any 2-tuple whose first element is 0 and captures the second element as <code>y</code>.   So <code>(0, 5)</code> fits here, and <code>y</code> would be 5, resulting in <code>On the Y-axis at y=5</code>.</li> <li><code>(x, 0)</code> matches any 2-tuple with second element 0, capturing the first element as <code>x</code>.</li> <li><code>(x, y)</code> (the most general) matches any 2-tuple, capturing both elements.</li> </ul> <p>Only one case will run: the first one that matches in order. In our example, <code>point = (0, 5)</code> matches the second pattern <code>(0, y)</code> because the first element is 0 (literal match) and it binds <code>y = 5</code>. The remaining cases are skipped.</p>"},{"location":"C08_Pattern_Matching/#details","title":"Details","text":"<ul> <li> <p>Types that qualify: Sequence patterns work on any iterable that is sequence-like.   This generally means instances of <code>collections.abc.Sequence</code> (such as list, tuple, range, str) except that mappings (dicts) are treated by the mapping pattern instead (covered in next section).   For built-in sequences like <code>list</code> or <code>tuple</code>, the match will check the length and elements.   For custom sequence classes, Python uses the sequence protocol (<code>__len__</code> and <code>__getitem__</code>) to attempt a match.   Strings are considered sequences of characters, so be cautious: a pattern like <code>case ['H','i']:</code> would match the string <code>\"Hi\"</code> (as a sequence of two chars) as well as a list <code>['H','i']</code>.   If you specifically want to match a <code>list</code> and not a <code>tuple</code> or other sequence, you can use a class pattern like <code>case list([...])</code> as described below.</p> </li> <li> <p>Length matching: The number of subpatterns in brackets must match the length of the sequence (unless you use a starred pattern for variable length).   If the lengths differ, the pattern fails.   In the example above, each pattern has 2 elements, so only sequences of length 2 can match any of those.   If <code>point</code> were a 3-tuple, none of those cases would match (unless we added a case for 3-length).</p> </li> <li> <p>Element matching: Each position in the pattern can be any kind of subpattern (literal, capture, wildcard, even another nested pattern).   All subpatterns must match their corresponding element for the whole pattern to succeed.   In <code>(0, y)</code>, the first subpattern <code>0</code> must equal the first element and the second subpattern <code>y</code> will always succeed (capturing that element).   If any subpattern fails, the whole pattern fails, and the next case is tried.</p> </li> <li> <p>Starred subpattern (<code>*</code>): Sequence patterns support a \"rest\" pattern using <code>*</code>.   This is similar to unpacking with a star in assignments.   You can write one subpattern as <code>*name</code> (or <code>*_</code> to ignore) to soak up the remaining elements of a sequence.   For example:</p> </li> </ul> <pre><code># example_8.py\ndef rest_pattern(*values):\n    match values:\n        case [first, second, *rest]:\n            print(f\"{first = }, {second = }, {rest = }\")\n\n\nrest_pattern(10, 20, 30, 40)\n## first = 10, second = 20, rest = [30, 40]\nrest_pattern(\"a\", \"b\", \"c\", \"d\")\n## first = 'a', second = 'b', rest = ['c', 'd']\n</code></pre> <p>This pattern matches any sequence of length <code>&gt;= 2</code>. The first element is bound to <code>first</code>, second to <code>second</code>, and the rest of the sequence (which could be zero-length if there were only two arguments) is bound as a list to <code>rest</code>. If <code>values</code> is <code>[10, 20, 30, 40]</code>, the output would be \"First=10, second=20, rest=[30, 40]\". If <code>values</code> is <code>[10, 20]</code>, then <code>rest</code> would be an empty list <code>[]</code>. Using <code>*rest</code> makes the length flexible. You can only use one starred subpattern in a sequence pattern. Also note that <code>*rest</code> will always be a list, even if the original sequence is a tuple (Python creates a new list for the remaining elements when matching).</p> <p>The pattern matching syntax (the structure you write after <code>case</code>) is not designed to include inline type annotations. Thus, you cannot write something like: <code>case [first: int, second: int, *rest: list[int]]:</code> However, we can put an annotation on the argument (<code>values</code>) passed to the <code>match</code> expression:</p> <pre><code># subject_annotations.py\nfrom typing import Tuple\n\n\ndef subject_annotation(*values: int) -&gt; None:\n    match values:\n        case [first, second, *rest]:\n            # Here the type checker infers:\n            # --first: int\n            # --second: int\n            # --rest: list[int]\n            print(f\"{first = }, {second = }, {rest = }\")\n\n\nsubject_annotation(10, 20, 30, 40)\n## first = 10, second = 20, rest = [30, 40]\n# rest_pattern(\"a\", \"b\", \"c\", \"d\")  # Disallowed\n</code></pre> <p>Nested patterns: You can nest sequence patterns within sequences for multidimensional data.:</p> <pre><code># nested_patterns.py\nfrom typing import cast\n\n\ndef nested_pattern(*values: int) -&gt; None:\n    match values:\n        case [first, second, *rest]:\n            # Here the type checker infers:\n            # --first: int\n            # --second: int\n            # --rest: list[int]\n            print(f\"{first = }, {second = }, {rest = }\")\n\n        case [(x, y), *rest]:\n            # Known pattern matching limitation in mypy:\n            x, y = cast(tuple[int, int], rest)\n            print(f\"({x=}, {y=}), *{rest}\")\n\n\nnested_pattern(10, 20, 30, 40)\n## first = 10, second = 20, rest = [30, 40]\n# Type checkers haven't caught up:\nnested_pattern((50, 60), 70, 80)  # type: ignore\n## first = (50, 60), second = 70, rest = [80]\n</code></pre> <p>The first element, a 2-tuple, is matched by the subpattern <code>(x, y)</code>. The remaining elements go into <code>rest</code>. This destructures a complex list-of-tuples or tuple-of-tuples structures in a single pattern.</p> <p>Sequence patterns basically generalize what you might do with a series of <code>isinstance</code> checks and tuple unpacking. They make the code for handling sequences declarative. Instead of writing length checks and index accesses, you describe the shape of the data you expect. This can be both clearer and less error-prone.</p> <p>Type annotations and static analysis: If a variable is annotated with a sequence type with a fixed length (e.g. <code>tuple[int, int, int]</code> for a triple), a corresponding sequence pattern (like <code>[x, y, z]</code>) naturally fits that structure. Static type checkers can verify that your patterns make sense given the declared types. For example, if a function parameter is <code>coords: tuple[int, int]</code>, then a pattern with two elements will always match, whereas a pattern with three would be flagged as possibly unreachable (since a tuple[int,int] can't have length 3). Additionally, the types of captured variables can be inferred: if <code>coords</code> is <code>tuple[int,int]</code>, then in <code>case (x, y):</code> the checker knows <code>x</code> and <code>y</code> are <code>int</code>. This synergy makes pattern matching with sequences both convenient and type-safe in well-typed code.</p>"},{"location":"C08_Pattern_Matching/#mapping-patterns","title":"Mapping Patterns","text":"<p>Mapping patterns are designed to match dictionary-like objects by their keys and values. They use a <code>{...}</code> pattern syntax that resembles a dictionary literal, but in a <code>case</code> pattern it means \"match a mapping with these keys and corresponding value patterns.\" This is useful for working with JSON-like data or configuration dictionaries.</p> <p>For example, imagine we receive event data as dictionaries, and we want to handle different event types:</p> <pre><code># example_9.py\nevent = {\"type\": \"keypress\", \"key\": \"Enter\"}\nmatch event:\n    case {\"type\": \"keypress\", \"key\": k}:\n        print(f\"Key pressed: {k}\")\n    case {\"type\": \"mousemove\", \"x\": x, \"y\": y}:\n        print(f\"Mouse moved to ({x}, {y})\")\n    case _:\n        print(\"Unknown event\")\n## Key pressed: Enter\n</code></pre> <p>In this match:</p> <ul> <li>The first case <code>{\"type\": \"keypress\", \"key\": k}</code> matches any mapping that has at least the keys <code>\"type\"</code> and <code>\"key\"</code>, with the <code>\"type\"</code> value equal to the string <code>\"keypress\"</code>, and it captures the <code>\"key\"</code> value into variable <code>k</code>.   For our <code>event</code>, this matches (since <code>event[\"type\"] == \"keypress\"</code>), so it would print <code>Key pressed: Enter</code>.</li> <li>The second case looks for a <code>\"type\"</code> of <code>\"mousemove\"</code> and keys <code>\"x\"</code> and <code>\"y\"</code> present, capturing their values into <code>x</code> and <code>y</code>.</li> <li>The default case <code>_</code> handles any other shape of event (or if an expected key is missing).</li> </ul> <p>Key rules and features of mapping patterns:</p> <ul> <li> <p>Required keys: All keys listed in the pattern must be present in the subject mapping for a match.   If any of those keys are missing in the dict, the pattern fails.   In the example, if <code>event</code> lacked an <code>\"x\"</code> key, it wouldn't match the second pattern.</p> </li> <li> <p>Literal keys: The keys in the pattern are taken as literal constants (not variables).   Typically, they will be quoted strings (as above) or other hashable constants (like numbers or enum values).   You cannot use a capture for a key name--that wouldn't make sense because a capture binds to a value, not a key.   (If you need to iterate or check arbitrary keys, pattern matching isn't the tool; you'd use normal dict methods in that case.)</p> </li> <li> <p>Value subpatterns: For each key in the pattern, you provide a subpattern that will be matched against the value for that key.   In <code>{\"key\": k}</code>, the subpattern is the capture <code>k</code> which matches any value and binds it.   In <code>{\"type\": \"keypress\"}</code>, the subpattern is the literal <code>\"keypress\"</code>, so that requires the subject's <code>\"type\"</code> value to equal that string.   You can nest deeper patterns too; e.g., <code>case {\"pos\": (x, y)}</code> would require a <code>\"pos\"</code> key whose value is a sequence of length 2 (tuple/list) matching the subpattern <code>(x, y)</code>.</p> </li> <li> <p>Extra keys: By default, a mapping pattern does not require that the subject has no other keys besides the ones listed.   It only insists those specified keys exist with matching values.   Additional keys in the dictionary are ignored (they don't make the match fail).   In our example, if <code>event</code> had other keys (like <code>\"time\": 12345</code>), the first pattern could still match as long as <code>\"type\"</code> and <code>\"key\"</code> were there and correct.   If you want to ensure no extra keys, you can use the double-star wildcard.   For example, <code>case {\"type\": t, \\*\\*rest}:</code> will match and capture all other keys and values into a new dict <code>rest</code>.   Conversely, <code>case {\"type\": t} if len(event) == 1:</code> could be used with a guard to ensure only that key is present, but <code>\\*\\*rest</code> is the idiomatic way to capture \"the rest\" of a mapping.</p> </li> <li> <p>Mapping type: By default, the mapping pattern works on <code>dict</code> and other <code>Mapping</code> implementations (it checks for the presence of a mapping interface).   If the subject is not a mapping, the pattern will fail.   If you specifically want to narrow the type (say you only want to match <code>dict</code> objects), you could combine a class pattern with a mapping pattern using the syntax <code>case dict({...})</code> similarly to how we did <code>list([...])</code> for sequences.   This would first check <code>isinstance(subject, dict)</code> then apply the mapping subpattern.</p> </li> </ul> <pre><code># double_star_wildcard.py\nuser_info = {\n    \"name\": \"Alice\",\n    \"age\": 30,\n    \"country\": \"US\",\n}\n\nmatch user_info:\n    case {\"name\": name, **rest}:\n        print(f\"Name: {name}, info: {rest}\")\n## Name: Alice, info: {'age': 30, 'country': 'US'}\n</code></pre> <p>This pattern looks for a <code>\"name\"</code> key and captures its value into <code>name</code>. The <code>**rest</code> in the pattern captures any remaining key-value pairs into the dictionary <code>rest</code>. So for the given <code>user_info</code>, it would print something like: \"Name is Alice, other info: {'age': 30, 'country': 'US'}\". If <code>user_info</code> had only a <code>\"name\"</code> key, then <code>rest</code> would be an empty dict. If it had no <code>\"name\"</code> key, the pattern would not match at all.</p> <p>Static analysis and mappings: For dicts, static type checking is less precise than with sequences because the set of keys is not always known through type annotations (unless using <code>TypedDict</code> or specific <code>Literal</code> keys). However, if you use something like <code>TypedDict</code> or <code>Mapping[str, X]</code>, a type checker can ensure the values you capture are of the expected type <code>X</code>. Pattern matching shines in expressiveness rather than static type rigor for mappings. If you have a fixed schema for a dict, pattern matching can clearly express the shape, and a tool like mypy can check that you at least treat captured values consistently with their annotated types. (For truly fixed keys, a dataclass or custom class might be a better fit, which leads us to class patterns.)</p>"},{"location":"C08_Pattern_Matching/#class-patterns","title":"Class Patterns","text":"<p>Class patterns match objects of a specific class and extract their attributes. They use a syntax reminiscent of calling a constructor, but no object is created in a case pattern--instead, Python checks the subject is an instance of that class and then pulls out specified attributes. This is a form of structured binding or deconstruction for user-defined types.</p> <p>The basic form is <code>ClassName(attr1=subpattern1, attr2=subpattern2, ...)</code>. You list the class to match and the attributes you want to check or capture. For example, suppose we have a basic data class representing a user:</p> <pre><code># example_10.py\nfrom dataclasses import dataclass\n\n\n@dataclass\nclass User:\n    name: str\n    age: int\n\n\nuser = User(\"Carol\", 25)\n\nmatch user:\n    case User(name=\"Alice\", age=age):\n        print(f\"Found Alice, age {age}\")\n    case User(name=name, age=age):\n        print(f\"User {name} is {age} years old\")\n    case _:\n        print(\"Not a User instance\")\n## User Carol is 25 years old\n</code></pre> <p>What happens here:</p> <ul> <li><code>case User(name=\"Alice\", age=age)</code>: This matches if <code>user</code> is an instance of <code>User</code> and its <code>name</code> attribute equals <code>\"Alice\"</code>.   If so, it captures the <code>age</code> attribute into the variable <code>age</code>.   In our example <code>user.name</code> is <code>Carol</code>, not <code>Alice</code>, so this case fails.</li> <li><code>case User(name=name, age=age)</code>: This matches any <code>User</code> instance (since no literal value restrictions now, just captures).   It will bind <code>name = user.name</code> and <code>age = user.age</code>.   For our <code>User(\"Carol\", 25)</code>, this matches, setting <code>name = \"Carol\"</code> and <code>age = 25</code>, and prints \"User Carol is 25 years old.\"</li> <li><code>case _</code>: If <code>user</code> wasn't a <code>User</code> at all (say it was an int or some other type), the first two patterns would fail and the wildcard would catch it.   Here we put a message for non-User instances.</li> </ul> <p>So effectively, <code>User(name=X, age=Y)</code> in a pattern means \"is the subject a <code>User</code>? If yes, let <code>X = subject.name</code> and <code>Y = subject.age</code>, and proceed; otherwise this pattern fails.\" The class pattern is doing an <code>isinstance(subject, User)</code> check and attribute lookups.</p>"},{"location":"C08_Pattern_Matching/#details_1","title":"Details","text":"<ul> <li>Type check: When you use a class in a pattern, Python will call <code>isinstance(subject, ClassName)</code>.   If that fails, the pattern doesn't match, period.   This means class patterns naturally filter by type.   This is great for branching logic based on object type without manually calling <code>isinstance</code> in your code.</li> <li>Attribute matching: By specifying <code>attr=...</code> in the pattern, Python will retrieve that attribute from the object and attempt to match it to the given subpattern.   All specified attributes must exist, and all their subpatterns must match for the class pattern to succeed.   In the <code>User(name=name, age=age)</code> case, it checks that <code>user.name</code> exists (it does) and binds it, and <code>user.age</code> exists and binds it.   You can also put literal patterns for attributes (like the <code>\"Alice\"</code> literal for <code>name</code> in the first case), requiring that attribute to equal a specific value.</li> <li>Positional parameters and <code>__match_args__</code>: The example above used <code>name=</code> and <code>age=</code> as keyword patterns.   Python's pattern matching also allows positional subpatterns in class patterns, which are matched against attributes defined by the class's <code>__match_args__</code>.   By default, dataclasses and normal classes don't set <code>__match_args__</code> automatically (it's an attribute you can define as a tuple of attribute names).   For example, if <code>User.__match_args__ = (\"name\", \"age\")</code>, then you could write <code>case User(\"Alice\", age)</code> as shorthand for the same pattern.   In the absence of <code>__match_args__</code>, you must use keyword <code>attr=value</code> form to match attributes.   Using positional patterns on a class without <code>__match_args__</code> will result in a MatchError at runtime.   For clarity, many developers prefer the keyword form even if <code>__match_args__</code> is set, because it's explicit about which attribute is matched.</li> <li>Multiple class patterns and inheritance: If you have a class hierarchy, a class pattern will match subclasses as well (since it's based on <code>isinstance</code>).   If you need to differentiate subclasses, you can use different class patterns or guards.   Class patterns can also be combined with OR patterns to accept an object of one of several classes.   For example, <code>case Cat(name=n) | Dog(name=n): ...</code> could match either a <code>Cat</code> or <code>Dog</code> instance and capture a <code>name</code> attribute from either.</li> </ul> <p>One subtle aspect to remember is that writing something like <code>case User(\"Bob\")</code> in a pattern does not call the <code>User</code> constructor. It might look like a construction, but in a <code>case</code> context it's pattern syntax. Whatever appears after <code>case</code> is interpreted purely as a pattern, not normal executable code. If <code>User</code> were a dataclass with a <code>__post_init__</code> that prints when an object is created, a subject expression of <code>match User(\"Alice\"):</code> creates a <code>User(\"Alice\")</code> instance as an expression to match. But <code>case User(\"Bob\"):</code> does not create a new user; it just means \"match a User with some attribute equal to Bob.\" This distinction is important. Class patterns let you destructure objects, not create them.</p> <p>Customizing class matching: If you are designing your own classes to be matched frequently, you might consider adding a <code>__match_args__</code> for convenience, or even defining a special <code>__match_repr__</code> (in Python 3.11+, some classes can control matching via <code>__match_args__</code> and <code>__match_self__</code>, but that's beyond the scope of this chapter). For most uses, using keyword patterns as shown is sufficient.</p> <p>Static analysis benefits: Class patterns go hand-in-hand with type annotations. If a variable is annotated as a base class or a union of classes, a match statement with class patterns can effectively act as a type-safe downcast. For example, if a function parameter <code>shape: Shape</code> where <code>Shape</code> is a union of <code>Circle | Square</code>, you might do:</p> <pre><code># example_11.py\nfrom typing_extensions import NamedTuple\n\n\nclass Circle(NamedTuple):\n    radius: float\n\n\nclass Square(NamedTuple):\n    side: float\n\n\ndef shape_area(shape: Circle | Square) -&gt; float:\n    match shape:\n        case Circle(radius=r):\n            # Here shape is type Circle:\n            return 3.14 * r**2\n        case Square(side=s):\n            # Here shape is type Square:\n            return s**2\n        case _:\n            raise ValueError(\"Unsupported shape\")\n</code></pre> <p>Within each case, static type checkers know <code>shape</code> (or the captured attributes) have the specific class type, so you get auto-completion and type checking on those attributes. Furthermore, like with enums, a checker can warn if your match isn't exhaustive over all possible classes in the union. Class patterns thus enable a form of type narrowing similar to <code>isinstance</code> checks, but often more cleanly.</p>"},{"location":"C08_Pattern_Matching/#or-patterns","title":"OR Patterns (<code>|</code>)","text":"<p>An OR pattern (also called alternative pattern) allows one case to match multiple different patterns. You use the vertical bar <code>|</code> to separate two or more subpatterns. The whole pattern matches if any one of the subpatterns matches. OR patterns are quite flexible--the subpatterns can be of completely different shapes or types. This is useful to avoid repetition when the action for multiple cases would be the same.</p> <p>An example of OR patterns is handling multiple literals in one go. For instance, if you want to check if some input is an affirmative \"yes\" in various forms:</p> <pre><code># example_12.py\nuser_input = \"y\"\nmatch user_input.lower:\n    case \"yes\" | \"y\" | \"yeah\":\n        print(\"User said yes\")\n    case \"no\" | \"n\" | \"nope\":\n        print(\"User said no\")\n    case _:\n        print(\"Unrecognized response\")\n## Unrecognized response\n</code></pre> <p>Here <code>\"yes\" | \"y\" | \"yeah\"</code> is a single pattern that will match the subject if it equals any of those three strings. The first case will trigger for <code>\"yes\"</code>, <code>\"Y\"</code>, <code>\"yeah\"</code>, etc. (we lowercased the input to handle capital letters). Similarly, for the negative responses. This is more concise than writing separate cases for each variant, and it keeps logically related alternatives together.</p> <p>OR patterns are not limited to literals; you can alternate between any pattern types. For example:</p> <ul> <li><code>case 0 | 1 | 2:</code> would match if the subject is 0, 1, or 2.</li> <li><code>case (0, 0) | (0, y) | (x, 0):</code> could combine some of the tuple patterns from earlier into one case (though you might separate for clarity, it's possible to combine).</li> <li><code>case User(name=\"Alice\") | User(name=\"Bob\"):</code> could run the same block for either Alice or Bob, if that's the logic needed.</li> </ul> <p>Each alternative pattern is tried in order (left to right) as part of the same case. If anyone succeeds, the whole OR pattern succeeds and that case executes. If an OR pattern is complex, be mindful that all subpatterns should make sense in the same context because they share the same action block. Also, variables bound in an <code>OR</code> pattern must be bound in all alternatives to be usable in the block (otherwise it'd be ambiguous which value they have). For instance, <code>case (\"a\", x) | (\"b\", x):</code> is valid because either way an <code>x</code> will be bound (if the tuple second element, whether the pattern matches \"a\" or \"b\" as first element). But <code>case (\"a\", x) | \"foo\":</code> is tricky--in the first alternative <code>x</code> would be bound, but in the second alternative (just the string \"foo\"), there's no <code>x</code>. In such cases, the capture <code>x</code> is not allowed because it wouldn't always have a value. You'd need to restructure the patterns (perhaps use two separate cases in that scenario).</p> <p>OR patterns are great for merging cases that result in the same outcome, but if each alternative needs a very different explanation, separate cases might be clearer. However, for things like multiple literal aliases (as shown with \"yes\"/\"y\"/\"yeah\"), OR patterns keep the code succinct.</p> <p>Type checking with OR patterns: If your patterns correspond to different types, a static type checker will infer the subject is one of those types after the match. For example, if you do:</p> <pre><code># example_13.py\ndef type_narrowing(data: int | float | str):\n    match data:\n        case int(x) | float(x):\n            ...\n            # handle as numeric (x will be int or float here)\n        case str(s):\n            ...\n            # handle as string\n</code></pre> <p>Here <code>int(x) | float(x)</code> uses two class patterns in an OR. In the action block, <code>x</code> is either int or float. Some type checkers might narrow it to a common supertype (like <code>x: float</code> if float and int are both numbers--int is subtype of float in the type system). If you need to handle each type differently, it's better to split into separate cases. But if the handling is the same (say you treat int and float uniformly as \"number\"), OR is perfect. For literal OR patterns, as mentioned, exhaustiveness can be checked. Ensure you cover the necessary types for class OR patterns.</p> <p>Generally, OR patterns complement union types in annotations: if a variable is <code>X | Y</code>, a match with <code>case X(...)|Y(...):</code> will cover those. Remember that the action block sees the union of the possibilities.</p>"},{"location":"C08_Pattern_Matching/#as-patterns","title":"AS Patterns","text":"<p>An AS pattern allows you to capture a matched value under a name while still enforcing a subpattern on it. It uses the syntax <code>&lt;pattern&gt; as &lt;variable&gt;</code>. This is extremely handy when you want to both check a complex pattern and keep a reference to the whole thing (or a large part of it) for use in the code.</p> <p>A basic scenario is matching a sequence but also retaining it:</p> <pre><code># example_14.py\npair = [4, 5]\nmatch pair:\n    case [first, second] as full_pair:\n        print(\n            f\"First element: {first}, second: {second}, pair: {full_pair}\"\n        )\n## First element: 4, second: 5, pair: [4, 5]\n</code></pre> <p>This will match if <code>pair</code> is a sequence of length 2 (since the subpattern is <code>[first, second]</code>). If it matches, it binds <code>first = 4</code>, <code>second = 5</code>, and additionally <code>full_pair = pair</code> (i.e., the entire list <code>[4, 5]</code>). The output here would be: \"First element: 4, second: 5, pair: [4, 5]\". The <code>as</code> keyword effectively gives a name to the value that the preceding subpattern matched.</p> <p>Another use case: suppose you have nested structures and want to both break them down and keep some part intact. For instance, consider parsing a nested coordinate:</p> <pre><code># example_15.py\ndata = {\"coords\": [7, 3]}\nmatch data:\n    case {\"coords\": [x, y] as point}:\n        print(f\"Point {point} has x={x}, y={y}\")\n## Point [7, 3] has x=7, y=3\n</code></pre> <p>This pattern checks that <code>data</code> is a mapping with a <code>\"coords\"</code> key whose value is a sequence of two elements. If that matches, it captures <code>x</code> and <code>y</code> from the sequence, and also captures the entire sequence as <code>point</code>. In our example, it would print: <code>Point [7, 3] has x=7, y=3</code>. We got to both validate the structure (<code>\"coords\"</code> exists, has two elements) and keep the list <code>[7,3]</code> intact in <code>point</code> for convenient use (perhaps to pass it somewhere as a whole).</p> <p>Key points for <code>as</code> patterns:</p> <ul> <li>The subpattern before <code>as</code> is fully matched first.   Only if it succeeds will the <code>as</code> binding happen.   If the subpattern fails, the whole pattern fails (and nothing is bound).</li> <li>The name after <code>as</code> will be bound to the exact value that the subpattern matched.   If the subpattern spans multiple elements (like <code>[x, y]</code> matching a list), the name gets the entire matched object (the list).   If the subpattern is just part of the structure, you essentially get a reference to that part.</li> <li>You can use <code>as</code> after any complex pattern, not just sequences.   For example: <code>case User(name=n, age=a) as u:</code> would match a <code>User</code> into <code>n</code> and <code>a</code> and also bind <code>u</code> to the whole User object.   This might seem redundant (since you already have the object in the variable being matched, e.g., <code>user</code>), but it becomes useful in OR patterns or nested patterns where you don't have a simple name for the whole thing in that scope.</li> <li>Only one <code>as</code> is allowed at the same pattern level (you can't do <code>A as x as y</code>).   However, you can nest them in different parts of a pattern if needed.</li> </ul> <p>Why use <code>as</code>? Sometimes after matching a structure, you need the whole object for something (like logging it, or passing it to another function), and reconstructing it from parts would be inconvenient. <code>as</code> provides a shorthand to avoid repeated computation. It also improves clarity when you want to refer to \"the thing we just matched\" without losing the context after destructuring it.</p> <p>One common pattern is using <code>as</code> in the default case to bind the unmatched value for error reporting or assertion. For example:</p> <pre><code># example_16.py\nfrom colors import Color\n\n\ndef handle_color(color: Color):\n    match color:\n        case Color.RED | Color.GREEN | Color.BLUE:\n            ...  # handle known colors\n        case _ as unknown:\n            raise ValueError(f\"Unknown color: {unknown}\")\n</code></pre> <p>Here, <code>_ as unknown</code> catches anything not handled and gives it the name <code>unknown</code> so we can include it in the error message. This is clearer than just <code>_</code> and then using the original variable (especially if the original variable might not be directly accessible, or you want to emphasize the unmatched value).</p> <p>Relation to static analysis: The <code>as</code> pattern doesn't change what types are matched; it just introduces an extra name. Static checkers will give that name the type of the subpattern's value. In the example with <code>{\"coords\": [x,y] as point}</code>, if <code>data</code> is of type <code>dict[str, list[int]]</code>, then <code>point</code> is inferred as <code>list[int]</code> (same type as <code>data[\"coords\"]</code>), while <code>x</code> and <code>y</code> are <code>int</code>. It's mainly a convenience; the presence of <code>as</code> doesn't affect whether a pattern matches or not, so it doesn't factor into exhaustiveness or type narrowing decisions beyond providing a new symbol.</p>"},{"location":"C08_Pattern_Matching/#guard-patterns-pattern-guards","title":"Guard Patterns (Pattern Guards)","text":"<p>Sometimes a pattern needs an additional condition beyond just structural matching. A Guard specifies an <code>if &lt;condition&gt;</code> at the end of a case pattern, making the case only match if the pattern succeeds and the condition is true. This is useful for imposing value constraints that can't be expressed by the pattern alone.</p> <p>The syntax is: <code>case &lt;pattern&gt; if &lt;boolean expression&gt;:</code>. The guard expression can use the variables bound by the pattern (as well as any other in-scope names) to decide whether to accept the match.</p> <p>For example, suppose we want to match a pair of numbers but only if they satisfy some relationship:</p> <pre><code># example_17.py\npair = (5, 5)\nmatch pair:\n    case (x, y) if x == y:\n        print(\"The two values are equal.\")\n    case (x, y):\n        print(\"The values are different.\")\n## The two values are equal.\n</code></pre> <p>Here the first case is a sequence pattern <code>(x, y)</code> with a guard <code>if x == y</code>. This will match any 2-tuple (binding <code>x</code> and <code>y</code>), then check the guard condition. If <code>x == y</code>, then and only then does the case succeed. In our example, <code>pair</code> is <code>(5,5)</code>, so it matches <code>(x,y)</code> with <code>x=5, y=5</code>, then the guard <code>5 == 5</code> is true, so it prints \"The two values are equal.\" If <code>pair</code> were <code>(5, 7)</code>, the first pattern would match structurally (<code>x=5,y=7</code>), but the guard <code>5 == 7</code> would be false, causing that case to fail overall and move to the next case. The second case has no guard and would then match by default, printing \"The values are different.\"</p> <p>Guards effectively let you refine a pattern match with arbitrary logic:</p> <ul> <li>Use guards to check relationships between captured variables (like x == y, or one value greater than another, etc.).</li> <li>Use guards to call functions or methods for deeper checks (e.g., <code>case User(age=a) if a &gt;= 18:</code> to only match adult users, or <code>case s if validate(s):</code> to apply an external predicate).</li> <li>Guards can also prevent a case from handling a scenario that should be passed to a later case.   For instance, if you have overlapping patterns, a guard can differentiate them.</li> </ul> <p>It's important to note that the guard is evaluated after the pattern matches. If the pattern doesn't match, Python doesn't even evaluate the guard. If the pattern matches but the guard is False, the overall result is as if the pattern didn't match at all, and the next case is tried.</p> <p>One must be careful with guards: since they can run arbitrary code, they could have side effects or be slow. Keep guards relatively simple and pure (avoid changing state in a guard). They should ideally just inspect the bound variables or the subject.</p> <p>Combining mapping patterns with guards can handle situations like \"match a dict with a key and then check something about the value\":</p> <pre><code># example_18.py\nfrom typing import Any, cast\n\nrequest = {\"method\": \"POST\", \"payload\": {\"id\": 42}}\n\nmatch request:\n    case {\"method\": m, \"payload\": data} if (\n        m == \"POST\" and \"id\" in data\n    ):\n        data = cast(dict[str, Any], data)\n        print(f\"POST request with id {data['id']}\")\n\n    case {\"method\": m}:\n        print(f\"Other request method: {m}\")\n## POST request with id 42\n</code></pre> <p>In the first case, the pattern <code>{\"method\": m, \"payload\": data}</code> extracts <code>m</code> and <code>data</code>. The guard then checks that <code>m</code> is \"POST\" and that the dictionary <code>data</code> has an <code>\"id\"</code> key. Only if both are true does the case run. Otherwise, it falls through to perhaps a more general case (second one handles any other method).</p> <p>Guard vs multiple patterns: Sometimes you can express the same logic with either a more complex pattern or a guard. For example, <code>case (x, y) if x == y:</code> could also be expressed by a single pattern if Python allowed something like <code>(x, x)</code> (which it currently does not--you can't repeat the same capture name in one pattern, since that would be ambiguous). In this case, the guard was necessary to enforce equality. In other situations, you might have the choice: e.g., <code>case [*_] if len(some_list) &gt; 5:</code> versus <code>case [_, _, _, _, _, *_]:</code> to check \"at least 6 elements.\" The latter uses a pattern with star to check length in structure, the former uses a guard with a length check. Both work; using patterns for structural conditions and guards for non-structural conditions is a good guideline.</p> <p>Static analysis: Guards are essentially runtime checks, and static type checkers typically don't reason about them much. However, if a guard uses an <code>isinstance</code> or similar, a smart type checker might narrow types in the true branch. For example:</p> <pre><code># example_19.py\n\n\ndef narrow(obj):\n    match obj:\n        case list as lst if all(isinstance(x, int) for x in lst):\n            # Here, lst is a list and we asserted all elements are int.\n            total: int = sum(lst)\n</code></pre> <p>In this contrived example, the guard ensures every element in the list is int, so inside the case it might be safe to treat it as <code>list[int]</code>. Type checkers are not guaranteed to catch that nuance, but you as the programmer know it. More commonly, you'd have already annotated or known types. Guards are mainly for logic, not for static type discrimination (that's what class patterns are for).</p>"},{"location":"C08_Pattern_Matching/#pattern-matching-vs","title":"Pattern Matching vs.","text":"<p>Inheritance</p>"},{"location":"C08_Pattern_Matching/#conclusion","title":"Conclusion","text":"<p>Structural pattern matching can be composed in various ways--you can nest patterns arbitrarily, use OR inside sequence patterns, add guards to class patterns, and so on, to model the logic you need.</p> <p>When used thoughtfully, pattern matching can make code more readable by aligning it closely with the structure of the data it's handling. It can reduce boilerplate (no more long chains of <code>isinstance</code> and indexing) and help catch errors (exhaustiveness checks with static typing, for example). Your code will be more readable and maintainable if you do not overcomplicate patterns--strive for clarity. Often a straightforward series of cases is better than one mega-pattern that is hard to understand.</p> <p>With practice, you'll find pattern matching to be a natural extension of Python's ethos of readable and expressive code. It brings Python closer to languages like Scala or Haskell in this regard, but in a Pythonic way. Use the references and examples in this chapter as a guide to the various forms, and happy matching!</p>"},{"location":"C08_Pattern_Matching/#references","title":"References","text":"<ol> <li>Structural pattern matching in Python 3.10</li> <li>What's New In Python 3.10--Python 3.13.3 documentation</li> <li>Literal types and Enums--mypy 1.15.0 documentation</li> <li>Structural Pattern Matching in Python--Real Python</li> </ol>"},{"location":"C09_Generics/","title":"Generics","text":"<p>Generics in Python produce flexible, reusable code that remains type-safe. They enable the definition of classes, functions, and types that can operate on a variety of types while preserving type information. With generics, you can avoid writing duplicate code for similar operations on different types and catch type errors early during development.</p> <p>TODO: Probably divide this into \"Generics\" here and \"Advanced Generics\" at the end of the book.</p>"},{"location":"C09_Generics/#defining-custom-generics","title":"Defining Custom Generics","text":"<p>Python directly supports parameterized types. This allows you to declare a type variable as a placeholder for an arbitrary type.</p>"},{"location":"C09_Generics/#generic-functions","title":"Generic Functions","text":"<p>For functions, a type variable enables the function to accept and return values of the same arbitrary type. Here is a generic function expressing identity:</p> <pre><code># generic_function.py\n\n\ndef identity[T](value: T) -&gt; T:\n    return value\n\n\nprint(identity(42))\n## 42\nprint(identity(\"Hello\"))\n## Hello\n</code></pre> <p>Here, the type variable <code>T</code> contains the type of both the <code>value</code> parameter and the return type. The type checker enforces that both are the same type. If you call <code>identity(42)</code>, <code>T</code> is inferred as <code>int</code>, so the function takes returns an <code>int</code>. For <code>identity(\"Hello\")</code>, <code>T</code> is <code>str</code>. Thus, this function works for any type but always returns the same type it is given.</p> <p>Generic functions are useful for algorithms that work uniformly on multiple types. Common examples include utility functions like <code>identity</code>, data retrieval functions that return the type of whatever they fetch, or factory functions that construct objects of a type.</p>"},{"location":"C09_Generics/#old-syntax","title":"Old Syntax","text":"<p>Originally, type variables had to be explicitly declared using <code>TypeVar</code>:</p> <pre><code># typevars.py\nfrom typing import TypeVar\n\nT = TypeVar(\"T\")  # Define a TypeVar named T\n\n\ndef identity(value: T) -&gt; T:\n    return value\n\n\nprint(identity(42))\n## 42\nprint(identity(\"Hello\"))\n## Hello\n</code></pre> <p>Python 3.12 removed this requirement, improving the syntax significantly. This book uses the modern syntax, but you may come across older code that uses <code>TypeVar</code>s.</p>"},{"location":"C09_Generics/#generic-classes","title":"Generic Classes","text":"<p>For classes, generics allow the class to operate on or store various types without sacrificing type safety. Here's a generic class <code>Box</code> that can hold a value of any type:</p> <pre><code># box.py\nfrom dataclasses import dataclass\nfrom typing_extensions import reveal_type\n\n\n@dataclass\nclass Box[U]:\n    content: U\n\n    def get_content(self) -&gt; U:\n        # reveal_type(self.content)\n        return self.content\n\n\nint_box = Box(123)  # U is inferred as int\nstr_box = Box(\"Python\")  # U is inferred as str\nprint(int_box.get_content())\n## 123\nprint(str_box.get_content())\n## Python\n</code></pre> <p><code>Box</code> is a generic class parameterized by <code>U</code>. When we create <code>Box(123)</code>, the type checker knows <code>U</code> is <code>int</code> for that instance. For <code>Box(\"Python\")</code>, <code>U</code> is <code>str</code> (<code>Box[str]</code>). The attribute <code>content</code> and return type of <code>get_content</code> are accordingly typed.</p> <p>The class definition <code>class Box[U]</code> tells the type system that <code>Box</code> has a type parameter <code>U</code>. At runtime, <code>Box</code> is just a normal class (after all, Python's generics are mostly static and erased at runtime), but for type checking, <code>Box[int]</code> and <code>Box[str]</code> are treated as different instantiations of the generic class. This prevents, for example, accidentally putting a <code>str</code> into a <code>Box[int]</code>.</p> <p>Note that we did not explicitly write <code>Box[int]</code> or <code>Box[str]</code> when constructing the boxes. The type checker infers <code>U</code> from the constructor argument. We can also annotate variables or parameters with explicit instantiations like <code>Box[int]</code> if needed.</p>"},{"location":"C09_Generics/#constraints-and-bounds-on-type-variables","title":"Constraints and Bounds on Type Variables","text":"<p>Sometimes you want a type variable to be limited to certain types, rather than truly any type. Python's typing provides two mechanisms for this: constraints and bounds.</p>"},{"location":"C09_Generics/#constraints","title":"Constraints","text":"<p>You can specify an explicit finite set of allowable types for a type variable. This is useful when a function or class should only work with specific types that aren't in an inheritance relationship. In <code>add</code>, we constrain <code>Number</code> to be either an <code>int</code> or a <code>float</code>:</p> <pre><code># constrained_type_variable.py\n\n\ndef add[Number: (int, float)](a: Number, b: Number) -&gt; Number:\n    return a + b\n\n\nadd(5, 10)  # valid, both int\nadd(3.5, 2.5)  # valid, both float\n# ERROR: cannot mix types:\nadd(5, 2.5)  # type: ignore\n# ERROR: str not allowed for Number:\nadd(\"A\", \"Z\")  # type: ignore\n</code></pre> <p>The <code>add</code> function will only accept one of those types for both its arguments--you cannot mix types. Passing any type other than <code>int</code> or <code>float</code> produces a type checking error.</p>"},{"location":"C09_Generics/#bounds","title":"Bounds","text":"<p>A bound restricts a type variable to subtypes of a given class (or to classes implementing a given protocol). This is known as an upper bound. For example, if we have a base class <code>Animal</code>, we might want a generic function to only accept subclasses of <code>Animal</code>:</p> <pre><code># animals.py\nfrom dataclasses import dataclass\nfrom typing import Optional\n\n\n@dataclass\nclass Animal:\n    name: Optional[str] = None\n\n    def say(self) -&gt; None:\n        print(f\"{self.name}: Animal sound\")\n\n\nclass Dog(Animal):\n    def say(self) -&gt; None:\n        print(f\"{self.name}: Woof\")\n\n\ndef speak[T: Animal](creatures: list[T]) -&gt; None:\n    for creature in creatures:\n        creature.say()\n</code></pre> <p><code>T</code> is bounded by <code>Animal</code>, meaning any substitution for <code>T</code> must be <code>Animal</code> or a subclass of <code>Animal</code>. The <code>speak</code> function can then accept a list of <code>Animal</code> or any subtype (like <code>Dog</code>). Inside the function, we know that each item has the <code>speak()</code> method (since everything is at least <code>Animal</code>). If we tried to call <code>speak</code> with a list of something else (say <code>str</code> or <code>int</code>), the type checker rejects it.</p> <pre><code># animal_demo.py\nfrom animals import Animal, Dog, speak\nfrom book_utils import Catch\n\npets: list[Dog] = [Dog(\"Rags\"), Dog(\"Spot\")]\nspeak(pets)  # Dog is a subclass of Animal\n## Rags: Woof\n## Spot: Woof\nspeak([Animal(\"Mittens\")])  # Animal is the bound\n## Mittens: Animal sound\nwith Catch():\n    speak([\"bob\"])  # type: ignore\n</code></pre> <p>Use constraints when the valid types are a specific set of unrelated types. Use a bound when the valid types share a common base class or trait that you want to enforce. Bounds are often more flexible, as new subclasses automatically fit the bound without changing the type variable definition. Constraints are stricter and must be explicitly extended if a new type should be allowed.</p>"},{"location":"C09_Generics/#multiple-type-variables-and-relationships","title":"Multiple Type Variables and Relationships","text":"<p>You can use more than one type variable in a generic function or class. For instance, consider a function that takes two parameters of possibly different types and returns a tuple containing them:</p> <pre><code># multiple_type_variables.py\n\n\ndef pairify[A, B](x: A, y: B) -&gt; tuple[A, B]:\n    return x, y\n\n\nresult = pairify(\"Alice\", 5)  # tuple[str, int]\n</code></pre> <p>Here <code>A</code> and <code>B</code> are independent type variables. The type of <code>result</code> is a <code>tuple</code> whose first element is a <code>str</code> and second is an <code>int</code>, as inferred from the arguments.</p> <p>Type variables can also depend on each other through constraints or bounds. However, Python's typing does not allow directly expressing complex relationships (like saying two type variables must be the same subtype of some base). In such cases, it's common to use a single type variable in multiple places to indicate they must match. You can also use protocols (discussed later) for more complex constraints.</p>"},{"location":"C09_Generics/#type-variable-tuples","title":"Type Variable Tuples","text":"<p>A type variable tuple is like <code>*args</code>, but for types. It defines generic classes and functions that accept a variable number of types, creating more powerful and flexible type-safe abstractions. This is called variadic generics.</p> <p>Suppose you want a generic <code>TupleWrapper</code> that can handle any number of types. Without type variable tuples, you'd have to manually define each arity. With it, you can write:</p> <pre><code># tuple_wrapper.py\n\n\nclass TupleWrapper[*T]:\n    def __init__(self, *values: *T):\n        self.values = values\n\n\nt1 = TupleWrapper(1)  # TupleWrapper[int]\nt2 = TupleWrapper(\"a\", 2, 3.14)  # TupleWrapper[str, int, float]\n</code></pre> <p>The type checker tracks the number and types of elements in <code>*T</code> individually. Let's explore the type variable tuple by implementing a type-safe version of Python's built-in <code>zip()</code> function that works on <code>tuple</code>s of different types:</p> <pre><code># variadic_zip.py\n\n\ndef zip_variadic[*T](\n    *args: tuple[*T],\n) -&gt; tuple[tuple[*T], ...]:\n    return tuple(zip(*args))\n\n\ndef unzip_variadic[*T](\n    packed: tuple[tuple[*T], ...],\n) -&gt; tuple[tuple[*T], ...]:\n    return tuple(zip(*packed))\n\n\na: tuple[int, str, float] = (1, \"a\", 3.14)\nb: tuple[int, str, float] = (2, \"b\", 2.71)\nc: tuple[int, str, float] = (3, \"c\", 1.41)\n\nzipped = zip_variadic(a, b, c)\nunzipped = unzip_variadic(zipped)\n\nprint(f\"Zipped: {zipped}\")\n## Zipped: ((1, 2, 3), ('a', 'b', 'c'), (3.14, 2.71, 1.41))\n# Zipped: ((1, 2, 3), ('a', 'b', 'c'), (3.14, 2.71, 1.41))\nprint(f\"Unzipped: {unzipped}\")\n## Unzipped: ((1, 'a', 3.14), (2, 'b', 2.71), (3, 'c', 1.41))\n# Unzipped: ((1, 'a', 3.14), (2, 'b', 2.71), (3, 'c', 1.41))\n</code></pre> <p>The <code>zip_variadic</code> signature says:</p> <ul> <li><code>args</code> is a variadic list of tuples, each shaped like <code>tuple[*T]</code>.</li> <li>The return value is a tuple of rows, where each row is <code>tuple[*T]</code> (e.g., one <code>int</code> row, one <code>str</code> row, one <code>float</code>   row).</li> </ul>"},{"location":"C09_Generics/#limitations-2025","title":"Limitations (2025)","text":"<ul> <li>Can't yet mix type variable and type variable tuple freely in all places</li> <li>Still not supported in some older tools or linters</li> </ul>"},{"location":"C09_Generics/#related-concepts","title":"Related Concepts","text":"Feature Purpose Type variable A single generic type Parameter spec A tuple of parameter types for callables Type variable tuple A tuple of arbitrary generic types"},{"location":"C09_Generics/#example-n-dimensional-tensor-shape","title":"Example: N-dimensional Tensor Shape","text":"<p>// Introduce Tensors</p> <p>Suppose you're building a generic <code>Tensor</code> type that carries its shape as part of its type. For example, <code>Tensor[float, 3, 3]</code> for a 3\u00d73 matrix, or <code>Tensor[float, 2, 2, 2]</code> for a 3D cube. With type variable tuple, we can capture the variable number of dimension sizes.</p> <pre><code># n_dimensional_tensor.py\nfrom typing import Literal, TypeAlias\n\n\nclass Tensor[T, *Shape]:\n    def __init__(self, data: list, *, shape: tuple[*Shape]):\n        self.data = data\n        self.shape = shape\n\n    def __repr__(self) -&gt; str:\n        return f\"Tensor(shape={self.shape})\"\n\n\nShape3x3: TypeAlias = tuple[Literal[3], Literal[3]]\nShape2x2x2: TypeAlias = tuple[Literal[2], Literal[2], Literal[2]]\n\nt1 = Tensor[float, *Shape3x3](data=[[1.0] * 3] * 3, shape=(3, 3))\n\nt2 = Tensor[int, *Shape2x2x2](\n    data=[[[1, 2], [3, 4]], [[5, 6], [7, 8]]],\n    shape=(2, 2, 2),\n)\n\nprint(t1)  # Tensor(shape=(3, 3))\n## Tensor(shape=(3, 3))\nprint(t2)  # Tensor(shape=(2, 2, 2))\n## Tensor(shape=(2, 2, 2))\n</code></pre> <ul> <li>Type checker sees Tensor[float, 3, 3]</li> <li>Shape is statically typed as (3, 3)</li> </ul>"},{"location":"C09_Generics/#an-argument-preserving-decorator","title":"An Argument-Preserving Decorator","text":"<p>Here's a decorator that logs a function call without changing its type signature, no matter how many arguments it takes:</p> <pre><code># argument_preserving_decorator.py\nfrom typing import Callable\n\n\ndef log_call[**P, R](fn: Callable[P, R]) -&gt; Callable[P, R]:\n    def wrapper(*args: P.args, **kwargs: P.kwargs) -&gt; R:\n        print(f\"Calling {fn.__name__} with {args=}, {kwargs=}\")\n        return fn(*args, **kwargs)\n\n    return wrapper\n\n\n@log_call\ndef greet(name: str, age: int) -&gt; str:\n    return f\"Hi {name}, age {age}\"\n\n\n@log_call\ndef add(a: int, b: int) -&gt; int:\n    return a + b\n\n\nprint(greet(\"Alice\", 30))\n## Calling greet with args=('Alice', 30), kwargs={}\n## Hi Alice, age 30\nprint(add(2, 3))\n## Calling add with args=(2, 3), kwargs={}\n## 5\n</code></pre> <ul> <li>Type checker knows <code>greet</code> returns <code>str</code>, and <code>add</code> returns <code>int</code></li> <li>Arguments are preserved exactly</li> </ul> <p>This isn't strictly a type variable tuple, but it complements it:</p> <ul> <li>type variable tuple handles variadic type lists</li> <li>Parameter specifications handle variadic function arguments</li> </ul>"},{"location":"C09_Generics/#a-record-type-for-heterogeneous-tuples","title":"A Record Type for Heterogeneous Tuples","text":"<p>Let\u2019s say you want a type-safe <code>Record</code> that stores a fixed tuple of fields, where each field can be a different type (like a database row or spreadsheet line):</p> <pre><code># heterogeneous_record.py\nfrom dataclasses import dataclass\n\n\n@dataclass\nclass Record[*Fields]:\n    fields: tuple[*Fields]\n\n    def __repr__(self) -&gt; str:\n        return f\"{self.__class__.__name__}(fields={self.fields})\"\n\n\nprint(Record((1, \"Alice\", 3.14)))\n## Record(fields=(1, 'Alice', 3.14))\nprint(Record((True, None)))\n## Record(fields=(True, None))\n</code></pre> <p>Each <code>Record</code> preserves the exact type signature of its fields.</p>"},{"location":"C10_Callables/","title":"Callables","text":"<p>ChatGPT 4.5 generated this placeholder text. It will be significantly rewritten as the book is developed. You can add comments to either https://bsky.app/bruceeckel or GitHub Issues.</p>"},{"location":"C10_Callables/#annotating-functions-and-lambdas","title":"Annotating Functions and Lambdas","text":"<p>Clearly annotating functions and lambda expressions improves readability and type safety:</p>"},{"location":"C10_Callables/#function-annotations","title":"Function Annotations","text":"<pre><code># example_1.py\ndef add(x: int, y: int) -&gt; int:\n    return x + y\n</code></pre>"},{"location":"C10_Callables/#lambda-annotations","title":"Lambda Annotations","text":"<p>Annotating lambdas directly isn't supported; however, annotations can be implied:</p> <pre><code># example_2.py\nfrom typing import Callable\n\nadder: Callable[[int, int], int] = lambda x, y: x + y  # type: ignore\n</code></pre> <p>This explicit approach ensures that lambda behavior is type-checked properly.</p>"},{"location":"C10_Callables/#using-callable-for-higher-order-functions","title":"Using <code>Callable</code> for Higher-Order Functions","text":"<p>The <code>Callable</code> type is essential for annotating functions that accept or return other functions:</p> <pre><code># example_3.py\nfrom typing import Callable\n\n\ndef operate(\n    a: int, b: int, func: Callable[[int, int], int]\n) -&gt; int:\n    return func(a, b)\n\n\nresult = operate(5, 3, lambda x, y: x * y)  # returns 15\n</code></pre> <p>Using <code>Callable</code> clearly defines expected function signatures, enhancing maintainability and correctness.</p>"},{"location":"C10_Callables/#advanced-function-annotations-with-parameter-specifications","title":"Advanced Function Annotations with Parameter Specifications","text":"<p>Introduced in Python 3.10, parameter specifications allow annotating decorators and generic functions while preserving original function signatures:</p> <pre><code># example_4.py\nfrom typing import Callable\n\n\ndef logging_decorator[**P, R](\n    func: Callable[P, R],\n) -&gt; Callable[P, R]:\n    def wrapper(*args: P.args, **kwargs: P.kwargs) -&gt; R:\n        print(\n            f\"Calling {func.__name__} with {args} and {kwargs}\"\n        )\n        return func(*args, **kwargs)\n\n    return wrapper\n\n\n@logging_decorator\ndef multiply(a: int, b: int) -&gt; int:\n    return a * b\n\n\nmultiply(2, 3)\n## Calling multiply with (2, 3) and {}\n</code></pre> <p>Parameter specifications help decorators maintain accurate type information for wrapped functions.</p>"},{"location":"C10_Callables/#implementing-function-overloading-with-overload","title":"Implementing Function Overloading with <code>@overload</code>","text":"<p>Python allows specifying multiple function signatures through the <code>@overload</code> decorator for better static type checking:</p> <pre><code># example_5.py\nfrom typing import overload\n\n\n@overload\ndef double(value: int) -&gt; int: ...\n\n\n@overload\ndef double(value: str) -&gt; str: ...\n\n\ndef double(value: int | str) -&gt; int | str:\n    if isinstance(value, int):\n        return value * 2\n    return value + value\n\n\nprint(double(4))  # Output: 8\n## 8\nprint(double(\"Hi\"))  # Output: HiHi\n## HiHi\n</code></pre> <p><code>@overload</code> clearly defines each acceptable signature, providing strong typing and preventing misuse.</p>"},{"location":"C10_Callables/#annotation-strategies-for-apis-and-libraries","title":"Annotation Strategies for APIs and Libraries","text":"<p>Clear annotations greatly enhance public API usability and reliability. Strategies include:</p>"},{"location":"C10_Callables/#explicit-and-detailed-annotations","title":"Explicit and Detailed Annotations","text":"<ul> <li>Clearly annotate all public API interfaces and return types.</li> <li>Avoid overly broad types like <code>Any</code> unless necessary.</li> </ul>"},{"location":"C10_Callables/#using-type-aliases-for-complex-signatures","title":"Using Type Aliases for Complex Signatures","text":"<pre><code># example_6.py\nfrom typing import Callable, TypeAlias\n\nRequestHandler: TypeAlias = Callable[[str, dict], dict]\n\n\ndef handle_request(path: str, handler: RequestHandler) -&gt; dict:\n    response = handler(path, {})\n    return response\n</code></pre>"},{"location":"C10_Callables/#consistent-annotation-patterns","title":"Consistent Annotation Patterns","text":"<ul> <li>Follow consistent patterns for similar methods or functions within an API.</li> </ul>"},{"location":"C10_Callables/#leveraging-protocols-and-callables","title":"Leveraging Protocols and Callables","text":"<p>Using <code>Protocol</code> for clearly defined callable behaviors:</p> <pre><code># example_7.py\nfrom typing import Protocol\n\n\nclass Handler(Protocol):\n    def __call__(self, request: dict) -&gt; dict: ...\n\n\ndef process_request(handler: Handler, request: dict) -&gt; dict:\n    return handler(request)\n</code></pre> <p>Following these strategies ensures type-safe, clear, and developer-friendly APIs and libraries.</p>"},{"location":"C11_Structural_Typing/","title":"Structural Typing","text":"<p>In type systems, there are two fundamental ways to decide if one type is compatible with another: nominal typing and structural typing. Nominal typing (name-based typing) means type compatibility is determined by explicit declarations and the class hierarchy--an object's type is what its class name (or inheritance) says it is. For example, if class <code>Dog</code> inherits from class <code>Animal</code>, then <code>Dog</code> is-a subtype of <code>Animal</code> by definition, and a <code>Dog</code> instance can be used wherever an <code>Animal</code> is expected. This is how traditional object-oriented languages like Java or C++ work, and it's also the primary mode in Python's type system by default.</p> <p>On the other hand, structural typing determines type compatibility by the structure or capabilities of the object, not its explicit inheritance. In a structural type system, if an object has all the required methods and attributes of a type, then it qualifies as that type, regardless of its class name or parent classes. In other words, if it \"walks like a duck and quacks like a duck, then it's treated as a duck.\" This is the essence of the famous duck typing principle.</p> <p>Duck typing is a runtime concept in Python: you invoke methods or attributes on an object, and as long as it supports those operations, things work (if a required method is missing, you get an <code>AttributeError</code> at runtime). Structural typing can be seen as the static, compile-time equivalent of duck typing. Instead of waiting for a runtime error, a structural type system (with the help of a static type checker) can verify ahead of time that an object has the necessary attributes to be used in a given context. This approach is more flexible than nominal typing because it doesn't require pre-planned inheritance relationships. It is also more explicit and safe than unguarded duck typing because the structure is checked (by a type checker) before the code runs.</p> <p>Python historically embraced duck typing at runtime--you call methods on objects and trust they exist. Prior to Python 3.8, static type checking in Python (via tools like MyPy, PyRight, etc.) was largely nominal: you would use abstract base classes or concrete classes to annotation the types, and an object's class had to match the annotation or inherit from a matching class. This could make it awkward to type-annotation code written in a duck-typed style. For instance, if you had a function that worked with any object that had a <code>.read()</code> method, there wasn't a straightforward way to express that in a type annotation without making all such objects share a common base class or using <code>typing.Any</code>. Python 3.8 remedied this by introducing protocols in the <code>typing</code> module. A protocol defines a structural interface that other classes can fulfill just by having the right methods/attributes, without inheritance. This brings the flexibility of duck typing into the realm of static type checking--essentially formalizing \"If it quacks like a duck, it can be treated as a duck\" in the type system.</p> <p>Nominal typing ties compatibility to declared relationships (e.g., subclassing an interface or abstract class), whereas structural typing ties compatibility to an object's shape (the presence of specific methods/attributes). Python's type system now supports both: use nominal typing for clarity and runtime consistency with class relationships, and use structural typing (via protocols) for flexibility and to more directly model Python's duck-typed nature.</p>"},{"location":"C11_Structural_Typing/#defining-and-using-protocols","title":"Defining and Using Protocols","text":"<p>To leverage structural typing in Python's type annotations, you define protocols. A protocol in Python is essentially an interface or template for a set of methods and attributes. It's defined by inheriting from <code>typing.Protocol</code> (available in the standard library <code>typing</code> module as of Python 3.8, or in <code>typing_extensions</code> for earlier versions). By creating a class that subclasses <code>Protocol</code>, you declare a group of methods and properties that form a \"protocol.\" Static type checkers consider any class with those methods and properties (with compatible types) an implementation of that protocol, even if it doesn't formally inherit from the protocol.</p> <p>To define a protocol: Create a class that inherits <code>Protocol</code> and define the method signatures (and any attribute types) that are required. Protocol methods typically have empty bodies (often using <code>...</code> or <code>pass</code>) because you're not providing an implementation, just a definition of the interface. For example, suppose we want a protocol for \"speaking\" creatures or objects: it should have a method <code>speak()</code> that returns a string. We can define:</p> <pre><code># speaker.py\nfrom typing import Protocol\n\n\nclass Speaker(Protocol):\n    def speak(self) -&gt; str: ...\n</code></pre> <p>Here, <code>Speaker</code> is a protocol that any \"speaker\" object should follow. Now, any class that defines a <code>speak(self) -&gt; str</code> method is considered a <code>Speaker</code> for typing purposes. We can create two completely unrelated classes that fulfill this protocol without explicit inheritance:</p> <pre><code># announce.py\nfrom speaker import Speaker\n\n\nclass Dog:\n    def speak(self) -&gt; str:\n        return \"woof\"\n\n\nclass Robot:\n    def speak(self) -&gt; str:\n        return \"beep-boop\"\n\n\ndef announce(speaker: Speaker) -&gt; None:\n    # `speaker` can be any object with .speak() returning str\n    print(\"Announcement:\", speaker.speak())\n\n\nannounce(Dog())  # OK, Dog has speak()\n## Announcement: woof\nannounce(Robot())  # OK, Robot has speak()\n## Announcement: beep-boop\n</code></pre> <p>Even though <code>Dog</code> and <code>Robot</code> do not inherit from <code>Speaker</code> (and are not related to each other at all), the static type checker will accept them as valid arguments to <code>announce</code> because they structurally conform to the <code>Speaker</code> protocol by implementing the required method. This is the power of structural typing. The type checker treats <code>Dog</code> and <code>Robot</code> as subtypes of <code>Speaker</code> because they have the right <code>speak()</code> method signature. If we tried to pass an object that lacks a <code>speak()</code> method (or has an incompatible signature), the type checker would flag an error, ensuring type safety.</p> <p>It's important to note that protocols are primarily a static concept--they are enforced by type checkers, not by the Python runtime (by default). Unlike an abstract base class (ABC), a protocol doesn't require classes to formally subclass it, and Python will not produce an error at runtime if a required method is missing. For example, in the code above, if we call <code>announce(Dog())</code> and <code>Dog.speak</code> is missing or misnamed, we would only find out at runtime via an <code>AttributeError</code>. The protocol helps catch such issues before runtime by using tools like Mypy. The protocols defined in <code>typing</code> are optional and have no runtime effect on their own. This means you can use them freely for type annotations without incurring runtime overhead or restrictions. Protocols do inherit from <code>abc.ABC</code>, but by default <code>isinstance()</code> and <code>issubclass()</code> checks against a protocol will not work without an explicit opt-in.</p> <p>Using a protocol in type annotations: Once you have a protocol class, you use it as a type in annotations just like you would use an ABC or a concrete class. In the above example, the function <code>announce</code> was annotated to accept a <code>Speaker</code>. That tells readers and type checkers that any argument should \"speak.\" This is more expressive than using a base class like <code>Animal</code> or a union of types--we directly specify the capability we need. Another example: Python's standard library defines an <code>Iterable[T]</code> protocol (in <code>collections.abc</code> or <code>typing</code>) that essentially says the object has an <code>__iter__</code> method returning an iterator. If you annotate a function parameter as <code>Iterable[str]</code>, any object that can be iterated over to yield strings is accepted--whether it's a list, a tuple, a custom container class with an <code>__iter__</code>, etc. The type checker doesn't require them to inherit from <code>Iterable</code>; having the method is enough. This demonstrates that many idiomatic Python \"protocols\" (iteration, context managers, etc.) are recognized structurally. Python's typing module and static checkers come with several predefined protocols (either explicitly as in <code>typing.Protocol</code> classes or implicitly via ABCs with structural hooks) for common patterns.</p> <p>Let's look at a slightly more elaborate example of defining and using a protocol. Imagine we have objects that need to support a <code>close()</code> method (like files or network connections). We can define a protocol <code>Closable</code> and use it to write a function that closes a batch of resources:</p> <pre><code># file_resource.py\nfrom typing import Protocol\n\n\nclass Closable(Protocol):\n    def close(self) -&gt; None: ...\n\n\nclass FileResource:\n    def __init__(self, path: str):\n        self.file = open(path, \"w\")\n\n    def close(self) -&gt; None:\n        self.file.close()\n\n\nclass SocketResource:\n    def close(self) -&gt; None:\n        print(\"Socket closed\")\n</code></pre> <pre><code># file_resource_demo.py\nfrom file_resource import (\n    Closable,\n    FileResource,\n    SocketResource,\n)\nfrom typing import Iterable\n\n\ndef close_all(resources: Iterable[Closable]) -&gt; None:\n    for res in resources:\n        res.close()\n\n\n# All these have a close():\nclosables = (\n    FileResource(\"data.txt\"),\n    SocketResource(),\n    open(\"other.txt\", \"w\"),\n)\nclose_all(closables)\n## Socket closed\n</code></pre> <p>In this code, <code>Closable</code> is a protocol requiring a <code>.close()</code> method. We created a <code>FileResource</code> class and a <code>SocketResource</code> class that both implement <code>close()</code>. We also use a built-in file object from <code>open()</code>, which we know has a <code>close()</code> method. The <code>close_all</code> function is annotated to accept any iterable of <code>Closable</code> objects. Thanks to structural typing, it doesn't matter that these objects are of different types and don't share a common ancestor named <code>Closable</code>--as long as each has a callable <code>close()</code> method, the static type checker is satisfied and, at runtime, the code will work. Mypy considers the built-in file object and our custom classes all as subtypes of <code>Closable</code> because they provide the required attribute.</p> <p>One thing to be aware of: protocols by default cannot be used with <code>isinstance()</code> or <code>issubclass()</code> checks at runtime. If you try <code>isinstance(some_obj, Closable)</code> in the above example, Python will raise a <code>TypeError</code> unless you take additional steps. This is because the protocol is not a real base class of those objects (they never inherited from it). However, Python's <code>typing</code> module provides a decorator <code>@runtime_checkable</code> that you can apply to a protocol to make runtime <code>isinstance</code> checks possible on it. Marking a protocol with <code>@runtime_checkable</code> means it gets a special <code>__instancecheck__</code> that will return True if the object has the required attributes (much like ABCs in <code>collections.abc</code> do with their <code>__subclasshook__</code>). For example:</p> <pre><code># example_4.py\nfrom typing import runtime_checkable, Protocol\nfrom file_resource import FileResource\n\n\n@runtime_checkable\nclass Closable(Protocol):\n    def close(self) -&gt; None: ...\n\n\n# FileResource has close():\nprint(isinstance(FileResource(\"data.txt\"), Closable))\n## True\n</code></pre> <p>Now <code>Closable</code> can be used in <code>isinstance</code> and <code>issubclass</code> as a structural check. Use this feature carefully; it's useful for type introspection in frameworks or for asserting an object meets an interface at runtime. However, it only checks the presence of attributes and not their types and could give false positives if an attribute name matches, but semantics differ. In most cases, protocols are used purely for static checking and documentation.</p>"},{"location":"C11_Structural_Typing/#practical-protocol-examples","title":"Practical Protocol Examples","text":"<p>Protocols shine in real-world scenarios where you want to decouple code and reduce dependencies on concrete classes. A common use case is dependency injection and testing. In Python, it's common to write functions or classes that operate on objects with a particular interface without caring about the concrete implementation. Protocols let you formally capture that interface in the type system. This makes your code's expectations clear and allows static analysis to validate those expectations. Let's discuss a few practical examples.</p> <p>1. Dependency injection and interchangeable components: Suppose you're writing a service that needs to log messages. You might want the ability to swap out the logger--sometimes logging to a file, sometimes to the console, or maybe collecting logs in memory for testing. You can define a protocol for the logger's interface and program against that. For instance:</p> <pre><code># logger_protocol.py\nfrom contextlib import AbstractContextManager\nfrom pathlib import Path\nfrom typing import Protocol\n\n\nclass Logger(Protocol):\n    def log(self, message: str) -&gt; None: ...\n\n\nclass FileLogger(AbstractContextManager):\n    \"\"\"\n    Logger that writes to a known log file in a fixed directory.\n    \"\"\"\n\n    def __init__(self, path: Path = Path(\"./log.txt\")):\n        path.parent.mkdir(parents=True, exist_ok=True)\n        self.filename = path\n        self._file = self.filename.open(\"w\", encoding=\"utf-8\")\n\n    def log(self, message: str) -&gt; None:\n        self._file.write(message + \"\\n\")\n        self._file.flush()\n\n    def __exit__(self, exc_type, exc_value, traceback) -&gt; None:\n        self._file.close()\n\n\nclass ListLogger:\n    \"\"\"\n    Logger that stores messages in a list\n    \"\"\"\n\n    def __init__(self):\n        self.messages: list[str] = []\n\n    def log(self, message: str) -&gt; None:\n        self.messages.append(message)\n\n\ndef run_process(task_name: str, logger: Logger) -&gt; None:\n    logger.log(f\"Starting {task_name}\")\n    # Perform the task ...\n    logger.log(f\"Finished {task_name}\")\n</code></pre> <p>In <code>Logger(Protocol)</code>, we specify that a logger must have a <code>.log(str)</code> method. Our <code>run_process</code> function doesn't care how the logging is done, just that the object passed in can <code>.log</code> a message. <code>FileLogger</code> and <code>ListLogger</code> are two implementations--one writes to a file, the other stores messages in a Python list. Notice that neither<code>FileLogger</code>nor<code>ListLogger</code>subclasses<code>Logger</code>; they don't need to. They implicitly satisfy the protocol by having the correct<code>log</code>method. This design is very flexible: you can add new logger classes later (say, a<code>DatabaseLogger</code>that writes to a database, or reuse Python's built-in<code>logging.Logger</code>by writing an adapter with a<code>log</code>method) without changing the code that uses the logger.</p> <p>Here, <code>FileLogger</code> stores results in <code>log.txt</code>, and we can use<code>ListLogger</code>to capture logs and make assertions on them:</p> <pre><code># logger_protocol_demo.py\nfrom logger_protocol import (\n    FileLogger,\n    ListLogger,\n    run_process,\n)\n\nwith FileLogger() as file_logger:\n    run_process(\"DataCleanup\", file_logger)\n    print(f\"log file: {file_logger.filename}\")\n    print(file_logger.filename.read_text(encoding=\"utf-8\"))\n## log file: log.txt\n## Starting DataCleanup\n## Finished DataCleanup\n\n# logs to list in memory:\ntest_logger = ListLogger()\nrun_process(\"DataCleanup\", test_logger)\nprint(\"Captured logs:\", test_logger.messages)\n## Captured logs: ['Starting DataCleanup', 'Finished DataCleanup']\n</code></pre> <p>The static type checker ensures that any object we pass as a<code>logger</code>to<code>run_process</code>has a<code>log(str)</code>method. In a nominal type system, you might have to define an abstract base class<code>Logger</code> and make every logger inherit it. With protocols, you get the benefit of an interface without inheritance. This reduces coupling and makes it easier to integrate third-party classes that weren't written with your ABC in mind.</p> <p>2. Testing with fake or mock objects: Building on the above example, protocols are extremely handy for unit testing. In tests, we often use fake objects or mocks to simulate real components (like databases, web services, etc.) without having to perform the real operations. With protocols, you can give those test doubles a clear interface. For example, if you have a function that fetches data from an API, you could define a protocol for the fetcher. In production, you pass a real HTTP client, in tests you pass a fake object that returns predetermined data. The protocol assures the fake has the same method signature as the real client. This avoids type checker warnings and makes tests cleaner. It's essentially the static typing analog of using an interface in other languages for dependency injection in tests. Many testing libraries (like <code>unittest.mock</code>) create dynamic mocks that can be configured with attributes on the fly; to type-annotate those, you can either cast them to a Protocol or use a Protocol as a base for a fake implementation. Using protocols in this way documents what methods a mock is expected to provide. This can prevent situations where your test double is missing a method or has a typo that wouldn't be caught until runtime. In short, whenever you say \"I need an object that can do X in my code, and I might swap different implementations of it,\" that's a cue to define a protocol for X.</p> <p>3.Interface design and third-party integration: Protocols can serve as interfaces in your application design. Even if you're not writing multiple implementations immediately, defining a protocol for a role in your system can clarify the design. For example, you might define a <code>DataStore</code> protocol with methods like <code>save(item)</code> and <code>load(id)</code> that any storage backend should implement. Today you only have a database implementation, but tomorrow you might add an in-memory or file-based implementation--the protocol makes the contract clear. Moreover, if you want to accept objects from a third-party library with the necessary methods, protocols let you do so without subclassing or modifying those classes. Suppose you're writing a function that can output data to any \"file-like\" object (something with a <code>.write()</code> method). The <code>io.TextIOBase</code> abstract class in Python is nominal, but not every file-like object will inherit it. By defining your own protocol with a <code>write(str)</code> method, your function can accept a wide range of objects (file handles, <code>io.StringIO</code> instances, custom writer objects) as long as they implement <code>write</code>. This is especially useful when working with libraries that weren't built with your interfaces; you can adapt them via protocols instead of being forced into their class hierarchy. Protocols thus increase the reusability and extensibility of your code by focusing on what an object can do rather than what it is.</p> <p>It's worth mentioning that Python's standard library and frameworks have embraced the concept of protocols (even before the formal <code>Protocol</code> type existed) by using \"duck typing\" and abstract base classes. For instance, the act of iterating in Python checks for an <code>__iter__</code> method--any object with <code>__iter__</code> is iterable. The static typing system knows this too: you don't have to explicitly register your class as an <code>Iterable</code> ABC; if it has the right method, tools like Mypy will treat it as iterable. With <code>Protocol</code>, we can create our own such abstractions. In modern Python, the combination of protocols and <code>@runtime_checkable</code> even lets us approximate some features of a language with a built-in interface system.</p> <p>4. Composition and adapters using protocols: Another practical pattern is using protocols to enable composition and decorators. Because protocols don't require inheritance, you can make wrapper classes that add functionality while still conforming to an interface. For example, you might have a basic service class and then a logging wrapper class that takes a service and also implements the same service protocol to proxy calls and add logging. As long as both implement the protocol, code using the protocol can accept either the plain or the wrapped version. This was illustrated by defining an <code>AddServiceProtocol</code> for an addition service and creating both a normal implementation and a logging decorator implementation that forwards calls. The key takeaway is that structural typing focuses on the behavior, so even objects that don't share lineage can work together if they fulfill the same behavioral contract.</p>"},{"location":"C11_Structural_Typing/#combining-dataclasses-with-protocols","title":"Combining Dataclasses with Protocols","text":"<pre><code># dataclasses_and_protocols.py\nfrom dataclasses import dataclass\nfrom typing import Protocol\n\n\nclass Identifiable(Protocol):\n    id: int\n\n\n@dataclass\nclass User:\n    id: int\n    name: str\n\n\n@dataclass\nclass Product:\n    id: int\n    price: float\n\n\ndef print_id(entity: Identifiable) -&gt; None:\n    print(f\"ID: {entity.id}\")\n\n\nprint_id(User(1, \"Alice\"))\n## ID: 1\nprint_id(Product(101, 19.99))\n## ID: 101\n</code></pre>"},{"location":"C11_Structural_Typing/#combining-protocols-with-generics","title":"Combining Protocols with Generics","text":"<p>Just like classes and functions can be generic (using a type variable to operate over a range of types), protocol classes can be generic as well. A generic protocol allows you to define a protocol parameterized by a type (or multiple types), enabling more precise typing of method arguments and return values. Many built-in protocols are generic--for example, <code>Iterable[T]</code> is a protocol that can be <code>Iterable[int]</code>, <code>Iterable[str]</code>, etc., depending on what type it yields. We can do the same with our own protocols.</p> <p>To define a generic protocol, we put the type variable in brackets after <code>Protocol</code> when defining the class. Let's say we want to define a container protocol that yields items of some type. We can make it generic so that a <code>Container[int]</code> is a protocol for \"container of ints\" and <code>Container[str]</code> for \"container of strings,\" but both are based on the same generic interface. For example:</p> <pre><code># container.py\nfrom typing import Protocol\n\n\nclass Container[T](Protocol):\n    def get_item(self) -&gt; T: ...\n</code></pre> <p>Here, <code>Container[T]</code> is a generic <code>Protocol</code> with a single type variable <code>T</code>. It specifies one method <code>get_item</code> that returns an object of type <code>T</code>. Now we can implement this protocol for different types by providing concrete type parameters. For instance, a container of strings and a container of integers:</p> <pre><code># container_types.py\nclass StringContainer:\n    def __init__(self, value: str):\n        self.value = value\n\n    def get_item(self) -&gt; str:\n        return self.value\n\n\nclass IntContainer:\n    def __init__(self, value: int):\n        self.value = value\n\n    def get_item(self) -&gt; int:\n        return self.value\n</code></pre> <p><code>StringContainer</code> and <code>IntContainer</code> each implement <code>get_item</code> returning the appropriate type. They don't subclass <code>Container</code>, but they structurally match <code>Container[str]</code> and <code>Container[int]</code>. We can write functions that use the generic protocol to accept any kind of container and preserve the type information of the contained item:</p> <pre><code># generic_function.py\nfrom container import Container\nfrom container_types import StringContainer, IntContainer\n\n\ndef print_item_and_return[T](container: Container[T]) -&gt; T:\n    item = container.get_item()\n    print(f\"{item = }, {type(item) = }\")\n    return item\n\n\n# Use generic function with different container types:\nx: str = print_item_and_return(StringContainer(\"hello\"))\n## item = 'hello', type(item) = &lt;class 'str'&gt;\ny: int = print_item_and_return(IntContainer(42))\n## item = 42, type(item) = &lt;class 'int'&gt;\n</code></pre> <p>In the function <code>print_item_and_return</code>, we used <code>C</code> (could also use <code>T</code> again) as a type variable for the container's item type. When we call this function with a <code>StringContainer</code>, the type checker knows <code>C</code> is <code>str</code> in that call, so it infers that the function returns a <code>str</code>. Similarly, with <code>IntContainer</code>, <code>C</code> becomes <code>int</code>. This is the benefit of generic protocols: they let you write flexible code that is still type-safe and retains specific type information. In other words, one protocol can work for many types without losing the ability to distinguish those types when it matters. The syntax we used (<code>Container[C]</code> inside the function annotation) leverages Python's ability to support generics in type annotations. <code>Container[int]</code> is a parameterized protocol instance, but conceptually you can think of it like an interface template.</p> <p>Keep in mind that user-defined generic protocols follow the same rules as normal generic classes for type checking. You can declare variance for type variables if needed (covariant, contravariant) using <code>typing.Final</code> or by special syntax in a type variable, although if you don't declare, the type checker will assume invariance (meaning <code>Container[SubClass]</code> is not a subtype of <code>Container[BaseClass]</code> unless you marked variance). In our container example, this is not an issue because we're primarily using it to carry the exact type.</p> <p>Another scenario for combining protocols with generics is when you want to put protocols as bounds on type variables. For instance, you can declare <code>[T: SomeProtocol]</code> to indicate that a type variable must satisfy a certain protocol. With classes, a bound indicates that <code>T</code> must subclass the bound. However, protocols aren't part of the class hierarchy, so this is analogous to saying, \"<code>T</code> must structurally implement the protocol.\" For example, if we have:</p> <pre><code># protocols_as_bounds.py\nfrom logger_protocol import Logger\n\n\ndef f[T: Logger](x: T) -&gt; T:\n    x.log(f\"In f({x})\")\n    return x\n\n\nclass C[T: Logger]:\n    def f(self, x: T) -&gt; T:\n        x.log(f\"In C.f({x})\")\n        return x\n</code></pre> <p>This means any type filling in for <code>T</code> must have a <code>.log(str) -&gt; None</code> method. You could use such a bound in a generic function or class to ensure the operations you perform on <code>T</code> are valid. This is a powerful way to write generic algorithms that operate on any objects meeting a certain interface, without tying them to a base class.</p> <p>Python 3.12 introduced an even more concise way to define generic protocols (and generic classes in general) by allowing type variables in the definition of methods directly (PEP 695--Type Parameter Syntax):</p> <pre><code># generic_method_in_protocol.py\nfrom typing import Protocol\n\n\nclass Container(Protocol):\n    def get_item[T](self, type_: type[T]) -&gt; T: ...\n</code></pre> <p>This defines a generic method <code>get_item</code> in a protocol. However, this still creates a generic protocol with a type variable <code>T</code>.</p> <p>Combining protocols with generics expresses flexible and reusable type relationships. You can create protocols that work over a family of types while still preserving type information. Many of Python's built-in protocols are generic (for example, an iterator protocol <code>Iterator[T]</code> yields items of type T), and you can do the same in your own designs. This enables things like container types, numeric operations, or callback interfaces to be both generic and structural. When designing a generic protocol, think about what parts of the interface should change with the type (those become type variables) and which are fixed. The result is a powerful abstraction that remains easy to use.</p>"},{"location":"C11_Structural_Typing/#when-to-choose-structural-typing-over-nominal-typing","title":"When to Choose Structural Typing Over Nominal Typing","text":"<p>When should you use one over the other? The answer often depends on the context and goals. Both approaches have their strengths, and in Python they complement each other rather than one completely replacing the other. Here are some guidelines, pros and cons, and practices:</p> <p>Use nominal typing (classes/ABCs) when:</p> <ul> <li> <p>You want to reuse code via inheritance.   If you have default method implementations or shared attributes that can be defined in a base class, an abstract base class can provide that.   Inheritance isn't the only way to reuse code, but when it makes sense   (e.g., a base class providing common functionality), nominal typing naturally goes along with it because subclasses inherit from the base.</p> </li> <li> <p>You need a strict class hierarchy or runtime type information.   If it's important in your design to maintain subclass relationships (perhaps for identity checks, <code>isinstance</code> checks, or because you rely on Python's method resolution order and <code>super()</code> calls), then using nominal types is appropriate.   For example, if you have a plugin system where all plugins must register as subclasses of <code>BasePlugin</code> to be discovered, that's a nominal approach.</p> </li> <li> <p>The interface is large or complex, with many methods, and tightly coupled to an implementation.   While you could model this with a protocol, it may be clearer to use an abstract class to group behavior.   If multiple methods are meant to be overridden together, an ABC can enforce that at instantiation time (trying to instantiate a subclass that hasn't implemented all abstract methods raises an error).   In short, for class designs that naturally form an \"is-a\" hierarchy and possibly share some code, nominal typing fits well.</p> </li> </ul> <p>Use structural typing (protocols) when:</p> <ul> <li> <p>You want to keep it lightweight and focused purely on the method/attribute requirements.   Protocols are great for defining a narrow interface that multiple disparate classes can implement without formal coupling.   If you only care about one or a few methods on an object (and not about its exact type), a protocol enables that.   This is especially useful for function parameters:   you can annotate a function to accept any object with a <code>.close()</code> method, or a <code>.write()</code> method, etc., without forcing a common base class.</p> </li> <li> <p>You are working with third-party or existing classes that you can't modify to fit into your class hierarchy.   Structural typing shines here because you can define a protocol that matches the external class's abilities.   For example, if a third-party library gives you objects that have a <code>.to_json()</code> method,   and you want to treat those objects uniformly in your code,   you can create a <code>ToJsonable</code> protocol with <code>to_json(self) -&gt; str</code> and use that in your type annotations.   Any object from the library will satisfy the protocol if it has the method,   without you needing to make it inherit from anything.   This decoupling is very powerful in a language as dynamic as Python,   where often we \"duck type\" through frameworks--now you can put an type annotation on it.</p> </li> <li> <p>You need generic interfaces or extension of existing ones.   Protocols are useful for creating ad-hoc interfaces that might not have been foreseen initially.   For instance, you might realize that two classes in different parts of your system happen to have similar methods for, say, resetting their state.   You could retroactively define a <code>Resettable</code> protocol and update type annotations to use it, without touching the classes themselves.   If you later make those classes formally implement an ABC, fine--but the protocol gave you an immediate way to express the concept in types and check it.   Additionally, if you're designing a library and want to allow users to plug in their own objects (as long as they have certain methods), providing a protocol in your public API documentation is a nice way to communicate that.   Users can either implement that Protocol (statically) or just ensure their classes match the signature.</p> </li> </ul> <p>Pros and Cons Summary: Nominal typing (using concrete classes and ABCs) offers clarity in terms of design--it's very clear that ClassX is a kind of InterfaceY because it explicitly inherits it. It also allows enforcement: abstract base classes can ensure at runtime that certain methods are implemented (attempting to instantiate a subclass that hasn't implemented an abstract method will error out). They can also provide default behavior. However, nominal typing is less flexible--everything must be planned or adapted to fit the hierarchy. If you want an external class to be treated as an InterfaceY, you might have to write an adapter or subclass it, which could be clunky or impossible (if you don't control that class). Structural typing (using protocols) is extremely flexible and mirrors Python's dynamic nature--you can \"write the interface after the fact.\" It encourages designing for capabilities rather than inheritance. The downside is that protocols are primarily static--they rely on the developer running a type checker. Python won't stop you from passing an object that does not fulfill the protocol (until you call a missing method and get an error at runtime, just like normal duck typing). So if you need guaranteed enforcement in a running program, protocols alone won't give you that (they are optional). That said, in a team or project using type checks as part of CI, protocols can prevent a lot of mistakes. Another minor con is that protocols, if overused, could make it less obvious which classes implement which interface; with nominal typing you can always search for subclasses of an ABC. A mix is often best: use protocols for the broad \"this is what we expect\" contracts, especially for external boundaries and flexible APIs, and use concrete classes or ABCs internally when you want more structure or reuse.</p> <p>Practices: It's not an either/or choice--you can use both in the same codebase. For example, you might define an ABC with some default methods for a complex interface but also define a protocol for a subset of that interface for use in a more generic function. Choose structural typing when you want minimal coupling and maximum flexibility, especially at boundaries of your system or for \"pluggable\" functionality. Choose nominal typing when you want an explicit, enforced contract and possibly to leverage inheritance of code. Remember that protocols are most valuable when you are using static type checking; if your project doesn't use type checks, then a protocol is a <code>abc.ABC</code> with no abstract methods--it won't enforce anything by itself at runtime. In such cases, if enforcement is needed, an ABC with abstract methods (or even just documentation) might be better. However, even in purely dynamic contexts, many developers find protocols useful as documentation: by reading the Protocol class, you know what an object is expected to do.</p> <p>In Python's type system evolution, protocols were introduced to complement nominal typing, not to replace it. They give you the freedom to write code in the Pythonic duck-typed style while still reaping the benefits of static analysis. A good guideline is to use protocols to describe roles that can be played by objects of different class hierarchies and use nominal typing for relationships within a class hierarchy. By following these practices, you can make your code both flexible and robust, leveraging the best of both worlds in Python's type system.</p>"},{"location":"C11_Structural_Typing/#references","title":"References","text":"<ol> <li>Github Issues</li> <li>Protocols and structural subtyping--mypy 1.15.0 documentation</li> <li>What's the Difference Between Nominal, Structural, and Duck Typing?--DEV Community</li> <li>Duck typing--Wikipedia</li> <li>Python Protocols: Leveraging Structural Subtyping--Real Python</li> <li>PEP 544--Protocols: Structural subtyping (static duck typing) | peps.python.org</li> <li>Abstract Base Classes and Protocols--Justin A. Ellis</li> <li>Protocols and Composition in Python--DEV Community</li> </ol>"},{"location":"C12_Make_Illegal_Types_Unrepresentable/","title":"Make Illegal Types Unrepresentable","text":"<p>A common strategy for preventing problems is to validate function arguments. This spreads validation code across functions, producing maintenance problems. This chapter moves validation into custom types that make invalid arguments impossible. In addition, data is checked when you create an instance, rather than when data is passed to a function. This approach:</p> <ol> <li>Discovers problems sooner.</li> <li>Clarifies the meaning of code.</li> <li>Shares custom type benefits across all functions that use those types.</li> <li>Eliminates duplicate validation checks and their associated maintenance.</li> <li>Makes changes easier by localizing validation to a single point.</li> <li>Eliminates the need for techniques such as Design By Contract (DBC).</li> <li>Enables more focused testing with finer granularity.</li> <li>Helps produce Domain-Driven Design.</li> </ol>"},{"location":"C12_Make_Illegal_Types_Unrepresentable/#stringly-typed","title":"\"Stringly Typed\"","text":"<p>Years ago I came across some research looking at the way generic components like <code>List</code>, <code>Set</code> and <code>Map</code> were used in Java. Only a tiny percentage of the code reviewed used anything except strings as type parameters. This study suggested that the vast majority of systems were using strings as their primary data type.</p> <p>Because you can put any characters in any format into a string, such \"stringly typed\" systems (an ironic play on \"strongly typed\") may be the worst of all possible worlds. Unless it's text, classifying something as a string doesn't tell you anything. When a function receives a string meant to represent a type, that function can assume precisely nothing about it. Every such function must start from scratch and analyze that string to see if it conforms to what that function needs.</p> <p>Changing the meaning of a stringly-typed item is a daunting job. You must hunt through your code base and ensure that your change is reflected in the validations in every single function. Because the logic is distributed, it's highly likely you will miss some.</p> <p>Consider representing phone numbers as strings. Here are some formats you might encounter:</p> <pre><code># string_phone_numbers.py\n# Some problematic formats\nphone_numbers: list[str] = [\n    \"5551234\",  # No formatting \u2013 unclear area code\n    \"555-1234\",  # US format, but without area code\n    \"(555) 123-4567\",  # US format with punctuation\n    \"555.123.4567\",  # Inconsistent punctuation\n    \"+1-555-123-4567\",  # International format\n    \"+44 20 7946 0958\",  # UK format \u2013 space-separated\n    \"5551234567\",  # No formatting at all\n    \"555 1234\",  # Ambiguous \u2013 local format?\n    \"555-12ab\",  # Invalid characters\n    \"CallMeMaybe\",  # Completely invalid\n    \"01234\",  # Leading zero \u2013 looks like a zip code\n    \"\",  # Empty string\n    \" 5551234 \",  # Whitespace issues\n]\n</code></pre> <p>Any function that takes a phone number as a string must first validate that argument. Here's a common but awkward approach:</p> <pre><code># phone_number_functions.py\nimport re\n\n\ndef f1(phone: str):\n    valid = re.compile(\n        r\"^\\+?(\\d{1,3})?[\\s\\-.()]*([\\d\\s\\-.()]+)$\"\n    )\n    if not valid.match(phone):\n        print(f\"Error {phone = }\")\n        return\n    ...\n\n\ndef f2(phone_num: str):\n    check = re.compile(\n        r\"^\\+?(\\d{1,3})?[\\s\\-.()]*([\\d\\s\\-.()]+)$\"\n    )\n    assert check.match(phone_num), f\"Invalid {phone_num}\"\n    ...\n\n\ndef f3(phonenumber: str):\n    phone_number = re.compile(\n        r\"^\\+?(\\d{1,3})?[\\s\\-.()]*([\\d\\s\\-.()]+)$\"\n    )\n    if not phone_number.match(phonenumber):\n        return f\"Bad {phonenumber = }\"\n    ...\n</code></pre> <p>Each function has its own custom code and reports errors differently. There might be many such functions spread throughout the system. If there's a bug or any change in the way phone numbers are validated, all validation code must be found and corrected, and any tests must also be updated.</p> <p>Does anyone set out to write code like this? Probably not--it starts out seeming like \"the simplest thing\" and just continues to accumulate, one logical step at a time. Although you might not write code like this, systems like this exist for phone numbers and for many other data items represented as strings.</p>"},{"location":"C12_Make_Illegal_Types_Unrepresentable/#design-by-contract","title":"Design by Contract","text":"<p>The argument-validation problem was observed by Bertrand Meyer and introduced as a core concept in his Eiffel programming language, described in the book Object-Oriented Software Construction (1988). Design By Contract (DbC) tried to reduce errors by treating the interaction between software components as a formal agreement:</p> <ul> <li>Preconditions:   What must be true before a function/method runs.</li> <li>Postconditions:   What must be true after the function completes.</li> <li>Invariants:   What must always be true about the object state.</li> </ul> <p>Eiffel provided explicit keywords to make Design by Contract a first-class citizen in the language:</p> Keyword Purpose <code>require</code> Preconditions <code>ensure</code> Postconditions <code>invariant</code> Class-wide conditions <code>old</code> Refers to previous state in postconditions <p>The intent was that each function used these to ensure the correctness of the inputs and outputs of that function, and the state of the object. In particular, <code>require</code> typically checks the argument values for correctness. For preconditions in Python, we can create a <code>requires</code> decorator to check argument values:</p> <pre><code># require.py\nfrom dataclasses import dataclass\nfrom typing import Callable\nfrom functools import wraps\n\n\n@dataclass(frozen=True)\nclass Condition:\n    check: Callable[..., bool]\n    message: str\n\n\ndef requires(*conditions: Condition):\n    def decorator(func: Callable):\n        @wraps(func)\n        def wrapper(*args, **kwargs):\n            for condition in conditions:\n                if not condition.check(*args, **kwargs):\n                    raise ValueError(condition.message)\n            return func(*args, **kwargs)\n\n        return wrapper\n\n    return decorator\n</code></pre> <p>A <code>Condition</code> combines each <code>check</code> with a description of the failure condition. <code>check</code> is a <code>Callable</code> (usually a function) that takes the same arguments as the decorated function and returns a <code>bool</code> indicating whether the condition is satisfied.</p> <p><code>requires</code> is a decorator factory; it returns a decorator that can be applied to any function. It accepts any number of <code>Condition</code> instances. The inner function <code>decorator</code> is the decorator that wraps the target function <code>func</code>. <code>wrapper</code> is the new function that will replace <code>func</code>. <code>@wraps(func)</code> preserves metadata like the function name and docstring.</p> <p>To use it, create one or more <code>Condition</code> objects, then use those to decorate functions with <code>requires</code>:</p> <pre><code># basic_requires.py\nfrom book_utils import Catch\nfrom require import requires, Condition\n\npositivity = Condition(\n    check=lambda x: x &gt; 0, message=\"x must be positive\"\n)\n\n\n@requires(positivity)\ndef sqrt(x) -&gt; float:\n    return x**0.5\n\n\nprint(sqrt(4))\n## 2.0\nwith Catch():\n    sqrt(-2)\n## Error: x must be positive\n</code></pre> <p><code>requires</code> produces an improved Design by Contract tool for validating function arguments. Consider managing a bank account:</p> <pre><code># bank_account.py\nfrom dataclasses import dataclass\nfrom decimal import Decimal\n\nfrom book_utils import Catch\nfrom require import requires, Condition\n\npositive_amount = Condition(\n    check=lambda self, amount: amount &gt;= Decimal(\"0\"),\n    message=\"Amount cannot be negative\",\n)\n\nsufficient_balance = Condition(\n    check=lambda self, amount: self.balance &gt;= amount,\n    message=\"Insufficient balance\",\n)\n\n\n@dataclass\nclass BankAccount:\n    balance: Decimal\n\n    @requires(positive_amount)\n    def deposit(self, amount: Decimal) -&gt; str:\n        self.balance += amount\n        return f\"Deposit {amount}, balance: {self.balance}\"\n\n    @requires(positive_amount, sufficient_balance)\n    def withdraw(self, amount: Decimal) -&gt; str:\n        self.balance -= amount\n        return f\"Withdraw {amount}, balance: {self.balance}\"\n\n\naccount = BankAccount(Decimal(100))\nprint(account.deposit(Decimal(50)))\n## Deposit 50, balance: 150\nprint(account.withdraw(Decimal(30)))\n## Withdraw 30, balance: 120\nwith Catch():\n    account.withdraw(Decimal(200))\n## Error: Insufficient balance\nwith Catch():\n    account.deposit(Decimal(-10))\n## Error: Amount cannot be negative\n</code></pre> <p>Here, the <code>Condition</code>s are applied to methods, so their <code>lambda</code>s both include <code>self</code>. In <code>withdraw</code> you see multiple <code>Condition</code>s applied within one <code>requires</code> decorator.</p> <p>If they validate their arguments, traditional Python functions tend to duplicate that validation code at the beginning of each function body. Design by Contract is an improvement over this. The <code>@requires</code> clearly shows that the arguments are constrained, and <code>Condition</code>s reduce duplicated code.</p> <p>Design by Contract helps, but it has limitations:</p> <ol> <li>A programmer can forget to use <code>requires</code>,    or choose to perform argument checks by hand if Design by Contract doesn't make sense to them.</li> <li>Validations are spread throughout your system.    Using <code>Condition</code> reduces logic duplication, but making changes still risks missing updates on functions.</li> <li>It can be tricky; note the use of <code>self</code> in <code>positive_amount</code> and <code>sufficient_balance</code> so those can be applied to methods.    This might require new understanding for the user of <code>requires</code>.</li> </ol>"},{"location":"C12_Make_Illegal_Types_Unrepresentable/#centralizing-validation-into-custom-types","title":"Centralizing Validation into Custom Types","text":"<p>A more straightforward approach than DbC is to encode validations into custom types. This way, incorrect objects of those types cannot successfully be created. Custom types tend to be easier to understand and use than precondition checks. If a type constraint changes, that change immediately propagates to all usages of that type. In addition, the types are usually domain driven, that is, they represent a concept from the problem domain.</p> <p>For the bank example, we start by creating an <code>Amount</code>, which is a <code>Decimal</code> value with some fundamental constraints. If an <code>Amount</code> object exists, you know it cannot contain a negative value or more than two decimal places:</p> <pre><code># amount.py\nfrom __future__ import annotations\n\nfrom dataclasses import dataclass\nfrom decimal import Decimal\nfrom typing import Self\n\n\n@dataclass(frozen=True)\nclass Amount:\n    value: Decimal\n\n    @classmethod\n    def of(cls, value: int | float | str | Decimal) -&gt; Self:\n        if isinstance(value, float):\n            text = repr(value)\n            if \"e\" in text.lower():\n                raise ValueError(f\"{value!r}: out of range\")\n            parts = text.split(\".\", 1)\n            if len(parts) == 2 and len(parts[1]) &gt; 2:\n                raise ValueError(f\"{value!r}: &gt;2 decimal places\")\n            dec = Decimal(text)\n        else:\n            dec = (\n                value\n                if isinstance(value, Decimal)\n                else Decimal(str(value))\n            )\n\n        return cls(dec)\n\n    def __post_init__(self) -&gt; None:\n        if self.value &lt; Decimal(\"0\"):\n            raise ValueError(f\"Negative Amount({self.value})\")\n\n        if int(self.value.as_tuple().exponent) &gt; 2:\n            raise ValueError(\n                f\"Amount({self.value}): &gt;2 decimal places\"\n            )\n\n    def __add__(self, other: Amount) -&gt; Amount:\n        return Amount.of(self.value + other.value)\n\n    def __sub__(self, other: Amount) -&gt; Amount:\n        return Amount.of(self.value - other.value)\n</code></pre> <p>The <code>of()</code> method is intended to be the single point of creation of an <code>Amount</code>, however you can still create an <code>Amount</code> directly from a <code>Decimal</code>. Even then, <code>__post_init__</code> will be called and will ensure that <code>value</code> is positive and has no more than two decimal places.</p> <p>Note that <code>__add__</code> and <code>__sub__</code> return new <code>Amount</code> objects without checking whether they are non-negative. The <code>Amount</code> initialization takes care of that.</p> <p>Because <code>Amount</code> objects are immutable, you don't have to worry that they'll be changed to an illegal state after they're created.</p> <p>If you provide an incorrect <code>value</code> to <code>Amount</code>, the <code>Decimal</code> constructor throws an exception:</p> <pre><code># demo_amount.py\nfrom decimal import Decimal\n\nfrom amount import Amount\nfrom book_utils import Catch\n\nprint(Amount.of(123))  # int\n## Amount(value=Decimal('123'))\nprint(Amount.of(\"123\"))  # str\n## Amount(value=Decimal('123'))\nprint(Amount.of(1.23))  # float\n## Amount(value=Decimal('1.23'))\nprint(Amount.of(Decimal(\"1.23\")))\n## Amount(value=Decimal('1.23'))\nwith Catch():\n    Amount.of(-123)\n## Error: Negative Amount(-123)\nwith Catch():\n    Amount.of(1.111)\n## Error: 1.111: &gt;2 decimal places\nwith Catch():\n    Amount.of(\"not-a-number\")\n## Error: [&lt;class 'decimal.ConversionSyntax'&gt;]\n# Can construct from Decimal:\nprint(Amount(Decimal(\"12.34\")))\n## Amount(value=Decimal('12.34'))\nwith Catch():\n    Amount(Decimal(\"-12.34\"))\n## Error: Negative Amount(-12.34)\nwith Catch():\n    Amount(Decimal(\"1.111\"))\n</code></pre> <p>Now we define a bank-account <code>Balance</code> that contains an <code>Amount</code>, but doesn't need special construction behavior:</p> <pre><code># balance.py\nfrom __future__ import annotations\nfrom dataclasses import dataclass\nfrom amount import Amount\n\n\n@dataclass(frozen=True)\nclass Balance:\n    amount: Amount\n\n    def deposit(self, amount: Amount) -&gt; Balance:\n        return Balance(self.amount + amount)\n\n    def withdraw(self, amount: Amount) -&gt; Balance:\n        return Balance(self.amount - amount)\n</code></pre> <p>Note that <code>Balance</code> produces new immutable objects when you <code>deposit</code> and <code>withdraw</code>. Because it uses <code>Amount</code>, it needs no special validation checks.</p> <p>In the new, improved <code>BankAccount</code>, the need for argument validation disappears because it is automatically enforced by the types:</p> <pre><code># typed_bank_account.py\nfrom dataclasses import dataclass\n\nfrom amount import Amount\nfrom balance import Balance\nfrom book_utils import Catch\n\n\n@dataclass\nclass BankAccount:\n    balance: Balance\n\n    def deposit(self, amount: Amount) -&gt; str:\n        self.balance = self.balance.deposit(amount)\n        return (\n            f\"Deposit {amount.value}, \"\n            f\"Balance: {self.balance.amount.value}\"\n        )\n\n    def withdraw(self, amount: Amount) -&gt; str:\n        self.balance = self.balance.withdraw(amount)\n        return (\n            f\"Withdraw {amount.value}, \"\n            f\"Balance: {self.balance.amount.value}\"\n        )\n\n\naccount = BankAccount(Balance(Amount.of(100)))\nprint(account.deposit(Amount.of(50)))\n## Deposit 50, Balance: 150\nprint(account.withdraw(Amount.of(30)))\n## Withdraw 30, Balance: 120\nwith Catch():\n    account.withdraw(Amount.of(200))\n## Error: Negative Amount(-80)\nwith Catch():\n    account.deposit(Amount.of(-10))\n## Error: Negative Amount(-10)\n</code></pre> <p>This code is significantly more straightforward to understand and change. If we need to modify the underlying representation of <code>Amount</code> we only do it in one place. For example, suppose we discover Python's implementation of <code>Decimal</code> is too slow. We can modify <code>Amount</code> to use, for example, a Rust implementation of decimal numbers. We only need to change the code for <code>Amount</code>; all code that uses <code>Amount</code> automatically adopts the new behavior.</p> <p>All code we write that uses our custom types benefits from all the type validations for those custom types. If we add more validations to <code>Amount</code> or <code>Balance</code>, they automatically propagate to each site where those types are used.</p>"},{"location":"C12_Make_Illegal_Types_Unrepresentable/#a-phonenumber-type","title":"A <code>PhoneNumber</code> Type","text":"<p>Let's apply this approach to the stringly-typed phone number problem shown at the beginning of the chapter.</p> <pre><code># phone_number.py\n# Validated and normalized phone number\nfrom __future__ import annotations\nfrom dataclasses import dataclass\nfrom typing import Self\nimport re\n\n_PHONE_RE = re.compile(\n    r\"^\\+?(\\d{1,3})?[\\s\\-.()]*([\\d\\s\\-.()]+)$\"\n)\n\n\n@dataclass(frozen=True)\nclass PhoneNumber:\n    country_code: str\n    number: str  # Digits only, no formatting\n\n    @classmethod\n    def of(cls, raw: str) -&gt; Self:\n        # Parse and validate a raw phone number string.\n        match = _PHONE_RE.match(raw.strip())\n        if not match:\n            raise ValueError(f\"Invalid phone number: {raw!r}\")\n        cc, num = match.groups()\n        digits = re.sub(r\"\\D\", \"\", num)\n        if not digits:\n            raise ValueError(f\"No digits in: {raw!r}\")\n        country_code = cc or \"1\"  # default to US\n        return cls(country_code, digits)\n\n    def __post_init__(self) -&gt; None:\n        # Validate country code: 1-3 digits\n        if not re.fullmatch(r\"\\d{1,3}\", self.country_code):\n            raise ValueError(\n                f\"Invalid country code: {self.country_code!r}\"\n            )\n        # Validate number: digits only\n        if not re.fullmatch(r\"\\d+\", self.number):\n            raise ValueError(\n                f\"Invalid number digits: {self.number!r}\"\n            )\n\n    def format_number(self) -&gt; str:\n        if len(self.number) == 10:\n            area, prefix, line = (\n                self.number[:3],\n                self.number[3:6],\n                self.number[6:],\n            )\n            return f\"({area}) {prefix}-{line}\"\n        return self.number\n\n    def __str__(self) -&gt; str:\n        return f\"+{self.country_code} {self.format_number()}\"\n\n    def __eq__(self, other: object) -&gt; bool:\n        if not isinstance(other, PhoneNumber):\n            return NotImplemented  # Instead of False\n        return (\n            self.country_code == other.country_code\n            and self.number == other.number\n        )\n</code></pre> <p>We can test this against the list in <code>string_phone_numbers.py</code>:</p> <pre><code># phone_numbers_as_types.py\nfrom phone_number import PhoneNumber\nfrom string_phone_numbers import phone_numbers\nfrom book_utils import Catch\n\nfor raw in phone_numbers:\n    with Catch():\n        print(PhoneNumber.of(raw))\n## +555 1234\n## +555 1234\n## +1 (555) 123-4567\n## +555 1234567\n## +1 (555) 123-4567\n## +44 (207) 946-0958\n## +555 1234567\n## +555 1234\n## Error: Invalid phone number: '555-12ab'\n## Error: Invalid phone number: 'CallMeMaybe'\n## +012 34\n## Error: Invalid phone number: ''\n## +555 1234\nprint(PhoneNumber(\"886\", \"7775551212\"))\n## +886 (777) 555-1212\n</code></pre> <p>Every function that works with phone numbers only uses the <code>PhoneNumber</code> type. If you need to modify the behavior of a <code>PhoneNumber</code>, you do it in only one place. If you need to improve the performance of <code>PhoneNumber</code> creation and use, you do it in only one place.</p>"},{"location":"C12_Make_Illegal_Types_Unrepresentable/#the-programmable-meter","title":"The Programmable Meter","text":"<p>I recently visited my friend Matt, who is a physics professor (we were undergraduate physics students together). He has a stellar reputation as a teacher, and I realized I had never watched him teach, so I decided to see him in action. This was an electronics lab, and the students were using programmable measurement tools. The interface language these tools used was Python. To send commands to the programmable meter, the meter developers had used the \"stringly-typed\" route (The docs had a reference to Turbo C, so the meter was created long before Python's annotated types). The students ended up puzzling over getting the format of the strings correct rather than doing the lab.</p>"},{"location":"C12_Make_Illegal_Types_Unrepresentable/#how-cyclopts-uses-types","title":"How Cyclopts uses Types","text":"<p>Create a simplified example from python_example_validator.py.</p>"},{"location":"C13_Errors_as_Values/","title":"Errors as Values","text":"<p>Most of what we've been working towards in programming\u2014whether we are aware of it or not\u2014is composability.</p> <p>Discovering the meaning of composability is part of this path--there are different definitions depending on the programming language paradigm under scrutiny. Here\u2019s my definition:</p> <p>The ability to assemble bigger pieces from smaller pieces.</p> <p>This is less precise than some definitions. For example, composition in object-oriented programming means \"putting objects inside other objects.\" When dealing with functions, composability means \"calling functions within other functions.\" Both definitions fit my overall definition; they achieve the same goal but in different specific ways.</p> <p>To enable the easy construction of programs, we need to be able to effortlessly assemble components in the same way that a child assembles Legos\u2014by sticking them together, without requiring extra activities. On top of that, such assemblages become their own components that can be stuck together just as easily. This composability scales up regardless of the size of the components.</p> <p>Over the years, we have encountered numerous roadblocks to this goal.</p>"},{"location":"C13_Errors_as_Values/#goto-considered-harmful","title":"Goto Considered Harmful","text":"<p>Dijkstra's 1968 note had quite an impact on the programming community, which at the time consisted largely of assembly-language programmers. For these, the goto statement was foundational, and denigrating it was a shock. Although he never explicitly mentioned functions in his note, the effect was to push programmers towards functions. The creator of Structured Concurrency provides a clear description of this.</p> <p>Rather than jumping about within a limited program, functions present the caller with a single entry and exit point. This dramatically improves composability because you can no longer leave a section of code at any point using a goto. Within a function scope you cannot know what\u2019s outside that scope, thus you can\u2019t jump somewhere because you don\u2019t know a destination to jump to.</p> <p>My programming training was primarily as a computer engineer, and I spent the first few years of my career programming in assembly. Assembly supports subroutine calls and returns, but not the loading of arguments on the stack and passing results back out\u2014the programmer must write this error-prone code by hand.</p> <p>Higher-level languages handle function arguments and returns for you, which made them a very desirable improvement as the size and complexity of programs grew beyond what the assembly programmer was able to hold in their head.</p>"},{"location":"C13_Errors_as_Values/#modules","title":"Modules","text":"<p>Tim Peters celebrated namespaces in The Zen of Python. This is the foundation for modules, found in more modern languages (for backwards compatibility, C++ was forced to use C\u2019s messy system). In Python, modules map nicely onto files.</p> <p>It wasn\u2019t always this way. Breaking assembly-language programs into pieces was not easy, and early higher-level languages tended to be single-file programs and did not consider modularity. When the idea began to surface, it was incorporated as a main feature of the Modula-2 language (a descendant of Pascal). The name tells you what a significant shift it was considered at the time.</p> <p>Modula-2 and similar languages required an explicit declaration of a module:</p> <pre><code>MODULE Hello;\nFROM STextIO IMPORT WriteString;\nBEGIN\n  WriteString(\"Hello World!\")\nEND Hello.\n</code></pre> <p>This allowed complete granularity independent of file organization; perhaps this was because programmers were used to thinking in terms of one big file-per-program. Merging modules with files in Python makes more sense in hindsight and has the benefit of eliminating the (significant) extra verbiage, of which you only see a portion here.</p> <p>The main benefit of modules is name control. Each module creates a scope for names (a namespace) which allows programmers the freedom to choose any name at will within a module. This prevents name collisions across a project and reduces the cognitive load on the programmer. Prior to this, programs reached scaling limits as they grew larger. Program size in assembly language programs was limited by many different factors, so the need for modules was not seen until systems were able to grow larger because higher-level languages solved enough of these other factors.</p> <p>In modern languages, modularity is part of the background of a language, and we can ignore it except when it reports errors. At one time, however, the lack of modularity was a significant roadblock to code composability.</p>"},{"location":"C13_Errors_as_Values/#inheritance","title":"Inheritance","text":"<p>Object-oriented programming has a bit of a tortured history. Although the first OO language was Simula-67 (a compiled language), OO found its first real success with Smalltalk. But Smalltalk might be the most dynamic language you\u2019ll ever encounter\u2014literally everything is evaluated at runtime. This worked well for the kinds of problems Smalltalk was good at solving. However, taking the ideas of Smalltalk and imprinting them into a statically typed language lost a lot in translation.</p>"},{"location":"C13_Errors_as_Values/#error-handling","title":"Error Handling","text":"<p>Error reporting and handling have been a significant impediment to composability.</p>"},{"location":"C13_Errors_as_Values/#history","title":"History","text":"<p>Original programs were small by present-day standards. They were written in assembly language (machine code quickly became too unwieldy), and tightly coupled to the underlying hardware. If something went wrong, the only way to report it was to change the output on a wire, to turn on a light or a buzzer. If you had one, you put a message on the console, which might be a dot-matrix display. Such an error message probably wasn\u2019t friendly to the end-user of the system and usually required a tech support call to the manufacturer.</p> <p>Two of my first jobs were building embedded systems that controlled hardware. These systems had to work right. There was no point in reporting most errors because an error normally meant the software was broken.</p> <p>For business and scientific programming, Fortran and Cobol were batch processed on punch cards. If something went wrong, either the compilation failed or the resulting data was bad. No real-time error-handling was necessary because the program didn\u2019t run in real time.</p> <p>As time-sharing operating systems like Unix became a common way to distribute computing resources, program execution became more immediate. Users began to expect more interactive experiences, so programmers had to begin thinking about how to report and handle errors during the execution of a program, and in ideal cases recovering from those errors so the program could continue without shutting down.</p> <p>Programmers produced a scattered collection of solutions to the reporting problem:</p> <ul> <li> <p>Indicate failure by returning a special value from a function call.   This only works when the special value doesn't occur from an ordinary call to that function.   For example, if your function returns any <code>int</code>, you can't use <code>0</code> or <code>-1</code> to report an error.   A bigger problem is that you rely on the client programmer to pay attention to the return value and know what to do   about errors.</p> </li> <li> <p>Indicate failure by setting a global flag.   This is a single flag shared by all functions in the program.   The client programmer must know to watch that flag.   If the flag isn't checked right away, it might get overwritten by a different function call,   in which case the error is lost.</p> </li> <li> <p>Use signals if the operating system supports it.</p> </li> </ul> <p>The operating system needed to be discovered. Programmers found themselves rewriting the same basic code over and over again. Much of that repeated code involved manipulating hardware. It became clear that we needed a layer to eliminate this extra work--work that virtually all programs required.</p> <p>A fundamental question that designers were trying to understand during this evolution was:</p> <p>Who is responsible for error handling, the OS or the language?</p> <p>Since every program has the potential for errors, it initially seemed obvious that this activity should be the domain of the operating system. Some early operating systems allowed the program to invoke an error which would then jump to the operating system. A few OSes even experimented with the ability to \"resume\" back to the point where the error occurred, so the handler could fix the problem and continue processing. Notably, these systems did not find success and resumption was removed.</p> <p>Further experiments eventually made it clear that the language needed primary responsibility for error reporting and handling (there are a few special cases, such as out-of-memory errors, which must still be handled by the OS). This is because an OS is designed to be general purpose and thus cannot know the specific situation that caused an error, whereas language code can be close to the problem. Customization is normally the domain of the language. You could imagine calling the OS to install custom error-handling routines, and you can also imagine how quickly that would become overwhelmingly messy.</p> <p>If errors are in the language domain, the next question is how to report and handle them.</p>"},{"location":"C13_Errors_as_Values/#exceptions","title":"Exceptions","text":"<p>Unifying error reporting and recovery</p> <p>There were different language implementations of exceptions:</p> <ul> <li>Lisp (was this the origin of language-based exceptions?).   Possibly ironic as Lisp is the first functional language.</li> <li>BASIC had \"On Error Go To\" (and \"resume\"?)</li> <li>Pascal</li> <li>C++</li> <li>Java created checked exceptions, which must be explicitly dealt with in your code, and runtime exceptions, which could   be ignored.</li> <li>Python has exceptions but doesn\u2019t provide any type annotation or other mechanism to indicate what exceptions might   emerge from a function call.</li> </ul> <p>Exceptions seemed like a great idea:</p> <ol> <li>A standardized way to correct problems so that an operation can recover and retry.</li> <li>There's only one way to report errors.</li> <li>Errors cannot be ignored\u2014they flow upward until caught or displayed on the console with program termination.</li> <li>Errors can be handled close to the origin or generalized by catching them \"further out\" so that multiple error    sources can be managed with a single handler.</li> <li>Exception hierarchies allow more general exception handlers to handle multiple exception subtypes.</li> </ol> <p>To be clear, exceptions were a big improvement over all the previous (non) solutions to the error reporting problem. Exceptions moved us forward for a while (and became entrenched in programming culture) until folks started discovering pain points. As is often the case, this happened as we tried to scale up to create larger and more complex systems. And once again, the underlying issue was composability.</p>"},{"location":"C13_Errors_as_Values/#problems-with-exceptions","title":"Problems with Exceptions","text":"<p>In the small (and especially when teaching them), exceptions seem to work quite well. It's hard to prove during language design; things work in the small but don't scale. We only figure it out when scaling composability.</p>"},{"location":"C13_Errors_as_Values/#1-the-two-kinds-of-errors-are-conflated","title":"1. The Two Kinds of Errors are Conflated","text":"<p>Recoverable vs. panic (Recovering/Retrying requires programming) With exceptions, the two types are conflated. One of the best explanations of this is by Joe Duffy.</p>"},{"location":"C13_Errors_as_Values/#2-not-part-of-the-type-system","title":"2. Not Part of the Type System","text":"<p>If the type system doesn\u2019t include exceptions as part of a function signature, you can\u2019t know what exceptions you must handle when calling other functions (i.e.: composing). Even if you track down all the possible exceptions thrown explicitly in the code (by hunting for them in their source code!), built-in exceptions can still happen without evidence in the code: divide-by-zero is a great example of this.</p> <p>You can be using a library and handling all the exceptions from it (or perhaps just the ones you found in the documentation), and a newer version of that library can quietly add a new exception, and suddenly you are no longer detecting and/or handling all the exceptions. Even though you made no changes to your code.</p> <p>Languages like C++ and Java attempted to solve this problem by adding exception specifications, a notation that allows you to add the exception types that may be thrown, as part of the function\u2019s type signature.</p> <p>Object-oriented languages that enforce exception specifications (C++, Java) and create exception hierarchies introduce another problem. Exception hierarchies allow the library programmer to use an exception base type in the exception specification. This obscures important details; if the exception specification just uses a base type, there\u2019s no way for the compiler to enforce coverage of specific exceptions.</p> <p>When errors are included in the type system, you can know all the errors that can occur just by looking at the type information. If a library component adds a new error, then that must be reflected in that component\u2019s type signature. This means it no longer covers all error conditions and produces type errors until it is fixed.</p>"},{"location":"C13_Errors_as_Values/#3-exception-specifications-create-a-shadow-type-system","title":"3. Exception Specifications Create a \"Shadow Type System\"","text":"<p>Languages like C++ and Java attempted to add notation indicating the exceptions that might emerge from a function call. This was well-intentioned and seems to produce the necessary information the client programmer needs to handle errors. The fundamental problem was that this created an alternate or \"shadow\" type system that doesn\u2019t follow the same rules as the primary type system. To make the shadow type system work, its rules were warped to the point where it became effectively useless (a discovery that has taken years to realize).</p> <p>C++ exception specifications were originally optional and not statically type-checked. After many years these were deprecated in favor of the statically-typed <code>expected</code> specification (which takes the functional approached described in this chapter).</p> <p>Java created checked exceptions, which must be explicitly dealt with in your code, and runtime exceptions, which could be ignored. Eventually, they added a feature that allows checked exceptions to be easily converted into runtime exceptions. Java functions can always return <code>null</code> without any warning.</p> <p>Both systems (the original C++ dynamic exception specifications and Java exception specifications) had too many holes, and it was too difficult to effectively support both the main and shadow type systems.</p>"},{"location":"C13_Errors_as_Values/#4-exceptions-destroy-partial-calculations","title":"4. Exceptions Destroy Partial Calculations","text":"<p>Let\u2019s start with an example where we populate a <code>List</code> with the results from a sequence of calls to the function <code>fa</code>:</p> <pre><code># discarded_state.py\n# Exception throws everything away\nfrom book_utils import Catch\n\n\ndef fa(i: int) -&gt; int:\n    if i == 1:\n        raise ValueError(f\"fa({i})\")\n    return i\n\n\nwith Catch():\n    result = [fa(i) for i in range(3)]\n    print(result)\n## Error: fa(1)\n</code></pre> <p><code>fa</code> throws a <code>ValueError</code> if its argument is <code>1</code>. The <code>range(3)</code> is 0, 1, and 2; only one of these values causes the exception. So <code>result</code> contains only one problem; the other two values are fine. However, we lose everything that we were calculating when the exception is thrown. This:</p> <ol> <li>Is computationally wasteful, especially with large calculations.</li> <li>Makes debugging harder.    It would be quite valuable to see in <code>result</code> the parts that succeeded and those that failed.</li> </ol>"},{"location":"C13_Errors_as_Values/#the-functional-solution","title":"The Functional Solution","text":"<p>Instead of creating a complex implementation to report and handle errors, the functional approach creates a \"return package\" containing the answer along with the (potential) error information. Instead of only returning the answer, we return this package from the function.</p> <p>This package is a new type, with operations that prevent the programmer from plucking the result from the package without dealing with error conditions (a failing of the Go language approach).</p> <p>A first attempt uses type unions to create a nameless return package:</p> <pre><code># return_union.py\n# Type union aka Sum Type\n# Success vs error is not clear\n\n\ndef fa(i: int) -&gt; int | str:  # Sum type\n    if i == 1:\n        return f\"fa({i})\"\n    return i\n\n\nprint(outputs := [(i, fa(i)) for i in range(5)])\n## [(0, 0), (1, 'fa(1)'), (2, 2), (3, 3), (4, 4)]\n\nfor i, r in outputs:\n    match r:\n        case int(answer):\n            print(f\"{i}: {answer = }\")\n        case str(error):\n            print(f\"{i}: {error = }\")\n## 0: answer = 0\n## 1: error = 'fa(1)'\n## 2: answer = 2\n## 3: answer = 3\n## 4: answer = 4\n</code></pre> <p><code>fa</code> returns a <code>str</code> to indicate an error, and an <code>int</code> answer if there is no error. In the pattern match, we must check the result type to determine whether an error occurs; we cannot just assume it is an <code>int</code>.</p> <p>An important problem with this approach is that it is not clear which type is the success value and which type represents the error condition\u2014because we are trying to repurpose existing built-in types to represent new meanings.</p> <p>In hindsight, it might seem like this \"return package\" approach is much more obvious than the elaborate exception-handling scheme that was adopted for C++, Java and other languages, but at the time the apparent overhead of returning extra bytes seemed unacceptable (I don\u2019t know of any comparisons between that and the overhead of exception-handling mechanisms, but I do know that the goal of C++ exception handling is to have zero execution overhead if no exceptions occur).</p> <p>Note that in the definition of <code>composed</code>, the type checker requires that you return <code>int | str</code> because <code>fa</code> returns those types. Thus, when composing, type-safety is preserved. This means you won\u2019t lose error type information during composition, so composability automatically scales.</p>"},{"location":"C13_Errors_as_Values/#creating-a-new-return-type","title":"Creating a New Return Type","text":"<p>We now have the unfortunate situation that <code>outputs</code> contains multiple types: both <code>int</code> and <code>str</code>. The solution is to create a new type that unifies the \"answer\" and \"error\" types. We\u2019ll call this <code>Result</code> and define it using generics to make it universally applicable:</p> <pre><code># result.py\n# Generic Result with Success &amp; Failure subtypes\nfrom dataclasses import dataclass\n\n\nclass Result[ANSWER, ERROR]:\n    pass\n\n\n@dataclass(frozen=True)\nclass Success[ANSWER, ERROR](Result[ANSWER, ERROR]):\n    answer: ANSWER  # Usage: return Success(answer)\n\n    def unwrap(self) -&gt; ANSWER:\n        return self.answer\n\n\n@dataclass(frozen=True)\nclass Failure[ANSWER, ERROR](Result[ANSWER, ERROR]):\n    error: ERROR  # Usage: return Failure(error)\n</code></pre> <p>Each subtype of <code>Result</code> only holds one field: <code>answer</code> for a successful <code>Success</code> calculation, and <code>error</code> for a <code>Failure</code>. If a <code>Failure</code> is returned, the client programmer cannot reach in and grab the <code>answer</code> because that field doesn\u2019t exist. The client programmer must properly analyze the <code>Result</code>.</p> <p>To use <code>Result</code>, you <code>return Success(answer)</code> when you\u2019ve successfully created an answer, and <code>return Failure(error)</code> to indicate a failure. <code>unwrap</code> is a convenience method that is only available for a <code>Success</code>.</p> <p>The modified version of the example using <code>Result</code> is now:</p> <pre><code># return_result.py\n# Result type returns Success/Failure\n# Using https://github.com/dry-python/returns\nfrom returns.result import Failure, Result, Success\n\n\ndef fa(i: int) -&gt; Result[int, str]:\n    if i == 1:\n        return Failure(f\"fa({i})\")\n    return Success(i)\n</code></pre> <pre><code># return_result_demo.py\nfrom pprint import pprint\nfrom return_result import fa\n\npprint([(i, fa(i)) for i in range(5)])\n## [(0, &lt;Success: 0&gt;),\n##  (1, &lt;Failure: fa(1)&gt;),\n##  (2, &lt;Success: 2&gt;),\n##  (3, &lt;Success: 3&gt;),\n##  (4, &lt;Success: 4&gt;)]\n</code></pre> <p>Now <code>fa</code> returns a single type, <code>Result</code>. The first type parameter to <code>Result</code> is the type returned by <code>Success</code> and the second type parameter is the type returned by <code>Failure</code>. The <code>outputs</code> from the comprehension are all of type <code>Result</code>, and we have preserved the successful calculations even though there is a failing call. We can also pattern-match on outputs; it is clear which is for success and failure.</p> <p>The <code>returns</code> library has been slipped in here, but its basic form is that of <code>result.py</code>.</p>"},{"location":"C13_Errors_as_Values/#composing-with-result","title":"Composing with <code>Result</code>","text":"<p>The previous examples included composition in the <code>composed</code> functions which just called a single other function. What if you need to compose a more complex function from multiple other functions? The <code>Result</code> type ensures that the <code>composed</code> function properly represents both the <code>Answer</code> type but also the various different errors that can occur:</p> <pre><code># composing_functions.py\nfrom pprint import pprint\n\nfrom return_result import fa\nfrom returns.result import (\n    Failure,\n    Result,\n    Success,\n    safe,\n)\n\n\n# Use an exception as info (but don't raise it):\ndef fb(i: int) -&gt; Result[int, ValueError]:\n    if i == 2:\n        return Failure(ValueError(f\"fb({i})\"))\n    return Success(i)\n\n\n# Convert exception to Failure:\ndef fc(i: int) -&gt; Result[int, ZeroDivisionError]:\n    try:\n        j = int(1 / (i - 3))\n    except ZeroDivisionError as e:\n        return Failure(ZeroDivisionError(f\"fc({i}): {e}\"))\n    return Success(j)\n\n\n@safe  # Convert existing function\ndef fd(\n    i: int,\n) -&gt; str:  # Result[str, ZeroDivisionError]\n    j = int(1 / i)\n    return f\"fd({i}): {j}\"\n\n\ndef composed(\n    i: int,\n) -&gt; Result[str, str | ValueError | ZeroDivisionError]:\n    result_a = fa(i)\n    if isinstance(result_a, Failure):\n        return result_a  # type: ignore\n\n    # unwrap() gets the answer from Success:\n    result_b = fb(result_a.unwrap())\n    if isinstance(result_b, Failure):\n        return result_b  # type: ignore\n\n    result_c = fc(result_b.unwrap())\n    if isinstance(result_c, Failure):\n        return result_c  # type: ignore\n\n    return fd(result_c.unwrap())  # type: ignore\n</code></pre> <pre><code># composing_functions_demo.py\nfrom pprint import pprint\nfrom composing_functions import composed\n\npprint([(i, composed(i)) for i in range(5)])\n## [(0, &lt;Failure: division by zero&gt;),\n##  (1, &lt;Failure: fa(1)&gt;),\n##  (2, &lt;Failure: fb(2)&gt;),\n##  (3, &lt;Failure: fc(3): division by zero&gt;),\n##  (4, &lt;Success: fd(1): 1&gt;)]\n</code></pre> <p>The <code>fa</code>, <code>fb</code> and <code>fc</code> functions each have argument values that are unacceptable. Notice that <code>fb</code> and <code>fc</code> both use built-in exception types as arguments to <code>Failure</code>, but those exceptions are never raised\u2014they are used to convey information, just like the <code>str</code> in <code>fa</code>.</p> <p>In <code>composed</code>, we call <code>fa</code>, <code>fb</code> and <code>fc</code> in sequence. After each call, we check to see if the result type is <code>Failure</code>. If so, the calculation has failed. We can\u2019t continue, so we return a <code>Failure</code> object containing the reason for the failure. Succeeding produces a <code>Success</code> containing an <code>unwrap</code> method used to extract the answer from that calculation. It returns the <code>ANSWER</code> type so its use can be properly type-checked.</p> <p>This means that any failure during a sequence of composed function calls will short-circuit out of <code>composed</code>, returning a <code>Failure</code> that tells you what happened. You can\u2019t ignore it and assume that it will \"bubble up\" until it finds an appropriate handler. You must deal with it at the point of origin, the place where you typically know the most about an error.</p>"},{"location":"C13_Errors_as_Values/#simplifying-composition-with-bind","title":"Simplifying Composition with <code>bind</code>","text":"<p>There\u2019s still a problem that impedes our ultimate goal of composability: every time you call a function within a composed function, you must write code to check the <code>Result</code> type and extract the <code>answer</code> with <code>unwrap</code>. This is extra repetitive work that interrupts the flow and readability of the program. We need some way to reduce or eliminate the extra code.</p> <p>Let's modify <code>Result</code> to add a new member function, <code>bind</code>:</p> <pre><code># result_with_bind.py\nfrom __future__ import annotations\n\nfrom dataclasses import dataclass\nfrom typing import Callable\n\n\nclass Result[ANSWER, ERROR]:\n    def bind(\n        self, func: Callable[[ANSWER], Result]\n    ) -&gt; Result[ANSWER, ERROR]:\n        if isinstance(self, Success):\n            return func(self.unwrap())\n        return self  # Pass the Failure forward\n\n\n@dataclass(frozen=True)\nclass Success[ANSWER, ERROR]:\n    answer: ANSWER\n\n    def unwrap(self) -&gt; ANSWER:\n        return self.answer\n\n\n@dataclass(frozen=True)\nclass Failure[ANSWER, ERROR]:\n    error: ERROR\n</code></pre> <p><code>bind</code> removes the duplicated code:</p> <pre><code># composing_with_bind.py\nfrom pprint import pprint\nfrom returns.result import Result\n\nfrom composing_functions import fa, fb, fc, fd\n\n\ndef composed(\n    i: int,\n) -&gt; Result[str, str | ZeroDivisionError | ValueError]:\n    # fmt: off\n    return (\n        # TODO: typing is incorrect &amp; needs fixing\n        fa(i)\n        .bind(fb)  # type: ignore\n        .bind(fc)  # type: ignore\n        .bind(fd)  # type: ignore\n    )\n\n\npprint([(i, composed(i)) for i in range(5)])\n## [(0, &lt;Failure: division by zero&gt;),\n##  (1, &lt;Failure: fa(1)&gt;),\n##  (2, &lt;Failure: fb(2)&gt;),\n##  (3, &lt;Failure: fc(3): division by zero&gt;),\n##  (4, &lt;Success: fd(1): 1&gt;)]\n</code></pre> <p>In <code>composed</code>, we call <code>fa(i)</code> which returns a <code>Result</code>. The <code>bind</code> method is called on that <code>Result</code>, passing it the next function we want to call (<code>fb</code>) as an argument. The return value of <code>bind</code> is also a <code>Result</code>, so we can call <code>bind</code> again upon that <code>Result</code>, passing it the third function we want to call (<code>fc</code>), and so on.</p> <p>At each \"chaining point\" in <code>fa(i).bind(fb).bind(fc).bind(fd)</code>, <code>bind</code> checks the <code>Result</code> type to see if it <code>Success</code>. If so, it passes the result <code>answer</code> from that call as the argument to the next function in the chain. If not, that means <code>self</code> is a <code>Failure</code> object (containing specific error information), so all it needs to do is <code>return self</code>. The next call in the chain sees that the returned type is <code>Failure</code>, so it doesn\u2019t try to apply the next function but just (again) returns the <code>Failure</code>. Once you produce a <code>Failure</code>, no more function calls occur (that is, it short-circuits) and the <code>Failure</code> result gets passed all the way out of the composed function so the caller can deal with that specific failure.</p>"},{"location":"C13_Errors_as_Values/#handling-multiple-arguments","title":"Handling Multiple Arguments","text":"<p>We could continue adding features to our <code>Result</code> library until it becomes a complete solution. However, others have worked on this problem, so it makes more sense to reuse their libraries. The most popular Python library that includes this extra functionality is Returns. <code>Returns</code> includes other features, but we will only focus on <code>Result</code>.</p> <p>What if you need to create a <code>composed</code> function that takes multiple arguments? For this, we use something called \"do notation,\" which you access using <code>Result.do</code>:</p> <pre><code># multiple_arguments.py\nfrom pprint import pprint\n\nfrom composing_functions import fa, fb, fc\nfrom returns.result import Result\n\n\ndef add(first: int, second: int, third: int) -&gt; str:\n    return f\"add({first} + {second} + {third}): {first + second + third}\"\n\n\ndef composed(\n    i: int, j: int\n) -&gt; Result[str, str | ZeroDivisionError | ValueError]:\n    # fmt: off\n    return Result.do(\n        add(first, second, third)\n        for first in fa(i)\n        for second in fb(j)\n        for third in fc(i + j)\n    )\n\n\ninputs = [(1, 5), (7, 2), (2, 1), (7, 5)]\npprint([(args, composed(*args)) for args in inputs])\n## [((1, 5), &lt;Failure: fa(1)&gt;),\n##  ((7, 2), &lt;Failure: fb(2)&gt;),\n##  ((2, 1), &lt;Failure: fc(3): division by zero&gt;),\n##  ((7, 5), &lt;Success: add(7 + 5 + 0): 12&gt;)]\n</code></pre> <p><code>Returns</code> provides a <code>@safe</code> decorator that you see applied to the \"plain\" function <code>fb</code>. This changes the normal <code>int</code> return type into a <code>Result</code> that includes <code>int</code> for the <code>Success</code> type but is also somehow able to recognize that the division might produce a <code>ZeroDivisionError</code> and include that in the <code>Failure</code> type. In addition, <code>@safe</code> is apparently catching the exception and converting it to the <code>ZeroDivisionError</code> returned as the information object in the <code>Failure</code> object. <code>@safe</code> is a helpful tool when converting exception-throwing code into error-returning code.</p> <p><code>fc</code> adds some variety by rejecting <code>-1</code> and producing a <code>str</code> result. We can now produce <code>composed</code> using a <code>pipe</code> and <code>bind</code>. All the previous error-checking and short-circuiting behaviors happen as before, but the syntax is now more straightforward and readable.</p> <p>Notice that when the <code>outputs</code> list is created, the output from <code>reject0</code> only happens for the values <code>-1</code> and <code>2</code>, because the other values cause errors in the <code>composed</code> chain of operations. The value <code>1</code> never gets to <code>fb</code> because it is intercepted by the prior <code>composed</code> call to <code>fa</code>. The value <code>0</code> causes <code>fb</code> to produce a <code>ZeroDivisionError</code> when it tries to perform the division inside the <code>print</code>.</p> <p>[Explain the rest of the example]</p> <p>Note that there may be an issue with the <code>Returns</code> library: for proper type checking it requires using a MyPy extension. So far I have been unable to get that extension to work (however, I have no experience with MyPy extensions).</p>"},{"location":"C13_Errors_as_Values/#functional-error-handling-is-happening","title":"Functional Error Handling is Happening","text":"<p>Functional error handling has already appeared in languages like Rust, Kotlin, and recent versions of C++ support these combined answer-error result types, with associated unpacking operations. In these languages, errors become part of the type system, and it becomes difficult for an error to be lost.</p> <p>Python has only been able to support functional error handling since the advent of typing and type checkers, and it doesn\u2019t provide any direct language or library constructs for this. The benefits of better error handling and robust composability make it worth adopting a library like <code>Results</code>.</p>"},{"location":"C14_Advanced_Generics/","title":"Advanced Generics","text":"<p>Most of the time you will be a consumer of generic code rather than a producer. It is useful to understand the introductory generic material in [C09_Generics]. Occasionally you will need to know the material in this chapter.</p>"},{"location":"C14_Advanced_Generics/#variance","title":"Variance","text":"<p>In the context of generics, variance describes how subtyping between complex types relates to subtyping between their component types. In Python, all generics are invariant by default, meaning <code>Container[SubType]</code> is not a subtype of <code>Container[BaseType]</code> even if <code>SubType</code> is a subtype of <code>BaseType</code>. This is a common source of confusion for those coming from languages like Java or C#, but it's an important aspect of type safety.</p> <p>Python 3.12 introduced variance inference, so you do not have to specify variance. This is a great benefit, as people often find variance confusing.</p>"},{"location":"C14_Advanced_Generics/#invariant","title":"Invariant","text":"<p>A generic class is invariant by default. For example, given <code>Dog</code> is a subclass of <code>Animal</code>, <code>Box[Dog]</code> is not considered a subtype of <code>Box[Animal]</code>. This is unsafe because you can then put a <code>Cat</code> (another <code>Animal</code>) into a <code>Box[Animal]</code> which is a <code>Box[Dog]</code> internally. The type checker forbids treating <code>Box[Dog]</code> as a <code>Box[Animal]</code>.</p>"},{"location":"C14_Advanced_Generics/#covariance","title":"Covariance","text":"<p>Covariance usually makes sense for read-only or producer containers. For example:</p> <pre><code># covariance.py\nfrom animals import Animal, Dog\n\n\nclass ReadOnlyBox[T]:\n    def __init__(self, content: T):\n        self._content = content\n\n    def get_content(self) -&gt; T:\n        return self._content\n\n\ndog_box: ReadOnlyBox[Dog] = ReadOnlyBox(Dog())\n# Covariance in action:\nanimal_box: ReadOnlyBox[Animal] = dog_box\n# pet is an Animal, a Dog:\npet: Animal = animal_box.get_content()\n</code></pre> <p>Here, <code>ReadOnlyBox[T]</code> is covariant with the type parameter <code>T</code>. That signals to the type checker that it is safe to treat <code>ReadOnlyBox[Dog]</code> as a <code>ReadOnlyBox[Animal]</code>, because <code>ReadOnlyBox</code> only produces <code>T</code> (via <code>get_content</code>) and never consumes it in a type-specific way. Covariance is appropriate when the generic class is basically a container of <code>T</code> that only returns <code>T</code> (and doesn't accept <code>T</code> instances that can violate assumptions).</p>"},{"location":"C14_Advanced_Generics/#contravariance","title":"Contravariance","text":"<p>Contravariance is suitable for consumer objects that only take in data of type <code>T</code> and do not produce it. For example:</p> <pre><code># contravariance.py\nfrom animals import Animal, Dog\n\n\nclass Sink[T]:\n    def send(self, value: T) -&gt; None:\n        print(f\"Processing {value}\")\n\n\nanimal_sink: Sink[Animal] = Sink()\n# Contravariance in action:\ndog_sink: Sink[Dog] = animal_sink  # type: ignore # Pycharm\n# dog_sink expects at least Dog, and Animal is broader:\ndog_sink.send(Dog())\n## Processing Dog(name=None)\n</code></pre> <p>In this example, <code>Sink[T]</code> is contravariant, indicating it only consumes values of type <code>T</code> (here, via <code>send</code>). Because a <code>Sink[Animal]</code> can accept a <code>Dog</code> (since <code>Dog</code> is an <code>Animal</code>), it is safe to assign <code>animal_sink</code> to a <code>dog_sink</code> reference. In general, contravariance allows broadening the accepted types when substituting; a <code>Sink[Animal]</code> can stand in for a <code>Sink[Dog]</code> because anything that expects to only handle <code>Dog</code>s can also handle <code>Animal</code>s (but not vice versa).</p>"},{"location":"C14_Advanced_Generics/#using-variance","title":"Using Variance","text":"<p>Function type variables are always invariant. Most built-in collections in Python are invariant (e.g., <code>list</code> is invariant, so <code>list[Dog]</code> is not assignable to <code>list[Animal]</code>). Some abstract collection types or protocols are covariant. For instance, <code>collections.abc.Sequence</code> is covariant in its element type, because sequences are read-only containers as far as the typing system is concerned.</p> <p>Understanding variance is an advanced topic--many developers use generics effectively without explicitly declaring covariant/contravariant type variables. If you design your own generic classes, think about whether they only produce values of type <code>T</code> (covariant), only consume values of type <code>T</code> (contravariant), or both (invariant). Fortunately, since Python 3.12, invariance is inferred.</p>"},{"location":"C14_Advanced_Generics/#function-currying-with-generics","title":"Function Currying with Generics","text":"<p>Function currying is the technique of transforming a function that takes multiple arguments into a chain of functions, each taking a single argument (or fewer arguments). In Python, we can leverage generics to curry functions while preserving type information.</p> <p>For example, imagine a function that takes two arguments, and we want to get a new function that has the first argument fixed (a partial application). We can write a generic higher-order function to do this:</p> <pre><code># curry_two_arg.py\nfrom typing import Callable\n\n\ndef curry_two_arg[X, Y, Z](\n    func: Callable[[X, Y], Z],\n) -&gt; Callable[[X], Callable[[Y], Z]]:\n    def curried(x: X) -&gt; Callable[[Y], Z]:\n        def inner(y: Y) -&gt; Z:\n            return func(x, y)\n\n        return inner\n\n    return curried\n\n\ndef multiply(a: int, b: float) -&gt; float:\n    return a * b\n\n\ncurried_mul = curry_two_arg(multiply)\n# get_double is now Callable[[float], float]:\nget_double = curried_mul(2)\nprint(get_double(3.5))\n## 7.0\n</code></pre> <p>Here, <code>curry_two_arg</code> is a generic function that works with any two-argument function. The type variables <code>X</code>, <code>Y</code>, <code>Z</code> ensure that if <code>func</code> takes an <code>X</code> and a <code>Y</code> and returns <code>Z</code>, then <code>curry_two_arg(func)</code> returns a function that takes <code>X</code> and returns another function which takes <code>Y</code> and returns <code>Z</code>. In the example, <code>multiply</code> takes an <code>int</code> and a <code>float</code> and returns a <code>float</code>, so after currying, <code>curried_mul</code> is a function that takes an <code>int</code> and returns a function <code>Callable[[float], float]</code>. The types are correctly maintained.</p> <p>This kind of generic currying function uses higher-order generics (a function that returns another function). Python's <code>Callable</code> type is used to annotate callables. We can also achieve a similar result using parameter specifications, which allow capturing an arbitrary list of parameters. However, using explicit type variables for a fixed small number of parameters is straightforward for illustration.</p> <p>Currying is not common in idiomatic Python but can be useful for creating specialized functions from generic ones. The benefit of adding generics in currying (as opposed to writing a lambda or using <code>functools.partial</code>) is that the intermediate and final functions retain precise type information. This helps catch errors if you pass wrong types to the curried functions and provides better auto-completion in editors.</p>"},{"location":"C14_Advanced_Generics/#recursive-generics","title":"Recursive Generics","text":"<p>Recursive generics refer to types that are defined in terms of themselves. This is often needed for recursive data structures (like trees or linked lists) or for type definitions that refer to themselves (like a JSON structure type that can contain nested instances of itself).</p>"},{"location":"C14_Advanced_Generics/#self-referencing-generic-classes","title":"Self-referencing Generic Classes","text":"<p>Consider a tree data structure where each node contains a value and a list of children which are themselves nodes. We want to parameterize the tree by the type of its values (e.g., <code>Tree[int]</code> or <code>Tree[str]</code>). The class needs to refer to itself for the children. Here's how we can do it:</p> <pre><code># self_referencing.py\n# For forward-referenced types:\nfrom __future__ import annotations\nfrom dataclasses import dataclass, field\n\n\n@dataclass\nclass Tree[T]:\n    value: T\n    children: list[Tree[T]] = field(default_factory=list)\n\n    def add_child(self, child_value: T) -&gt; Tree[T]:\n        child = Tree(child_value)\n        self.children.append(child)\n        return child\n\n\nroot: Tree[str] = Tree(\"root\")\nchild_node = root.add_child(\"child1\")\ngrandchild = child_node.add_child(\"grandchild1\")\n</code></pre> <p>In <code>Tree[T]</code>:</p> <ul> <li>We use <code>list[Tree[T]]</code> to type the <code>children</code> as a list of <code>Tree</code> nodes with the same value type <code>T</code>.</li> <li>We needed to use a forward reference for <code>Tree[T]</code> inside the class definition.   In Python 3.11+, the <code>annotations</code> feature is on by default, but for earlier versions, we import <code>annotations</code> from   <code>__future__</code> to allow the string form of the annotation (<code>'Tree[T]'</code>) to be resolved later.   Alternatively, we could have written <code>children: list[\"Tree[T]\"] = ...</code> with quotes around <code>Tree</code> as a string literal   in Python &lt; 3.11 to achieve the same effect.</li> <li>The <code>add_child</code> method creates a new <code>Tree[T]</code> with the given value and appends it to the children.   It returns the new child node.   Notice the return type is also <code>Tree[T]</code>, not <code>Tree[Any]</code> or something unspecified.   This means if <code>root</code> is a <code>Tree[str]</code>, <code>add_child</code> returns a <code>Tree[str]</code> as well.</li> </ul> <p>Such a recursive generic class allows building complex nested structures while keeping type information consistent. If you try to, say, add a <code>Tree[int]</code> as a child of a <code>Tree[str]</code>, the type checker will flag an error. At runtime, this is just a normal class; Python doesn't prevent mixing types in the list, but the static typing helps you avoid those mistakes in your code.</p>"},{"location":"C14_Advanced_Generics/#f-bounded-polymorphism-self-types","title":"F-Bounded Polymorphism (Self types)","text":"<p>TODO: Check that self types are introduced earlier, probably in \"Using Types\"</p> <p>Another scenario with recursive generics is when a class needs to use its own type as a type variable. This is sometimes called F-bounded polymorphism or self-referential generics. A typical example is implementing a fluent interface or a cloning method that returns the same type as the subclass. Consider a base class that should return an instance of the subclass in a method:</p> <pre><code># f_bounded_polymorphism.py\nfrom __future__ import annotations\n\nfrom dataclasses import dataclass, field\nfrom typing import cast\n\n\n@dataclass\nclass Form[T]:\n    title: str = \"\"\n\n    def set_title(self, title: str) -&gt; T:\n        self.title = title\n        # Returns self as type T for fluent chaining:\n        return cast(T, self)\n\n\n@dataclass\nclass ContactForm(Form[\"ContactForm\"]):\n    fields: list[str] = field(default_factory=list)\n\n    def add_field(self, name: str) -&gt; ContactForm:\n        self.fields.append(name)\n        return self\n\n\nform = ContactForm().set_title(\"Feedback\").add_field(\"email\")\n</code></pre> <p>The generic base class <code>Form[T]</code> provides a method that returns <code>self</code> as type <code>T</code> for type-safe, fluent chaining in subclasses. <code>T</code> is a type variable bounded to <code>Form</code> (the base class). The base class <code>Form</code> itself is generic in <code>T</code>. The <code>set_title</code> method is annotated to return <code>T</code>.</p> <p><code>ContactForm</code> inherits <code>Form['ContactForm']</code>. By binding <code>T</code> to the subclass type, <code>set_title</code> will return <code>ContactForm</code> when called on a <code>ContactForm</code> instance.</p> <p>The method <code>add_field</code> in <code>ContactForm</code> returns <code>ContactForm</code> explicitly. Now, the fluent interface works: <code>ContactForm().set_title(...).add_field(...)</code> is correctly understood by the type checker as returning a <code>ContactForm</code> with the methods of <code>ContactForm</code> available after chaining.</p> <p>This pattern ensures that each subclass of <code>Form</code> will have <code>set_title</code> (inherited) returning the subclass type, not the base type. It's a bit complex to set up, but it provides more precise typing for chaining methods. Python 3.11+ provides <code>typing.Self</code> (PEP 673) that simplifies this pattern by allowing methods to return <code>Self</code> (the type of the class). For example:</p> <pre><code># return_self.py\n\"\"\"\nReturn `Self` enables type-safe method chaining in subclasses\nwithout the complexity of F-bounded generics.\n\"\"\"\n\nfrom dataclasses import dataclass, field\nfrom typing import Self\n\n\n@dataclass\nclass Form:\n    title: str = \"\"\n\n    def set_title(self, title: str) -&gt; Self:\n        self.title = title\n        return self\n\n\n@dataclass\nclass ContactForm(Form):\n    fields: list[str] = field(default_factory=list)\n\n    def add_field(self, name: str) -&gt; Self:\n        self.fields.append(name)\n        return self\n\n\nform = ContactForm().set_title(\"Feedback\").add_field(\"email\")\n</code></pre> <p>Using <code>Self</code> removes the need for the type variable and generic base class. However, <code>Self</code> is limited to describing that a method returns the same type as the class it was called on, whereas the type variable approach can express more complex relationships.</p>"},{"location":"C14_Advanced_Generics/#recursive-type-aliases","title":"Recursive Type Aliases","text":"<p>Sometimes, you might want to define a type alias that refers to itself. This is common when describing recursive data structures in a type alias form rather than a class. A classic example is a JSON-like data type, where a JSON value can be a <code>dict</code> of string keys to JSON (nested), or a list of JSON, or a primitive (<code>str</code>, <code>int</code>, <code>bool</code>, etc.). We can express this as:</p> <pre><code># recursive_alias.py\nJSON = (\n    dict[str, \"JSON\"]\n    | list[\"JSON\"]\n    | str\n    | int\n    | float\n    | bool\n    | None\n)\n</code></pre> <p>This defines <code>JSON</code> as a recursive type alias: it can be a dictionary mapping strings to JSON values, or a list of JSON values, or a primitive type. We have to put <code>'JSON'</code> in quotes because we are referring to the name <code>JSON</code> before it's fully defined (again, Python 3.11+ with automatic postponed evaluation of annotations handles this without quotes if you use <code>from __future__ import annotations</code> or run in a module where that's the default).</p> <p>Most type checkers support such recursive type aliases. In use, if you annotate a variable as <code>JSON</code>, the type checker will understand nested structures of dicts and lists accordingly. For example:</p> <pre><code># recursive_alias_applied.py\nfrom recursive_alias import JSON\n\nconfig: JSON = {\n    \"name\": \"App\",\n    \"features\": [\"login\", \"signup\"],\n    \"settings\": {\"theme\": \"dark\", \"volume\": 5},\n}\n</code></pre> <p>Overly deep recursion can sometimes confuse type checkers or lead to performance issues in type checking. Recursive aliases cannot be directly made generic with type variable in the current typing system (you can wrap recursive structures inside generic classes if needed).</p>"},{"location":"C14_Advanced_Generics/#structural-subtyping-with-protocols","title":"Structural Subtyping with Protocols","text":"<p>Python's static typing supports two forms of subtype compatibility: nominal and structural. Nominal subtyping is the traditional style; an object of class <code>C</code> is a subtype of class <code>B</code> if <code>C</code> subclasses <code>B</code>. Structural subtyping, on the other hand, is about the shape or structure of the type--often called \"duck typing\" for types. If an object has the required methods/attributes, it can be used as that type, regardless of its class in the inheritance hierarchy.</p> <p>Python 3.8 introduced protocols to facilitate structural typing. A <code>Protocol</code> defines methods and attributes that a type must have, without specifying a particular base class. Any class that has those members with compatible types is considered a subtype of the protocol, even if it doesn't explicitly inherit from <code>Protocol</code>. Protocols create interfaces or contracts that can be satisfied by any class, matching Python's dynamic duck typing in a static type checking context.</p>"},{"location":"C14_Advanced_Generics/#a-drawable-protocol","title":"A Drawable Protocol","text":"<p>You define a protocol by subclassing <code>typing.Protocol</code> and declaring the methods and properties that must exist. For example, let's define a protocol for \"drawable\" objects that must have a <code>draw()</code> method:</p> <pre><code># drawable.py\nfrom typing import Protocol\n\n\nclass Drawable(Protocol):\n    def draw(self) -&gt; None: ...\n</code></pre> <p>The <code>...</code> a.k.a. <code>pass</code> means we don't implement behavior in the <code>Protocol</code>, we only provide the signature.</p> <p>Now any object of any class that has a <code>draw()</code> method returning <code>None</code> is considered a <code>Drawable</code> by the type system. We can write functions that accept a <code>Drawable</code>:</p> <pre><code># render_drawable.py\nfrom drawable import Drawable\n\n\ndef render(item: Drawable) -&gt; None:\n    item.draw()\n\n\n# Example classes that satisfy the protocol:\nclass Circle:\n    def draw(self) -&gt; None:\n        print(\"Drawing a circle\")\n\n\nclass Text:\n    def draw(self) -&gt; None:\n        print(\"Rendering text\")\n\n\ncircle = Circle()\ntext = Text()\nrender(circle)  # OK, Circle has draw()\n## Drawing a circle\nrender(text)  # OK, Text has draw()\n## Rendering text\n# render(123)   # type checker error: int has no draw()\n</code></pre> <p>In this snippet, neither <code>Circle</code> nor <code>Text</code> subclasses <code>Drawable</code>, but they are accepted by the <code>render</code> function because they fulfill the structural requirements of the <code>Drawable</code> protocol. This is static duck typing in action: if it quacks like a duck, treat it as a duck.</p> <p>Protocols with Attributes: Protocols can also specify that an attribute exists (with a certain type). For example:</p> <pre><code># protocols_with_attributes.py\nfrom typing import Protocol\n\n\nclass Named(Protocol):\n    name: str\n\n\ndef greet(entity: Named) -&gt; None:\n    print(f\"Hello, {entity.name}!\")\n</code></pre> <p>Any object with a string attribute <code>name</code> qualifies as <code>Named</code>. If you pass an object to <code>greet</code> that has a <code>name</code> attribute (say an instance of a class that defines <code>name</code>), it will be accepted.</p> <p>Generic Protocols: Protocols can be generic. For example, the built-in <code>Iterable[T]</code> protocol (from <code>collections.abc</code> or <code>typing</code>) is a generic protocol that requires an <code>__iter__</code> method yielding type <code>T</code>. You can define your own:</p> <pre><code># iterable_protocol.py\nfrom typing import Iterator, Protocol\n\n\nclass IterableLike[T](Protocol):\n    def __iter__(self) -&gt; Iterator[T]: ...\n</code></pre> <p>Now <code>IterableLike[T]</code> can be used to describe any iterable of <code>T</code> without forcing a specific inheritance. For a function that processes an iterable of <code>T</code>, you can annotate a parameter as <code>IterableLike[T]</code>. Any class that has an <code>__iter__</code> method returning an iterator of <code>T</code> will match. For example, built-in lists, sets, etc., already implement <code>__iter__</code>, so they satisfy <code>IterableLike</code>.</p>"},{"location":"C14_Advanced_Generics/#a-file-like-protocol","title":"A File-like Protocol","text":"<p>Suppose we want a function that can write to any file or file-like object (like an open file handle or an in-memory buffer), without tying it to a specific class. We can define a protocol for the methods we need (say, a <code>write</code> method) and use it as the parameter type:</p> <pre><code># file_protocol.py\nfrom typing import Protocol\nfrom pathlib import Path\nfrom io import StringIO\n\n\nclass Writable(Protocol):\n    def write(self, __s: str) -&gt; int: ...\n\n\ndef save_message(out: Writable, message: str) -&gt; None:\n    out.write(f\"{message}\\n\")\n\n\n# With a file:\nfile_path = Path(\"message.txt\")\nwith file_path.open(\"w\", encoding=\"utf-8\") as f:\n    save_message(f, \"Hello, World!\")\n\n# With an in-memory buffer:\nbuffer = StringIO()\nsave_message(buffer, \"Hello, Buffer!\")\nbuffer.seek(0)\nprint(buffer.read())\n## Hello, Buffer!\n</code></pre> <p>In this example, any object that implements <code>write(str)</code> can be passed to <code>save_message</code>. We demonstrated it with a real file (opened via <code>pathlib.Path</code>) and a <code>StringIO</code> buffer. Both work because both have a compatible <code>write</code> method. The protocol approach allows <code>save_message</code> to work with any current or future file-like object, without needing a common base class or inheritance.</p> <p>By default, Protocols are a static concept. You typically wouldn't use <code>isinstance(x, Drawable)</code> or <code>issubclass(C, Drawable)</code> with a protocol at runtime, because <code>Protocol</code> classes by themselves don't have special status as base classes. However, if you need to do runtime checks, the <code>typing.runtime_checkable</code> decorator can be applied to a Protocol class, which then allows using <code>isinstance(obj, ProtocolName)</code> to check if an object conforms (this requires that either the object's class explicitly inherits the Protocol or that the Protocol is annotated with <code>runtime_checkable</code>; a purely structural match at runtime without explicit registration isn't directly supported). In general, it's more common to rely on static checking for protocols and use normal duck typing at runtime, \"asking forgiveness rather than permission.\"</p> <p>Use cases: Protocols are useful when you want to accept \"any object that has these methods.\" For example:</p> <ul> <li>A serialization utility that works with any object that has a <code>to_json()</code> method can define a protocol for that   method.</li> <li>Defining callback signatures via protocols (PEP 544 allows a special case of protocols with <code>__call__</code> to match   callables).</li> </ul> <p>Protocols bring the flexibility of dynamic typing (duck typing) to the static type world. They avoid over-constraining function arguments to specific classes when all you care about is the presence of a method or attribute.</p>"},{"location":"C14_Advanced_Generics/#generic-type-aliases","title":"Generic Type Aliases","text":"<p>Type aliases in Python let you create alternative names for types, which can improve code clarity. For example, you might write <code>Coordinate = tuple[float, float]</code> to give a semantic name to a tuple of two floats. Generic type aliases extend this idea by allowing aliases to be parameterized with type variables.</p> <p>Creating a generic type alias is straightforward: use a type variable in the definition of the alias. For instance:</p> <pre><code># generic_alias.py\n\ntype Pair[T] = tuple[T, T]\ntype StrDict[T] = dict[str, T]\n</code></pre> <p>Here, <code>Pair</code> and <code>StrDict</code> are generic type aliases. <code>Pair[int]</code> is equivalent to <code>tuple[int, int]</code>, <code>Pair[str]</code> to <code>tuple[str, str]</code>, etc. <code>StrDict[float]</code> means <code>dict[str, float]</code>.</p> <p>Using generic aliases is straightforward:</p> <pre><code># generic_alias_applied.py\nfrom generic_alias import Pair, StrDict\n\np: Pair[int] = (10, 20)\nq: Pair[str] = (\"a\", \"b\")\ndata: StrDict[int] = {\"age\": 30, \"year\": 2025}\n</code></pre> <p>These annotations make the intent clearer: <code>p</code> is a pair of ints, <code>q</code> a pair of strs, and <code>data</code> is a string-to-int map. The type checker treats <code>Pair[int]</code> as <code>tuple[int, int]</code>. If you do not subscript the alias (e.g., just use <code>Pair</code> by itself), the type variables are typically treated as <code>Any</code>. For example:</p> <pre><code># generic_alias_tuple.py\nfrom generic_alias import Pair\n\n# type checker treats this as tuple[Any, Any]:\nr: Pair = (\n    \"x\",\n    5,\n)\n</code></pre> <p>This will not raise an immediate error, because <code>Pair</code> unqualified is basically <code>tuple[Any, Any]</code>, but it defeats the purpose of the alias since it's not enforcing that both elements share the same type. Always supply type parameters for a generic alias to avoid inadvertently falling back to <code>Any</code>.</p>"},{"location":"C14_Advanced_Generics/#alias-vs-direct-use","title":"Alias vs. Direct Use","text":"<p>Type aliases don't create new types at runtime; they are solely for type checking and readability. In code, <code>Pair[int]</code> does not exist as a real class; it's just an alias for <code>tuple[int, int]</code>. If you inspect <code>Pair[int]</code> at runtime, you'll get the underlying type. For example:</p> <pre><code># inspect_alias.py\nfrom generic_alias import Pair\nfrom typing import get_origin, get_args\n\nprint(get_origin(Pair[int]))\n## Pair\nprint(get_args(Pair[int]))\n## (&lt;class 'int'&gt;,)\n</code></pre> <p>This shows that <code>Pair[int]</code> is recognized by the typing introspection as a tuple with two int arguments. Type aliases are resolved during type checking and are essentially transparent at runtime.</p>"},{"location":"C14_Advanced_Generics/#parameterized-aliases-in-functions-and-classes","title":"Parameterized Aliases in Functions and Classes","text":"<p>You can use generic aliases to simplify annotations inside other generics. For example:</p> <pre><code># vector.py\n\ntype Vector[T] = list[tuple[T, T]]\n\n\ndef scale_points(\n    points: Vector[int], factor: int\n) -&gt; Vector[int]:\n    return [(x * factor, y * factor) for (x, y) in points]\n</code></pre> <p>Here <code>Vector[int]</code> is easier to read than <code>list[tuple[int, int]]</code>. The type checker ensures consistency just as if we wrote the full type.</p>"},{"location":"C14_Advanced_Generics/#declaring-aliases-explicitly","title":"Declaring Aliases Explicitly","text":"<p>Python 3.10 introduced <code>TypeAlias</code> to explicitly declare that an assignment is a type alias (especially when the right-hand side might be ambiguous). For example:</p> <pre><code># typealias_annotation.py\nfrom typing import TypeAlias\n\nCoordinates: TypeAlias = tuple[float, float]\n</code></pre> <p>However, for basic cases, just using a capitalized variable name for the alias as above is usually clear enough to type checkers. (By convention, user-defined type aliases often start with a capital letter.) Python 3.12 is expected to bring a new syntax for generic aliases using the <code>type</code> keyword (PEP 695), but that's beyond the scope of this chapter.</p>"},{"location":"C14_Advanced_Generics/#guidelines","title":"Guidelines","text":"<p>Generics greatly enhance the expressiveness of Python's type system, but they can also introduce complexity.</p>"},{"location":"C14_Advanced_Generics/#pitfall-invariance-confusion","title":"Pitfall: Invariance Confusion","text":"<p>As mentioned earlier, most types are invariant. A common mistake is expecting container types to be covariantly interchangeable:</p> <pre><code># invariance_confusion.py\nfrom animals import Animal, Dog\n\nanimals: list[Animal] = [Animal()]\ndogs: list[Dog] = [Dog()]\nanimals = dogs  # type: ignore\n</code></pre> <p>Here a newcomer might think \"a list of Dogs is a list of Animals,\" but that's not allowed because of invariance. The pitfall is not realizing that mutation of the list can break type assumptions. If you find yourself needing to treat a <code>list[SubType]</code> as a <code>list[BaseType]</code>, reconsider your design or use abstract interfaces (<code>Sequence[BaseType]</code> which is covariant for reading, or <code>Collection[BaseType]</code>). Alternatively, copy the list to a new covariant container if needed for output only.</p>"},{"location":"C14_Advanced_Generics/#pitfall-too-general-or-overuse-of-any","title":"Pitfall: Too General (or Overuse of Any)","text":"<p>Using a type variable when your function expects a more specific capability can lead to confusing errors or overly permissive acceptance. For example:</p> <pre><code># too_general.py\n\n\ndef sort_items[T](items: list[T]) -&gt; list[T]:\n    # PyRight issue:\n    return sorted(items)  # type: ignore\n</code></pre> <p>This function will type-check, but it's not truly safe for all <code>T</code>--it assumes that the items are comparable (have an ordering defined). If you call <code>sort_items</code> on a list of objects that can't be ordered, you'll get a runtime error. The type checker wouldn't catch it because <code>T</code> was unconstrained (it can be anything). A better approach is to constrain <code>T</code> to types that support ordering:</p> <pre><code># bound_type_variable.py\nfrom typing import Protocol, Any\n\n\nclass Comparable(Protocol):\n    def __lt__(self, other: Any) -&gt; bool: ...\n\n\ndef sort_items[U: Comparable](items: list[U]) -&gt; list[U]:\n    return sorted(items)\n</code></pre> <p>Now <code>sort_items</code> explicitly requires that the item type implements <code>&lt;</code> (as per the <code>Comparable</code> protocol).</p> <p>Don't use a totally unconstrained type variable if the function or class really needs the type to have some capability. Either use a type bound or a protocol to encode that requirement. Conversely, if you truly intend a function to accept anything (like a generic passthrough that just returns what it was given), then using <code>Any</code> might be appropriate, or a type variable with no constraints if you need to preserve the type identity. A function using <code>Any</code> will accept and return anything without errors--it turns off type checking for that element.</p>"},{"location":"C14_Advanced_Generics/#pitfall-ignoring-type-variable-scope","title":"Pitfall: Ignoring type variable Scope","text":"<p>Unless the function is truly generic, generics can cause more confusion than clarity. Remember that a type variable is specific to the generic function or class where it's used. If you define a type variable at the top of a module and use it in a function signature, that function is generic. If you intended the function to only work with one specific type, you might accidentally make it generic.</p> <p>If a type variable appears only once in a function signature, that function is technically generic, but there's no way to connect the type to anything else (e.g., a return value or another parameter). Type checkers will flag this as suspicious:</p> <pre><code># accidental_genericity.py\nglobal_var = None\n\n\n# warning: type variable \"T\" appears only     \u2502\n# once in generic function signature\ndef set_value[T](x: T) -&gt; None:  # type: ignore\n    global global_var\n    global_var = x\n</code></pre> <p>If <code>global_var</code> is not also parameterized by <code>T</code> somehow, this use of <code>T</code> is misleading. The function <code>set_value</code> as written can accept any type, and the type of <code>global_var</code> cannot be described properly after calling it (it can be <code>int</code> if called with <code>int</code>, <code>str</code> if called with <code>str</code>, etc.). This is probably a design mistake. In such cases, use a normal specific type (or <code>Any</code>) if the function isn't meant to be generic. Use type variable only for functions that really need to be generic.</p>"},{"location":"C14_Advanced_Generics/#practice-use-descriptive-type-variable-names-for-clarity","title":"Practice: Use Descriptive Type Variable Names for Clarity","text":"<p>While the convention is to use single-letter type variables like <code>T</code>, <code>U</code>, <code>V</code> for common cases, in more complex generics consider using more descriptive names. For example:</p> <pre><code># descriptive_type_variables.py\n\n\nclass BiMap[KT, VT]: ...\n</code></pre> <p>This can make the code more self-documenting, especially if there are multiple type parameters that have roles (key vs. value, input vs. output, etc.).</p>"},{"location":"C14_Advanced_Generics/#practice-leverage-protocols-for-flexibility","title":"Practice: Leverage Protocols for Flexibility","text":"<p>If you find yourself wanting to accept \"any object that has method X,\" don't force a class hierarchy for typing purposes. Use a Protocol. This decouples your code's type requirements from specific implementations. It makes your functions more reusable. The standard library's <code>typing</code> module provides many ready-made protocols (like <code>Iterable</code>, <code>Iterator</code>, <code>Sequence</code>, <code>Mapping</code>, etc.) which you should use in type annotations instead of concrete types when possible. For instance, if a function just needs to read from a container, annotate it as accepting <code>Iterable[T]</code> rather than <code>list[T]</code>. This way, <code>tuple</code>s, <code>set</code>s, or any <code>Iterable</code> will also be accepted.</p>"},{"location":"C14_Advanced_Generics/#practice-version-compatibility","title":"Practice: Version Compatibility","text":"<p>The typing ecosystem has evolved quickly. Be aware of the Python version you are targeting:</p> <ul> <li>Python 3.7 and earlier: Use <code>from __future__ import annotations</code> to avoid forward reference issues.   The <code>typing_extensions</code> module provides <code>Protocol</code>, <code>Literal</code>, <code>Final</code>, etc., which were not yet in <code>typing</code>.   Also, generic built-in types like <code>list[int]</code> were not available; you had to use <code>typing.List[int]</code>.</li> <li>Python 3.8: <code>typing.Protocol</code> introduced via PEP 544.   Also <code>Literal</code> and <code>Final</code> were added.</li> <li>Python 3.9: Built-in generic types like <code>list[int]</code>, <code>dict[str, int]</code> are supported (PEP 585), so you no longer need   to import those from <code>typing</code>.   Also, <code>typing.Annotated</code> was introduced for adding metadata to types.</li> <li>Python 3.10: The <code>X | Y</code> union syntax (PEP 604) replaces <code>typing.Union[X, Y]</code> for brevity.   <code>typing.TypeAlias</code> was introduced for explicit alias declarations (PEP 613).</li> <li>Python 3.11: <code>typing.Self</code> was introduced (PEP 673) for easier self-referential return types.   Also, variance for certain standard collections might be adjusted in the background (for example, <code>str</code> and <code>bytes</code>   now share <code>AnyStr</code> logic differently, and <code>typing.AnyStr</code> is essentially <code>TypeVar('AnyStr', str, bytes)</code>).</li> <li>Python 3.12+ (future): PEP 695 (Type Parameter Syntax) will allow writing <code>class MyClass[T]: ...</code> and   <code>def func[X](arg: X) -&gt; X: ...</code> directly, and the <code>type</code> statement for aliases (e.g.,   <code>type ListOrSet[T] = list[T] | set[T]</code>).   These make generics more concise but require newer Python versions.</li> </ul>"},{"location":"C14_Advanced_Generics/#references","title":"References","text":"<ol> <li>Generics--typing documentation</li> <li>Protocols and structural subtyping--typing documentation</li> <li>Protocols and structural subtyping--typing documentation</li> </ol>"},{"location":"Z01_Appendix_Quick_Reference/","title":"Appendix: Quick Reference","text":"Annotation Description Example <code>int</code>, <code>str</code>, <code>float</code>, <code>bool</code> Basic built-in types <code>age: int = 25</code> <code>List[T]</code>, <code>list[T]</code> List containing items of type <code>T</code> <code>scores: list[int]</code> <code>Tuple[T, ...]</code>, <code>tuple[T, ...]</code> Tuple with specified item types <code>coords: tuple[float, float]</code> <code>Dict[K, V]</code>, <code>dict[K, V]</code> Dictionary with keys <code>K</code>, values <code>V</code> <code>user_data: dict[str, int]</code> <code>Set[T]</code>, <code>set[T]</code> Set containing items of type <code>T</code> <code>tags: set[str]</code> <code>Optional[T]</code> Type <code>T</code> or <code>None</code> <code>name: Optional[str]</code> <code>Union[T1, T2]</code> or <code>T1</code> | <code>T2</code> Either type <code>T1</code> or <code>T2</code> <code>value: int</code> | <code>str</code> <code>Callable[[Args], ReturnType]</code> Function types <code>adder: Callable[[int, int], int]</code> <code>Literal[\"value\"]</code> Specific literal values <code>mode: Literal[\"auto\", \"manual\"]</code> <code>Annotated[T, metadata]</code> Type <code>T</code> with additional metadata <code>UserID = Annotated[int, \"primary key\"]</code> <code>NewType('Name', T)</code> New distinct type based on type <code>T</code> <code>UserId = NewType('UserId', int)</code> <code>Protocol</code> Structural typing protocol <code>class Speaker(Protocol): ...</code> <p>[Add links to introductions in book]</p> Term Definition Annotation Explicit type declaration for variables, functions, or classes. Duck Typing Determining an object's suitability based on presence of methods/attributes Generics Type annotations parameterized by type variables. Literal Types Types representing specific literal values. Protocol Interface defined by structural compatibility, rather than explicit inheritance. Stub Files Files (<code>.pyi</code>) containing type annotations without implementations. Type Alias Simplified or descriptive alias for complex type annotations. Type Checking Verification of type consistency either statically or at runtime. Type Narrowing Refining variable types within specific control-flow branches. Variance Rules describing subtype relationships between generic types (covariant, contravariant). Static Typing Types checked before execution (compile-time). Dynamic Typing Types determined and checked during execution (runtime). Covariance Generic type that accepts subtypes as substitutes for its type parameter. Contravariance Generic type that accepts supertypes as substitutes for its type parameter. Invariant Generic type that requires exact type matches for its type parameters."},{"location":"Z02_Appendix_Reference/","title":"Appendix: Reference","text":"<p>Type annotations (or \"type hints\") declare the expected data types of variables, function parameters, and return values. Python remains dynamically typed at runtime--these annotations are not enforced by the interpreter and are mainly for static analysis and documentation. Tools like type checkers (e.g., mypy, PyRight) and IDEs use the annotations to catch errors or suggest code completions. Python's core team has no plan to make type annotations mandatory; they are optional aids to improve code quality.</p>"},{"location":"Z02_Appendix_Reference/#introduction-via-peps","title":"Introduction via PEPs","text":"<p>Function annotation syntax was first introduced by PEP 3107 (Python 3.0) with no fixed semantics. PEP 484 (Python 3.5) later defined a standard for using these annotations as type hints, establishing a formal type annotation system. The <code>typing</code> module provides a standardized vocabulary of types. This enables gradual typing--code can be partially or fully annotated, and type checkers will treat unannotated parts as dynamically typed (effectively type <code>Any</code>).</p>"},{"location":"Z02_Appendix_Reference/#basic-annotation-syntax-and-usage","title":"Basic Annotation Syntax and Usage","text":""},{"location":"Z02_Appendix_Reference/#function-annotations-parameters-and-return","title":"Function Annotations (Parameters and Return)","text":"<p>You can annotate function parameters and return types using the syntax introduced in PEP 484. For example:</p> <pre><code># example_1.py\ndef greet(name: str, excited: bool = False) -&gt; str:\n    return f\"Hello, {'!' if excited else ''}{name}\"\n</code></pre> <p><code>name: str</code> and <code>excited: bool = False</code> annotate the parameter types, and <code>-&gt; str</code> annotates the return type. An unannotated parameter defaults to type <code>Any</code> in static analysis. If a function does not return a value (or returns <code>None</code>), it's good practice to annotate the return type as <code>None</code> (e.g. <code>-&gt; None</code>), especially for <code>__init__</code> methods.</p>"},{"location":"Z02_Appendix_Reference/#variable-annotations","title":"Variable Annotations","text":"<p>Python 3.6 (PEP 526) introduced syntax for annotating variables and class attributes with types. For example: <code>age: int = 21</code> or <code>pi: float</code> (with or without initialization). These annotations can appear at the class or module level as well as inside functions. When annotating class variables (as opposed to instance variables), use <code>typing.ClassVar</code>. For instance:</p> <pre><code># example_2.py\nfrom typing import ClassVar\n\n\nclass Starship:\n    stats: ClassVar[dict[str, int]] = {}  # class variable\n    damage: int = 10  # instance variable\n</code></pre> <p>Here <code>stats</code> is marked as a class-level attribute, whereas <code>damage</code> is an instance attribute. ClassVar helps type checkers distinguish the two. (At runtime, annotations are stored in the <code>__annotations__</code> attribute of the function or class, but they don't affect execution.)</p>"},{"location":"Z02_Appendix_Reference/#type-comments-legacy","title":"Type Comments (Legacy)","text":"<p>In older code or for compatibility, type annotations can be given in comments (e.g. <code># type: int</code>) as described in PEP 484. This was mainly used for Python 2 or situations where inline annotation syntax was not available. Modern Python prefers explicit annotation syntax, but you might encounter type comments or stub files in some codebases.</p>"},{"location":"Z02_Appendix_Reference/#core-built-in-types-and-collections-in-annotations","title":"Core Built-in Types and Collections in Annotations","text":""},{"location":"Z02_Appendix_Reference/#built-in-types","title":"Built-in Types","text":"<p>For types like <code>int</code>, <code>str</code>, <code>bool</code>, etc., you can use the type name directly as an annotation. For example, <code>x: int = 5</code> or <code>user: str</code>. The same goes for classes and custom types--you annotate with the class itself (e.g. <code>file: io.TextIOBase</code>).</p>"},{"location":"Z02_Appendix_Reference/#generic-collections-pep-585","title":"Generic Collections (PEP 585)","text":"<p>Modern Python allows using built-in container types directly as generics. For example, use <code>list[int]</code> instead of <code>typing.List[int]</code>, <code>dict[str, float]</code> instead of <code>typing.Dict[str, float]</code>, and so on. PEP 585 (Python 3.9) enabled this, so the <code>typing</code> module's capitalized aliases (List, Dict, etc.) are no longer necessary in new code. These generics let you specify element types: e.g. <code>list[int]</code> means \"list of ints.\" (Note: these annotations are for the benefit of type checkers; at runtime <code>list[int]</code> is mainly recognized by the interpreter for typing purposes but still behaves like a normal list). Tuples can also be annotated, e.g. <code>tuple[int, str]</code> for a fixed-length 2-tuple, or <code>tuple[int,...]</code> for a variable-length tuple of ints.</p>"},{"location":"Z02_Appendix_Reference/#union-types-and-optional-pep-604","title":"Union Types and Optional (PEP 604)","text":"<p>A union type means a value could be one of several types. You can write a union as <code>typing.Union[X, Y]</code> or, more readably in Python 3.10+, using the <code>|</code> operator: <code>X | Y</code>. For example, <code>def parse(data: str | bytes) -&gt; None:</code> indicates <code>data</code> can be either a string or bytes. If one of the types is <code>None</code>, you can use shorthand: <code>Optional[T]</code> is equivalent to <code>T | None</code>. For example, <code>Optional[int]</code> (or <code>int | None</code>) means the value can be an int or None.**Important</p> <p>The <code>Optional</code> annotation refers to \"may be <code>None</code>\"; it does not mean an argument is optional in the sense of having a default. An argument with a default value isn't automatically <code>Optional</code> unless you explicitly want to allow <code>None</code> as a value.</p>"},{"location":"Z02_Appendix_Reference/#the-any-type","title":"The <code>Any</code> Type","text":"<p><code>typing.Any</code> is a special type that essentially disables type checking for that variable. A value of type <code>Any</code> is allowed to be passed or assigned to any type, and vice versa. Every type is compatible with <code>Any</code>, and <code>Any</code> is compatible with every type. You might use <code>Any</code> when you genuinely cannot predict the type (e.g., a function that can return any type depending on usage). However, overusing <code>Any</code> undermines the benefits of static typing, so it's best used sparingly when other typing features can't express the concept. (If a function can accept literally any object, a practice is to annotate it as <code>object</code> rather than <code>Any</code> to signal that no specific behavior is assumed.)</p>"},{"location":"Z02_Appendix_Reference/#noreturn-never","title":"NoReturn / Never","text":"<p>If a function never returns normally (for example, it always raises an exception or calls <code>sys.exit()</code>), you can annotate its return type as <code>NoReturn</code> (or <code>Never</code>, a synonymous alias introduced in Python 3.11). This signals to type checkers that the function doesn't produce a value at all. For instance:</p> <pre><code># example_3.py\nfrom typing import NoReturn\n\n\ndef fatal_error(msg: str) -&gt; NoReturn:\n    raise RuntimeError(msg)\n</code></pre> <p>Here, callers can know that <code>fatal_error()</code> will not return normally. <code>Never</code>/<code>NoReturn</code> is the bottom type in the type system, meaning no value can ever have this type (except in a theoretical sense). Static analyzers use it to understand control flow (e.g., after a call to a NoReturn function, execution doesn't continue).</p>"},{"location":"Z02_Appendix_Reference/#type-aliases-and-custom-types","title":"Type Aliases and Custom Types","text":""},{"location":"Z02_Appendix_Reference/#type-aliases","title":"Type Aliases","text":"<p>Sometimes you have a complex type and want to give it a short name (alias) for readability. You can create a type alias by assignment or using the new <code>type</code> statement. For example: <code>Address = tuple[str, int]</code> creates an alias <code>Address</code> for \"tuple of (str, int)\". In Python 3.12+, you can declare aliases more explicitly with the <code>type</code> keyword (PEP 695):</p> <pre><code># example_4.py\ntype Point = tuple[float, float]\n</code></pre> <p>This creates a type alias <code>Point</code> that static checkers will treat as <code>tuple[float, float]</code>. Type aliases can also be generic, e.g. <code>type Response[T] = tuple[T, int]</code> to parameterize the alias. In older versions, you might see <code>TypeAlias</code> from <code>typing</code> used as an annotation to mark an assignment as a type alias, especially when forward references are involved (to indicate to the checker that a string is meant to be a type name). PEP 695 deprecates the need for <code>TypeAlias</code> by introducing the explicit alias syntax.</p>"},{"location":"Z02_Appendix_Reference/#newtype-distinct-types-based-on-existing-ones","title":"NewType--Distinct Types Based on Existing Ones","text":"<p>The <code>typing.NewType</code> helper defines a distinct type that is interchangeable with some base type at runtime but treated as a separate type by type checkers. For example:</p> <pre><code># example_5.py\nfrom typing import NewType\n\nUserId = NewType(\"UserId\", int)\n</code></pre> <p>This creates a new type <code>UserId</code> that behaves like an <code>int</code> at runtime (it's essentially an identity function that returns the int you give it), but static type checkers will consider <code>UserId</code> incompatible with plain <code>int</code> unless explicitly allowed. This is useful when you want to prevent mix-ups of semantically different values that share an underlying type (e.g. <code>UserId</code> vs <code>ProductId</code> both as ints). Using <code>NewType</code>, you can catch such mix-ups in static analysis. Calling <code>UserId(5)</code> just returns 5 at runtime, so there's no extra performance cost beyond a function call. In Python 3.10+ <code>NewType</code> is implemented as a class for better performance.</p>"},{"location":"Z02_Appendix_Reference/#generics-and-type-variables","title":"Generics and Type Variables","text":""},{"location":"Z02_Appendix_Reference/#generic-functions-and-typevar","title":"Generic Functions and TypeVar","text":"<p>Python supports parametric polymorphism (generics) in functions and classes. A type variable represents an unknown type that can vary between calls or instances. Type variables allow generic code to be checked for type consistency--a key feature of static typing.</p> <p>Before Python 3.12, to write a function that returns the same type as it receives, you had to use <code>TypeVar</code>:</p> <pre><code># example_6.py\nfrom typing import TypeVar\n\nT = TypeVar(\"T\")\n\n\ndef identity(item: T) -&gt; T:\n    return item\n</code></pre> <p>Here <code>T</code> is a type variable that can stand for any type, and the function <code>identity</code> is generic--if you pass an <code>int</code>, it returns an <code>int</code>, if you pass a <code>str</code>, it returns a <code>str</code>, etc. As of Python 3.12, you can declare type parameters directly in the function signature (PEP 695):</p> <pre><code># example_7.py\ndef identity[T](item: T) -&gt; T:\n    return item\n</code></pre> <p>This is equivalent to the earlier definition. Type variables can be given bounds or constraints to restrict what types they can represent. For instance, <code>[U: Number]</code> means <code>U</code> can be any subclass of <code>Number</code> (upper-bounded) while <code>[V: (int, str)]</code> means V can only be <code>int</code> or <code>str</code> (union constraint).</p>"},{"location":"Z02_Appendix_Reference/#generic-classes","title":"Generic Classes","text":"<p>You can parameterize classes with type variables:</p> <pre><code># example_8.py\n\n\nclass Box[T]:\n    def __init__(self, content: T):\n        self.content = content\n\n    def get_content(self) -&gt; T:\n        return self.content\n</code></pre> <p><code>Box[T]</code> is a generic class that can hold a value of type T. One can create <code>Box[int]</code>, <code>Box[str]</code>, etc., and the methods will be type-safe.</p> <p>When subclassing generics or creating more complex hierarchies, you might need to be mindful of type variance, but for most user-defined generics, the default invariance (type must match exactly) is fine.</p>"},{"location":"Z02_Appendix_Reference/#typingtype-for-class-objects","title":"<code>typing.Type</code> for Class Objects","text":"<p>When you want to indicate that a function parameter or return is not an instance of a class but rather a class itself, use <code>Type[T]</code> (or <code>type[T]</code> in Python 3.9+) where T is a class. For example, <code>def factory(cls: type[T]) -&gt; T:</code> indicates that <code>factory</code> expects a class (subclass) of T and will return an instance of that class. If you want to accept specific subclasses, you can use a union; for example, <code>user_class: type[BasicUser]</code> means a class object inheriting from <code>BasicUser</code>. In documentation, you may see <code>Type[Base]</code> to mean \"any subclass of Base.\" This is helpful for functions that need to work with class constructors or class methods.</p>"},{"location":"Z02_Appendix_Reference/#structural-subtyping-with-protocols","title":"Structural Subtyping with Protocols","text":"<p>Python's static typing supports structural typing via <code>Protocol</code> classes.</p>"},{"location":"Z02_Appendix_Reference/#protocols-pep-544","title":"Protocols (PEP 544)","text":"<p>A <code>Protocol</code> defines a set of methods and properties that a type must have to satisfy the protocol, without requiring inheritance. For example:</p> <pre><code># example_9.py\nfrom typing import Protocol\n\n\nclass SupportsClose(Protocol):\n    def close(self) -&gt; None: ...\n</code></pre> <p>Any object with a <code>.close()</code> method returning None will be considered a <code>SupportsClose</code> for static typing purposes, even if it doesn't inherit from <code>SupportsClose</code>. This is akin to an interface or \"duck typing\" check. Protocols enable static type checking of duck-typed code. If you mark a protocol with <code>@typing.runtime_checkable</code>, you can even use <code>isinstance(obj, ProtocolName)</code> at runtime; this checks for the presence of required attributes. Protocols can themselves be generic (e.g., an <code>Iterable[T]</code> protocol defines an <code>__iter__</code> that yields <code>T</code>). The standard library defines many protocols (e.g. <code>typing.Iterable</code>, <code>typing.Sized</code>) that correspond to common Python protocols. Using Protocols allows one to write functions that accept any object that \"has the right methods,\" enabling flexible, decoupled code with static checks. PEP 544 formalized this in Python 3.8; it's an extension of abstract base classes (ABCs) toward a more implicit structural approach.</p>"},{"location":"Z02_Appendix_Reference/#callable-types-and-function-overloading","title":"Callable Types and Function Overloading","text":"<p>Functions are first-class in Python, so you may want to annotate variables or parameters that are themselves functions (callables).</p>"},{"location":"Z02_Appendix_Reference/#callable","title":"Callable","text":"<p>The <code>typing.Callable</code> type is used to describe the signature of a callable. For example, <code>Callable[[int, str], bool]</code> means \"a callable that takes an <code>int</code> and a <code>str</code> and returns a <code>bool</code>.\" If you don't want to specify the parameters (so you can accept any callable returning a specific type), use an ellipsis: <code>Callable[..., bool]</code> means any callable returning bool. For example:</p> <pre><code># example_10.py\nfrom typing import Callable\n\n\ndef apply_to_ints(\n    func: Callable[[int, int], int], a: int, b: int\n) -&gt; int:\n    return func(a, b)\n</code></pre> <p>This function takes another function <code>func</code> that adds or combines two ints and returns int. When you pass a lambda or function to <code>apply_to_ints</code>, a type checker will ensure it matches the described signature.</p>"},{"location":"Z02_Appendix_Reference/#overloaded-functions-pep-484","title":"Overloaded Functions (PEP 484)","text":"<p>Sometimes a function can be called with different argument types and behave differently (especially common in library stubs). The <code>@typing.overload</code> decorator allows you to declare multiple overload variants for a function for static typing purposes. For example:</p> <pre><code># example_11.py\nfrom typing import overload\n\n\n@overload\ndef read(data: bytes) -&gt; str: ...\n\n\n@overload\ndef read(data: str) -&gt; str: ...\n\n\ndef read(data: str | bytes) -&gt; str:\n    # single implementation handling both\n    return data.decode() if isinstance(data, bytes) else data\n</code></pre> <p>Here two overloads declare that <code>read()</code> accepts either bytes or str and always returns str. The implementation (without @overload) handles both. Type checkers will resolve calls to the appropriate signature. Overloading is for the benefit of static analysis; at runtime only the final implementation exists.</p>"},{"location":"Z02_Appendix_Reference/#override-decorator-pep-698","title":"Override decorator (PEP 698)","text":"<p>In Python 3.12 the <code>typing.override</code> decorator was added to improve correctness in class hierarchies. You place <code>@override</code> on a method to override a method of the same name in the base class. This doesn't change runtime behavior, but a type checker will verify that you are overriding a base class method and that your method's signature is compatible with the base class version. This helps catch errors where you intended to override a method but misspelled its name or got the signature wrong. Using <code>@override</code> can make code maintenance safer in large class hierarchies.</p>"},{"location":"Z02_Appendix_Reference/#parameter-specification-variables-for-higher-order-functions-pep-612","title":"Parameter Specification Variables for Higher-Order Functions (PEP 612)","text":"<p>PEP 612 introduced parameter specification variables to support typing of higher-order functions--functions that accept or return other functions with arbitrary signatures. A parameter specification variable, typically denoted <code>**P</code>, captures a list of parameters (types and kinds) of a <code>Callable</code>. For example, you might write:</p> <pre><code># example_12.py\nfrom typing import Callable\n\n\ndef make_logged[**P](\n    func: Callable[P, int],\n) -&gt; Callable[..., int]:\n    def wrapper(\n        prefix: str, *args: P.args, **kwargs: P.kwargs\n    ) -&gt; int:\n        print(f\"{prefix} Calling: {func.__name__}\")\n        result = func(*args, **kwargs)\n        print(f\"{prefix} Result: {result}\")\n        return result\n\n    return wrapper\n\n\n@make_logged\ndef add(x: int, y: int) -&gt; int:\n    return x + y\n\n\nadd(\"[LOG]\", 3, 4)\n## [LOG] Calling: add\n## [LOG] Result: 7\n</code></pre> <p><code>make_logged</code> takes a function <code>func</code> that returns an <code>int</code> and has some parameters <code>**P</code>. It returns a new function that adds a <code>prefix: str</code> in front of <code>func</code>'s parameters. We use <code>Callable[P, int]</code> to represent the input function's signature and <code>Callable[..., int]</code> for the wrapper's signature. <code>**P</code> allows the wrapper to forward the original function's parameters while adding new ones, preserving full type information. This technique is useful for decorators and wrapper functions that modify call signatures.</p>"},{"location":"Z02_Appendix_Reference/#advanced-and-new-type-constructs","title":"Advanced and New Type Constructs","text":""},{"location":"Z02_Appendix_Reference/#literal-types-pep-586-and-pep-675","title":"Literal Types (PEP 586 and PEP 675)","text":"<p>A <code>Literal</code> type allows you to indicate that a value is not just of a general type, but a specific constant value (or one of a specific set of constants). For example, <code>Literal[\"GET\", \"POST\"]</code> can be used to type a variable that should only ever equal <code>\"GET\"</code> or <code>\"POST\"</code>. This is helpful for functions that behave differently based on constant string or numeric inputs. In Python 3.8, PEP 586 introduced <code>typing.Literal</code>. E.g. <code>def set_mode(mode: Literal[\"fast\", \"slow\"]) -&gt; None:...</code> means mode must be one of those two strings. More recently, PEP 675 (Python 3.11) added <code>LiteralString</code>, a special type to mark literal strings for security-sensitive APIs. <code>LiteralString</code> is a subtype of <code>str</code> that static analyzers treat as strings that are either literal in the source or derived from other literal strings. The goal is to prevent untrusted or dynamic strings from flowing into places where they could cause injection attacks (SQL queries, shell commands, etc.). For example:</p> <pre><code># example_13.py\nfrom typing import LiteralString\n\n\ndef run_query(query: LiteralString):  # noqua\n    ...\n\n\nrun_query(\"SELECT * FROM users\")  # OK, literal\nq = \"DROP TABLE users\"\n# type checker error (q is not literal):\nrun_query(q)  # type: ignore\n</code></pre> <p>Here, passing a non-literal string to <code>run_query</code> would be flagged by a type checker. Literal types thus allow more precise typing for functions expecting fixed values or literal-derived values.</p>"},{"location":"Z02_Appendix_Reference/#final-and-constants-pep-591","title":"Final and Constants (PEP 591)","text":"<p>To indicate that a name should not be reassigned (treated as a constant in type-checking), use the <code>Final</code> qualifier. For example, <code>MAX_SIZE: Final[int] = 100</code> tells the type checker that <code>MAX_SIZE</code> should never be re-bound to a different value or type. Attempting to assign to it elsewhere produces a type error. You can also mark classes as <code>final</code> using <code>@typing.final</code> decorator, which means the class is not intended to be subclassed. Similarly, marking a method with <code>@final</code> means it should not be overridden in subclasses. This is purely for type checker and linters; Python won't prevent subclassing or overriding at runtime, but it helps catch design violations in large projects. Using <code>Final</code> is useful for constants or to explicitly close off class hierarchies when appropriate.</p>"},{"location":"Z02_Appendix_Reference/#annotated-types-pep-593","title":"Annotated Types (PEP 593)","text":"<p><code>Annotated</code> was added in Python 3.9 to enrich type annotations with additional metadata that third-party consumers can use. It supports use-cases like data validation, ORM field specifications, or units attached to values, all while keeping the primary type information.</p> <p>Its syntax is <code>Annotated[T, X]</code> where <code>T</code> is a normal type and <code>X</code> is metadata (which can be any value, often a class or string). This metadata can be used by frameworks or tools at runtime or by linters for additional validation. For instance, one can annotate a type with a range, as in <code>Annotated[int, Between(0, 100)]</code> to indicate an <code>int</code> that should lie between 0 and 100. The Python interpreter and core type checkers mostly ignore the second argument of <code>Annotated</code> (they treat the variable as just type <code>T</code>), but specific libraries can inspect it.</p>"},{"location":"Z02_Appendix_Reference/#type-guards-pep-647","title":"Type Guards (PEP 647)","text":"<p>A type guard is a special kind of function that informs the type checker of a type refinement. Introduced in Python 3.10, <code>typing.TypeGuard</code> is used as a return annotation on a boolean function to indicate that if the function returns True, its argument is of a certain type. For example:</p> <pre><code># example_14.py\nfrom typing import TypeGuard\n\n\ndef is_str_list(\n    vals: list[object],\n) -&gt; TypeGuard[list[str]]:\n    return all(isinstance(x, str) for x in vals)\n</code></pre> <p>Here, <code>is_str_list</code> returns a <code>bool</code>, but the <code>TypeGuard[list[str]]</code> annotation tells the checker that upon a True result, the input <code>vals</code> can be treated as <code>list[str]</code> (not just a <code>list</code> of object). This enables writing custom <code>isinstance</code>-like helpers that narrow types. Python's <code>match</code> statement and <code>isinstance</code> checks also perform narrowing; TypeGuard extends this to user-defined predicates. This concept helps make code with conditional type logic (like parsing JSON to specific shapes) more type-safe and clear to the type checker.</p>"},{"location":"Z02_Appendix_Reference/#self-type-pep-673","title":"<code>Self</code> Type (PEP 673)","text":"<p>In class methods that return <code>self</code> (or class/instance attributes of the same class type), Python 3.11 introduced <code>typing.Self</code> to simplify the annotation. Using <code>Self</code> in a method return type or parameter type means \"the same type as the class in which this method is defined.\" For example:</p> <pre><code># example_15.py\nfrom typing import Self\n\n\nclass MyBuilder:\n    def set_name(self, name: str) -&gt; Self:\n        self.name = name  # type: ignore\n        return self\n</code></pre> <p>The return type <code>Self</code> indicates that <code>set_name</code> returns the exact same class (<code>MyBuilder</code> in this case). In subclasses, it will correctly infer the subclass type. Without <code>Self</code>, one would have to use a type variable bound to the class, or a string annotation of the class name--both less convenient. Common use cases for <code>Self</code> are fluent interfaces (methods that return <code>self</code>), alternative constructors (<code>classmethod</code>s that return an instance of <code>cls</code>), and methods like <code>__enter__</code> in context managers that conventionally return self. <code>Self</code> ensures the return type is automatically updated in subclasses, preventing type checkers from thinking a subclass method returning <code>self</code> is returning the base class.</p>"},{"location":"Z02_Appendix_Reference/#typeddicts-pep-589-and-extensions","title":"TypedDicts (PEP 589 and extensions)","text":"<p>A <code>TypedDict</code> is a way to describe the expected shape of dictionaries with specific string keys. Introduced in Python 3.8, TypedDict allows you to create a type that expects certain keys with certain value types, mimicking the behavior of JavaScript objects or dataclasses but for dicts. For example:</p> <pre><code># example_16.py\nfrom typing import TypedDict\n\n\nclass Movie(TypedDict):\n    title: str\n    year: int\n</code></pre> <p>This defines a type <code>Movie</code> that is a dict with keys <code>\"title\"</code> (str) and <code>\"year\"</code> (int). Any extra keys would be a type checker error, and missing required keys are also an error. At runtime, a <code>TypedDict</code> is just a plain <code>dict</code> (there's no special dictionary class), so this is a static construct only. You can also create TypedDict types using a functional syntax: <code>Movie = TypedDict('Movie', {'title': str, 'year': int})</code>. By default, all keys are required, but you can make some optional. Initially, you could specify <code>total=False</code> on the TypedDict to make all keys optional. Later, PEP 655 (Python 3.11) introduced <code>Required</code> and <code>NotRequired</code> markers to allow fine-grained control: you can mark individual keys as optional in an otherwise total TypedDict. For example:</p> <pre><code># example_17.py\nfrom typing import TypedDict, Required, NotRequired\n\n\nclass Movie(TypedDict, total=False):\n    title: Required[str]  # must have title\n    year: NotRequired[int]  # may omit year\n</code></pre> <p>This says <code>title</code> is always required, <code>year</code> can be omitted. When using <code>total=False</code>, by default all keys are optional unless marked <code>Required</code>. Conversely, with <code>total=True</code> (default), all keys are required unless marked <code>NotRequired</code>. \\ Another addition is PEP 705 (Python 3.13) which introduced <code>typing.ReadOnly</code> for TypedDict. This designates certain keys as read-only (cannot be changed once set) for static checking purposes. Example: <code>class Config(TypedDict): host: ReadOnly[str]; port: int</code>. Changing <code>host</code> after creation would be flagged. This is helpful to model immutable data within dictionaries. \\ TypedDicts are particularly useful for structures like configuration dicts or JSON data, where you want static validation of keys. They are also used in kwargs type annotations: Python 3.11 allows \"spreading\" a TypedDict into function arguments withkwargs (PEP 692). For instance, <code>def create_movie(**kwargs: Unpack[Movie]) -&gt; None:</code> will ensure that the keyword arguments match the Movie TypedDict schema. Here <code>typing.Unpack</code> is used to unpack the TypedDict type. This feature helps in writing functions that explicitly accept a set of keyword arguments without listing them in the function signature.</p>"},{"location":"Z02_Appendix_Reference/#data-class-transform-pep-681","title":"Data Class Transform (PEP 681)","text":"<p>Python's <code>dataclasses</code> module and third-party libraries like Pydantic or attrs generate methods (like <code>__init__</code>, <code>__repr__</code>) automatically based on class attributes. PEP 681 introduced the <code>typing.dataclass_transform</code> decorator (Python 3.11) which library authors can apply to their decorator or metaclass to tell static type checkers that the decorator will produce certain dunder methods or behaviors similar to <code>dataclasses</code>. For example, Pydantic's <code>BaseModel</code> or attr's <code>@define</code> can use this so that type checkers know that after applying the decorator, the class has an <code>__init__</code> with parameters corresponding to the annotated fields. This is a more advanced feature primarily for library developers to improve user experience of static typing when using those libraries.</p>"},{"location":"Z02_Appendix_Reference/#forward-references-and-postponed-evaluation","title":"Forward References and Postponed Evaluation","text":""},{"location":"Z02_Appendix_Reference/#forward-references","title":"Forward References","text":"<p>It's common to have types that refer to classes or types not yet defined (e.g., a method in class <code>A</code> that returns an instance of class <code>B</code> defined later in the file). To handle this, Python allows using string literals in annotations for forward references. For example:</p> <pre><code># example_18.py\nclass Node:\n    def add_child(self, child: \"Node\") -&gt; None: ...\n</code></pre> <p>The quotes allow <code>Node</code> to be incompletely defined when the annotation is evaluated. Quoted annotations defer evaluation of that name. In Python 3.7+, an alternative to quoting every forward reference is to use <code>from __future__ import annotations</code>, which causes all annotations to be stored as strings by default (PEP 563). This \"postponed evaluation\" was optional in 3.7--3.9 and was meant to become the default behavior in Python 3.10. However, that plan was revised: PEP 563's default activation was put on hold. The Python steering council decided not to turn on the automatic stringification by default due to various issues it caused for runtime introspection and decided to explore a different approach (PEP 649).</p>"},{"location":"Z02_Appendix_Reference/#pep-649-deferred-annotations","title":"PEP 649 (Deferred Annotations)","text":"<p>PEP 649, accepted for Python's future (targeted for 3.13+), proposes a new mechanism where annotations are neither evaluated at function definition time nor stored as strings. Instead, annotations would be stored as code in a special function (<code>__annotate__</code>) that computes them on demand. This aims to solve forward references and performance issues more elegantly: the evaluation of annotations is deferred until needed, without losing the object references or incurring the issues of stringified annotations. As of the latest Python (3.12), this is still in progress--by default, Python 3.12 still evaluates annotations normally (unless you use the future import). When writing modern code, you can rely on <code>from __future__ import annotations</code> to handle most forward references conveniently (or just use quotes for specific cases). Static type checkers themselves resolve forward references even if you leave them as raw names, so this is mostly a runtime concern for introspection via <code>inspect.get_annotations</code> or similar. The takeaway: forward references are supported via quoting or future imports, and the language is evolving to make annotation evaluation lazy by default in a robust way.</p>"},{"location":"Z02_Appendix_Reference/#tools-stubs-and-practices","title":"Tools, Stubs, and Practices","text":""},{"location":"Z02_Appendix_Reference/#type-checkers-and-ide-support","title":"Type Checkers and IDE Support","text":"<p>To make the most of type annotations, use a static type checker (like mypy, pyright, Pyre) or an IDE with built-in checking (PyCharm, VS Code, etc.). These tools will read your annotations and warn you of type mismatches, missing return statements for functions declared to return non-<code>None</code>, improper overrides, etc. The type system is standardized enough that most checkers agree on core behavior. You can customize their strictness (for example, disallowing implicit <code>Any</code> types). Run these checkers as part of your development or CI process to catch bugs early.</p>"},{"location":"Z02_Appendix_Reference/#stub-files-pep-484-pep-561","title":"Stub Files (PEP 484 &amp; PEP 561)","text":"<p>If you are using a library that isn't annotated, or you cannot modify source code to add annotations (e.g., C extension modules or third-party code), you can use stub files (<code>.pyi</code> files) to provide type information. A stub file is a skeletal version of a module with only <code>pass</code> statements and type annotations. PEP 561 describes how libraries can distribute these stubs so that your type checker picks them up. For instance, popular libraries often ship a <code>py.typed</code> marker and include inline types or separate stub packages (e.g. <code>types-requests</code>). As a user, you typically don't need to write stub files unless you're providing types for an untyped library or doing something very dynamic. But it's good to know that the ecosystem supports them, enabling gradual adoption of typing even for older code.</p>"},{"location":"Z02_Appendix_Reference/#general-best-practices","title":"General Best Practices","text":"<ul> <li>Adopt Gradually: You don't have to annotate everything at once.   It's common to start by annotating function signatures of key modules or adding stubs for critical libraries.   Unannotated code defaults to <code>Any</code> types, which type checkers will by default let pass (or you can configure them to be strict).</li> <li>Be Comprehensive in Signatures: For a function that you're annotating, try to annotate all parameters and the return type.   Partial annotations can sometimes mislead type inference.   If a function returns nothing, use <code>-&gt; None</code> for clarity.   If a parameter has a default, remember that doesn't automatically make it Optional unless you intend <code>None</code> as a valid value.</li> <li>Prefer Specific Types or Protocols: When annotating arguments, use the most general type that works for your function (Liskov substitution principle).   For example, if your function only needs to read from a collection, annotate it as <code>Iterable[T]</code> or <code>Sequence[T]</code> instead of <code>list[T]</code>, to allow more types (like tuples, sets).   If a parameter can be any object with a certain method, consider using a Protocol instead of a concrete class.   Conversely, for return types, it's usually best to be as specific as possible (don't return <code>Any</code> if you can return a concrete type).</li> <li>Use Modern Syntax: Prefer the new concise annotation syntax that Python now supports.   This means using built-in collection types (e.g.   <code>list[int]</code> rather than <code>typing.List[int]</code>) , using <code>X | Y</code> for unions rather than <code>typing.Union[X, Y]</code> , and <code>X | None</code> instead of <code>typing.Optional[X]</code>.   These make annotations more readable.   The older syntax is still accepted for compatibility, but the newer syntax is encouraged in current code.</li> <li>Limit <code>Any</code> and Unsafe Casts: Try to avoid using <code>Any</code> unless absolutely necessary.   If you find yourself needing to bypass the type system (via casts or <code># type: ignore</code> comments), consider if there's a better way--such as using Union types, overloading, or restructuring code.   If you do use <code>Any</code> (for example, when interfacing with dynamically typed libraries), isolate it at the boundary of your code.</li> <li>Leverage Type Narrowing: Write code in a type-friendly way.   Use <code>isinstance</code> checks or guard functions (even custom TypeGuard functions) to narrow types, instead of, say, <code>assert isinstance(x, SomeType)</code> which some type checkers might not understand.   Many checkers can infer that after <code>if isinstance(obj, str):... else:...</code>, in the else branch <code>obj</code> is not a str.   This makes your code safer and your type checker happier.</li> <li>Keep Types Up to Date: Treat type annotations as part of the code documentation.   If the code changes, update the annotations to match.   Inconsistencies between code and annotations can be more confusing than no annotations.   Running a type checker will catch these mismatches.</li> <li>Performance Consideration: Annotations are designed to have minimal runtime overhead.   They're stored as metadata and can be turned into strings with <code>from __future__ import annotations</code>.   Unless you introspect them at runtime (with <code>typing.get_type_hints()</code>), they won't slow down your program.   That said, using a type checker in development might slightly slow down your build/test cycle, but it's usually worth the trade-off for the bugs it prevents.</li> </ul> <p>Each of these topics is elaborated in the official and Python Enhancement Proposals. For further reading, the typing section in the Python documentation is an excellent resource. They provide code examples and deeper explanations for advanced scenarios, helping you stay up to date with the evolving landscape of type annotations in modern Python.</p>"},{"location":"Z02_Appendix_Reference/#references","title":"References","text":"<ol> <li>typing--Support for type hints--Python 3.13.2 documentation</li> <li>PEP 484--Type Hints | peps.python.org</li> <li>Did You Know Some Types in Python's Typing Module Are Now...</li> <li>Typing Best Practices--typing documentation</li> <li>What's New In Python 3.12--Python 3.13.2 documentation</li> <li>What's New In Python 3.11--Python 3.13.2 documentation</li> <li>PEP 649--Deferred Evaluation Of Annotations Using Descriptors | peps.python.org</li> <li>Distributing type information--typing documentation</li> <li>Python typing documentation</li> <li>\"Typing Cheat Sheet\" for Python</li> </ol>"},{"location":"Z03_Appendix_Guidelines/","title":"Appendix: Guidelines","text":"<p>[[Needs lots of work]]</p> <p>This placeholder text was generated by ChatGPT 4.5. It will be significantly rewritten as the book is developed. You can add comments to either https://bsky.app/bruceeckel or Github Issues.</p>"},{"location":"Z03_Appendix_Guidelines/#effective-patterns-for-clear-and-maintainable-annotations","title":"Effective Patterns for Clear and Maintainable Annotations","text":"<p>Clear type annotations significantly improve code quality and maintainability:</p>"},{"location":"Z03_Appendix_Guidelines/#consistent-type-annotation-style","title":"Consistent Type Annotation Style","text":"<ul> <li>Standardize type annotations across your project.</li> <li>Clearly annotate function signatures, class attributes, and return types.</li> </ul> <pre><code># example_1.py\ndef calculate_area(width: float, height: float) -&gt; float:\n    return width * height\n</code></pre>"},{"location":"Z03_Appendix_Guidelines/#use-type-aliases-for-complex-types","title":"Use Type Aliases for Complex Types","text":"<p>Simplify repetitive or complex annotations:</p> <pre><code># example_2.py\ntype UserData = dict[str, list[int]]\n\n\ndef process_data(data: UserData) -&gt; None:\n    pass\n</code></pre> <p>Type aliases enhance readability, making complex types easier to understand.</p>"},{"location":"Z03_Appendix_Guidelines/#leverage-dataclasses-and-typeddicts","title":"Leverage Dataclasses and TypedDicts","text":"<ul> <li>Dataclasses simplify structured data definitions.</li> <li>TypedDicts clarify expected dictionary structures.</li> </ul> <pre><code># example_3.py\nfrom dataclasses import dataclass\n\n\n@dataclass\nclass User:\n    id: int\n    name: str\n</code></pre> <p>These patterns improve explicitness and reduce boilerplate code.</p>"},{"location":"Z03_Appendix_Guidelines/#common-pitfalls-and-how-to-avoid-them","title":"Common Pitfalls and How to Avoid Them","text":""},{"location":"Z03_Appendix_Guidelines/#overusing-any","title":"Overusing <code>Any</code>","text":"<p>Overuse of <code>Any</code> defeats the purpose of type annotations:</p> <ul> <li>Pitfall:</li> </ul> <pre><code># example_4.py\nfrom typing import Any\n\n\ndef process(data: Any) -&gt; Any:\n    pass\n</code></pre> <ul> <li>Solution: Provide specific type annotations whenever possible.</li> </ul>"},{"location":"Z03_Appendix_Guidelines/#missing-or-inconsistent-annotations","title":"Missing or Inconsistent Annotations","text":"<p>Incomplete annotations lead to confusion:</p> <ul> <li>Always annotate public APIs clearly.</li> <li>Regularly review annotations during code reviews.</li> </ul>"},{"location":"Z03_Appendix_Guidelines/#complex-union-types","title":"Complex Union Types","text":"<p>Avoid overly complex union types:</p> <ul> <li>Pitfall:</li> </ul> <pre><code># example_5.py\n\n\ndef handle(\n    value: int | str | None | float,\n) -&gt; None:\n    pass\n</code></pre> <ul> <li>Solution: Refactor to simplify or use custom types.</li> </ul>"},{"location":"Z03_Appendix_Guidelines/#balancing-simplicity-readability-and-explicitness","title":"Balancing Simplicity, Readability, and Explicitness","text":""},{"location":"Z03_Appendix_Guidelines/#simplicity","title":"Simplicity","text":"<ul> <li>Aim for the simplest annotation that accurately represents the type.</li> </ul>"},{"location":"Z03_Appendix_Guidelines/#readability","title":"Readability","text":"<ul> <li>Ensure annotations improve, rather than obscure, readability.</li> </ul>"},{"location":"Z03_Appendix_Guidelines/#explicitness","title":"Explicitness","text":"<ul> <li>Favor explicit annotations that clarify intent, especially at API boundaries.</li> </ul> <p>Striking the right balance ensures maintainable and understandable code.</p>"},{"location":"Z03_Appendix_Guidelines/#strategies-for-large-scale-typed-codebases","title":"Strategies for Large-Scale Typed Codebases","text":"<p>Managing large-scale typed codebases requires strategic approaches:</p>"},{"location":"Z03_Appendix_Guidelines/#incremental-adoption","title":"Incremental Adoption","text":"<ul> <li>Gradually introduce type annotations to existing codebases.</li> <li>Prioritize critical and frequently changed components.</li> </ul>"},{"location":"Z03_Appendix_Guidelines/#automate-type-checking","title":"Automate Type Checking","text":"<ul> <li>Integrate tools like <code>mypy</code> and <code>pyright</code> into CI/CD.</li> <li>Regularly enforce type checking to maintain standards.</li> </ul>"},{"location":"Z03_Appendix_Guidelines/#continuous-review-and-improvement","title":"Continuous Review and Improvement","text":"<ul> <li>Regularly review annotations during code reviews.</li> <li>Address inconsistencies and improve clarity over time.</li> </ul>"},{"location":"Z03_Appendix_Guidelines/#comprehensive-documentation","title":"Comprehensive Documentation","text":"<ul> <li>Document type annotation standards and practices.</li> <li>Ensure all team members follow consistent annotation strategies.</li> </ul> <p>Implementing these strategies helps sustain clarity, maintainability, and robustness in large, typed Python projects.</p>"},{"location":"Z04_Appendix_Automatic_Annotations/","title":"Appendix: Automatic Annotations","text":"<p>[Too specific to mypy--should cover other tools]</p> <p>This placeholder text was generated by ChatGPT 4.5. It will be significantly rewritten as the book is developed. You can add comments to either https://bsky.app/bruceeckel or Github Issues.</p>"},{"location":"Z04_Appendix_Automatic_Annotations/#introduction-to-pyi-stub-files","title":"Introduction to <code>.pyi</code> Stub Files","text":"<p><code>.pyi</code> stub files provide type annotations for Python modules, especially useful when source code lacks annotations or is unavailable:</p> <ul> <li>Contains type definitions without implementations.</li> <li>Enables static type checking for third-party libraries.</li> </ul> <p>Example:</p> <pre><code># math.pyi\ndef sqrt(x: float) -&gt; float: ...\n</code></pre> <p>Stub files clearly document expected types, significantly improving interoperability.</p>"},{"location":"Z04_Appendix_Automatic_Annotations/#generating-stubs-automatically-with-stubgen","title":"Generating Stubs Automatically with <code>stubgen</code>","text":"<p><code>stubgen</code> is a tool included with <code>mypy</code> to automatically generate stub files from existing Python code:</p>"},{"location":"Z04_Appendix_Automatic_Annotations/#installation-and-basic-use","title":"Installation and Basic Use","text":"<pre><code>pip install mypy\nstubgen -m your_module\n</code></pre> <p>Generates a <code>.pyi</code> file with inferred annotations, saving manual effort:</p> <pre><code># generated_example.pyi\ndef greet(name: str) -&gt; str: ...\n</code></pre> <p>Auto-generated stubs provide a starting point for type annotations.</p>"},{"location":"Z04_Appendix_Automatic_Annotations/#writing-effective-stubs-manually","title":"Writing Effective Stubs Manually","text":"<p>Manual stub writing is essential when automatic inference is insufficient:</p>"},{"location":"Z04_Appendix_Automatic_Annotations/#example-stub-file","title":"Example Stub File","text":"<pre><code># custom_module.pyi\nclass User:\n    id: int\n    name: str\n\n\ndef fetch_user(user_id: int) -&gt; User: ...\n</code></pre>"},{"location":"Z04_Appendix_Automatic_Annotations/#practices","title":"Practices","text":"<ul> <li>Clearly annotate arguments and return types.</li> <li>Use ellipsis (<code>...</code>) to indicate stub implementation.</li> <li>Reflect original module's behavior accurately.</li> </ul> <p>Manual stub files enhance readability and ensure accurate type definitions.</p>"},{"location":"Z04_Appendix_Automatic_Annotations/#distributing-and-versioning-typing-stubs","title":"Distributing and Versioning Typing Stubs","text":"<p>Typing stubs can be distributed independently or alongside the original package:</p>"},{"location":"Z04_Appendix_Automatic_Annotations/#bundled-with-package","title":"Bundled with Package","text":"<p>Include stubs directly in your package:</p> <pre><code>your_package/\n\u251c\u2500\u2500 __init__.py\n\u2514\u2500\u2500 __init__.pyi\n</code></pre>"},{"location":"Z04_Appendix_Automatic_Annotations/#separate-distribution","title":"Separate Distribution","text":"<p>Publish stubs as standalone packages:</p> <pre><code>pip install types-requests\n</code></pre> <p>Use semantic versioning aligned with the original package for clarity and compatibility:</p> <pre><code>types-requests==2.25.1\n</code></pre> <p>Effective versioning ensures seamless integration and updates.</p>"},{"location":"Z04_Appendix_Automatic_Annotations/#typing-third-party-libraries-without-native-annotations","title":"Typing Third-party Libraries without Native Annotations","text":"<p>When third-party libraries lack native annotations:</p>"},{"location":"Z04_Appendix_Automatic_Annotations/#use-third-party-typing-packages","title":"Use Third-party Typing Packages","text":"<p>Install existing typing packages from PyPI:</p> <pre><code>pip install types-requests\n</code></pre>"},{"location":"Z04_Appendix_Automatic_Annotations/#custom-stubs","title":"Custom Stubs","text":"<p>Write custom stub files within your project:</p> <pre><code>stubs/\n\u251c\u2500\u2500 requests.pyi\n</code></pre>"},{"location":"Z04_Appendix_Automatic_Annotations/#ignoring-missing-annotations","title":"Ignoring Missing Annotations","text":"<p>Temporarily ignore missing annotations with <code>mypy</code> configuration:</p> <pre><code>[mypy-requests]\nignore_missing_imports = True\n</code></pre> <p>Using stubs significantly improves type checking for libraries without built-in annotations, maintaining robust and reliable codebases.</p>"},{"location":"Z05_Appendix_Type_Checkers/","title":"Appendix: Type Checkers","text":"<p>This placeholder text was generated by ChatGPT 4.5. It will be significantly rewritten as the book is developed. You can add comments to either https://bsky.app/bruceeckel or Github Issues.</p>"},{"location":"Z05_Appendix_Type_Checkers/#getting-started-with-mypy-installation-and-basic-use","title":"Getting Started with <code>mypy</code>: Installation and Basic Use","text":"<p><code>mypy</code> is a popular static type checker for Python that validates type annotations:</p>"},{"location":"Z05_Appendix_Type_Checkers/#installation","title":"Installation","text":"<pre><code>pip install mypy\n</code></pre>"},{"location":"Z05_Appendix_Type_Checkers/#basic-use","title":"Basic Use","text":"<p>Run <code>mypy</code> on your script or module to identify type errors:</p> <pre><code>mypy your_script.py\n</code></pre> <p>Example:</p> <pre><code># script.py\n\n\ndef greet(name: str) -&gt; str:\n    return f\"Hello, {name}!\"\n\n\n# Incorrect type:\nprint(greet(123))  # type: ignore\n## Hello, 123!\n</code></pre> <p>Running <code>mypy script.py</code> outputs:</p> <pre><code>script.py:4: error: Argument 1 to \"greet\" has incompatible type \"int\"; expected \"str\"\n</code></pre>"},{"location":"Z05_Appendix_Type_Checkers/#advanced-configuration-and-fine-tuning-of-mypy","title":"Advanced Configuration and Fine-tuning of <code>mypy</code>","text":"<p>Customize <code>mypy</code> behavior using a <code>mypy.ini</code> or <code>pyproject.toml</code> file:</p>"},{"location":"Z05_Appendix_Type_Checkers/#example-mypyini","title":"Example <code>mypy.ini</code>","text":"<pre><code>[mypy]\nignore_missing_imports = True\nstrict = True\ncheck_untyped_defs = True\n</code></pre>"},{"location":"Z05_Appendix_Type_Checkers/#example-pyprojecttoml","title":"Example <code>pyproject.toml</code>","text":"<pre><code>[tool.mypy]\nignore_missing_imports = true\nstrict = true\n</code></pre> <p>Advanced configuration allows precise control over type-checking behavior and strictness levels.</p>"},{"location":"Z05_Appendix_Type_Checkers/#exploring-pyright-and-ide-integration-vscode-pycharm","title":"Exploring <code>pyright</code> and IDE Integration (VSCode, PyCharm)","text":"<p><code>pyright</code>, developed by Microsoft, offers high-performance static type checking, integrated seamlessly with popular IDEs.</p>"},{"location":"Z05_Appendix_Type_Checkers/#using-pyright-cli","title":"Using <code>pyright</code> (CLI)","text":"<p>Install globally using npm:</p> <pre><code>npm install -g pyright\npyright your_script.py\n</code></pre>"},{"location":"Z05_Appendix_Type_Checkers/#vscode-integration","title":"VSCode Integration","text":"<p><code>pyright</code> powers VSCode's built-in Python type checking, providing immediate feedback:</p> <ul> <li>Install the Python extension in VSCode.</li> <li>Real-time inline error highlighting and suggestions.</li> </ul>"},{"location":"Z05_Appendix_Type_Checkers/#pycharm-integration","title":"PyCharm Integration","text":"<p>PyCharm supports built-in type checking:</p> <ul> <li>Provides live error detection, highlighting, and quick-fix suggestions.</li> <li>Navigate to <code>Preferences &gt; Editor &gt; Inspections</code> to configure type-checking rules.</li> </ul>"},{"location":"Z05_Appendix_Type_Checkers/#incremental-typing-strategies-gradual-adoption","title":"Incremental Typing Strategies: Gradual Adoption","text":"<p>Adopt typing gradually, focusing first on critical paths:</p> <ul> <li>Annotate high-risk or frequently changing modules first.</li> <li>Enable type checking incrementally to avoid overwhelming your team:</li> </ul> <pre><code>[mypy]\nfiles = core/, utils/\n</code></pre> <p>Incremental typing balances immediate benefits with manageable adoption efforts.</p>"},{"location":"Z05_Appendix_Type_Checkers/#integrating-type-checking-into-continuous-integration","title":"Integrating Type Checking into Continuous Integration","text":"<p>Automate type checking within your CI/CD pipeline to enforce consistency and catch errors early:</p>"},{"location":"Z05_Appendix_Type_Checkers/#example-github-actions-workflow","title":"Example GitHub Actions Workflow","text":"<pre><code>name: Type Check\n\non: [ push, pull_request ]\n\njobs:\n  type-check:\n    runs-on: ubuntu-latest\n\n    steps:\n      - uses: actions/checkout@v3\n      - uses: actions/setup-python@v3\n        with:\n          python-version: \"3.11\"\n\n      - run: pip install mypy\n      - run: mypy .\n</code></pre> <p>Automated checks ensure ongoing compliance with typing standards and maintain high code quality.</p>"},{"location":"Z05_Appendix_Type_Checkers/#handling-and-resolving-common-errors","title":"Handling and Resolving Common Errors","text":"<p>Common type-checking errors and their resolutions:</p>"},{"location":"Z05_Appendix_Type_Checkers/#incorrect-type-annotation","title":"Incorrect Type Annotation","text":"<pre><code># example_2.py\n# Error: Incompatible types in assignment\n# (expression has type \"int\", variable has type \"str\")\nname: str = 123  # type: ignore\n</code></pre>"},{"location":"Z05_Appendix_Type_Checkers/#missing-imports","title":"Missing Imports","text":"<p>Use <code>ignore_missing_imports</code> or install type stubs:</p> <pre><code>[mypy]\nignore_missing_imports = True\n</code></pre> <p>Or install stubs:</p> <pre><code>pip install types-requests\n</code></pre>"},{"location":"Z05_Appendix_Type_Checkers/#union-and-optional-errors","title":"Union and Optional Errors","text":"<p>Resolve ambiguity clearly:</p> <pre><code># example_3.py\nfrom typing import Optional\n\n\n# Error: Incompatible return value type (got \"None\", expected \"int\")\ndef find_index(item: str, items: list[str]) -&gt; Optional[int]:\n    try:\n        return items.index(item)\n    except ValueError:\n        return None\n</code></pre> <p>Effectively handling and resolving these errors leads to clearer, more reliable, and maintainable codebases.</p>"},{"location":"Z06_Appendix_Class_Attributes/","title":"Appendix: Class Attributes","text":"<p>A number of type tools use a syntax that hacks class attribute syntax; the most obvious is dataclasses but there are others. It's important to understand that this is special behavior created by the tool, and that ordinary classes do not behave this way.</p> <p>While contributing to an open-source project, I was stopped short by this (names have been changed):</p> <pre><code># data_point.py\nclass DataPoint:\n    measurement1 = None\n    measurement2 = None\n    measurement3 = None\n\n\nd = DataPoint()\nd.measurement1 = 100  # type: ignore\nd.measurement2 = 200  # type: ignore\nd.measurement3 = 300  # type: ignore\n</code></pre> <p>Why give names and initialization values to <code>class</code> attributes, then when you make an object, immediately create and initialize instance variables with the same names as the class attributes? I began to suspect a misunderstanding about class attributes.</p> <p>I asked one of the coaches of the project (not the original author). They explained that this was the way you provide default values for Python objects. When I attempted to disagree, the effects were demonstrated using a debugger. The argument looked something like this:</p> <pre><code># like_default_values.py\n\n\nclass A:\n    x: int = 100\n\n\na = A()\nprint(f\"{a.x = }\")\n## a.x = 100\na.x = -1\nprint(f\"{a.x = }\")\n## a.x = -1\na2 = A()\nprint(f\"{a2.x = }\")\n## a2.x = 100\n</code></pre> <p>(<code>f\"{a.x = }\"</code> is an f-string feature that eliminates the redundancy of displaying a variable.)</p> <p>Sure enough, if I create an <code>A</code> object called <code>a</code> and ask for <code>a.x</code>, it looks like <code>x</code> has the \"default value\" of <code>100</code>. I can set <code>a.x</code> to <code>-1</code> and create a second <code>A</code> object <code>a2</code> which once again is given the \"default value\" of 100---separate storage appears to have been created and initialized for the <code>x</code> in both <code>a</code> and <code>a2</code>. Based on this example, Python class attributes seem to produce default value behavior.</p>"},{"location":"Z06_Appendix_Class_Attributes/#where-did-this-idea-come-from","title":"Where Did This Idea Come From?","text":"<p>Because of the way class attributes are defined, someone coming from either C++ or Java might assume they work the same as in C++ or Java: Storage for those variables is allocated and initialized before the constructor[^1] is called. Indeed, the first time I saw class attributes used for automated constructor generation (shown later in this appendix), I wondered if I had previously missed something magical about class attributes.</p> <p>Here's a Java example exploring the same ideas:</p> <pre><code>// DefaultValues.java\n// Java automatically initializes from defaults\n\nclass A {\n    int x = 100;\n\n    public A() {\n        // x is already initialized:\n        System.out.println(\"In A constructor: \" + this);\n    }\n\n    @Override\n    public String toString() {\n        return \"x = \" + x;\n    }\n}\n\nclass B {\n    static int x = 100;\n\n    @Override\n    public String toString() {\n        // Accessing static via instance:\n        return \"x = \" + x;\n        // Same as \"x = \" + this.x;\n    }\n\n    static public String statics() {\n        return \"B.statics(): B.x = \" + B.x;\n    }\n    // Cannot shadow identifier names:\n    // int x = -1;\n    // Variable 'x' is already defined in the scope\n}\n\npublic class DefaultValues {\n    public static void main(String[] args) {\n        A a = new A();\n        // In A constructor: x = 100\n        System.out.println(\"a: \" + a);\n        // a: x = 100\n        a.x = -1;\n        System.out.println(\"a: \" + a);\n        // a: x = -1\n        System.out.println(\"new A(): \" + new A());\n        // In A constructor: x = 100\n        // new A(): x = 100\n\n        B b = new B();\n        System.out.println(\"b: \" + b);\n        // b: x = 100\n        System.out.println(B.statics());\n        // B.statics(): B.x = 100\n        // Accessing static via class:\n        B.x = -1;\n        System.out.println(\"b: \" + b);\n        // b: x = -1\n        System.out.println(B.statics());\n        // B.statics(): B.x = -1\n        B b2 = new B();\n        System.out.println(\"b2: \" + b2);\n        // b2: x = -1\n    }\n}\n</code></pre> <p>Inside the constructor <code>A()</code>, the storage for <code>x</code> has already been allocated and initialized. Changing the value of <code>a.x</code> doesn't influence further new <code>A</code> objects, which are initialized to <code>100</code>.</p> <p>In <code>class B</code>, <code>x</code> is changed to a <code>static</code> variable. This means there is only a single piece of <code>x</code> storage for the class---no matter how many instances of that class you create. This is how Python class attributes work: they are <code>static</code> variables without using the <code>static</code> keyword.</p> <p>In <code>B</code>'s <code>toString()</code>, notice that <code>B</code>'s <code>x</code> is accessed the same way it is in <code>Class A</code>'s <code>toString()</code>: as if it were an ordinary object field rather than a <code>static</code> field. When you do this, Java automatically uses the <code>static</code> <code>x</code> even though you are syntactically treating it like the object's <code>x</code>.</p> <p>In <code>statics()</code>, <code>x</code> is accessed through the class by saying <code>B.x</code>. If <code>x</code> were not a <code>static</code> you couldn't do this.</p> <p>At the end of <code>class B</code>, notice that we cannot \"shadow\" an identifier name like we can in Python: we cannot have both an ordinary and a <code>static</code> variable of the same name. <code>main()</code> demonstrates that the <code>static x</code> in <code>B</code> is indeed associated with the class, and there's only one piece of storage shared by all objects of <code>class B</code>.</p> <p>C++ has virtually identical behavior, although <code>static</code> initialization syntax is different for variables:</p> <pre><code>// default_values.cpp\n// C++ automatically initializes from defaults\n// Tested on http://cpp.sh\n#include &lt;iostream&gt;\n\nclass A {\n    public:\n    int x = 100;\n    A() { // x is already initialized:\n        std::cout &lt;&lt; \"constructor: \" &lt;&lt; x &lt;&lt; std::endl;\n    }\n};\n\nclass B {\n    public:\n    static int x;\n    B() { // x has been initialized:\n        std::cout &lt;&lt; \"constructor: \" &lt;&lt; x &lt;&lt; std::endl;\n    }\n    // Cannot shadow identifier name:\n    // int x = 1;\n    // 'int B::x' conflicts with a previous declaration\n};\n\n// Static variables must be initialized outside the class:\nint B::x = 100;\n\n// Static consts are initialized inline:\nclass C {\n    public:\n    static const int x = 100;\n};\n\nint main() {\n    A a;\n    // constructor: 100\n    std::cout &lt;&lt; a.x &lt;&lt; std::endl;\n    // 100\n    a.x = -1;\n    std::cout &lt;&lt; a.x &lt;&lt; std::endl;\n    // -1\n\n    B b;\n    // constructor: 100\n    std::cout &lt;&lt; b.x &lt;&lt; std::endl;\n    // 100\n    // Accessing static via instance:\n    b.x = -1;\n    std::cout &lt;&lt; b.x &lt;&lt; std::endl;\n    // -1\n    // Accessing static via class:\n    B::x = -99;\n    std::cout &lt;&lt; b.x &lt;&lt; std::endl;\n    // -99\n\n    C c;\n    std::cout &lt;&lt; c.x &lt;&lt; std::endl;\n    // 100\n    // Cannot assign to const:\n    // c.x = -1;\n}\n</code></pre> <p>Just like Java, storage is allocated and initialized for <code>x</code> by the time the <code>A()</code> constructor is called.</p> <p>In <code>class B</code>, the <code>static int x</code> definition only indicates that <code>x</code> exists for <code>B</code>. To allocate and initialize static variable storage, the external definition <code>int B::x = 100</code> is required. If, however, the <code>static</code> is <code>const</code>, the initialization value is included in the definition as seen in <code>class C</code>. The compiler is able to inline <code>const</code> values where they are used, so no storage is required.</p> <p>In <code>class B</code>, you see that, like Java, C++ also disallows name shadowing. <code>main()</code> shows that <code>static x</code> can be accessed either through the class or using an instance of the class.</p> <p>Notice that both Java and C++ have explicit <code>static</code> keywords, whereas Python does not. This adds to the confusion, so when a Java or C++ programmer (who has not learned about class attributes) sees something of the form:</p> <pre><code># no_static_keyword.py\nclass X:\n    a = 1\n    b = 2\n    c = 3\n</code></pre> <p>It is quite reasonable to expect the same results as from similar-looking C++ or Java code. After doing a few experiments as in <code>like_default_values.py</code>, a C++ or Java programmer might well conclude that Python does indeed work that way. And, because a class attribute is a single variable that is \"global to the class,\" it can be mistaken for a default value.</p>"},{"location":"Z06_Appendix_Class_Attributes/#how-things-break","title":"How Things Break","text":"<p>Here's the worst thing. Code written with the assumption that class attributes are just default initialization values seems to work most of the time. It seemed to work for the situation I encountered. The code passes its tests, so how can I call it \"wrong?\"</p> <p>The problem occurs when you're least expecting it. Here is just one configuration that produces a surprise:</p> <pre><code># it_all_goes_wrong.py\n\n\nclass A:\n    x: int = 100\n    y: int = 200\n\n    @classmethod\n    def change_x(cls):\n        cls.x = 999\n\n    @classmethod\n    def change_y(cls):\n        cls.y = 313\n\n\ndef reset():\n    A.x = 100\n    A.y = 200\n\n\na1: A = None  # type: ignore\na2: A = None  # type: ignore\na3: A = None  # type: ignore\n\n\ndef display(counter: int):\n    print(f\"display({counter})\")\n    if a1:\n        print(f\"{a1.x = }, {a1.y = }\")\n    if a2:\n        print(f\"{a2.x = }, {a2.y = }\")\n    if a3:\n        print(f\"{a3.x = }, {a3.y = }\")\n\n\na1 = A()\ndisplay(1)\n## display(1)\n## a1.x = 100, a1.y = 200\na1.x = -1\na1.y = -2\ndisplay(2)\n## display(2)\n## a1.x = -1, a1.y = -2\na1.change_x()\ndisplay(3)\n## display(3)\n## a1.x = -1, a1.y = -2\na2 = A()\ndisplay(4)\n## display(4)\n## a1.x = -1, a1.y = -2\n## a2.x = 999, a2.y = 200\na2.y = 17\ndisplay(5)\n## display(5)\n## a1.x = -1, a1.y = -2\n## a2.x = 999, a2.y = 17\nA.change_y()\na3 = A()\ndisplay(6)\n## display(6)\n## a1.x = -1, a1.y = -2\n## a2.x = 999, a2.y = 17\n## a3.x = 999, a3.y = 313\nreset()\ndisplay(7)\n## display(7)\n## a1.x = -1, a1.y = -2\n## a2.x = 100, a2.y = 17\n## a3.x = 100, a3.y = 200\n</code></pre> <p>Every object instance has its own dictionary. When you assign to an instance variable, you add a binding to the instance dictionary. But a class definition creates a (class) object, which also has its own dictionary. When you define a class attribute, you add a binding to the class dictionary.</p> <p>When Python looks up an attribute, it (generally) starts at the instance and if it doesn't find the attribute there, falls back to looking it up in the associated class/type dictionary (the same way that C++ and Java do).</p> <p><code>class A</code> contains two class attributes. <code>change_x()</code> and <code>change_y()</code> are \"class methods,\" which mean they operate on the class object, and not a particular instance of that class. The first parameter of a <code>classmethod</code> is thus not <code>self</code> (the instance reference) but instead <code>cls</code> (the class reference). <code>change_x()</code> and <code>change_y()</code> modify the class attributes, and <code>reset()</code> sets both class attributes back to their original values.</p> <p>The main code starts by creating three <code>A</code> references initialized to <code>None</code>, and a <code>display()</code> function that shows the <code>x</code> and <code>y</code> values for each non-<code>None</code> object.</p> <p>Everything looks like it exhibits \"default value\" behavior until we call <code>change_x()</code> and <code>change_y()</code>, then things get strange. The original <code>a1</code> produces the same results as before, but <code>a2</code> is partially affected (<code>x</code> changes but not <code>y</code>) and the new <code>a3</code> has different \"default values.\" Calling <code>reset()</code> modifies <code>a2</code> (partially) and <code>a3</code> (completely), but not <code>a1</code>.</p> <p><code>reset()</code> changes objects it has no direct connection with. The changes themselves are inconsistent across the different objects. Imagine these kinds of errors appearing in your code base, and trying to track them down based on the varying behavior of these so-called \"default values.\"</p>"},{"location":"Z06_Appendix_Class_Attributes/#class-attributes","title":"Class Attributes","text":"<p>The source of confusion is twofold:</p> <ol> <li> <p>Python's dynamic nature.    Instance variables are not automatically created, not even in the constructor.    They are created the first time they are assigned to, which can happen just about anywhere.</p> </li> <li> <p>Unlike C++ and Java, Python allows instance variables to shadow (have the same name as) class attributes.    This feature gets significant use in libraries that simplify configuration by using class attributes to automatically generate constructors and other methods.</p> </li> </ol> <p>The two confusions compound, because if you ask for an uncreated instance variable with the same name as a class attribute, Python quietly returns the class attribute. If at some later point the instance variable of the same name is created (by assigning something to its identifier), the object will from then on produce the instance variable instead of the class attribute. The same behavior that makes a class attribute look like a default value can cause subtle bugs.</p> <p>To see this in action, we need a function that displays the inside of classes and objects:</p> <pre><code># look_inside.py\n\n\ndef attributes(d: object) -&gt; str:\n    return (\n        \", \".join(\n            [\n                f\"{k}: {v}\"\n                for k, v in vars(d).items()\n                if not k.startswith(\"__\")\n            ]\n        )\n        or \"Empty\"\n    )\n\n\ndef show(obj: object, obj_name: str) -&gt; None:\n    klass: type = obj.__class__\n    print(f\"[Class {klass.__name__}] {attributes(klass)}\")\n    print(f\"[Object {obj_name}] {attributes(obj)}\")\n</code></pre> <p><code>attributes()</code> can be applied to either a class or an object. It uses the builtin <code>vars()</code> function to produce the dictionary, skips dunder functions, and produces names and values or <code>\"Empty\"</code> if there are none. <code>attributes()</code> is used in <code>show()</code> to display both the class and an object of that class. Now we can see the details when using class attributes:</p> <pre><code># class_attributes.py\nfrom look_inside import show\n\n\nclass A:\n    x: int = 100\n\n\nclass B:\n    x: int = 100\n\n    def __init__(self, x_init: int):\n        # Shadows the class attribute name:\n        self.x = x_init\n\n\na = A()\nshow(a, \"a\")\n## [Class A] x: 100\n## [Object a] Empty\na.x = 1\nshow(a, \"a\")\n## [Class A] x: 100\n## [Object a] x: 1\nb = B(-99)\nshow(b, \"b\")\n## [Class B] x: 100\n## [Object b] x: -99\n</code></pre> <p>Creating an <code>A</code> requires no constructor arguments (because there is no constructor). There are no instance variables for <code>a</code> until after the assignment <code>a.x = 1</code>. <code>B</code>'s constructor requires an argument and uses it to assign to an instance variable (thus creating it).</p> <p>Let's look at the original example using <code>show()</code>:</p> <pre><code># like_default_values_shown.py\nfrom look_inside import show\n\n\nclass A:\n    x: int = 100\n\n\na = A()\nshow(a, \"a\")\n## [Class A] x: 100\n## [Object a] Empty\nprint(f\"{a.x = }\")\n## a.x = 100\na.x = -1\nshow(a, \"a\")\n## [Class A] x: 100\n## [Object a] x: -1\nprint(f\"{a.x = }\")\n## a.x = -1\na2 = A()\nshow(a2, \"a2\")\n## [Class A] x: 100\n## [Object a2] Empty\nprint(f\"{a2.x = }\")\n## a2.x = 100\n</code></pre> <p>In the first <code>print()</code>, the instance variable <code>x</code> has not yet been created, so Python helpfully produces the class attribute of the same name. But the assignment <code>a.x = -1</code> creates an instance variable, and so the second <code>print()</code> sees that instance variable. When we create a new <code>A</code> for <code>a2</code>, we're back to a new object without an instance variable so it once again produces the class attribute, making it look like a default value.</p> <p>If you never do anything more complex than this, you won't know there are lurking problems.</p>"},{"location":"Z06_Appendix_Class_Attributes/#the-class-attribute-trick","title":"The Class Attribute Trick","text":"<p>Name shadowing is an intentional part of Python's design, and has become an integral part of the way some libraries provide easy class configuration. The first time I saw it was in Django:</p> <pre><code># example_9.py\n# class Blog(models.Model):\n#     name = models.CharField(max_length=100)\n#     tagline = models.TextField()\n#\n#     def __str__(self):\n#         return self.name\n</code></pre> <p>This seemed magical and confusing. There's no visible constructor but somehow <code>__str__</code> can access <code>self.name</code>. Presumably the base-class constructor creates the instance variables by using the class attributes as a template.</p> <p>Python's <code>dataclasses</code> use a decorator to generate code for the constructor and other methods using class attributes as a template. adding <code>dataclasses</code> to <code>it_all_goes_wrong.py</code> fixes the problem:</p> <pre><code># example_10.py\nfrom dataclasses import dataclass\n\n\n@dataclass\nclass A:\n    x: int = 100\n    y: int = 200\n</code></pre> <p>I suspect that the use of class attributes as code-generation templates will continue.</p>"},{"location":"Z06_Appendix_Class_Attributes/#recommendations","title":"Recommendations","text":"<p>The solution is to not make class attributes seem like default values. Instead, write proper constructors with default arguments, as you see in <code>class A</code>:</p> <pre><code># choices.py\nfrom look_inside import show\nfrom dataclasses import dataclass\n\n\nclass A:\n    def __init__(self, x: int = 100, y: int = 200, z: int = 300):\n        self.x = x\n        self.y = y\n        self.z = z\n\n\n# OR:\n\n\n@dataclass\nclass AA:\n    x: int = 100\n    y: int = 200\n    z: int = 300\n\n\na = A()\nshow(a, \"a\")\n## [Class A] Empty\n## [Object a] x: 100, y: 200, z: 300\na.x = -1\na.y = -2\na.z = -3\nshow(a, \"a\")\n## [Class A] Empty\n## [Object a] x: -1, y: -2, z: -3\n\naa = AA()\nprint(aa)\n## AA(x=100, y=200, z=300)\nshow(aa, \"aa\")\n## [Class AA] x: 100, y: 200, z: 300\n## [Object aa] x: 100, y: 200, z: 300\naa.x = -1\naa.y = -2\naa.z = -3\nshow(aa, \"aa\")\n## [Class AA] x: 100, y: 200, z: 300\n## [Object aa] x: -1, y: -2, z: -3\naa2 = AA(-4, -5, -6)\nshow(aa2, \"aa2\")\n## [Class AA] x: 100, y: 200, z: 300\n## [Object aa2] x: -4, y: -5, z: -6\n\n# Even if we modify the class attributes, the\n# constructor default arguments stay the same:\nAA.x = 42\nAA.y = 74\nAA.z = 22\naa3 = AA()\nshow(aa3, \"aa3\")\n## [Class AA] x: 42, y: 74, z: 22\n## [Object aa3] x: 100, y: 200, z: 300\n</code></pre> <p>You can also use a <code>dataclass</code> as seen in <code>class AA</code>. Notice the result of <code>print(aa)</code> produces a useful description of the object because the <code>dataclass</code> automatically generates a <code>__repr__()</code>.</p> <p>The <code>dataclass</code> decorator generates a constructor with default arguments that match the class attributes. After that you can modify the class attributes and it has no effect on the constructed objects. It seems like <code>dataclasses</code> are what the original author of the code I encountered was hoping for.</p> <p>Although Python's syntax can make it look like other languages, its dynamic nature strongly influences the language's semantics. Assumptions that it works like C++ or Java will generally produce incorrect results.</p> <p>You can learn more about <code>dataclasses</code> from my Pycon 2022 presentation Making Dataclasses Work for You, on YouTube (not yet available at this writing).</p> <p>Thanks to Barry Warsaw for reviewing and giving feedback.</p> <p>[^1]: Languages like C++ and Java use constructor to mean \"activities performed after storage allocation and basic initialization.\" C++ also has a <code>new()</code> for controlling memory allocation, calling it \"operator new\" rather than \"constructor.\" In contrast, Python's constructor is usually defined as the <code>__new__()</code> function, and <code>__init__()</code> is called the initializer. C++'s operator <code>new()</code> and Python's <code>__new__()</code> are almost never overridden, and are rarely even mentioned (The common usage for Python's <code>__new__()</code> seems to be to create Factory functions). To keep things I just say \"constructor\" when referring to <code>__init__()</code>.</p>"},{"location":"Z07_Appendix_Tools/","title":"Appendix: Tools","text":"<p>Useful tools</p> <ul> <li>Mkinit. Automatically generates <code>__init__.py</code> files.   Can solve import problems, but if it doesn't, try making all <code>__init__.py</code> files empty and perform full path imports.</li> </ul>"},{"location":"Z08_Appendix_Book_Utilities/","title":"Appendix: Book Utilities","text":"<p>These are incorporated into book examples to make them easier to read and to reduce code duplication. They are placed in a subdirectory off the root of the project, named <code>book_utils</code>. Because the book examples are extracted into a flat layout in the examples repository, you can import directly from <code>book_utils</code>.</p>"},{"location":"Z08_Appendix_Book_Utilities/#exception-catcher","title":"Exception Catcher","text":"<p>When a function call is known to succeed, the ordinary <code>print()</code> can be used. If a function call can fail with an exception, <code>Catch</code> used as a context manager will catch and display the error.</p> <pre><code># book_utils/exception_catcher.py\n\"\"\"\nContext manager that catches exceptions and prints their error messages,\nand can be used as a callable via its __call__ method.\n\nWhen used as a callable, argument evaluation must be delayed until inside\nthe context manager in case argument evaluation raises an exception.\nTo do this the function should be provided as a zero-argument callable.\nIf the function takes arguments, it must be wrapped in a lambda to delay evaluation.\n\"\"\"\nfrom __future__ import annotations\n\nimport traceback as _traceback\nfrom typing import Any, Callable\n\n_NO_REPORT = [\"# type: ignore\", \"# noqa\"]\n\n\nclass Catch:\n    \"\"\"\n    Catch and print expected errors, but allow _fatal_exceptions to propagate.\n    Lines annotated with any marker in _NO_REPORT are not reported.\n    \"\"\"\n\n    _fatal_exceptions = (SyntaxError, NameError, TypeError, AttributeError)\n\n    def __enter__(self) -&gt; Catch:\n        return self\n\n    def __exit__(self, exc_type: Any, exc_value: Any, tb: Any) -&gt; bool:\n        if exc_type is None:\n            return True\n\n        if self._is_ignored_frame(tb):\n            return True\n\n        if issubclass(exc_type, self._fatal_exceptions):\n            return False\n\n        print(f\"Error: {exc_value}\")\n        return True\n\n    def __call__[R](self, func: Callable[[], R]) -&gt; R | None:\n        try:\n            result = func()\n            if result is not None:\n                print(result)\n            return result\n        except Exception as e:\n            if self._is_ignored_frame(e.__traceback__):\n                return None\n\n            if isinstance(e, self._fatal_exceptions):\n                raise\n\n            print(f\"Error: {e}\")\n            return None\n\n    def _is_ignored_frame(self, tb: Any) -&gt; bool:\n        frames = _traceback.extract_tb(tb) if tb is not None else []\n        return any(\n            any(tag in (frame.line or \"\") for tag in _NO_REPORT)\n            for frame in frames\n        )\n</code></pre> <p>The <code>Catch</code> class serves two roles:</p> <ol> <li>Context Manager (<code>__enter__</code> and <code>__exit__</code> methods)</li> <li>Callable Object (<code>__call__</code> method)</li> </ol> <p>This combination allows it to handle exceptions and display meaningful error messages without stopping program execution.</p>"},{"location":"Z08_Appendix_Book_Utilities/#context-manager","title":"Context Manager","text":"<p>A context manager in Python is used with the <code>with</code> statement, typically to set up and tear down resources or to catch exceptions. The <code>Catch</code> class implements this using:</p> <ul> <li> <p><code>__enter__(self)</code>\\   When the context is entered, it returns the instance (<code>self</code>), making the methods of the class accessible within the   block.</p> </li> <li> <p><code>__exit__(self, exc_type, exc_value, traceback)</code>\\   Automatically called when the context manager block (<code>with</code> statement) finishes execution.   It receives details about any exception raised inside the block:</p> <ul> <li><code>exc_type</code>: the type of exception raised (e.g., <code>ValueError</code>)</li> <li><code>exc_value</code>: the exception object containing the message</li> <li><code>traceback</code>: the traceback object detailing where the exception occurred</li> </ul> </li> </ul> <p>If an exception occurs (<code>exc_type is not None</code>), the <code>Catch</code> class prints the error message and returns <code>True</code> to   indicate that the exception has been handled and should not propagate further.</p> <p>Example usage as a context manager:</p> <pre><code># basic_form.py\nfrom book_utils import Catch\n\nwith Catch():\n    _ = 1 / 0\n## Error: division by zero\n</code></pre>"},{"location":"Z08_Appendix_Book_Utilities/#callable-interface-__call__-method","title":"Callable Interface (<code>__call__</code> method)","text":"<p>The <code>Catch</code> class also defines a <code>__call__</code> method, allowing its instances to be called as functions. This explicitly wraps a callable (like a lambda or zero-argument function) inside its own try-except block, capturing and handling exceptions raised during both argument evaluation and function execution.</p> <p>In the <code>__call__</code> method signature, <code>func</code> is a zero-argument callable. It executes this callable within a try-except block:</p> <ul> <li>If the callable succeeds, it prints and returns the result (if not <code>None</code>).</li> <li>If an exception is raised, it prints the error and returns <code>None</code>.</li> </ul> <p>Here's an example showing callables within a context manager:</p> <pre><code># basic_lambda_form.py\nfrom book_utils import Catch\n\nwith Catch() as catch:\n    catch(lambda: 1 / 0)\n    catch(lambda: 1 / 0)\n    catch(lambda: 1 / 0)\n    print(\"No lambda aborts the context:\")\n    _ = 1 / 0\n    print(\"This doesn't run:\")\n    catch(lambda: 1 / 0)\n## Error: division by zero\n## Error: division by zero\n## Error: division by zero\n## No lambda aborts the context:\n## Error: division by zero\n</code></pre> <p>Using lambdas here is essential because it delays the evaluation of arguments until inside the <code>Catch</code> context, ensuring that errors raised during argument construction are caught properly. Here's a more complex example with argument construction that throws exceptions:</p> <pre><code># demo_exception_checker.py\nfrom dataclasses import dataclass\n\nfrom book_utils import Catch\n\n\n@dataclass\nclass Fob:\n    x: int\n\n    def __post_init__(self) -&gt; None:\n        if self.x &lt; 0:\n            raise ValueError(\n                f\"Fob arg {self.x} must be positive\"\n            )\n\n\ndef foo(a: int, b: Fob) -&gt; str:\n    if a &lt; 0:\n        raise ValueError(f\"foo arg {a} must be positive\")\n    return f\"foo({a}, {b}) succeeded\"\n\n\n# If you know it succeeds you can just run it without a context:\nprint(foo(0, Fob(0)))\n## foo(0, Fob(x=0)) succeeded\nwith Catch():  # Single-failure form\n    foo(1, Fob(-1))\n## Error: Fob arg -1 must be positive\n\n# In the form, success does NOT automatically display the result:\nwith Catch():\n    print(foo(42, Fob(42)))  # Must explicitly print\n## foo(42, Fob(x=42)) succeeded\n\n# Lambda form displays successful result:\nwith Catch() as catch:\n    catch(lambda: foo(42, Fob(42)))\n## foo(42, Fob(x=42)) succeeded\n\n# Multi-failure block requires lambda form:\nwith Catch() as catch:\n    catch(lambda: foo(1, Fob(1)))\n    catch(lambda: foo(0, Fob(0)))\n    catch(lambda: foo(-1, Fob(1)))\n    catch(lambda: foo(1, Fob(-1)))\n    catch(lambda: foo(-1, Fob(-1)))\n    catch(lambda: foo(10, Fob(11)))\n## foo(1, Fob(x=1)) succeeded\n## foo(0, Fob(x=0)) succeeded\n## Error: foo arg -1 must be positive\n## Error: Fob arg -1 must be positive\n## Error: Fob arg -1 must be positive\n## foo(10, Fob(x=11)) succeeded\n</code></pre>"},{"location":"Z08_Appendix_Book_Utilities/#book-utilities-__init__py","title":"Book Utilities <code>__init__.py</code>","text":"<p>To allow these utilities to be easily imported using <code>from book_utils</code>, we must set up the <code>__init__.py</code>:</p> <pre><code># book_utils/__init__.py\nfrom .exception_catcher import Catch\n\n__all__ = [\"Catch\"]\n</code></pre>"},{"location":"Z09_Appendix_Book_Notes/","title":"Appendix: Book Notes","text":"<p>Resources and Ideas for eventual inclusion in the book.</p> <ul> <li>Walrus operator?</li> </ul> <ul> <li>https://github.com/BruceEckel/RethinkingObjects (code from Pycon presentation, youtube video is not comprehensible)</li> <li>https://github.com/BruceEckel/RethinkingObjects-book</li> </ul> <ul> <li>reveal_type/assert_type</li> </ul>"},{"location":"Z09_Appendix_Book_Notes/#ai-generated-topic-list","title":"AI-Generated Topic List","text":"<p>Created by ChatGPT 4o.</p>"},{"location":"Z09_Appendix_Book_Notes/#part-i-the-basics-of-typing-in-python","title":"\ud83d\udcd8 Part I: The Basics of Typing in Python","text":""},{"location":"Z09_Appendix_Book_Notes/#introduction-to-static-typing","title":"Introduction to Static Typing","text":"<ul> <li>Why type your code?</li> <li>Benefits of types in Python (readability, tooling, correctness)</li> </ul>"},{"location":"Z09_Appendix_Book_Notes/#basic-type-annotations","title":"Basic Type Annotations","text":"<ul> <li>Built-in types:   <code>int</code>, <code>str</code>, <code>float</code>, <code>bool</code></li> <li>Variable annotations</li> <li>Function argument and return types</li> </ul>"},{"location":"Z09_Appendix_Book_Notes/#optional-and-union-types","title":"Optional and Union Types","text":"<ul> <li><code>Optional[T]</code> / <code>T | None</code></li> <li><code>Union</code> / <code>T1 | T2</code></li> <li>When and why to use</li> </ul>"},{"location":"Z09_Appendix_Book_Notes/#any-and-noreturn","title":"Any and NoReturn","text":"<ul> <li>When to use <code>Any</code></li> <li>Risks of <code>Any</code></li> <li>Meaning and use of <code>NoReturn</code></li> </ul>"},{"location":"Z09_Appendix_Book_Notes/#type-aliases","title":"Type Aliases","text":"<ul> <li>Creating and using <code>type MyAlias = ...</code></li> <li>Organizing complex types</li> </ul>"},{"location":"Z09_Appendix_Book_Notes/#part-ii-collections-and-generics","title":"\ud83d\udcd8 Part II: Collections and Generics","text":""},{"location":"Z09_Appendix_Book_Notes/#typing-built-in-collections","title":"Typing Built-in Collections","text":"<ul> <li><code>List</code>, <code>Dict</code>, <code>Tuple</code>, <code>Set</code></li> <li>Homogeneous vs heterogeneous types</li> <li>Variadic tuples</li> </ul>"},{"location":"Z09_Appendix_Book_Notes/#generic-types","title":"Generic Types","text":"<ul> <li>Understanding type variable and generic functions</li> <li>Creating generic classes</li> </ul>"},{"location":"Z09_Appendix_Book_Notes/#callable-and-lambdas","title":"Callable and Lambdas","text":"<ul> <li>Typing functions as values</li> <li>Callable signatures</li> </ul>"},{"location":"Z09_Appendix_Book_Notes/#iterables-and-iterators","title":"Iterables and Iterators","text":"<ul> <li><code>Iterable</code>, <code>Iterator</code>, <code>Generator</code></li> <li>Typing generators and coroutines</li> </ul>"},{"location":"Z09_Appendix_Book_Notes/#literal-types","title":"Literal Types","text":"<ul> <li>Restricting to fixed string or numeric values</li> <li>Using <code>Literal</code> for flags and enums</li> </ul>"},{"location":"Z09_Appendix_Book_Notes/#part-iii-advanced-concepts","title":"\ud83d\udcd8 Part III: Advanced Concepts","text":""},{"location":"Z09_Appendix_Book_Notes/#protocols-and-structural-typing","title":"Protocols and Structural Typing","text":"<ul> <li>Introduction to duck typing</li> <li><code>Protocol</code> classes and <code>@runtime_checkable</code></li> </ul>"},{"location":"Z09_Appendix_Book_Notes/#new-in-python-10","title":"New in Python 10+","text":"<ul> <li><code>|</code> syntax for unions</li> <li><code>match</code> statement and typing with pattern matching</li> </ul>"},{"location":"Z09_Appendix_Book_Notes/#annotated-and-metadata-types","title":"Annotated and Metadata Types","text":"<ul> <li>Using <code>Annotated</code> for richer metadata</li> <li>Use in CLI tools, validation, etc.</li> </ul>"},{"location":"Z09_Appendix_Book_Notes/#self-type-and-recursive-types","title":"Self Type and Recursive Types","text":"<ul> <li>Typing methods that return <code>self</code></li> <li>Recursive types like nested JSON</li> </ul>"},{"location":"Z09_Appendix_Book_Notes/#dataclasses-and-typing","title":"Dataclasses and Typing","text":"<ul> <li>Typing fields with and without defaults</li> <li><code>InitVar</code>, <code>field</code>, <code>kw_only</code>, etc.</li> </ul>"},{"location":"Z09_Appendix_Book_Notes/#part-iv-runtime-typing-and-validation","title":"\ud83d\udcd8 Part IV: Runtime Typing and Validation","text":""},{"location":"Z09_Appendix_Book_Notes/#type-checking-at-runtime","title":"Type Checking at Runtime","text":"<ul> <li><code>isinstance</code> and <code>typing.get_type_hints()</code></li> <li>Runtime enforcement libraries (e.g. Pydantic, Enforce)</li> </ul>"},{"location":"Z09_Appendix_Book_Notes/#validating-with-decorators","title":"Validating with Decorators","text":"<ul> <li>Type validation decorators</li> <li>Enforcing types in dynamic code</li> </ul>"},{"location":"Z09_Appendix_Book_Notes/#typeddict-and-json-like-structures","title":"TypedDict and JSON-like Structures","text":"<ul> <li>Using <code>TypedDict</code> for structured data</li> <li>Migration from <code>dict[str, Any]</code></li> </ul>"},{"location":"Z09_Appendix_Book_Notes/#enums-and-custom-types","title":"Enums and Custom Types","text":"<ul> <li>Strongly typed enums</li> <li>Creating domain-specific types</li> </ul>"},{"location":"Z09_Appendix_Book_Notes/#dynamic-typing-interop","title":"Dynamic Typing Interop","text":"<ul> <li>Working with untyped or partially typed code</li> <li>Handling <code>Any</code> gracefully</li> </ul>"},{"location":"Z09_Appendix_Book_Notes/#part-v-tooling-and-practices","title":"\ud83d\udcd8 Part V: Tooling and Practices","text":""},{"location":"Z09_Appendix_Book_Notes/#static-type-checkers","title":"Static Type Checkers","text":"<ul> <li>Using <code>mypy</code>, <code>pyright</code>, <code>pyre</code>, <code>pytype</code></li> <li>Configuration and workflows</li> </ul>"},{"location":"Z09_Appendix_Book_Notes/#ide-and-editor-support","title":"IDE and Editor Support","text":"<ul> <li>VS Code, PyCharm, etc.</li> <li>Type hinting with LSPs and plugins</li> </ul>"},{"location":"Z09_Appendix_Book_Notes/#refactoring-with-types","title":"Refactoring with Types","text":"<ul> <li>Incremental typing strategies</li> <li>Using types to guide refactoring</li> </ul>"},{"location":"Z09_Appendix_Book_Notes/#testing-and-typing","title":"Testing and Typing","text":"<ul> <li>Typing test code</li> <li>Type-aware mocking and fixtures</li> </ul>"},{"location":"Z09_Appendix_Book_Notes/#types-in-documentation","title":"Types in Documentation","text":"<ul> <li>Sphinx and autodoc with type annotations</li> <li>Docstrings vs annotations</li> </ul>"},{"location":"Z09_Appendix_Book_Notes/#part-vi-real-world-applications","title":"\ud83d\udcd8 Part VI: Real-World Applications","text":""},{"location":"Z09_Appendix_Book_Notes/#typing-apis-and-libraries","title":"Typing APIs and Libraries","text":"<ul> <li>Public API surfaces</li> <li>Library development with types</li> </ul>"},{"location":"Z09_Appendix_Book_Notes/#using-types-in-frameworks","title":"Using Types in Frameworks","text":"<ul> <li>Django/Pydantic/FastAPI with typing</li> <li>Typing decorators and middleware</li> </ul>"},{"location":"Z09_Appendix_Book_Notes/#typing-concurrency","title":"Typing Concurrency","text":"<ul> <li><code>async def</code>, <code>Awaitable</code>, <code>Coroutine</code></li> <li><code>Thread</code>, <code>Process</code>, <code>Queue</code></li> </ul>"},{"location":"Z09_Appendix_Book_Notes/#cross-version-compatibility","title":"Cross-Version Compatibility","text":"<ul> <li>Using <code>typing_extensions</code></li> <li>Supporting older Python versions</li> </ul>"},{"location":"Z09_Appendix_Book_Notes/#common-pitfalls-and-anti-patterns","title":"Common Pitfalls and Anti-Patterns","text":"<ul> <li>Misusing <code>Any</code></li> <li>Over-annotating</li> <li>Annotations that hinder readability</li> </ul>"},{"location":"Z10_Appendix_Error_Suppression/","title":"Appendix: Error Suppression","text":"Tool <code># type: ignore</code> Mypy Fully supported; can specify codes like <code>[arg-type]</code> Pyright Fully supported via PEP 484 Pyre Supported but prefers <code># pyre-ignore</code> Pytype Supported but prefers <code># pytype: disable=...</code> Flake8 Unsupported; Linter only, does not process type comments Ruff Unsupported; Same as Flake8 Tool Custom Directive Pyright <code># pyright: ignore</code>: Allows granular control; can target error categories Pyre <code># pyre-ignore</code>: Suppresses one error line; can include code Pytype <code># pytype: disable=</code>: Disables specific checks; re-enable with <code>enable=</code> Directive Tool Notes <code># noqa</code> Flake8 Suppresses all lint warnings on the line Ruff Fully compatible <code># ruff: noqa</code> Ruff File-level suppression <code># flake8: noqa</code> Flake8 File-level suppression <code># pylint: disable=</code> Pylint Pylint-specific suppression (not related to type checking) <p>Python's static checkers (like Mypy or Pyright) and linters (like Flake8 or Ruff) respect special end-of-line comments that disable error reporting. The most common is <code># type: ignore</code>, which tells type checkers to ignore all type errors on that line. For example:</p> <pre><code># example_1.py\nfrom book_utils import Catch\n\n\ndef add(x: int, y: int) -&gt; int:\n    return x + y\n\n\n# Without ignore, this produces a type error (int vs. str):\nwith Catch():\n    result = add(5, \"7\")  # type: ignore\n</code></pre> <p>Here the <code># type: ignore</code> comment silences the mismatch. Mypy's documentation explicitly notes that you can add <code># type: ignore</code> to silence the checker on a particular line.</p> <p>Mypy (and other checkers) also allow a more precise form: you can write <code># type: ignore[code]</code> to ignore only specific error codes on that line, preventing you from accidentally hiding other issues. For example, <code># type: ignore[attr-defined]</code> ignores just that one error. Pyright and other tools likewise recognize <code># type: ignore</code>. In Pyright you can also use tool-specific variants like <code># pyright: ignore</code>, which we discuss below.</p>"},{"location":"Z10_Appendix_Error_Suppression/#noqa","title":"<code># noqa</code>","text":"<p>Flake8 and Ruff (and many linters) use the <code># noqa</code> comment to suppress lint errors on a line. By default <code># noqa</code> with no code ignores all warnings on that line. For example:</p> <pre><code># example_2.py\nfrom math import *  # type: ignore  # noqa\n</code></pre> <p>Without <code># noqa</code>, a linter like Flake8 would warn about the wildcard import. You can also target specific rule codes. For instance, to silence Flake8's error code <code>E731</code> (\"do not assign lambda\"), you can write:</p> <pre><code># example_3.py\nsquare = lambda x: x * x  # noqa: E731\n</code></pre> <p>This line reports no <code>E731</code> error, but any other code issues would still be shown. Ruff is mostly Flake8-compatible: it recognizes <code># noqa</code> (and even a file-level <code># flake8: noqa</code> or <code># ruff: noqa</code> to disable the whole file). In short, use <code># noqa</code> to silence specific linter errors on a line (or none after the colon), and <code># flake8: noqa</code> or <code># ruff: noqa</code> at file top to skip an entire file.</p>"},{"location":"Z10_Appendix_Error_Suppression/#combining-directives","title":"Combining Directives","text":"<p>Sometimes you need to silence both a type checker and a linter on one line. In that case you can chain the comments. For example, to please both Mypy and Ruff, do:</p> <pre><code># example_4.py\nfrom book_utils import *  # type: ignore  # noqa\n</code></pre> <p>The order matters: put <code># type: ignore</code> before <code># noqa</code> (with at least two spaces) so each tool recognizes its part. Mypy scans the line first and stops, then Ruff/Flake8 reads <code># noqa</code>. Without careful ordering, you might accidentally hide errors from one tool or the other.</p>"},{"location":"Z10_Appendix_Error_Suppression/#tool-specific-suppression-comments","title":"Tool-Specific Suppression Comments","text":"<p>Beyond <code># type: ignore</code> and <code># noqa</code>, some checkers support their own suppressors:</p>"},{"location":"Z10_Appendix_Error_Suppression/#pyright","title":"Pyright","text":"<p>In addition to <code># type: ignore</code>, Pyright supports <code># pyright: ignore</code> to mute only Pyright's diagnostics. You can even specify particular rule names. For example:</p> <pre><code># example_5.py\nfoo: int = \"123\"  # pyright: ignore # noqa\nbar: int = \"123\"  # pyright: ignore [reportGeneralTypeIssues] # type: ignore # noqa\n</code></pre> <p>The first comment silences all Pyright errors on that line, the second suppresses only the named category. Pyright prefers its own <code># pyright: ignore</code> (it validates rule names) to avoid over-suppressing compared to the blanket <code># type: ignore</code>.</p>"},{"location":"Z10_Appendix_Error_Suppression/#pyre","title":"Pyre","text":"<p>The Pyre type checker (by Facebook) uses <code># pyre-ignore</code> and <code># pyre-ignore-all-errors</code>. A comment like <code># pyre-ignore[CODE]</code> tells Pyre to skip that error on the line (you omit the code to ignore all Pyre errors on that line). For example:</p> <pre><code># example_6.py\ndef f(x: int) -&gt; str:\n    return x  # type: ignore      # This mismatches return type\n    # pyre-ignore-all-errors[7]  # ignore \"incompatible return type\" for file\n</code></pre> <p>Pyre's docs explain that <code># pyre-ignore</code> means \"there's an issue with the type checker or code\u2026 we have decided not to fix this\". You can also put <code># pyre-ignore-all-errors</code> (optionally with codes) at the top of a file to silence types across the whole module.</p>"},{"location":"Z10_Appendix_Error_Suppression/#pytype","title":"Pytype","text":"<p>Google's Pytype supports <code># pytype: disable=ERROR</code> (and <code># pytype: enable=ERROR</code>) to turn off specific checks. For instance:</p> <pre><code># example_7.py\nclass Server:\n    def accept(self):\n        self.socket = object()  # imagine this is set in listen()\n        return self.socket.recv()  # pytype: disable=attribute-error # type: ignore # noqa\n</code></pre> <p>Here we disable the \"attribute-error\" warning that <code>socket</code> might not have <code>recv</code> yet. You can disable warnings per-line or even for the rest of the file by writing a <code>disable</code> comment on its own. The Pytype guide notes that this is preferred over a generic <code># type: ignore</code>, since it documents which error is expected.</p>"},{"location":"Z10_Appendix_Error_Suppression/#pylint","title":"Pylint","text":"<p>Although not a type checker, Pylint is a common static analyzer that uses comments like <code># pylint: disable=no-member</code> to suppress its own messages. (This is analogous to <code>noqa</code> for Pylint-specific checks.) If you use Pylint in a typed codebase, you can mix these with the other directives, but be aware Pylint does not understand <code># type: ignore</code> or <code># noqa</code>--it only looks for its own annotations.</p>"},{"location":"Z10_Appendix_Error_Suppression/#recommendations","title":"Recommendations","text":""},{"location":"Z10_Appendix_Error_Suppression/#prefer-specificity","title":"Prefer Specificity","text":"<p>Rather than blanket ignoring all errors, target a specific code or rule if possible. Mypy recommends <code># type: ignore[&lt;code&gt;]</code> over plain <code># type: ignore</code> to avoid hiding unrelated problems. Similarly, specify Flake8 codes after <code># noqa:</code> (e.g. <code># noqa: E731</code>) instead of <code># noqa</code> alone, so you don't accidentally silence other issues. (Some teams even use plugins to forbid bare <code># noqa</code> or <code># type: ignore</code>.)</p>"},{"location":"Z10_Appendix_Error_Suppression/#use-ignores-sparingly","title":"Use Ignores Sparingly","text":"<p>Treat these comments as a last resort when you truly cannot fix the error (e.g. missing stubs, dynamic patterns, legacy code). Overuse can mask bugs. Some linters can flag \"unused\" ignores or warn when an ignore comment doesn't cover an error (e.g., Pyright's <code>reportUnnecessaryTypeIgnoreComment</code>). It's good practice to document why you're ignoring: a short trailing comment can explain the rationale.</p>"},{"location":"Z10_Appendix_Error_Suppression/#fix-code-when-feasible","title":"Fix Code When Feasible","text":"<p>Often a better solution is to tweak the code or annotations. For example, instead of ignoring a missing attribute, consider adding a proper type annotation or refactoring. Tools like <code>typing.cast()</code> or the <code>Optional</code> type can sometimes eliminate the need for an ignore. Remember, <code># type: ignore</code> essentially reverts that expression to type <code>Any</code>, so you lose static checks there.</p>"},{"location":"Z10_Appendix_Error_Suppression/#note-tooling-differences","title":"Note Tooling Differences","text":"<p>If your project uses multiple tools, be aware of interactions. As shown above, ordering matters (<code># type: ignore</code> then <code># noqa</code>). Check each tool's docs: Pyright (for instance) only recognizes <code># pyright: ignore</code>, not Mypy's style, and vice versa. Conversely, most type checkers do understand <code># type: ignore</code> thanks to PEP 484.</p> <p>Using targeted ignores, documenting them, and preferring code fixes keeps your codebase clean while silencing the \"false positives\" or acceptable warnings that inevitably arise in static analysis.</p>"},{"location":"Z11_Appendix_Dynamic_Smalltalk_vs_Static_Typing/","title":"Appendix: Dynamic Smalltalk vs. Static Typing","text":"<p>NOTE: This material is being developed for one of the introductory chapters</p> <p>Smalltalk is extremely dynamic. A Smalltalk program runs inside a live image of objects that can be modified during execution. Every component of the system--classes, methods, even control structures--is an object that can be inspected and altered at runtime. This produces a highly interactive development experience--developers can change code and see the effects immediately without restarting. New methods or classes can be added on the fly, and objects will respond to new messages accordingly. This open-ended dynamism promising much greater developer productivity and innovation. It made Smalltalk a pioneer in object-oriented design.</p> <p>When C++ was originally created, its designers hoped that OOP developer productivity could be tied to the ideas of objects and inheritance, and were not essentially bound to the rest of Smalltalk's features and development environment. What we very slowly discovered over subsequent decades is that the fluid and open object model that Smalltalk enjoys cannot be replicated in statically typed languages.</p> <p>In effect, Smalltalk has no type system in the way that we've come to think about that term. One can send any message to any object, and the system will attempt to find a matching method on the object at runtime. If none exists, it triggers a <code>doesNotUnderstand:</code> handler (which by default raises a runtime \"message not understood\" error). The only way to know whether an object will understand a given message is to send the message and see if the object responds.</p> <p>Python has a lot of the dynamic flexibility of Smalltalk but:</p> <ol> <li>It has a compile phase--this is brief and simple compared to non-dynamic languages, but it does some basic checking before the program runs.</li> <li>Python's data elements have types; they are not just an object that will accept any message.</li> </ol> <p>Statically typed languages require that an object's type (its class, interface, or trait) explicitly declare all the methods it supports. Any call to a nonexistent method is caught at compile time as a type error. Statically typed languages trade away Smalltalk's on-the-fly flexibility for the guarantee that method calls won't go astray. Thus, certain idioms common in Smalltalk (such as adding methods to objects at runtime or relying on duck typing) are impractical or impossible to express in a statically typed language.</p> <p>In Smalltalk, the set of messages an object can respond to essentially defines its type at that moment--but this \"type\" is not a formal, static annotation; it's just the object's current behavior, which can even change as the program runs. Two objects are effectively the same type if they handle the same messages, regardless of their class lineage or internal representation. Smalltalk is strongly dynamically typed: every object's type is well-defined at runtime, and objects do not change types arbitrarily, but the language does not check types until a message is sent. Ultimately, whether Smalltalk can be said to have a \"type system\" in any meaningful sense depends on how one defines the term: it certainly lacks compile-time type checking, yet it still categorizes and dispatches on types at runtime. Meanwhile, languages like Java, Rust, and TypeScript use static type systems to rigidly define what can happen in a program, prioritizing reliability and clarity over the dynamic extensibility that made Smalltalk so uniquely powerful.</p> <p>Smalltalk is described as a reflective, object-oriented language known for its simplicity, dynamic nature, and highly interactive development environment, treating everything as an object. and supporting live coding for great flexibility and interactivity. Smalltalk was designed to be a highly dynamic language, allowing developers to manipulate and experiment with code in real-time.</p> <p>Because Smalltalk doesn't have a static way to encode expectations (types), the community invented TDD--writing tests--to catch errors; xUnit testing was prototyped in Smalltalk.</p>"},{"location":"Z11_Appendix_Dynamic_Smalltalk_vs_Static_Typing/#emulating-smalltalk-in-python","title":"Emulating Smalltalk in Python","text":"<p>Because Python is a dynamic language, it is possible to emulate Smalltalk's behavior. <code>type()</code> is most commonly seen as a function that returns the type of its argument:</p> <pre><code># type_function.py\nclass Plumbus:\n    pass\n\n\nprint(type(Plumbus()))\n## &lt;class '__main__.Plumbus'&gt;\n</code></pre> <p>However, <code>type()</code> can also be a class constructor to dynamically create a new class: <code>type(name, bases, dict)</code>:</p> <pre><code># dynamic_class_creation.py\n\nBaseAnimal = type(\n    \"BaseAnimal\",  # name\n    (object,),  # bases\n    # class body (attributes/methods):\n    {\"speak\": lambda self: print(\"Generic animal sound.\")},\n)\n\nCat = type(  # Subclassing\n    \"Cat\",\n    (BaseAnimal,),\n    {\"speak\": lambda self: print(\"Meow!\")},\n)\n\nfeline = Cat()\nfeline.speak()  # type: ignore\n## Meow!\n</code></pre> <p>Lambdas are used here for brevity; more typically you'll see function names placed in the class body <code>dict</code>.</p> <p>We can also create a Smalltalk-like object that dynamically adapts to new messages:</p> <pre><code># smalltalk_parrot.py\nfrom dataclasses import dataclass, field\n\n\n@dataclass\nclass Parrot:\n    known_phrases: set[str] = field(default_factory=set)\n\n    def __getattr__(self, name: str):\n        def handler(*args, **kwargs):\n            return self.not_found(name, *args, **kwargs)\n\n        return handler\n\n    def not_found(self, message: str, *args, **kwargs):\n        print(f\"[Class] Parrot learns: {message}\")\n\n        def new_method(self, *args, **kwargs):\n            print(f\"Parrot says: {message}\")\n            self.known_phrases.add(message)\n\n        setattr(self.__class__, message, new_method)\n        return getattr(self, message)(*args, **kwargs)\n</code></pre> <p>The <code>__getattr__</code> method only runs if you try to access an attribute or method that doesn\u2019t yet exist on either the instance or its class. It captures the missing attribute <code>name</code>. Then it returns a placeholder function <code>handler</code> that, when called, delegates to <code>self.not_found(...)</code>.</p> <p>The <code>not_found</code> method teaches the parrot a new \"method\" on the fly and then immediately invokes it. The <code>new_method</code> adds the phrase to that instance\u2019s <code>known_phrases</code>.</p> <p>The call to <code>setattr(self.__class__, message, new_method)</code> attaches <code>new_method</code> to the class. Now all <code>Parrot</code> instances have a method with the name in the argument <code>message</code>.</p> <p>Finally, <code>not_found</code> calls the new method in the <code>return</code> expression using <code>getattr</code>.</p> <p>So, the first time you say <code>polly.hello()</code>, <code>__getattr__</code> catches the missing <code>hello</code>, returns <code>handler</code>, which calls <code>not_found(\"hello\")</code>. <code>not_found</code> prints that the class learned <code>\"hello\"</code>, then dynamically creates and installs <code>Parrot.hello</code>, adds <code>\"hello\"</code> to <code>polly.known_phrases</code>, and invokes <code>polly.hello()</code>. For subsequent calls to <code>polly.hello()</code>, the method now exists on the class, so <code>__getattr__</code> is bypassed. It simply prints \"Parrot says: hello\" and adds again to that instance\u2019s list.</p> <p>Other instances (e.g., <code>coco</code>) immediately gain a <code>hello</code> method, but their <code>known_phrases</code> remain separate: each instance tracks only the phrases it has ever spoken.</p> <pre><code># learning_parrot.py\nfrom smalltalk_parrot import Parrot\n\npolly = Parrot()\ncoco = Parrot()\n\n# Before learning:\nprint(polly.known_phrases, coco.known_phrases)\n## set() set()\n\npolly.hello()\n## [Class] Parrot learns: hello\n## Parrot says: hello\ncoco.hello()\n## Parrot says: hello\ncoco.squawk()\n## [Class] Parrot learns: squawk\n## Parrot says: squawk\n\n# After learning:\nprint(polly.known_phrases, coco.known_phrases)\n## {'hello'} {'hello', 'squawk'}\n</code></pre> <p>Although <code>polly</code> and <code>coco</code> share each created method, each instance maintains its own <code>known_phrases</code> history.</p>"},{"location":"Z11_Appendix_Dynamic_Smalltalk_vs_Static_Typing/#the-smalltalk-programming-experience","title":"The Smalltalk Programming Experience","text":"<p>Smalltalk isn't just a language--it's a way of programming. Rather than designing everything up front, Smalltalk encourages programmers to build systems interactively, incrementally, and dynamically. The key ideas:</p> <ul> <li>Everything is an object.</li> <li>You send messages to objects, even if you don't know whether they understand them.</li> <li>Objects can learn new behaviors at runtime.</li> <li>The system evolves live as you work.</li> </ul> <p>We'll simulate the Smalltalk programming experience using Python, so you can see what it feels like to develop in the Smalltalk style. The entire session mirrors the experience of working in a Smalltalk image: there is no compile-run-edit loop. You interact with objects directly, teach them behavior, and the system grows and adapts as you explore it.</p> <p>We start with a basic object that handles unknown messages by implementing <code>not_found</code>, similar to how Smalltalk does it.</p> <pre><code># smalltalk_object.py\nclass SmalltalkObject:\n    def __getattr__(self, name):\n        def handler(*args, **kwargs):\n            return self.not_found(name, *args, **kwargs)\n\n        return handler\n\n    def not_found(self, message, *args, **kwargs):\n        print(\n            f\"{self.__class__.__name__}: '{message}' not found\"\n        )\n</code></pre> <p>When you say <code>obj.some_attr</code>, Python (internally) runs <code>type(obj).__getattribute__(obj, \"some_attr\")</code>. If that fails with <code>AttributeError</code>, and you've defined getattr, Python calls <code>obj.__getattr__(\"some_attr\")</code>.</p> <p>So for <code>SmalltalkObject</code>, when you access a missing method:</p> <pre><code># missing_method.py\nfrom smalltalk_object import SmalltalkObject\n\nobj = SmalltalkObject()\nobj.dance()\n## SmalltalkObject: 'dance' not found\n</code></pre> <p>Python can't find the method <code>dance</code>, so it calls <code>obj.__getattr__(\"dance\")</code> which returns a function <code>handler(...)</code>. Calling <code>obj.dance()</code> now runs <code>handler(...)</code>, which calls <code>self.not_found(\"dance\", ...)</code></p>"},{"location":"Z11_Appendix_Dynamic_Smalltalk_vs_Static_Typing/#a-blank-chatbot","title":"A blank chatbot","text":"<p>Here's a basic <code>Chatbot</code> class that doesn't yet respond to anything:</p> <pre><code># chatbot.py\nfrom smalltalk_object import SmalltalkObject\n\n\nclass Chatbot(SmalltalkObject):\n    def __init__(self):\n        self.history = set()\n</code></pre> <p>If we send the <code>hello()</code> message to the <code>Chatbot</code>, it doesn't understand it:</p> <pre><code># talk_to_chatbot.py\nfrom chatbot import Chatbot\n\nbot = Chatbot()\nbot.hello()\n## Chatbot: 'hello' not found\n</code></pre> <p>It uses <code>__getattr__</code> to search for <code>hello()</code> which it doesn't find, so it falls back to <code>not_found</code>.</p>"},{"location":"Z11_Appendix_Dynamic_Smalltalk_vs_Static_Typing/#teach-it-to-say-hello","title":"Teach it to say hello","text":"<pre><code># add_hello.py\nfrom chatbot import Chatbot\n\nbot = Chatbot()\n\n\ndef hello(self):\n    print(\"Hello! I'm your chatbot.\")\n    self.history.add(\"hello\")\n\n\nsetattr(Chatbot, \"hello\", hello)\nbot.hello()\n## Hello! I'm your chatbot.\n</code></pre> <p>We added this method at runtime. No compilation step--just live system growth.</p> <p>Now let's make it remember unknown messages by creating a new <code>not_found</code> that adds unknown messages to its <code>history</code>:</p> <pre><code># not_found_with_history.py\n\n\ndef not_found(self, message, *args, **kwargs):\n    print(f\"Don't know '{message}'; remembering it.\")\n    self.history.add(message)\n</code></pre> <p>We override the default <code>not_found</code> with our new version:</p> <pre><code># override_not_found.py\nfrom chatbot import Chatbot\nfrom not_found_with_history import not_found\n\nbot = Chatbot()\nsetattr(Chatbot, \"not_found\", not_found)\n\nbot.weather()\n## Don't know 'weather'; remembering it.\nbot.joke()\n## Don't know 'joke'; remembering it.\n</code></pre> <p>The chatbot learns from what it hears.</p>"},{"location":"Z11_Appendix_Dynamic_Smalltalk_vs_Static_Typing/#teach-it-a-joke","title":"Teach it a joke","text":"<pre><code># joke.py\ndef joke(self):\n    print(\"Why did the duck cross the road?\")\n    print(\"It was the chicken's day off.\")\n    self.history.add(\"joke\")\n</code></pre> <pre><code># learn_joke.py\nfrom chatbot import Chatbot\nfrom joke import joke\n\nbot = Chatbot()\nsetattr(Chatbot, \"joke\", joke)\nbot.joke()\n## Why did the duck cross the road?\n## It was the chicken's day off.\n</code></pre> <p>Again, we add behavior dynamically.</p>"},{"location":"Z11_Appendix_Dynamic_Smalltalk_vs_Static_Typing/#inspect-its-capabilities","title":"Inspect its capabilities","text":"<pre><code># introspection.py\nfrom add_hello import bot\n## Hello! I'm your chatbot.\nimport override_not_found\n## Don't know 'weather'; remembering it.\n## Don't know 'joke'; remembering it.\nimport learn_joke\n## Why did the duck cross the road?\n## It was the chicken's day off.\n\nprint([m for m in dir(bot) if not m.startswith(\"_\")])\n## ['hello', 'history', 'joke', 'not_found']\nprint(bot.history)\n## {'hello'}\n</code></pre> <p>Just like a Smalltalk browser, we inspect our object's current interface and state.</p>"},{"location":"Z11_Appendix_Dynamic_Smalltalk_vs_Static_Typing/#why-smalltalk-oop-didnt-become-statically-compiled-oop","title":"Why Smalltalk OOP Didn't Become Statically Compiled OOP","text":""},{"location":"Z11_Appendix_Dynamic_Smalltalk_vs_Static_Typing/#a-proof-of-concept-is-not-a-product","title":"A Proof-of-Concept is not a Product","text":""},{"location":"Z11_Appendix_Dynamic_Smalltalk_vs_Static_Typing/#the-dynamism-of-smalltalk-cant-be-tied-down","title":"The Dynamism of Smalltalk Can't be Tied Down","text":""},{"location":"Z11_Appendix_Dynamic_Smalltalk_vs_Static_Typing/#inheritance-forces-you-to-deal-with-the-base-class","title":"Inheritance Forces you to Deal with the Base Class","text":"<p>You must make your new class a \"type of\" the base class, and all that entails, including overriding methods you don't care about. Your new class belongs to the base class, but with composition, the member object belongs to your new class. With composition, the object does what you want it to do, with inheritance, you must do what the base class wants you to do.</p> <p>Arguably the only success story, Ruby, is a kind of Smalltalk.</p>"},{"location":"Z11_Appendix_Dynamic_Smalltalk_vs_Static_Typing/#type-in-smalltalk-a-dynamic-message-driven-perspective","title":"\"Type\" in Smalltalk: A Dynamic, Message--Driven Perspective","text":"<p>In Smalltalk, an object's identity and capabilities are not described by an explicit static type annotation. Instead, an object is defined by the messages it can respond to. In other words, an object's protocol--the collection of message selectors (methods) it understands--is effectively its \"type.\" You determine what an object can do by the messages you send it and how it responds, not by checking a formal static type label.</p> <p>This message-centric view is fundamental to the Smalltalk experience. All computation in Smalltalk is performed by sending messages to objects. There are no free functions or primitive operations outside of this model--every operation is a message sent to some object. The result of a message depends entirely on the receiver object: the same message selector might do something completely different on another object because each class provides its own method for that message. This means the object itself decides how to fulfill a request, reinforcing the idea that what matters is the object's behavior (its responses to messages), not an external static description.</p>"},{"location":"Z11_Appendix_Dynamic_Smalltalk_vs_Static_Typing/#type-as-an-emergent-set-of-behaviors-duck-typing","title":"\"Type\" as an Emergent Set of Behaviors (Duck Typing)","text":"<p>Because there are no declared types on variables or method arguments in Smalltalk, the concept of \"type\" becomes an emergent property of an object's behavior. A Smalltalk object's type can be thought of as \"the set of messages to which an object can meaningfully respond.\" In modern parlance, this is essentially duck typing--\"if it walks like a duck and quacks like a duck, it's a duck.\" Smalltalkers don't ask \"Is this object of type Duck?\"--there is no formal type check or interface to query. Instead, they ask *\"Can this object respond to the messages we associate with a duck (like <code>quack</code>or <code>swim</code>)?\". If yes, then for all intents and purposes, it can play the role of a duck in the program. Different classes can implement the same set of messages, thereby effectively conforming to the same \"duck type.\" This gives Smalltalk tremendous flexibility and polymorphism--any object that implements the expected messages can be used in a given context, regardless of its class.</p> <p>It's important to note that Smalltalk is not \"weakly typed\" or \"untyped.\" It is in fact strongly typed at runtime--if you send a message an object doesn't understand, the system will throw a runtime error rather than blindly misinterpreting it. Strong typing only means type errors are prevented; it does not require that they be prevented at compile time. Smalltalk enforces type safety dynamically: a <code>MessageNotUnderstood</code> error will halt a misuse, analogous to a type error in a static system, but occurring at runtime. Thus, every object has a type in the sense of a well-defined set of messages/methods; what Smalltalk lacks is a static type checker to verify those at compile time. A value's type is an intrinsic property of the object (determined by its class and methods) and not of the variable referencing it. Any variable can refer to any object, so the \"type\" lives with the object, not the variable. This is a form of optimistic typing--the system trusts the programmer to send appropriate messages and will dynamically prevent or flag errors if the trust is violated.</p>"},{"location":"Z11_Appendix_Dynamic_Smalltalk_vs_Static_Typing/#handling-the-unknown-doesnotunderstand","title":"*Handling the Unknown: <code>doesNotUnderstand:</code>","text":"<p>One fascinating aspect of Smalltalk's message-centric design is how it handles an unknown message. If you send an object a message for which it has no defined method, the runtime doesn't immediately crash. Instead, it sends a special message <code>doesNotUnderstand:</code> to that object, passing along a description of the original message. By default, <code>Object&gt;&gt;doesNotUnderstand:</code> will raise a <code>MessageNotUnderstood</code> error (often opening a debugger in a Smalltalk IDE), but critically, developers can override this method to change the behavior. This means an object can be designed to gracefully handle any message at all, even ones not originally defined in its class's method dictionary.</p> <p>For example, one could create a proxy object that intercepts all messages via <code>doesNotUnderstand:</code> and forwards them to another object, or a stub that logs all unknown messages for testing. In fact, Smalltalk was the first language to introduce this kind of open-ended message handling, and it unlocks a lot of power. Using <code>doesNotUnderstand:</code>, programmers have implemented features like remote method invocation proxies, lazy-loaded objects, futures, and other patterns that require catching arbitrary messages at runtime. The existence of <code>doesNotUnderstand:</code> underscores that an object's \"type\" (its message-handling ability) isn't necessarily fixed by its class--it can be extended or altered at runtime in a very dynamic fashion. Thanks to this mechanism, an object can respond to a message without considering when it was written. From a philosophical view, this pushes the \"duck typing\" idea to the extreme: an object can choose to attempt anything asked of it, defining its behavior on the fly.</p> <p>The flip side is that you truly don't know if a given message will be handled until you send it. In practice, Smalltalk programmers cope with this by testing and by building systems where the expectations are clear (or by using the interactive tools to inspect an object's class/protocol). But it does raise an interesting question: if the only way to know what an object can do is to try it and see, can we really say the object \"has a type\" in the same sense as in a statically typed language? The answer in Smalltalk is that type is a dynamic notion--it's something an object does, not something it declares. The object's type manifests when a message is sent and successfully understood. If it isn't, that's effectively a type mismatch, caught by the runtime (often during development in the live environment).</p>"},{"location":"Z11_Appendix_Dynamic_Smalltalk_vs_Static_Typing/#classes-as-behavioral-templates-not-compile-time-constraints","title":"Classes as Behavioral Templates, Not Compile-Time Constraints","text":"<p>Smalltalk is a class-based OO language, and every object is an instance of some class. However, a class in Smalltalk is not a \"type\" in the static sense; it's more like a template that defines behavior and structure. A class specifies which messages its instances will understand (by providing method implementations for those messages), and it defines the internal state structure. Two different classes could end up implementing the same protocol (thus effectively the same behavioral type), but they would still be distinct classes (perhaps with different internal representations). The Smalltalk system doesn't have a separate notion of an interface or protocol type distinct from classes--classes are how you organize and advertise what messages exist. But importantly, the system will never restrict you to using only a particular class in a given variable or call. There's no static type checker insisting \"this variable must contain an instance of class X.\" The class is a property of the object itself, not a restriction on its use by others.</p> <p>In the Smalltalk programmer's mind, classes serve as a useful guide and documentation of an object's capabilities, but not a rigid cage. They provide a shared vocabulary of messages for all instances of that class (and subclasses), which helps humans reason about what an object can do. For example, if you have a <code>GraphicsShape</code> class with methods like <code>drawOn:</code>, <code>area</code>, etc., you know any instance of that class (or its subclasses) will respond to those messages. In day-to-day practice, a Smalltalk developer does often think in terms of an object's class when reasoning about what messages it can handle--the class system is the primary organizational tool for behavior. But this is a convention and convenience, not an enforcement mechanism. You could always substitute an object of a completely different class in a piece of code, as long as it implements the needed messages. The Smalltalk environment even allows adding methods to classes at runtime or creating entirely new classes on the fly, which means the system's notion of who can respond to what is always malleable. Classes thus shape an object's behavior, but they do not constitute a static contract imposed on the rest of the program.</p> <p>It's illuminating to compare this with how statically typed languages use classes. In a language like Java or C++, a class (or an interface) is treated as a type contract. Programmers in those languages think of types as a form of guarantee or enforcement: if a variable is declared of interface type <code>Drawable</code>, the compiler guarantees it can only ever hold objects that implement the <code>draw()</code> method (and will refuse to compile code that tries to call a non-existent method or assign an incompatible type). Types in statically typed languages act like promises enforced by the compiler--they delineate what you can and cannot do at compile time. They also function as explicit documentation: you read a function signature and see what types it accepts/returns, shaping your expectations. Many developers in static systems conceptualize a type as a contractual specification of an object's interface (sometimes even enriched with static checks for invariants, generics, etc., as the \"shape\" of data).</p> <p>In Smalltalk, by contrast, a class is not a promise to the compiler (since there is no compile-time type checking). It's more a description for the programmer and a container of methods. The \"contract\" in Smalltalk is informal and psychological: you are expected to pass objects that will do the right thing. If you violate that expectation, the system will tell you at runtime. Thus, the mental model shifts from \"I have a guarantee this object supports X, Y, Z operations\" to \"I believe (or have tested) that this object supports X, Y, Z--and if I'm wrong, I'll find out when I run the code.\" The class of the object is a strong hint (since class defines the methods), but it's not an enforced boundary. Indeed, a seasoned Smalltalker might say an object's true \"type\" is simply the set of messages it knows how to handle, regardless of its class name. The class is one way to know that set, but it's not the only way--you could also query the object at runtime (ask it <code>respondsTo:</code> a certain selector) or consult documentation/tests.</p>"},{"location":"Z11_Appendix_Dynamic_Smalltalk_vs_Static_Typing/#living-with-dynamic-typing-the-programmers-experience","title":"Living with Dynamic Typing: The Programmer's Experience","text":"<p>The day-to-day experience of programming in Smalltalk is very dynamic and interactive, which affects how one thinks about types. In a static language, you often plan out type hierarchies and use the compiler as a tool to catch mistakes early. In Smalltalk, you rely on a combination of clear design, tests, and the interactive environment to ensure objects are used appropriately. For example, you might write a method that expects \"an object that can print itself.\" You won't declare a type, but you'll likely name the parameter suggestively (e.g. <code>anObject</code> or <code>aPrintable</code>) and maybe mention in a comment that it should respond to <code>printOn:</code>. When using that method, you ensure you pass something like a String or a Number (classes that you know implement <code>printOn:</code>). There is a lot of trust and convention involved--but it's trust backed by the ability to quickly try things out in the live environment.</p> <p>Smalltalk's development environment is a persistent image of objects, where you can test sending messages in a Workspace or inspect an object's class and methods on the fly. This means that if you're unsure about what messages an object supports, you can literally ask the object or its class at runtime. The system can list an object's method selectors or let you browse its class hierarchy. This introspective capability (made possible because everything is alive in the image) gives you a form of \"live documentation.\" A Smalltalk system is an ecosystem of live objects. You can query the running program directly, rather than rely solely on static type information.</p> <p>When you make a mistake--say you send a message an object doesn't understand--it's not usually a silent failure. In a typical Smalltalk IDE, a debugger pops up at the point of error (the MessageNotUnderstood). This is not just an error message; it's an opportunity. You can inspect the object that failed (seeing its class and state), figure out why it didn't have the method, and often even define the missing method right there in the debugger and continue execution. This exemplifies the \"lived\" experience: the program is malleable and can be fixed or extended on the fly. The boundary of what an object's \"type\" is can literally be extended during runtime by adding a new method to its class (or by implementing <code>doesNotUnderstand:</code> to catch that message next time). Such dynamism is foreign to statically typed environments but is natural in Smalltalk's philosophy. It emphasizes that software is fluid--an object's behavior (hence its type) can evolve as the program runs.</p> <p>From a philosophical standpoint, a Smalltalk programmer tends to think in terms of objects and messages first, and types (in the classical sense) hardly at all. Alan Kay, the father of Smalltalk, famously remarked that \"OOP to me means only messaging, local retention and protection and hiding of state-process, and extreme late-binding of all things.\" (Late-binding here refers to deciding at run-time what method to invoke for a given message--precisely what dynamic typing entails.) This mindset puts the focus on behavior rather than classification. If you ask a Smalltalker \"what type is this object?\" they are likely to answer in terms of its class or its responsibilities (e.g. \"this is a kind of stream object--it can next/nextPut: etc.\"). They wouldn't typically enumerate a static type name with a fixed interface contract because that's not how the language frames the discussion.</p> <p>All you can do with any object is send it a message and observe the result; therefore, conceptually, \"type\" is just a description of those results you can expect.</p>"},{"location":"Z11_Appendix_Dynamic_Smalltalk_vs_Static_Typing/#contrast-with-the-static-typing-mindset","title":"Contrast with the Static Typing Mindset","text":"<p>To crystallize the differences, it helps to compare the Smalltalk approach with how statically typed language programmers think about types:</p> <p>Types as Explicit Contracts (Static Languages): In a static language (Java, C#, Haskell, etc.), a type is an explicit contract or blueprint for both the compiler and the programmer. For instance, an interface in Java might guarantee that anything of that interface type has certain methods. The programmer leans on the compiler to enforce that contract--calling a non-existent method or violating type expectations is caught at compile time. This often leads to designing software by starting with type definitions (classes/interfaces) that model the problem domain and using those as constraints* to prevent incorrect usage. Types also serve as documentation: you know a function <code>foo(Vector v)</code> requires a <code>Vector</code> and you know what a <code>Vector</code> can do (from its class/interface definition). There's comfort (and some rigidity) in this; you can't accidentally call <code>v.turnPurple()</code> on a <code>Vector</code> if that method isn't in its type. But you also can't pass a <code>Matrix</code> to <code>foo</code> unless <code>Matrix</code> is declared to be a subclass or implementer of <code>Vector</code>--even if <code>Matrix</code> happens to support all the same operations needed, the static type system will reject it if it's not formally declared compatible.</p> <ul> <li>Types as Descriptions of Behavior (Smalltalk): In Smalltalk, types are not explicit labels but implicit descriptions of behavior.   If a method expects a \"duck-like\" object, you simply pass it an object and trust it knows how to quack; there is no   <code>IDuck</code> interface to check against.   As long as the object can handle the messages used inside the method, it works--otherwise a runtime error occurs.   This is often called \"programming by wishful   thinking\" or optimistic coding: you code as if the object will do what you want, and usually your design ensures it will.   In cases where you want to be cautious, you might do a runtime check (using <code>object respondsTo: #quack</code> or an   <code>isKindOf:</code> check), but ideally polymorphism makes that unnecessary.   The emphasis is on what an object can do, not what it is declared to be.   The result is a very flexible system: any object that meets the behavioral expectations can be used, even if it wasn't originally anticipated.   There is no need to cast or to adapt types to match an exact signature--the message itself is the only requirement.   This is why Smalltalk (and languages like it) enable a style where   \"if it quacks like a duck, it's a duck.\"   The trade-off is that mistakes show up at runtime, so thorough testing and a good suite of examples are essential to gain confidence in the code's correctness.</li> </ul> <p>Classes vs. Types: Smalltalk's classes fill some of the same roles as static types (grouping objects with similar behavior, giving a name to a set of methods), but they are not used as a compile-time gatekeeper. They are more for the programmer's organization and the runtime method lookup. In statically typed languages, you often have distinct concepts of \"class vs interface vs type parameter,\" etc., which are all part of the type system. Smalltalk collapses much of that--a class is essentially a concrete implementation and potentially* also the description of a protocol, but there's nothing like a separately declared interface. So a Smalltalk programmer might think \"this object is a kind of OrderedCollection because it's an instance of that class, so it supports all the collection messages.\" But they are also free to pass in any other object that honors the same messages (even if it's not a <code>OrderedCollection</code> subclass) to code that was written with <code>OrderedCollection</code> in mind. The flexibility is higher, though the guarantee is only verified when the code runs.</p> <p>Programmers in statically typed languages often view types as static contracts or enforcement mechanisms, whereas Smalltalk programmers view types as emergent properties of objects. The Smalltalker's mindset is shaped by a live, message-oriented world where you gain understanding by sending messages and watching objects behave. It's a very experience-driven understanding of type: an object \"proves\" its type by working correctly in response to your messages, not by satisfying a compiler check ahead of time. This can be incredibly liberating--it encourages focusing on what needs to happen in the problem domain, letting different kinds of objects participate as long as they behave appropriately. As the Smalltalk ethos would suggest, \"Look at what the object does, not what it says it is.\"</p>"},{"location":"Z11_Appendix_Dynamic_Smalltalk_vs_Static_Typing/#conclusion-the-philosophical-takeaway","title":"Conclusion: The Philosophical Takeaway","text":"<p>From a practical and philosophical perspective, \"type\" in Smalltalk is less a label and more a dynamic quality of an object's behavior. It's defined by the messages an object understands and how it respond--this is ultimately determined the class methods along with any clever <code>doesNotUnderstand:</code> tricks. An object can certainly be said to \"have a type\" in Smalltalk--but that type isn't a static tag; it's the set of messages it can handle, i.e., its protocol. Smalltalk's class system provides the structure for those protocols (acting as a template for behavior), but it doesn't impose the sort of strict borders that static type systems do. Instead of types as fences that keep misuse at bay, Smalltalk offers open pastures where objects roam freely as long as they know how to handle the interactions (messages) that come their way.</p> <p>The lived Smalltalk experience is one of constant discovery and feedback: you send a message and see what happens. This leads to a very concrete understanding of an object's capabilities--you gain knowledge of its \"type\" by observing it in action. Philosophically, this shifts the notion of type from an abstract compile-time idea to a tangible runtime reality. Rather than trust a compiler's assurances, you come to trust the objects themselves (and your tests of them). Smalltalk's message-driven worldview teaches that an object is defined only by what it does. By emphasizing messaging and late binding, it reminds us that software is ultimately about dynamic interactions. In statically typed systems, type is often treated as essence; in Smalltalk, type is experience. The result is a programming model that is highly flexible, deeply object-oriented, and rooted in the immediate reality of message sends--a model where the concept of \"type\" lives not in declarations, but in the rich interplay between objects at runtime.</p>"},{"location":"Z12_Appendix_Uncategorized_Topics/","title":"Appendix: Uncategorized Topics","text":"<p>These need to appear somewhere...</p>"},{"location":"Z12_Appendix_Uncategorized_Topics/#annotated-for-metadata","title":"<code>Annotated</code> for Metadata","text":"<p>Demonstration using Cyclopts</p> <p><code>Annotated</code> provides metadata for types, useful in documentation, validation, or frameworks:</p> <pre><code># example_2.py\nfrom typing import Annotated\n\nUserID = Annotated[int, \"Database primary key\"]\n\n\ndef fetch_user(user_id: UserID) -&gt; dict:\n    return {\"id\": user_id, \"name\": \"Alice\"}\n</code></pre> <p>Metadata within <code>Annotated</code> helps convey additional context beyond type annotations.</p>"},{"location":"Z12_Appendix_Uncategorized_Topics/#type-narrowing","title":"Type Narrowing","text":"<p>Perhaps a short chapter?</p> <p>Type narrowing refines a variable's type within conditional checks:</p>"},{"location":"Z12_Appendix_Uncategorized_Topics/#using-isinstance","title":"Using <code>isinstance</code>","text":"<pre><code># example_4.py\n\n\ndef process(value: int | str) -&gt; None:\n    if isinstance(value, int):\n        print(value + 1)\n    else:\n        print(value.upper())\n</code></pre>"},{"location":"Z12_Appendix_Uncategorized_Topics/#using-assertions","title":"Using assertions","text":"<pre><code># example_5.py\nfrom typing import Optional\n\n\ndef greet(name: Optional[str]) -&gt; None:\n    assert name is not None, \"Name cannot be None\"\n    print(f\"Hello, {name}\")\n</code></pre> <p>Type narrowing helps write precise, safe, and understandable code.</p>"},{"location":"Z12_Appendix_Uncategorized_Topics/#type-guards-isinstance-custom-type-guards-assertions","title":"Type Guards (<code>isinstance</code>, custom type guards, assertions)","text":"<p>Custom type guards offer explicit ways to narrow types more clearly:</p>"},{"location":"Z12_Appendix_Uncategorized_Topics/#custom-type-guard-functions-python-310","title":"Custom type guard functions (Python 3.10+)","text":"<pre><code># example_6.py\nfrom typing import TypeGuard\n\n\nclass Cat:\n    def meow(self):\n        print(\"Meow!\")\n\n\ndef is_cat(animal: object) -&gt; TypeGuard[Cat]:\n    return hasattr(animal, \"meow\")\n\n\nanimal = Cat()\nif is_cat(animal):\n    animal.meow()  # Safe to call\n## Meow!\n</code></pre> <p>Type guards enhance type narrowing accuracy, making code safer and cleaner.</p>"}]}