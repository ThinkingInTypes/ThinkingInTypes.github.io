{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Thinking in Types","text":"<p>by Bruce Eckel</p>"},{"location":"#building-stubbornly-resilient-python-code","title":"Building Stubbornly Resilient Python Code","text":""},{"location":"01_Preface/","title":"Preface","text":""},{"location":"01_Preface/#strong-typing-vs-strong-testing","title":"Strong Typing vs. Strong Testing","text":""},{"location":"01_Preface/#tight-vs-permissive-type-systems","title":"Tight vs Permissive Type Systems","text":""},{"location":"01_Preface/#why-am-i-creating-this-book-in-the-open","title":"Why am I creating this book \"in the open\"?","text":"<ul> <li> <p>Thinking in C++ and Thinking in Java</p> </li> <li> <p>A \"Business Model\" can be about more than just money</p> </li> </ul>"},{"location":"01_Preface/#acknowledgements","title":"Acknowledgements","text":"<p>Most of the understanding I needed to explain this topic came from my attempts to help on the book by Bill Frasure and James Ward, titled \"Effect-Oriented Programming,\" that we worked on for over four years. I\u2019ve also learned a lot from some of the interviews that James and I have done for the Happy Path Programming podcast.</p>"},{"location":"02_Foundations/","title":"Foundations","text":"<p>Assumptions I make about your Python &amp; programming knowledge.</p>"},{"location":"02_Foundations/#your-python-knowlege","title":"Your Python Knowlege","text":"<ul> <li>You have intermediate-level understanding of the language, including a reasonable grasp of classes</li> <li>You understand core language features and know how to look up and learn features you haven't seen</li> <li>I will explain things I think are outside the core</li> </ul>"},{"location":"02_Foundations/#this-book-uses","title":"This book uses","text":"<ul> <li>Version control with github</li> <li>Project management with uv</li> <li>Testing with Pytest (noting that there are valid reasons to use other systems)</li> <li>Project organization (src directory)</li> </ul>"},{"location":"02_Foundations/#programming-philosophy","title":"Programming Philosophy","text":"<ul> <li>Build up from small testable pieces, balanced with simplicity and clarity.</li> <li>Use the most modern/elegant coding mechanisms available (latest Python)</li> <li>Classes are for creating types. As much as possible, pretend inheritance doesn't exist.</li> </ul>"},{"location":"02_Foundations/#examples","title":"Examples","text":"<ul> <li>Each example has a \"slug line\" which is simply the name of the file in a single-line comment as line one of the example.</li> <li>That example is in the Github repository in a subdirectory named for the chapter.</li> <li>The examples do not have <code>__main__</code>s; everything is at the top level.</li> <li>If a top-level-statement (TLS) produces output, that output will appear on the following line(s), commented with <code>##</code>.</li> <li>Lines to be called out in text are marked with comments</li> <li>Black for consistent formatting</li> <li>Listings 47 Characters wide: readable on a phone</li> </ul>"},{"location":"03_What_is_a_Type/","title":"What is a Type?","text":"<p>This placeholder text was generated by ChatGPT 4.5. It will be significantly rewritten as the book is developed. In the meantime you can add comments to either https://bsky.app/bruceeckel or Github Issues.</p> <ul> <li>Types enable code generation tools, e.g. Typer, Cyclopts</li> </ul>"},{"location":"03_What_is_a_Type/#dynamic-vs-static-typing-definitions-pros-and-cons","title":"Dynamic vs. Static Typing: Definitions, Pros, and Cons","text":"<p>Python is traditionally known as a dynamically typed language. This means the types of variables are determined at runtime rather than explicitly declared. For example:</p> <pre><code># example_1.py\nx = 42  # x is dynamically assigned as an integer\ny = \"hello\"  # y is dynamically assigned as a string\n</code></pre> <p>In contrast, statically typed languages require explicit type declarations, and types are checked at compile time:</p> <pre><code>// int_and_string.cpp\n#include &lt;string&gt;\n\nint x = 42;               \nstd::string y = \"hello\";  \n</code></pre> <p>Pros of dynamic typing:</p> <ul> <li>Faster prototyping and development</li> <li>Greater flexibility in handling different types</li> <li>Easier learning curve for beginners</li> </ul> <p>Cons of dynamic typing:</p> <ul> <li>Runtime type errors can occur unexpectedly</li> <li>Less clarity on expected data types</li> <li>Reduced safety and predictability</li> </ul> <p>Pros of static typing:</p> <ul> <li>Type errors caught early at compile time</li> <li>Enhanced code clarity and readability</li> <li>Improved performance and optimization opportunities</li> </ul> <p>Cons of static typing:</p> <ul> <li>Verbose code with explicit declarations</li> <li>Potentially slower initial development</li> <li>Steeper learning curve for newcomers</li> </ul>"},{"location":"03_What_is_a_Type/#pythons-typing-evolution-from-duck-typing-to-type-annotations","title":"Python's Typing Evolution: From Duck Typing to Type Annotations","text":"<p>Python initially embraced the concept of \"duck typing,\" where the suitability of an object is determined by the presence of methods and properties, not by its explicit type. If it looks like a duck and quacks like a duck, it's treated as a duck:</p> <pre><code># example_2.py\nclass Duck:\n    def quack(self):\n        print(\"Quack!\")\n\n\ndef make_it_quack(bird):\n    bird.quack()\n\n\nmake_it_quack(Duck())  # works fine\n## Quack!\n</code></pre> <p>However, as Python projects grew in scale and complexity, the need for type safety and clearer documentation became apparent. Python 3.5 introduced type annotations, allowing developers to optionally specify expected types:</p> <pre><code># example_3.py\ndef greet(name: str) -&gt; str:\n    return f\"Hello, {name}!\"\n</code></pre> <p>This evolution combines the best of both worlds\u2014maintaining Python's flexibility while adding optional type safety.</p>"},{"location":"03_What_is_a_Type/#benefits-of-type-annotations-maintainability-readability-safety","title":"Benefits of Type Annotations: Maintainability, Readability, Safety","text":""},{"location":"03_What_is_a_Type/#maintainability","title":"Maintainability","text":"<ul> <li>Clearly defined types make code easier to refactor and maintain over time.</li> <li>Reduces uncertainty about the intended use of variables and functions.</li> </ul>"},{"location":"03_What_is_a_Type/#readability","title":"Readability","text":"<ul> <li>Type annotations serve as inline documentation.</li> <li>Quickly communicates developer intentions to other team members.</li> </ul>"},{"location":"03_What_is_a_Type/#safety","title":"Safety","text":"<ul> <li>Catch errors early, before the program runs.</li> <li>Reduces runtime exceptions due to unexpected types.</li> </ul>"},{"location":"03_What_is_a_Type/#type-checking-tools-overview-mypy-pyright-pycharm","title":"Type Checking Tools Overview (<code>mypy</code>, <code>pyright</code>, PyCharm)","text":"<p>Python\u2019s ecosystem provides robust tools to leverage type annotations:</p>"},{"location":"03_What_is_a_Type/#mypy","title":"mypy","text":"<ul> <li>One of the earliest static type checkers for Python.</li> <li>Highly configurable and widely adopted.</li> </ul> <pre><code>pip install mypy\nmypy your_script.py\n</code></pre>"},{"location":"03_What_is_a_Type/#pyright","title":"pyright","text":"<ul> <li>Developed by Microsoft, emphasizing performance and ease of use.</li> <li>Built into VSCode, offering real-time feedback.</li> </ul> <pre><code>npm install -g pyright\npyright your_script.py\n</code></pre>"},{"location":"03_What_is_a_Type/#pycharm","title":"PyCharm","text":"<ul> <li>Integrated IDE support for type checking.</li> <li>Provides immediate visual feedback as you write code.</li> </ul> <p>These tools allow developers to incrementally adopt static typing, improving code reliability without sacrificing Python's dynamic roots.</p>"},{"location":"03_What_is_a_Type/#understanding-runtime-vs-static-type-checking","title":"Understanding Runtime vs. Static Type Checking","text":""},{"location":"03_What_is_a_Type/#runtime-type-checking","title":"Runtime Type Checking","text":"<ul> <li>Types are validated as the program executes.</li> <li>Errors surface only when problematic code is executed.</li> </ul> <pre><code># example_4.py\nfrom book_utils import Catch\n\ndef add(a, b):\n    return a + b\n\nwith Catch():\n    add(1, \"2\")  # raises runtime TypeError\n## Error: unsupported operand type(s) for +: 'int'\n## and 'str'\n</code></pre>"},{"location":"03_What_is_a_Type/#static-type-checking","title":"Static Type Checking","text":"<ul> <li>Performed before the code runs, typically during development or as part of CI/CD pipelines.</li> <li>Prevents many type-related errors by analyzing code structure.</li> </ul> <pre><code># example_5.py\nfrom book_utils import Catch\n\n\ndef add(a: int, b: int) -&gt; int:\n    return a + b\n\nwith Catch():\n    add(1, \"2\")  # Static type checker flags this\n## Error: unsupported operand type(s) for +: 'int'\n## and 'str'\n</code></pre> <p>By combining runtime flexibility with static checking, Python provides a balanced approach that empowers developers to write safe, readable, and maintainable code.</p>"},{"location":"04_Predefined_Types/","title":"Predefined Types","text":"<p>This placeholder text was generated by ChatGPT 4.5. It will be significantly rewritten as the book is developed. In the meantime you can add comments to either https://bsky.app/bruceeckel or Github Issues.</p>"},{"location":"04_Predefined_Types/#built-in-types-int-str-float-bool-none","title":"Built-in Types (<code>int</code>, <code>str</code>, <code>float</code>, <code>bool</code>, <code>None</code>)","text":"<p>Python supports type annotations for its fundamental built-in types, allowing developers to clarify expected types of variables and function arguments explicitly:</p> <pre><code># example_1.py\nage: int = 25\nname: str = \"Alice\"\nsalary: float = 45000.50\nis_active: bool = True\nno_value: None = None\n</code></pre> <p>These annotations immediately communicate intent, simplifying code readability and maintainability.</p>"},{"location":"04_Predefined_Types/#variables-and-functions","title":"Variables and Functions","text":"<p>Type annotations can be added to variables and function parameters to indicate expected data types:</p>"},{"location":"04_Predefined_Types/#variables","title":"Variables","text":"<pre><code># example_2.py\nuser_id: int = 123\nusername: str = \"admin\"\n</code></pre>"},{"location":"04_Predefined_Types/#functions","title":"Functions","text":"<pre><code># example_3.py\ndef greet_user(username: str) -&gt; str:\n    return f\"Welcome, {username}!\"\n</code></pre> <p>Annotations clearly specify expected input and output types, helping prevent bugs and errors.</p>"},{"location":"04_Predefined_Types/#optional-types-and-default-values","title":"Optional Types and Default Values","text":"<p>Sometimes a variable or function argument can be a specific type or <code>None</code>. Python uses <code>Optional</code> from <code>typing</code> to indicate this:</p> <pre><code># example_4.py\nfrom typing import Optional\n\n\ndef find_user(user_id: int) -&gt; Optional[str]:\n    if user_id == 1:\n        return \"Alice\"\n    return None\n</code></pre> <p>Default values with optional annotations:</p> <pre><code># example_5.py\nfrom typing import Optional\n\n\ndef greet(name: Optional[str] = None) -&gt; str:\n    if name:\n        return f\"Hello, {name}!\"\n    return \"Hello!\"\n</code></pre>"},{"location":"04_Predefined_Types/#using-union-types-operator-vs-union","title":"Using Union Types (<code>|</code> operator vs. <code>Union</code>)","text":"<p>Python allows you to specify multiple acceptable types for variables or parameters. Traditionally, the <code>Union</code> type was used, but Python 3.10 introduced the <code>|</code> operator for readability:</p>"},{"location":"04_Predefined_Types/#using-union","title":"Using <code>Union</code>","text":"<pre><code># example_6.py\nfrom typing import Union\n\n\ndef process_value(value: Union[int, str]) -&gt; str:\n    return str(value)\n</code></pre>"},{"location":"04_Predefined_Types/#using-operator-python-310","title":"Using <code>|</code> operator (Python 3.10+)","text":"<pre><code># example_7.py\ndef process_value(value: int | str) -&gt; str:\n    return str(value)\n</code></pre> <p>The <code>|</code> operator provides clearer and more concise syntax.</p>"},{"location":"04_Predefined_Types/#defining-type-aliases","title":"Defining Type Aliases","text":"<p>Type aliases simplify complex annotations by providing a readable and reusable name for a type:</p> <pre><code># example_8.py\nfrom typing import List\n\nUserIDs = List[int]\n\n\ndef process_users(user_ids: UserIDs) -&gt; None:\n    for uid in user_ids:\n        print(f\"Processing user {uid}\")\n</code></pre> <p>Aliases improve code clarity, especially for complex types.</p>"},{"location":"04_Predefined_Types/#lists-tuples-sets-and-dictionaries","title":"Lists, Tuples, Sets and Dictionaries","text":"<p>Python provides built-in collection types such as lists, tuples, sets, and dictionaries. Annotating these clearly specifies their expected contents:</p>"},{"location":"04_Predefined_Types/#lists","title":"Lists","text":"<pre><code># example_9.py\nfrom typing import List\n\nscores: List[int] = [95, 85, 75]\n</code></pre>"},{"location":"04_Predefined_Types/#tuples","title":"Tuples","text":"<pre><code># example_10.py\nfrom typing import Tuple\n\ncoordinates: Tuple[float, float] = (23.5, 45.8)\n</code></pre>"},{"location":"04_Predefined_Types/#sets","title":"Sets","text":"<pre><code># example_11.py\nfrom typing import Set\n\nunique_ids: Set[str] = {\"abc\", \"xyz\", \"123\"}\n</code></pre>"},{"location":"04_Predefined_Types/#dictionaries","title":"Dictionaries","text":"<pre><code># example_12.py\nfrom typing import Dict\n\nuser_data: Dict[str, int] = {\"Alice\": 30, \"Bob\": 25}\n</code></pre> <p>These annotations enhance readability and help catch type-related errors early.</p>"},{"location":"04_Predefined_Types/#annotations-without-imports","title":"Annotations without Imports","text":"<p>Starting from Python 3.9, built-in collection types support direct annotations without importing from <code>typing</code>:</p> <pre><code># example_13.py\nscores: list[int] = [95, 85, 75]\nuser_data: dict[str, float] = {\"Alice\": 95.5, \"Bob\": 85.3}\n</code></pre> <p>This simplified syntax enhances readability and reduces verbosity.</p>"},{"location":"04_Predefined_Types/#specialized-annotations-sequence-mapping-iterable-iterator","title":"Specialized Annotations (<code>Sequence</code>, <code>Mapping</code>, <code>Iterable</code>, <code>Iterator</code>)","text":"<p>Python provides specialized annotations for greater flexibility:</p>"},{"location":"04_Predefined_Types/#sequence","title":"<code>Sequence</code>","text":"<ul> <li>For any ordered collection supporting indexing:</li> </ul> <pre><code># example_14.py\nfrom typing import Sequence\n\n\ndef average(numbers: Sequence[float]) -&gt; float:\n    return sum(numbers) / len(numbers)\n</code></pre>"},{"location":"04_Predefined_Types/#mapping","title":"<code>Mapping</code>","text":"<ul> <li>For dictionary-like objects:</li> </ul> <pre><code># example_15.py\nfrom typing import Mapping\n\n\ndef get_user_age(users: Mapping[str, int], username: str) -&gt; int:\n    return users.get(username, 0)\n</code></pre>"},{"location":"04_Predefined_Types/#iterable-and-iterator","title":"<code>Iterable</code> and <code>Iterator</code>","text":"<ul> <li>For looping over items:</li> </ul> <pre><code># example_16.py\nfrom typing import Iterable, Iterator\n\n\ndef print_items(items: Iterable[str]) -&gt; None:\n    for item in items:\n        print(item)\n\n\ndef generate_numbers(n: int) -&gt; Iterator[int]:\n    for i in range(n):\n        yield i\n</code></pre> <p>Specialized annotations enable broader compatibility with various collection types.</p>"},{"location":"04_Predefined_Types/#common-annotation-patterns-and-errors","title":"Common Annotation Patterns and Errors","text":""},{"location":"04_Predefined_Types/#common-patterns","title":"Common Patterns","text":"<ul> <li>Clearly annotate function parameters and return values.</li> <li>Use type aliases for complex or repetitive types.</li> <li>Use optional annotations when values can legitimately be <code>None</code>.</li> </ul>"},{"location":"04_Predefined_Types/#common-errors","title":"Common Errors","text":"<ul> <li>Incorrect annotations (e.g., annotating as <code>int</code> when the value might be <code>float</code>).</li> <li>Missing annotations on important public APIs or interfaces.</li> <li>Overuse of overly broad types like <code>Any</code>, reducing annotation benefits.</li> </ul> <p>Example error:</p> <pre><code># example_17.py\nfrom book_utils import Catch\n\ndef calculate_area(radius: int) -&gt; float:\n    return 3.14 * radius**2\n\nwith Catch():\n    calculate_area(3.5)  # Flagged by static type checker\n</code></pre> <p>Careful use of annotations combined with static checking tools significantly enhances code robustness and readability.</p>"},{"location":"05_Custom_Types/","title":"Custom Types","text":"<ul> <li>Add variations: NamedTuple, Enum</li> <li>Incorporate examples from https://github.com/BruceEckel/DataClassesAsTypes</li> </ul> <p>This chapter began as a presentation at a Python conference, inspired by conversations with fellow  programmers exploring functional programming techniques.  Specifically, the idea arose from a podcast discussion about Scala's smart types.  After extensive study of functional programming, several concepts coalesced into an approach that  leverages Python\u2019s data classes effectively.  This chapter aims to share those insights and illustrate the practical benefits of Python data classes, guiding  you towards clearer, more reliable code.</p>"},{"location":"05_Custom_Types/#misunderstanding-class-attributes","title":"Misunderstanding Class Attributes","text":"<p>This chapter contains additional tools that modify the normal behavior of class attributes. It's important to understand that this behavior is created by the tool, and that ordinary classes do not behave this way. Read the Class Attributes appendix for deeper understanding.</p>"},{"location":"05_Custom_Types/#the-initial-problem-ensuring-correctness","title":"The Initial Problem: Ensuring Correctness","text":"<p>Imagine building a simple customer feedback system using a rating from one to ten stars. Traditionally, Python programmers use an integer type, checking its validity whenever it's used:</p> <pre><code># int_stars.py\n# Using 1-10 stars for customer feedback.\nfrom book_utils import Catch\n\n\ndef f1(stars: int) -&gt; int:\n    # Must check argument...\n    assert 1 &lt;= stars &lt;= 10, f\"f1: {stars}\"\n    return stars + 5\n\ndef f2(stars: int) -&gt; int:\n    # ...each place it is used.\n    assert 1 &lt;= stars &lt;= 10, f\"f2: {stars}\"\n    return stars * 5\n\nstars1 = 6\nprint(stars1)\n## 6\nprint(f1(stars1))\n## 11\nprint(f2(stars1))\n## 30\nstars2 = 11\nwith Catch():\n    print(f1(stars2))\n## Error: f1: 11\nstars1 = 99\nwith Catch():\n    print(f2(stars1))\n## Error: f2: 99\n</code></pre> <p>However, each time the integer is used, its validity must be rechecked, leading to duplicated logic,  scattered validation, and potential mistakes.</p>"},{"location":"05_Custom_Types/#traditional-object-oriented-encapsulation","title":"Traditional Object-Oriented Encapsulation","text":"<p>Object-oriented programming (OOP) suggests encapsulating validation within the class. Python typically uses a private attribute (indicated with a single leading underscore) for encapsulation:</p> <pre><code># stars_class.py\nfrom book_utils import Catch\n\n\nclass Stars:\n    def __init__(self, n_stars: int):\n        self._number = n_stars  # Private by convention\n        self.condition()\n\n    def condition(self, s: int|None = None):\n        if s:\n            assert 1 &lt;= s &lt;= 10, f\"{self}: {s}\"\n        else:\n            assert 1 &lt;= self._number &lt;= 10, f\"{self}\"\n\n    # Prevent external modification:\n    @property\n    def number(self): return self._number\n\n    # Create readable output:\n    def __str__(self) -&gt; str:\n        return f\"Stars({self._number})\"\n\n    # Every member function must guard the private variable:\n    def f1(self, n_stars: int) -&gt; int:\n        self.condition(n_stars)  # Precondition\n        self._number = n_stars + 5\n        self.condition()  # Postcondition\n        return self._number\n\n    def f2(self, n_stars: int) -&gt; int:\n        self.condition(n_stars)  # Precondition\n        self._number = n_stars * 5\n        self.condition()  # Postcondition\n        return self._number\n\nstars1 = Stars(4)\nprint(stars1)\n## Stars(4)\nprint(stars1.f1(3))\n## 8\nwith Catch():\n    print(stars1.f2(stars1.f1(3)))\n## Error: Stars(40)\nwith Catch():\n    stars2 = Stars(11)\n## Error: Stars(11)\nstars3 = Stars(5)\nwith Catch():\n    print(stars3.f1(4))\n## 9\nwith Catch():\n    print(stars3.f2(22))\n## Error: Stars(9): 22\n# @property without setter prevents mutation:\n# stars1.number = 99\n# AttributeError: can't set attribute 'number'\n</code></pre> <p>This approach centralizes validation, yet remains cumbersome.  Each method interacting with the attribute still requires pre-and post-condition checks, cluttering the code and potentially introducing errors if a developer neglects these checks.</p>"},{"location":"05_Custom_Types/#data-classes","title":"Data Classes","text":"<p>Data classes, introduced in Python 3.7, significantly streamline this process by generating essential methods automatically.  They provide a structured, concise way to define data-holding objects:</p> <pre><code># messenger.py\nfrom dataclasses import dataclass, replace\n\n@dataclass\nclass Messenger:\n    name: str\n    number: int\n    depth: float = 0.0  # Default argument\n\nx = Messenger(name=\"x\", number=9, depth=2.0)\nm = Messenger(\"foo\", 12, 3.14)\nprint(m)\n## Messenger(name='foo', number=12, depth=3.14)\nprint(m.name, m.number, m.depth)\n## foo 12 3.14\nmm = Messenger(\"xx\", 1)  # Uses default argument\nprint(mm == Messenger(\"xx\", 1))  # Generates __eq__()\n## True\nprint(mm == Messenger(\"xx\", 2))\n## False\n\n# Make a copy with a different depth:\nmc = replace(m, depth=9.9)\nprint(m, mc)\n## Messenger(name='foo', number=12, depth=3.14)\n## Messenger(name='foo', number=12, depth=9.9)\n\n# Mutable:\nm.name = \"bar\"\nprint(m)\n## Messenger(name='bar', number=12, depth=3.14)\n# d = {m: \"value\"}\n# TypeError: unhashable type: 'Messenger'\n</code></pre> <p>In a <code>dataclass</code>, validation logic resides exclusively in the <code>__post_init__</code> method,  executed automatically after initialization.  This guarantees that only valid <code>Stars</code> instances exist. </p>"},{"location":"05_Custom_Types/#immutable-data-classes-and-functional-programming","title":"Immutable Data Classes and Functional Programming","text":"<p>Functional programming strongly advocates immutability, preventing accidental changes and thus simplifying  reasoning about your code. Python data classes support immutability through a <code>frozen=True</code> parameter:</p> <pre><code># frozen_data_classes.py\nfrom dataclasses import dataclass\n\n@dataclass(frozen=True)\nclass Messenger:\n    name: str\n    number: int\n    depth: float = 0.0  # Default\n\nm = Messenger(\"foo\", 12, 3.14)\nprint(m)\n## Messenger(name='foo', number=12, depth=3.14)\n# Frozen dataclass is immutable:\n# m.name = \"bar\"\n# dataclasses.FrozenInstanceError: cannot assign to field 'name'\n# Automatically creates __hash__():\nd = {m: \"value\"}\nprint(d[m])\n## value\n</code></pre> <p>We can apply this approach to our <code>Stars</code> example:</p> <pre><code># stars.py\nfrom dataclasses import dataclass\n\nfrom book_utils import Catch\n\n\n@dataclass(frozen=True)\nclass Stars:\n    number: int\n    def __post_init__(self) -&gt; None:\n        assert 1 &lt;= self.number &lt;= 10, f\"{self}\"\n\ndef f1(s: Stars) -&gt; Stars:\n    return Stars(s.number + 5)\n\ndef f2(s: Stars) -&gt; Stars:\n    return Stars(s.number * 5)\n\nstars1 = Stars(4)\nprint(stars1)\n## Stars(number=4)\nprint(f1(stars1))\n## Stars(number=9)\nwith Catch():\n    print(f2(f1(stars1)))\n## Error: Stars(number=45)\nwith Catch():\n    stars2 = Stars(11)\n## Error: Stars(number=11)\nwith Catch():\n    print(f1(Stars(11)))\n## Error: Stars(number=11)\n</code></pre> <p>Subsequent functions operating on <code>Stars</code> no longer require redundant checks. Modifying a <code>Stars</code> instance after creation raises an error, further safeguarding the data integrity:</p> <pre><code># example_4.py\n# from stars import Stars\n\n# def increase_stars(rating: Stars, increment: int) -&gt; Stars:\n#    return Stars(rating.stars + increment)\n</code></pre> <p>If this function tries to create an invalid rating, the data class validation immediately raises an error.  This greatly simplifies code maintenance and readability.</p> <p>Additionally, immutable objects can safely serve as keys in dictionaries, allowing reliable data lookups and caching.</p>"},{"location":"05_Custom_Types/#composing-data-classes","title":"Composing Data Classes","text":"<p>Composition, another functional programming cornerstone, allows building complex data types from simpler ones.  Consider a <code>Person</code> object composed of <code>FullName</code>, <code>BirthDate</code>, and <code>Email</code> data classes:</p> <pre><code># dataclass_composition.py\nfrom dataclasses import dataclass\n\n@dataclass(frozen=True)\nclass FullName:\n    name: str\n    def __post_init__(self) -&gt; None:\n        print(f\"FullName checking {self.name}\")\n        assert len(self.name.split()) &gt; 1, \\\n              f\"'{self.name}' needs first and last names\"\n\n@dataclass(frozen=True)\nclass BirthDate:\n    dob: str\n    def __post_init__(self) -&gt; None:\n        print(f\"BirthDate checking {self.dob}\")\n\n@dataclass(frozen=True)\nclass EmailAddress:\n    address: str\n    def __post_init__(self) -&gt; None:\n        print(f\"EmailAddress checking {self.address}\")\n\n@dataclass(frozen=True)\nclass Person:\n    name: FullName\n    date_of_birth: BirthDate\n    email: EmailAddress\n\nperson = Person(\n    FullName(\"Bruce Eckel\"),\n    BirthDate(\"7/8/1957\"),\n    EmailAddress(\"mindviewinc@gmail.com\")\n)\n## FullName checking Bruce Eckel\n## BirthDate checking 7/8/1957\n## EmailAddress checking mindviewinc@gmail.com\nprint(person)\n## Person(name=FullName(name='Bruce Eckel'),\n## date_of_birth=BirthDate(dob='7/8/1957'), email=\n## EmailAddress(address='mindviewinc@gmail.com'))\n</code></pre> <p>This hierarchical validation structure ensures correctness and clarity at every composition level.  Invalid data never propagates, vastly simplifying subsequent interactions.</p>"},{"location":"05_Custom_Types/#simple-type-aliasing-with-newtype","title":"Simple Type Aliasing with <code>NewType</code>","text":"<p><code>NewType</code> creates distinct types for stronger type checking without runtime overhead:</p> <pre><code># simple_type_aliasing.py\nfrom typing import NewType\n\nUserId = NewType(\"UserId\", int)\n\nuser_id = UserId(42)\n\n\ndef get_user(uid: UserId) -&gt; str:\n    return f\"User {uid}\"\n\n\n# get_user(42)  # type checker error\nget_user(user_id)  # correct usage\n</code></pre> <p><code>NewType</code> improves clarity, preventing accidental misuse of similar underlying types.</p>"},{"location":"05_Custom_Types/#literal-types","title":"Literal Types","text":"<p>Literal types allow specifying exact permissible values, enhancing type specificity and correctness:</p> <pre><code># literal_types.py\nfrom typing import Literal\n\n\ndef set_mode(mode: Literal[\"auto\", \"manual\"]) -&gt; None:\n    print(f\"Mode set to {mode}\")\n\n\nset_mode(\"auto\")  # valid\n## Mode set to auto\n# set_mode('automatic')  # invalid, detected by type checker\n</code></pre> <p>Literal types ensure values match expected exact constants, improving type safety.</p>"},{"location":"05_Custom_Types/#leveraging-enums-for-type-safety","title":"Leveraging Enums for Type Safety","text":"<p>An Enum is also a type, and is preferable when you have a smaller set of values. Enums provide additional type safety for fixed-value sets, such as months:</p> <pre><code># birth_date.py\n# \"Leap years are left as an exercise.\"\nfrom dataclasses import dataclass\nfrom enum import Enum\n\nfrom book_utils import Catch\n\n\n@dataclass(frozen=True)\nclass Day:\n    n: int\n    def __post_init__(self) -&gt; None:\n        assert 1 &lt;= self.n &lt;= 31, f\"{self}\"\n\n\n@dataclass(frozen=True)\nclass Year:\n    n: int\n    def __post_init__(self) -&gt; None:\n        assert 1900 &lt; self.n &lt;= 2022, f\"{self}\"\n\n\nclass Month(Enum):\n    JANUARY = (1, 31)\n    FEBRUARY = (2, 28)\n    MARCH = (3, 31)\n    APRIL = (4, 30)\n    MAY = (5, 31)\n    JUNE = (6, 30)\n    JULY = (7, 31)\n    AUGUST = (8, 31)\n    SEPTEMBER = (9, 30)\n    OCTOBER = (10, 31)\n    NOVEMBER = (11, 30)\n    DECEMBER = (12, 31)\n\n    @staticmethod\n    def number(month_number: int):\n        assert 1 &lt;= month_number &lt;= 12, f\"Month({month_number})\"\n        return list(Month)[month_number - 1]\n\n    def check_day(self, day: Day):\n        assert day.n &lt;= self.value[1], f\"{self} {day}\"\n\n    def __repr__(self):\n        return self.name\n\n\n@dataclass(frozen=True)\nclass BirthDate:\n    m: Month\n    d: Day\n    y: Year\n    def __post_init__(self):\n        self.m.check_day(self.d)\n\n\nfor date in [\n    (7, 8, 1957),\n    (0, 32, 1857),\n    (2, 31, 2022),\n    (9, 31, 2022),\n    (4, 31, 2022),\n    (6, 31, 2022),\n    (11, 31, 2022),\n    (12, 31, 2022),\n]:\n    with Catch():\n        print(date)\n        print(BirthDate(Month.number(date[0]), Day(date[1]), Year(date[2])))\n        print('-' * 30)\n## (7, 8, 1957)\n## BirthDate(m=JULY, d=Day(n=8), y=Year(n=1957))\n## ------------------------------\n## (0, 32, 1857)\n## Error: Month(0)\n## (2, 31, 2022)\n## Error: Month.FEBRUARY Day(n=31)\n## (9, 31, 2022)\n## Error: Month.SEPTEMBER Day(n=31)\n## (4, 31, 2022)\n## Error: Month.APRIL Day(n=31)\n## (6, 31, 2022)\n## Error: Month.JUNE Day(n=31)\n## (11, 31, 2022)\n## Error: Month.NOVEMBER Day(n=31)\n## (12, 31, 2022)\n## BirthDate(m=DECEMBER, d=Day(n=31),\n## y=Year(n=2022))\n## ------------------------------\n</code></pre> <p><pre><code># month_data_class.py\nfrom dataclasses import dataclass, field\nfrom typing import List\n\nfrom book_utils import Catch\n\n\n@dataclass(frozen=True)\nclass Day:\n    n: int\n    def __post_init__(self) -&gt; None:\n        assert 1 &lt;= self.n &lt;= 31, f\"Day({self.n})\"\n\n\n@dataclass(frozen=True)\nclass Year:\n    n: int\n    def __post_init__(self) -&gt; None:\n        assert 1900 &lt; self.n &lt;= 2022, f\"Year({self.n})\"\n\n\n@dataclass(frozen=True)\nclass Month:\n    name: str\n    n: int\n    max_days: int\n    def __post_init__(self):\n        assert 1 &lt;= self.n &lt;= 12, f\"Month({self.n})\"\n        assert self.max_days in [28, 30, 31], f\"Month max_days {self.max_days}\"\n\n    def check_day(self, day: Day):\n        assert day.n &lt;= self.max_days, f\"{self} {day}\"\n\n    @staticmethod\n    def make_months():\n        return [Month(m[0], m[1], m[2]) for m in [\n            (\"January\", 1, 31),\n            (\"February\", 2, 28),\n            (\"March\", 3, 31),\n            (\"April\", 4, 30),\n            (\"May\", 5, 31),\n            (\"June\", 6, 30),\n            (\"July\", 7, 31),\n            (\"August\", 8, 31),\n            (\"September\", 9, 30),\n            (\"October\", 10, 31),\n            (\"November\", 11, 30),\n            (\"December\", 12, 31),\n        ]]\n\n\n@dataclass(frozen=True)\nclass Months:\n    months: List[Month] = field(default_factory=Month.make_months)\n\n    def number(self, month_number: int):\n        assert 1 &lt;= month_number &lt;= 12, f\"Month({month_number})\"\n        return self.months[month_number - 1]\n\n\n@dataclass(frozen=True)\nclass BirthDate:\n    m: Month\n    d: Day\n    y: Year\n\n    def __post_init__(self):\n        self.m.check_day(self.d)\n\n\nmonths = Months()\nfor date in [\n    (7, 8, 1957),\n    (0, 32, 1857),\n    (2, 31, 2022),\n    (9, 31, 2022),\n    (4, 31, 2022),\n    (6, 31, 2022),\n    (11, 31, 2022),\n    (12, 31, 2022),\n]:\n    with Catch():\n        print(date)\n        print(BirthDate(months.number(date[0]), Day(date[1]), Year(date[2])))\n        print('-' * 30)\n## (7, 8, 1957)\n## BirthDate(m=Month(name='July', n=7,\n## max_days=31), d=Day(n=8), y=Year(n=1957))\n## ------------------------------\n## (0, 32, 1857)\n## Error: Month(0)\n## (2, 31, 2022)\n## Error: Month(name='February', n=2, max_days=28)\n## Day(n=31)\n## (9, 31, 2022)\n## Error: Month(name='September', n=9,\n## max_days=30) Day(n=31)\n## (4, 31, 2022)\n## Error: Month(name='April', n=4, max_days=30)\n## Day(n=31)\n## (6, 31, 2022)\n## Error: Month(name='June', n=6, max_days=30)\n## Day(n=31)\n## (11, 31, 2022)\n## Error: Month(name='November', n=11,\n## max_days=30) Day(n=31)\n## (12, 31, 2022)\n## BirthDate(m=Month(name='December', n=12,\n## max_days=31), d=Day(n=31), y=Year(n=2022))\n## ------------------------------\n</code></pre> <code>Month</code> can be created using dataclasses, but it's more complicated than using <code>Enum</code>, with questionable benefits.</p> <p>Using enums makes code both readable and safely constrained, improving robustness.  For simplicity and IDE interactivity, choose enums over data classes for fixed-value sets.</p>"},{"location":"05_Custom_Types/#specialized-tools","title":"Specialized Tools","text":""},{"location":"05_Custom_Types/#typed-namedtuples","title":"Typed NamedTuples","text":"<p>A typed <code>NamedTuple</code> combines tuple immutability with type annotations and named fields:</p> <pre><code># named_tuple.py\nfrom typing import NamedTuple\n\n\nclass Coordinates(NamedTuple):\n    latitude: float\n    longitude: float\n\n\ncoords = Coordinates(51.5074, -0.1278)\nprint(coords)\n## Coordinates(latitude=51.5074,\n## longitude=-0.1278)\nprint(coords.latitude)\n## 51.5074\n# coords.latitude = 123.4567 # Runtime error\n</code></pre> <p><code>NamedTuple</code> provides clarity, immutability, and easy unpacking, ideal for simple structured data. For brevity and cleanliness, this book will used <code>NamedTuple</code>s instead of frozen <code>dataclass</code>es whenever possible.</p>"},{"location":"05_Custom_Types/#leveraging-typeddicts-for-structured-data","title":"Leveraging TypedDicts for Structured Data","text":"<p><code>TypedDict</code> is useful when defining dictionary structures with known keys and typed values:</p> <pre><code># typed_dict.py\nfrom typing import TypedDict\n\n\nclass UserProfile(TypedDict):\n    username: str\n    email: str\n    age: int\n\n\nuser: UserProfile = {\"username\": \"alice\", \"email\": \"alice@example.com\", \"age\": 30}\n</code></pre> <p><code>TypedDict</code> clarifies expected keys and types, providing type safety for dictionary data.</p>"},{"location":"05_Custom_Types/#optional-fields-in-typeddict","title":"Optional Fields in TypedDict","text":"<p>You can specify optional fields using <code>NotRequired</code> (Python 3.11+) or <code>total=False</code>:</p> <pre><code># optional_typed_dict_fields.py\nfrom typing import TypedDict, NotRequired\n\n\nclass UserSettings(TypedDict):\n    theme: str\n    notifications_enabled: NotRequired[bool]\n\n\nsettings: UserSettings = {\"theme\": \"dark\"}\n</code></pre> <p>This flexibility allows clear definitions for complex, partially-optional data structures.</p>"},{"location":"05_Custom_Types/#combining-dataclasses-and-enums","title":"Combining Dataclasses and Enums","text":"<pre><code># dataclasses_and_enums.py\nfrom dataclasses import dataclass\nfrom enum import Enum\n\n\nclass Status(Enum):\n    ACTIVE = \"active\"\n    INACTIVE = \"inactive\"\n\n\n@dataclass\nclass User:\n    id: int\n    name: str\n    status: Status\n\n\nprint(User(id=1, name=\"Alice\", status=Status.ACTIVE))\n## User(id=1, name='Alice', status=&lt;Status.ACTIVE:\n## 'active'&gt;)\n</code></pre>"},{"location":"05_Custom_Types/#domain-driven-design-ddd","title":"Domain-Driven Design (DDD)","text":"<p>Strongly-typed domain models help clearly represent domain logic, improving robustness and maintainability. Define domain entities explicitly to enhance domain logic expressiveness:</p> <pre><code># ddd.py\nfrom dataclasses import dataclass\nfrom typing import List, NamedTuple\n\n\nclass Product(NamedTuple):\n    name: str\n    price: float\n\n\n@dataclass\nclass Order:\n    order_id: int\n    products: List[Product]\n\n    def total(self) -&gt; float:\n        return sum(product.price for product in self.products)\n</code></pre> <p>Strongly-typed domain models help catch issues early, facilitating clearer, safer, and more maintainable codebases.</p>"},{"location":"05_Custom_Types/#conclusion","title":"Conclusion","text":"<p>Python data classes simplify managing data integrity and composition, reducing repetitive checks and centralizing validation. Combined with functional programming principles like immutability and type composition, data classes significantly enhance the clarity, maintainability, and robustness of your code. Once you adopt this method, you'll find your development process smoother, more reliable, and enjoyable.</p>"},{"location":"05_Custom_Types/#generated-dataclass-intro-notes","title":"(Generated) Dataclass Intro Notes","text":"<p>Dataclasses simplify class definitions by automatically generating methods like <code>__init__</code>, <code>__repr__</code>, and <code>__eq__</code>:</p> <pre><code># generated_methods.py\nfrom dataclasses import dataclass\n\n\n@dataclass\nclass Product:\n    name: str\n    price: float\n    in_stock: bool = True\n\n\nproduct = Product(\"Laptop\", 999.99)\nprint(product)\n## Product(name='Laptop', price=999.99,\n## in_stock=True)\n</code></pre> <p>Dataclasses reduce boilerplate, ensuring concise and readable class definitions.</p> <p>Dataclasses support default factories, immutability, and more:</p> <pre><code># example_9.py\nfrom dataclasses import dataclass, field\nfrom typing import List\n\n\n@dataclass(frozen=True)\nclass Order:\n    order_id: int\n    items: List[str] = field(default_factory=list)\n\n\norder = Order(order_id=123)\n# order.order_id = 456  # Error: dataclass is frozen (immutable)\n</code></pre>"},{"location":"06_Pattern_Matching/","title":"Pattern Matching","text":"<p>This placeholder text was generated by ChatGPT 4.5. It will be significantly rewritten as the book is developed. In the meantime you can add comments to either https://bsky.app/bruceeckel or Github Issues.</p>"},{"location":"06_Pattern_Matching/#introduction-to-structural-pattern-matching-python-310","title":"Introduction to Structural Pattern Matching (Python 3.10+)","text":"<p>Python 3.10 introduced structural pattern matching, providing powerful and concise syntax to match objects against specific patterns:</p> <pre><code># example_1.py\ndef handle_command(command: str) -&gt; str:\n    match command:\n        case \"start\":\n            return \"Starting\"\n        case \"stop\":\n            return \"Stopping\"\n        case _:\n            return \"Unknown command\"\n</code></pre> <p>Pattern matching enhances readability and maintainability, reducing the complexity of conditional logic.</p>"},{"location":"06_Pattern_Matching/#annotating-code-with-pattern-matching","title":"Annotating Code with Pattern Matching","text":"<p>Annotations can clarify patterns used in structural matching, making code clearer and aiding static type checking:</p> <pre><code># example_2.py\nfrom typing import Union, NamedTuple\n\n\nclass Success(NamedTuple):\n    result: str\n\n\nclass Error(NamedTuple):\n    error: str\n\n\ndef process(response: Union[Success, Error]) -&gt; str:\n    match response:\n        case Success(result):\n            return f\"Success: {result}\"\n        case Error(error):\n            return f\"Error: {error}\"\n</code></pre> <p>This use of annotations and pattern matching simplifies complex decision-making logic.</p>"},{"location":"06_Pattern_Matching/#annotating-code-with-pattern-matching_1","title":"Annotating Code with Pattern Matching","text":"<p>When combining type annotations with pattern matching, carefully structuring types enhances type checker effectiveness:</p>"},{"location":"06_Pattern_Matching/#example-with-typeddict-and-pattern-matching","title":"Example with TypedDict and Pattern Matching","text":"<pre><code># example_3.py\nfrom typing import TypedDict\n\n\nclass Command(TypedDict):\n    action: str\n    payload: dict\n\n\ndef process_command(command: TypedDict) -&gt; None:\n    match command:\n        case {\"action\": \"create\", \"item\": item}:\n            print(f\"Creating {item}\")\n        case {\"action\": \"delete\", \"id\": int() as item_id}:\n            print(f\"Deleting item {item_id}\")\n        case _:\n            print(\"Unknown command\")\n</code></pre> <p>Annotations clearly define expected data shapes, improving readability and correctness.</p>"},{"location":"06_Pattern_Matching/#type-checking-considerations-with-match-statements","title":"Type Checking Considerations with <code>match</code> Statements","text":"<p>Static type checkers can analyze pattern matching effectively, but careful type design is essential:</p>"},{"location":"06_Pattern_Matching/#ensuring-consistent-patterns","title":"Ensuring Consistent Patterns","text":"<p>Pattern matching works best with clearly annotated and structurally consistent types:</p> <pre><code># example_4.py\nfrom typing import Union\n\n\nclass Cat:\n    def meow(self) -&gt; str:\n        return \"Meow\"\n\n\nclass Dog:\n    def bark(self) -&gt; str:\n        return \"Woof\"\n\n\ndef animal_sound(animal: Union[Cat, Dog]) -&gt; str:\n    match animal:\n        case Cat():\n            return animal.meow()\n        case Dog():\n            return animal.bark()\n</code></pre> <p>Properly annotated unions simplify handling of multiple types with clarity and safety.</p>"},{"location":"06_Pattern_Matching/#real-world-scenarios-for-pattern-matching","title":"Real-world Scenarios for Pattern Matching","text":"<p>Pattern matching is highly effective in real-world scenarios, such as:</p>"},{"location":"06_Pattern_Matching/#handling-api-responses","title":"Handling API Responses","text":"<pre><code># example_5.py\ndef process_response(response: dict) -&gt; str:\n    match response:\n        case {\"status\": \"success\", \"data\": data}:\n            return f\"Success: {data}\"\n        case {\"status\": \"error\", \"message\": error_msg}:\n            return f\"Error: {error}\"\n        case _:\n            return \"Unknown response format\"\n</code></pre>"},{"location":"06_Pattern_Matching/#parsing-complex-data-structures","title":"Parsing Complex Data Structures","text":"<pre><code># example_6.py\ndef parse_coordinates(coords: tuple) -&gt; str:\n    match coords := coords:\n        case (float(lat), float(lon)):\n            return f\"Latitude: {lat}, Longitude: {lon}\"\n        case _:\n            return \"Invalid coordinates\"\n</code></pre> <p>Pattern matching simplifies conditional logic, making code more maintainable.</p>"},{"location":"06_Pattern_Matching/#type-checking-considerations","title":"Type Checking Considerations","text":"<p>Ensure type annotations match patterns closely, as type checkers use them to validate correctness:</p> <ul> <li>Explicitly define type annotations for better static analysis.</li> <li>Carefully match patterns to annotated types for enhanced safety.</li> </ul> <p>Properly using pattern matching alongside type annotations helps catch potential runtime errors early, resulting in safer and more readable Python code.</p>"},{"location":"07_Immutability/","title":"Immutability","text":"<ul> <li>Benefits of immutability</li> <li>Historic immutability by convention with all caps</li> <li>Immutability with <code>Final</code></li> </ul> <p>Dataclasses support immutability with <code>frozen</code>:</p> <pre><code># example_2.py\nfrom dataclasses import dataclass, field\nfrom typing import List\n\n\n@dataclass(frozen=True)\nclass Order:\n    order_id: int\n    items: List[str] = field(default_factory=list)\n\n\norder = Order(order_id=123)\n# order.order_id = 456  # Error: dataclass is frozen (immutable)\n</code></pre> <ul> <li>show post_init with frozen</li> </ul>"},{"location":"08_Generics/","title":"Generics","text":"<p>This placeholder text was generated by ChatGPT 4.5. It will be significantly rewritten as the book is developed. In the meantime you can add comments to either https://bsky.app/bruceeckel or Github Issues.</p>"},{"location":"08_Generics/#defining-custom-generics-with-typevar-and-generic","title":"Defining Custom Generics with <code>TypeVar</code> and <code>Generic</code>","text":"<p>Custom generics allow functions and classes to handle various types flexibly:</p>"},{"location":"08_Generics/#using-typevar","title":"Using <code>TypeVar</code>","text":"<pre><code># example_1.py\nfrom typing import TypeVar, List\n\nT = TypeVar(\"T\")\n\n\ndef first_item(items: List[T]) -&gt; T:\n    return items[0]\n\n\nprint(first_item([1, 2, 3]))  # returns int\n## 1\nprint(first_item([\"a\", \"b\"]))  # returns str\n## a\n</code></pre>"},{"location":"08_Generics/#generic-classes","title":"Generic Classes","text":"<pre><code># example_2.py\nfrom dataclasses import dataclass\nfrom typing import Generic, TypeVar\n\nT = TypeVar(\"T\")  # Declare a type variable\n\n\n@dataclass\nclass Box(Generic[T]):\n    content: T\n\n\nbox_int = Box(123)  # Box[int]\nbox_str = Box(\"hello\")  # Box[str]\n</code></pre> <p>Custom generics enhance code reusability and type safety.</p>"},{"location":"08_Generics/#using-constraints-and-bounds-with-generics","title":"Using Constraints and Bounds with Generics","text":"<p>Generics can include constraints and bounds to restrict allowed types:</p>"},{"location":"08_Generics/#constraints","title":"Constraints","text":"<pre><code># example_3.py\nfrom typing import TypeVar\n\nU = TypeVar(\"U\", int, float)\n\n\ndef add(a: U, b: U) -&gt; U:\n    return a + b\n\n\nadd(1, 2)  # valid\nadd(1.5, 2.5)  # valid\n# add(\"a\", \"b\")  # invalid, detected by type checker\n</code></pre>"},{"location":"08_Generics/#bounds","title":"Bounds","text":"<pre><code># example_4.py\nfrom typing import TypeVar\n\n\nclass Animal:\n    def speak(self) -&gt; str:\n        return \"...\"\n\n\nA = TypeVar(\"A\", bound=Animal)\n\n\ndef animal_sound(animal: A) -&gt; str:\n    return animal.speak()\n\n\nclass Dog(Animal):\n    def speak(self) -&gt; str:\n        return \"Woof!\"\n\n\nprint(animal_sound(Dog()))  # \"Woof!\"\n## Woof!\n</code></pre> <p>Constraints and bounds improve specificity in generic type annotations, enhancing code clarity and correctness.</p>"},{"location":"08_Generics/#variance-covariance-and-contravariance-in-generics","title":"Variance, Covariance, and Contravariance in Generics","text":"<p>Variance controls type relationships between generic types:</p>"},{"location":"08_Generics/#covariance-covarianttrue","title":"Covariance (<code>covariant=True</code>)","text":"<p>Allows using subtypes in place of parent types:</p> <pre><code># example_7.py\nfrom typing import Generic, TypeVar\n\nT_co = TypeVar(\"T_co\", covariant=True)\n\n\nclass ReadOnlyList(Generic[T_co]):\n    def __init__(self, items: list[T_co]):\n        self.items = items\n\n\nints: ReadOnlyList[int] = ReadOnlyList([1, 2, 3])\nnumbers: ReadOnlyList[float] = ints  # Valid due to covariance\n</code></pre>"},{"location":"08_Generics/#contravariance-contravarianttrue","title":"Contravariance (<code>contravariant=True</code>)","text":"<p>Allows using parent types in place of subtypes, common in callbacks or consumers:</p> <pre><code># example_8.py\nfrom typing import TypeVar, Generic\n\nT_contra = TypeVar(\"T_contra\", contravariant=True)\n\n\nclass Processor(Generic[T_contra]):\n    def process(self, value: T_contra) -&gt; None:\n        print(value)\n\n\nint_processor: Processor[int] = Processor()\nnumber_processor: Processor[float] = int_processor  # Valid due to contravariance\n</code></pre> <p>Understanding variance ensures accurate type relationships, especially when designing flexible APIs or libraries.</p>"},{"location":"09_Callables/","title":"Callables","text":"<p>This placeholder text was generated by ChatGPT 4.5. It will be significantly rewritten as the book is developed. In the meantime you can add comments to either https://bsky.app/bruceeckel or Github Issues.</p>"},{"location":"09_Callables/#annotating-functions-and-lambdas","title":"Annotating Functions and Lambdas","text":"<p>Clearly annotating functions and lambda expressions improves readability and type safety:</p>"},{"location":"09_Callables/#function-annotations","title":"Function Annotations","text":"<pre><code># example_1.py\ndef add(x: int, y: int) -&gt; int:\n    return x + y\n</code></pre>"},{"location":"09_Callables/#lambda-annotations","title":"Lambda Annotations","text":"<p>Annotating lambdas directly isn't supported; however, annotations can be implied:</p> <pre><code># example_2.py\nfrom typing import Callable\n\nadder: Callable[[int, int], int] = lambda x, y: x + y\n</code></pre> <p>This explicit approach ensures that lambda behavior is type-checked properly.</p>"},{"location":"09_Callables/#using-callable-for-higher-order-functions","title":"Using <code>Callable</code> for Higher-Order Functions","text":"<p>The <code>Callable</code> type is essential for annotating functions that accept or return other functions:</p> <pre><code># example_3.py\nfrom typing import Callable\n\n\ndef operate(a: int, b: int, func: Callable[[int, int], int]) -&gt; int:\n    return func(a, b)\n\n\nresult = operate(5, 3, lambda x, y: x * y)  # returns 15\n</code></pre> <p>Using <code>Callable</code> clearly defines expected function signatures, enhancing maintainability and correctness.</p>"},{"location":"09_Callables/#advanced-function-annotations-with-paramspec","title":"Advanced Function Annotations with <code>ParamSpec</code>","text":"<p>Introduced in Python 3.10, <code>ParamSpec</code> allows annotating decorators and generic functions while preserving original function signatures:</p> <pre><code># example_4.py\nfrom typing import Callable, ParamSpec, TypeVar\n\nP = ParamSpec(\"P\")\nR = TypeVar(\"R\")\n\n\ndef logging_decorator(func: Callable[P, R]) -&gt; Callable[P, R]:\n    def wrapper(*args: P.args, **kwargs: P.kwargs) -&gt; R:\n        print(f\"Calling {func.__name__} with {args} and {kwargs}\")\n        return func(*args, **kwargs)\n\n    return wrapper\n\n\n@logging_decorator\ndef multiply(a: int, b: int) -&gt; int:\n    return a * b\n\n\nmultiply(2, 3)  # Output: Calling multiply with (2, 3) and {} then returns 6\n## Calling multiply with (2, 3) and {}\n</code></pre> <p><code>ParamSpec</code> helps decorators maintain accurate type information for wrapped functions.</p>"},{"location":"09_Callables/#implementing-function-overloading-with-overload","title":"Implementing Function Overloading with <code>@overload</code>","text":"<p>Python allows specifying multiple function signatures through the <code>@overload</code> decorator for better static type checking:</p> <pre><code># example_5.py\nfrom typing import overload, Union\n\n\n@overload\ndef double(value: int) -&gt; int: ...\n\n\n@overload\ndef double(value: str) -&gt; str: ...\n\n\ndef double(value: Union[int, str]) -&gt; Union[int, str]:\n    if isinstance(value, int):\n        return value * 2\n    return value + value\n\n\nprint(double(4))  # Output: 8\n## 8\nprint(double(\"Hi\"))  # Output: HiHi\n## HiHi\n</code></pre> <p><code>@overload</code> clearly defines each acceptable signature, providing strong typing and preventing misuse.</p>"},{"location":"09_Callables/#annotation-strategies-for-apis-and-libraries","title":"Annotation Strategies for APIs and Libraries","text":"<p>Clear annotations greatly enhance public API usability and reliability. Strategies include:</p>"},{"location":"09_Callables/#explicit-and-detailed-annotations","title":"Explicit and Detailed Annotations","text":"<ul> <li>Clearly annotate all public API interfaces and return types.</li> <li>Avoid overly broad types like <code>Any</code> unless necessary.</li> </ul>"},{"location":"09_Callables/#using-type-aliases-for-complex-signatures","title":"Using Type Aliases for Complex Signatures","text":"<pre><code># example_6.py\nfrom typing import Callable, TypeAlias\n\nRequestHandler: TypeAlias = Callable[[str, dict], dict]\n\n\ndef handle_request(path: str, handler: RequestHandler) -&gt; dict:\n    response = handler(path, {})\n    return response\n</code></pre>"},{"location":"09_Callables/#consistent-annotation-patterns","title":"Consistent Annotation Patterns","text":"<ul> <li>Follow consistent patterns for similar methods or functions within an API.</li> </ul>"},{"location":"09_Callables/#leveraging-protocols-and-callables","title":"Leveraging Protocols and Callables","text":"<p>Using <code>Protocol</code> for clearly defined callable behaviors:</p> <pre><code># example_7.py\nfrom typing import Protocol\n\n\nclass Handler(Protocol):\n    def __call__(self, request: dict) -&gt; dict: ...\n\n\ndef process_request(handler: Handler, request: dict) -&gt; dict:\n    return handler(request)\n</code></pre> <p>Following these strategies ensures type-safe, clear, and developer-friendly APIs and libraries.</p>"},{"location":"10_Structural_Typing/","title":"Structural Typing","text":"<p>This placeholder text was generated by ChatGPT 4.5. It will be significantly rewritten as the book is developed. In the meantime you can add comments to either https://bsky.app/bruceeckel or Github Issues.</p>"},{"location":"10_Structural_Typing/#introduction","title":"Introduction","text":"<p>In type systems, there are two fundamental ways to decide if one type is compatible with another: nominal typing and structural typing. Nominal typing (name-based typing) means type compatibility is determined by explicit declarations and the class hierarchy \u2013 an object\u2019s type is what its class name (or inheritance) says it is (Protocols and structural subtyping - mypy 1.15.0 documentation). For example, if class <code>Dog</code> inherits from class <code>Animal</code>, then <code>Dog</code> is-a* subtype of <code>Animal</code> by definition, and a <code>Dog</code> instance can be used wherever an <code>Animal</code> is expected (Protocols and structural subtyping - mypy 1.15.0 documentation). This is how traditional object-oriented languages like Java or C++ work, and it\u2019s also the primary mode in Python\u2019s type system by default.</p> <p>On the other hand, structural typing determines type compatibility by the actual structure or capabilities of the object, not its explicit inheritance. In a structural type system, if an object has all the required methods and attributes of a type, then it qualifies as that type, regardless of its class name or parent classes (Protocols and structural subtyping - mypy 1.15.0 documentation). In other words, if it \"walks like a duck and quacks like a duck, then it\u2019s treated as a duck\" \u2013 this is the essence of the famous duck typing principle. Duck typing is a runtime concept in Python: you invoke methods or attributes on an object, and as long as it supports those operations, things work (if a required method is missing, you get an <code>AttributeError</code> at runtime) (What's the Difference Between Nominal, Structural, and Duck Typing? - DEV Community) (Duck typing - Wikipedia). Structural typing can be seen as the static, compile-time equivalent of duck typing (Protocols and structural subtyping - mypy 1.15.0 documentation). Instead of waiting for a runtime error, a structural type system (with the help of a static type checker) can verify ahead of time* that an object has the necessary attributes to be used in a given context. This approach is more flexible than nominal typing because it doesn\u2019t require pre-planned inheritance relationships. It is also more explicit and safe than unguarded duck typing because the structure is checked (by a type checker) before the code runs.</p> <p>Python historically embraced duck typing at runtime \u2013 you just call methods on objects and trust they exist. Prior to Python 3.8, static type checking in Python (via tools like MyPy, PyRight, etc.) was largely nominal: you would use abstract base classes or concrete classes to hint the types, and an object\u2019s class had to match the annotation or inherit from a matching class. This could make it awkward to type-hint code that was written in a duck-typed style. For instance, if you had a function that worked with any object that had a <code>.read()</code> method, there wasn\u2019t a straightforward way to express that in a type hint without making all such objects share a common base class or using <code>typing.Any</code>. Python 3.8 remedied this by introducing protocols in the <code>typing</code> module (Python Protocols: Leveraging Structural Subtyping \u2013 Real Python). Protocols allow you to define a structural interface that other classes can fulfill just by having the right methods/attributes, without inheritance. This brings the flexibility of duck typing into the realm of static type checking \u2013 essentially formalizing \"If it quacks like a duck, it can be treated as a duck\" in the type system.</p> <p>In summary, nominal typing ties compatibility to declared relationships (e.g., subclassing an interface or abstract class), whereas structural typing ties compatibility to an object\u2019s actual shape (the presence of specific methods/attributes). Python\u2019s type system now supports both: use nominal typing for clarity and runtime consistency with class relationships, and use structural typing (via protocols) for flexibility and to more directly model Python\u2019s duck-typed nature (PEP 544 \u2013 Protocols: Structural subtyping (static duck typing) | peps.python.org).</p>"},{"location":"10_Structural_Typing/#defining-and-using-protocols","title":"Defining and Using Protocols","text":"<p>To leverage structural typing in Python\u2019s type hints, you define protocols. A protocol in Python is essentially an interface or template for a set of methods and attributes. It\u2019s defined by inheriting from <code>typing.Protocol</code> (available in the standard library <code>typing</code> module as of Python 3.8, or in <code>typing_extensions</code> for earlier versions). By creating a class that subclasses <code>Protocol</code>, you declare a group of methods and properties that form a \"protocol\" \u2013 any class that has those methods and properties (with compatible types) will be considered an implementation of that protocol by static type checkers, even if it doesn\u2019t formally inherit from the protocol.</p> <p>How to define a protocol: You simply create a class that inherits <code>Protocol</code> and define the method signatures (and any attribute types) that are required. Protocol methods typically have empty bodies (often using <code>...</code> or <code>pass</code>) because you\u2019re not providing an implementation, just a definition of the interface. For example, suppose we want a protocol for \"speaking\" creatures or objects: it should have a method <code>speak()</code> that returns a string. We can define:</p> <pre><code># speaker.py\nfrom typing import Protocol\n\n\nclass Speaker(Protocol):\n    def speak(self) -&gt; str: ...\n</code></pre> <p>Here, <code>Speaker</code> is a protocol that any \"speaker\" object should follow. Now, any class that defines a <code>speak(self) -&gt; str</code> method will be considered a <code>Speaker</code> for typing purposes. We can create two completely unrelated classes that fulfill this protocol without explicit inheritance:</p> <pre><code># announce.py\nfrom speaker import Speaker\n\n\nclass Dog:\n    def speak(self) -&gt; str:\n        return \"woof\"\n\n\nclass Robot:\n    def speak(self) -&gt; str:\n        return \"beep-boop\"\n\n\ndef announce(speaker: Speaker) -&gt; None:\n    # `speaker` can be any object that has .speak() returning str\n    print(\"Announcement:\", speaker.speak())\n\n\nannounce(Dog())  # OK, Dog has speak()\n## Announcement: woof\nannounce(Robot())  # OK, Robot has speak()\n## Announcement: beep-boop\n</code></pre> <p>Even though <code>Dog</code> and <code>Robot</code> do not inherit from <code>Speaker</code> (and are not related to each other at all), the static type checker will accept them as valid arguments to <code>announce</code> because they structurally conform to the <code>Speaker</code> protocol by implementing the required method. This is the power of structural typing. In fact, the type checker treats <code>Dog</code> and <code>Robot</code> as subtypes of <code>Speaker</code> because they have the right <code>speak()</code> method signature (Protocols and structural subtyping - mypy 1.15.0 documentation). If we tried to pass an object that lacks a <code>speak()</code> method (or has an incompatible signature), the type checker would flag an error, ensuring type safety.</p> <p>It\u2019s important to note that protocols are primarily a static concept \u2013 they are enforced by type checkers, not by the Python runtime (by default). Unlike an abstract base class (ABC), a protocol doesn\u2019t actually require classes to formally subclass it, and Python won\u2019t automatically error at runtime if a required method is missing. For example, in the code above, if we call <code>announce(Dog())</code> and <code>Dog.speak</code> is missing or misnamed, we would only find out at runtime via an <code>AttributeError</code>. The protocol helps catch such issues before runtime by using tools like Mypy. The protocols defined in <code>typing</code> are optional and have no runtime effect on their own (PEP 544 \u2013 Protocols: Structural subtyping (static duck typing) | peps.python.org). This means you can use them freely for type hints without incurring runtime overhead or restrictions. Protocols do inherit from <code>abc.ABC</code> under the hood, but by default <code>isinstance()</code> and <code>issubclass()</code> checks against a protocol will not work without an explicit opt-in, as we\u2019ll discuss shortly.)</p> <p>Using a protocol in type hints: Once you have a protocol class, you use it as a type in annotations just like you would use an ABC or a concrete class. In the above example, the function <code>announce</code> was annotated to accept a <code>Speaker</code>. That tells readers and type checkers that any argument should \"speak\". This is more expressive than using a base class like <code>Animal</code> or a union of types \u2013 we directly specify the capability we need. Another example: Python\u2019s standard library defines an <code>Iterable[T]</code> protocol (in <code>collections.abc</code> or <code>typing</code>) that essentially says the object has an <code>__iter__</code> method returning an iterator. If you annotate a function parameter as <code>Iterable[str]</code>, any object that can be iterated over to yield strings will be accepted \u2013 whether it\u2019s a list, a tuple, a custom container class with an <code>__iter__</code>, etc. The type checker doesn\u2019t require them to inherit from <code>Iterable</code>; having the method is enough (Protocols and structural subtyping - mypy 1.15.0 documentation). This demonstrates that many idiomatic Python \"protocols\" (iteration, context managers, etc.) are recognized structurally. Python\u2019s typing module and static checkers come with several predefined protocols (either explicitly as in <code>typing.Protocol</code> classes or implicitly via ABCs with structural hooks) for common patterns.</p> <p>Let\u2019s look at a slightly more elaborate example of defining and using a protocol. Imagine we have objects that need to support a <code>close()</code> method (like files or network connections). We can define a protocol <code>Closable</code> and use it to write a function that closes a batch of resources:</p> <pre><code># file_resource.py\nfrom typing import Protocol, Iterable\n\n\nclass Closable(Protocol):\n    def close(self) -&gt; None: ...\n\n\nclass FileResource:\n    def __init__(self, path: str):\n        self.file = open(path, \"w\")\n\n    def close(self) -&gt; None:\n        self.file.close()\n\n\nclass SocketResource:\n    def close(self) -&gt; None:\n        print(\"Socket closed\")\n\n\ndef close_all(resources: Iterable[Closable]) -&gt; None:\n    for res in resources:\n        res.close()\n\n\n# Using the close_all function with different resource types\nclosables = [FileResource(\"data.txt\"), SocketResource(), open(\"other.txt\", \"w\")]\nclose_all(\n    closables\n)  # OK: FileResource, SocketResource, and file objects all have close()\n## Socket closed\n</code></pre> <p>In this code, <code>Closable</code> is a protocol requiring a <code>.close()</code> method. We created a <code>FileResource</code> class and a <code>SocketResource</code> class that both implement <code>close()</code>. We also use a built-in file object from <code>open()</code>, which we know has a <code>close()</code> method. The <code>close_all</code> function is annotated to accept any iterable of <code>Closable</code> objects. Thanks to structural typing, it doesn\u2019t matter that these objects are of different types and don\u2019t share a common ancestor named <code>Closable</code> \u2013 as long as each has a callable <code>close()</code> method, the static type checker will be satisfied and, at runtime, the code will work. In fact, Mypy considers the built-in file object and our custom classes all as subtypes of <code>Closable</code> because they provide the required attribute (Protocols and structural subtyping - mypy 1.15.0 documentation).</p> <p>One thing to be aware of: protocols by default cannot be used with <code>isinstance()</code> or <code>issubclass()</code> checks at runtime. If you try <code>isinstance(some_obj, Closable)</code> in the above example, Python will raise a <code>TypeError</code> unless you take additional steps. This is because the protocol is not a real base class of those objects (they never inherited from it). However, Python\u2019s <code>typing</code> module provides a decorator <code>@runtime_checkable</code> that you can apply to a protocol to make runtime <code>isinstance</code> checks possible on it. Marking a protocol with <code>@runtime_checkable</code> means it gets a special <code>__instancecheck__</code> that will return True if the object has the required attributes (much like ABCs in <code>collections.abc</code> do with their <code>__subclasshook__</code>). For example:</p> <pre><code># example_4.py\nfrom typing import runtime_checkable, Protocol\nfrom file_resource import FileResource\n## Socket closed\n\n\n@runtime_checkable\nclass Closable(Protocol):\n    def close(self) -&gt; None: ...\n\n\nisinstance(FileResource(\"data.txt\"), Closable)  # True, because FileResource has close()\n</code></pre> <p>Now <code>Closable</code> can be used in <code>isinstance</code> and <code>issubclass</code> as a structural check (Abstract Base Classes and Protocols: What Are They? When To Use Them?? Lets Find Out! - Justin A. Ellis). Use this feature carefully \u2013 it\u2019s useful for type introspection in frameworks or for asserting an object meets an interface at runtime, but it only checks the presence of attributes and not their types, and could give false positives if an attribute name matches but semantics differ. In most cases, protocols are used purely for static checking and documentation.</p>"},{"location":"10_Structural_Typing/#practical-protocol-examples","title":"Practical Protocol Examples","text":"<p>Protocols shine in real-world scenarios where you want to decouple code and reduce dependencies on concrete classes. A common use case is dependency injection and testing. In Python, it\u2019s common to write functions or classes that operate on objects with a particular interface, without caring about the concrete implementation. Protocols let you formally capture that interface in the type system. This makes your code\u2019s expectations clear and allows static analysis to ensure you didn\u2019t violate those expectations. Let\u2019s discuss a few practical examples.</p> <p>1. Dependency injection and interchangeable components: Suppose you\u2019re writing a service that needs to log messages. You might want the ability to swap out the logger \u2013 sometimes logging to a file, sometimes to the console, or maybe collecting logs in memory for testing. You can define a protocol for the logger\u2019s interface and program against that. For instance:</p> <pre><code># logger_protocol.py\nfrom typing import Protocol\n\n\nclass Logger(Protocol):\n    def log(self, message: str) -&gt; None: ...\n\n\nclass FileLogger:\n    \"\"\"Concrete logger that writes to a file.\"\"\"\n\n    def __init__(self, filename: str):\n        self.filename = filename\n\n    def log(self, message: str) -&gt; None:\n        with open(self.filename, \"a\") as f:\n            f.write(message + \"\\n\")\n\n\nclass ListLogger:\n    \"\"\"Concrete logger that stores messages in a list (e.g., for testing).\"\"\"\n\n    def __init__(self):\n        self.messages: list[str] = []\n\n    def log(self, message: str) -&gt; None:\n        self.messages.append(message)\n\n\ndef run_process(task_name: str, logger: Logger) -&gt; None:\n    logger.log(f\"Starting {task_name}\")\n    # Perform the task ...\n    logger.log(f\"Finished {task_name}\")\n\n\n# Using the run_process with different loggers\nrun_process(\"DataCleanup\", FileLogger(\"app.log\"))  # logs to file\ntest_logger = ListLogger()\nrun_process(\"DataCleanup\", test_logger)  # logs to list in memory\nprint(\"Captured logs:\", test_logger.messages)\n## Captured logs: ['Starting DataCleanup',\n## 'Finished DataCleanup']\n</code></pre> <p>In <code>Logger(Protocol)</code>, we specify that a logger must have a <code>.log(str)</code> method. Our <code>run_process</code> function doesn\u2019t care how the logging is done, just that the object passed in can <code>.log</code> a message. FileLogger<code>and</code>ListLogger<code>are two implementations \u2013 one writes to a file, the other stores messages in a Python list. Notice that neither</code>FileLogger<code>nor</code>ListLogger<code>subclasses</code>Logger<code>; they don\u2019t need to. They implicitly satisfy the protocol by having the correct</code>log<code>method. This design is very flexible: you can add new logger classes later (say, a</code>DatabaseLogger<code>that writes to a database, or reuse Python\u2019s built-in</code>logging.Logger<code>by writing an adapter that has a</code>log<code>method) without changing the code that uses the logger. During testing, as shown, we can use</code>ListLogger<code>to capture logs and make assertions on them. The static type checker will ensure that any object we pass as a</code>logger<code>to</code>run_process<code>has a</code>log(str)<code>method. In a nominal type system, you might have to define an abstract base class</code>Logger` and make every logger inherit it. With protocols, you get the benefit of an interface without the inheritance \u2013 this reduces coupling and makes it easier to integrate third-party classes that weren\u2019t written with your ABC in mind (Python Protocols: Leveraging Structural Subtyping \u2013 Real Python) (Abstract Base Classes and Protocols: What Are They? When To Use Them?? Lets Find Out! - Justin A. Ellis).</p> <p>2. Testing with fake or mock objects: Building on the above example, protocols are extremely handy for unit testing. In tests, we often use fake objects or mocks to simulate real components (like databases, web services, etc.) without having to perform the real operations. With protocols, you can give those test doubles a clear interface. For example, if you have a function that fetches data from an API, you could define a protocol for the fetcher. In production you pass a real HTTP client, in tests you pass a dummy object that returns predetermined data. The protocol assures the dummy has the same method signature as the real client. This avoids type checker warnings and makes tests cleaner. It\u2019s essentially the static typing analog of using an interface in other languages for dependency injection in tests.) Many testing libraries (like <code>unittest.mock</code>) create dynamic mocks that can be configured with attributes on the fly; to type-annotate those, you can either cast them to a Protocol or use a Protocol as a base for a dummy implementation. Using protocols in this way documents exactly what methods a mock is expected to provide. This can prevent situations where your test double is missing a method or has a typo that wouldn\u2019t be caught until runtime. In short, whenever you say \"I need an object that can do X in my code, and I might swap different implementations of it,\" that\u2019s a cue to define a protocol for X.</p> <p>3.Interface design and third-party integration: Protocols can serve as interfaces in your application design. Even if you\u2019re not writing multiple implementations immediately, defining a protocol for a role in your system can clarify the design. For example, you might define a <code>DataStore</code> protocol with methods like <code>save(item)</code> and <code>load(id)</code> that any storage backend should implement. Today you only have a database implementation, but tomorrow you might add an in-memory or file-based implementation \u2013 the protocol makes the contract clear. Moreover, if you want to accept objects from a third-party library that already have the necessary methods, protocols let you do so without subclassing or modifying those classes (Abstract Base Classes and Protocols: What Are They? When To Use Them?? Lets Find Out! - Justin A. Ellis). Suppose you\u2019re writing a function that can output data to any \"file-like\" object (something with a <code>.write()</code> method). The <code>io.TextIOBase</code> abstract class in Python is nominal, but not every file-like object will inherit it. By defining your own protocol with a <code>write(str)</code> method, your function can accept a wide range of objects (actual file handles, <code>io.StringIO</code> instances, custom writer objects) as long as they implement <code>write</code>. This is especially useful when working with libraries that weren\u2019t built with your interfaces; you can adapt them via protocols instead of being forced into their class hierarchy. Protocols thus increase reusability and extensibility of your code by focusing on what an object can do rather than what it is.</p> <p>It\u2019s worth mentioning that Python\u2019s standard library and frameworks have embraced the concept of protocols (even before the formal <code>Protocol</code> type existed) by using \"duck typing\" and abstract base classes. For instance, the act of iterating in Python checks for an <code>__iter__</code> method \u2013 any object that has <code>__iter__</code> is iterable. The static typing system knows this too: you don\u2019t have to explicitly register your class as an <code>Iterable</code> ABC; if it has the right method, tools like Mypy will treat it as iterable (Protocols and structural subtyping - mypy 1.15.0 documentation). With <code>Protocol</code>, we can create our own such abstractions. In modern Python, the combination of protocols and <code>@runtime_checkable</code> even lets us approximate some features of a language with a built-in interface system.</p> <p>4. Composition and adapters using protocols: Another practical pattern is using protocols to enable composition and decorators. Because protocols don\u2019t require inheritance, you can make wrapper classes that add functionality while still conforming to an interface. For example, you might have a basic service class and then a logging wrapper class that takes a service and also implements the same service protocol to proxy calls and add logging. As long as both implement the protocol, code using the protocol can accept either the plain or the wrapped version. This was illustrated by defining an <code>AddServiceProtocol</code> for an addition service and creating both a normal implementation and a logging decorator implementation that forwards calls (Protocols and Composition in Python - DEV Community). The key takeaway is that structural typing focuses on the behavior, so even objects that don\u2019t share a lineage can work together if they fulfill the same behavioral contract.</p>"},{"location":"10_Structural_Typing/#combining-dataclasses-with-protocols","title":"Combining Dataclasses with Protocols","text":"<pre><code># dataclasses_and_protocols.py\nfrom dataclasses import dataclass\nfrom typing import Protocol\n\n\nclass Identifiable(Protocol):\n    id: int\n\n\n@dataclass\nclass User:\n    id: int\n    name: str\n\n\n@dataclass\nclass Product:\n    id: int\n    price: float\n\n\ndef print_id(entity: Identifiable) -&gt; None:\n    print(f\"ID: {entity.id}\")\n\n\nprint_id(User(1, \"Alice\"))\n## ID: 1\nprint_id(Product(101, 19.99))\n## ID: 101\n</code></pre>"},{"location":"10_Structural_Typing/#combining-protocols-with-generics","title":"Combining Protocols with Generics","text":"<p>Just like classes and functions can be generic (using <code>TypeVar</code> to operate over a range of types), protocol classes can be generic as well. A generic protocol allows you to define a protocol that is parameterized by a type (or multiple types), enabling more precise typing of method arguments and return values. Many built-in protocols are generic \u2013 for example, <code>Iterable[T]</code> is a protocol that can be <code>Iterable[int]</code>, <code>Iterable[str]</code>, etc., depending on what type it yields. We can do the same with our own protocols.</p> <p>To define a generic protocol, we use <code>TypeVar</code> and put the type variable in brackets after <code>Protocol</code> when defining the class (Python Protocols: Leveraging Structural Subtyping \u2013 Real Python). Let\u2019s say we want to define a simple container protocol that yields items of some type. We can make it generic so that a <code>Container[int]</code> will be a protocol for \"container of ints\" and <code>Container[str]</code> for \"container of strings,\" but both are based on the same generic interface. For example:</p> <pre><code># container.py\nfrom typing import Protocol, TypeVar\n\nT = TypeVar(\"T\")\n\n\nclass Container(Protocol[T]):\n    def get_item(self) -&gt; T: ...\n</code></pre> <p>Here, <code>Container[T]</code> is a generic protocol with a single type variable <code>T</code>. It specifies one method <code>get_item</code> that returns an object of type <code>T</code>. Now we can implement this protocol for different types by providing concrete type parameters. For instance, a container of strings and a container of integers:</p> <pre><code># container_types.py\n\nclass StringContainer:\n    def __init__(self, value: str):\n        self.value = value\n\n    def get_item(self) -&gt; str:\n        return self.value\n\n\nclass IntContainer:\n    def __init__(self, value: int):\n        self.value = value\n\n    def get_item(self) -&gt; int:\n        return self.value\n</code></pre> <p><code>StringContainer</code> and <code>IntContainer</code> each implement <code>get_item</code> returning the appropriate type. They don\u2019t subclass <code>Container</code>, but structurally they match <code>Container[str]</code> and <code>Container[int]</code> respectively. We can write functions that use the generic protocol to accept any kind of container and preserve the type information of the contained item:</p> <pre><code># generic_function.py\nfrom container import Container\nfrom container_types import StringContainer, IntContainer\n\ndef print_item_and_return[C](container: Container[C]) -&gt; C:\n    item = container.get_item()\n    print(\"Got:\", item)\n    return item  # The type of item is inferred as C\n\n\n# Using the generic function with different container types:\nx = print_item_and_return(StringContainer(\"hello\"))  # prints \"hello\", x is str\n## Got: hello\ny = print_item_and_return(IntContainer(42))  # prints \"42\", y is int\n## Got: 42\n</code></pre> <p>In the function <code>print_item_and_return</code>, we used <code>C</code> (could also use <code>T</code> again) as a type variable for the container\u2019s item type. When we call this function with a <code>StringContainer</code>, the type checker knows <code>C</code> is <code>str</code> in that call, so it infers that the function returns a <code>str</code>. Similarly, with <code>IntContainer</code>, <code>C</code> becomes <code>int</code>. This is the benefit of generic protocols: they let you write flexible code that is still type-safe and retains specific type information. In other words, one protocol can work for many types without losing the ability to distinguish those types when it matters. The syntax we used (<code>Container[C]</code> inside the function annotation) leverages Python\u2019s ability to support generics in type hints. Under the hood, <code>Container[int]</code> is a parameterized protocol instance, but conceptually you can think of it like an interface template.)</p> <p>Keep in mind that user-defined generic protocols follow the same rules as normal generic classes for type checking (PEP 544 \u2013 Protocols: Structural subtyping (static duck typing) | peps.python.org). You can declare variance for type variables if needed (covariant, contravariant) using <code>typing.Final</code> or by special syntax in <code>TypeVar</code>, although if you don\u2019t declare, the type checker will assume invariance (meaning <code>Container[SubClass]</code> is not a subtype of <code>Container[BaseClass]</code> unless you marked variance). In our container example, this is not an issue because we\u2019re primarily using it to carry the exact type.</p> <p>Another scenario for combining protocols with generics is when you want to put protocols as bounds on <code>TypeVar</code>s. For instance, you can declare <code>T = TypeVar('T', bound=SomeProtocol)</code> to indicate that a type variable must satisfy a certain protocol. This is analogous to saying \"T must be a subtype of this Protocol,\" except since protocols aren\u2019t part of the class hierarchy, it really means any type used for T must structurally implement the protocol. For example, if we have:</p> <pre><code># example_9.py\nfrom typing import TypeVar\nfrom logger_protocol import Logger\n## Captured logs: ['Starting DataCleanup',\n## 'Finished DataCleanup']\n\nT = TypeVar(\"T\", bound=Logger)  # using our Logger protocol from earlier\n</code></pre> <p>This means any type filling in for T must have a <code>.log(str) -&gt; None</code> method. You could use such a bound in a generic function or class to ensure the operations you perform on T (like calling <code>log</code>) are valid. This is a powerful way to write generic algorithms that operate on any objects meeting a certain interface, without tying them to a base class.</p> <p>It\u2019s also worth noting that Python 3.12 introduced an even more concise way to define generic protocols (and generic classes in general) by allowing type variables in the definition of methods directly (PEP 695 \u2013 Type Parameter Syntax). For instance, one could write something like:</p> <pre><code># generic_method_in_protocol.py\nfrom typing import Protocol\n\n\nclass Container(Protocol):\n    def get_item[T](self) -&gt; T: ...\n</code></pre> <p>to define a generic method <code>get_item</code> in a protocol. However, under the hood this still creates a generic protocol with a type variable <code>T</code>. Most code at the time of writing still uses the earlier syntax with explicit <code>TypeVar</code> declarations, which is what we\u2019ve shown above.</p> <p>In summary, combining protocols with generics lets you express very flexible and reusable type relationships. You can create protocols that work over a family of types while still preserving type information. Many of Python\u2019s built-in protocols are generic (for example, an iterator protocol <code>Iterator[T]</code> yields items of type T), and you can do the same in your own designs (Python Protocols: Leveraging Structural Subtyping \u2013 Real Python) (Python Protocols: Leveraging Structural Subtyping \u2013 Real Python). This enables things like container types, numeric operations, or callback interfaces to be both generic and structural. When designing a generic protocol, think about what parts of the interface should change with the type (those become type variables) and which are fixed. The result is a very powerful abstraction that remains easy to use.</p>"},{"location":"10_Structural_Typing/#when-to-choose-structural-typing-over-nominal-typing","title":"When to Choose Structural Typing Over Nominal Typing","text":"<p>Now that we\u2019ve explored what structural typing (via protocols) and nominal typing (via concrete classes or ABCs) offer, a natural question arises: When should you use one over the other? The answer often depends on the context and goals. Both approaches have their strengths, and in Python they complement each other rather than one completely replacing the other (PEP 544 \u2013 Protocols: Structural subtyping (static duck typing) | peps.python.org). Here are some guidelines, pros and cons, and best practices to help decide:</p> <p>Use nominal typing (classes/ABCs) when:</p> <ul> <li> <p>You want to reuse code via inheritance. If you have default method implementations or shared attributes that can be defined in a base class, an abstract base class can provide that. Inheritance isn\u2019t the only way to reuse code, but when it makes sense (e.g. a base class providing common functionality), nominal typing naturally goes along with it because subclasses inherit from the base.</p> </li> <li> <p>You need a strict class hierarchy or runtime type information. If it\u2019s important in your design to maintain actual subclass relationships (perhaps for identity checks, <code>isinstance</code> checks, or because you rely on Python\u2019s method resolution order and <code>super()</code> calls), then using nominal types is appropriate. For example, if you have a plugin system where all plugins must register as subclasses of <code>BasePlugin</code> to be discovered, that\u2019s a nominal approach.</p> </li> <li> <p>The interface is large or complex, with many methods, and tightly coupled to an implementation. While you could model this with a protocol, it may be clearer to use an abstract class to group behavior. If multiple methods are meant to be overridden together, an ABC can enforce that at instantiation time (trying to instantiate a subclass that hasn\u2019t implemented all abstract methods raises an error). In short, for class designs that naturally form an \"is-a\" hierarchy and possibly share some code, nominal typing fits well.</p> </li> </ul> <p>Use structural typing (protocols) when:</p> <ul> <li> <p>You want to keep it lightweight and focused purely on the method/attribute requirements. Protocols are great for defining a narrow interface that multiple disparate classes can implement without formal coupling. If you only care about one or a few methods on an object (and not about its exact type), a protocol lets you specify just that. This is especially useful for function parameters: you can annotate a function to accept any object that has a <code>.close()</code> method, or a <code>.write()</code> method, etc., without forcing a common base class (Abstract Base Classes and Protocols: What Are They? When To Use Them?? Lets Find Out! - Justin A. Ellis).</p> </li> <li> <p>You are working with third-party or existing classes that you can\u2019t modify to fit into your class hierarchy. Structural typing shines here because you can define a protocol that matches the external class\u2019s capabilities. For example, if a 3rd-party library gives you objects that have a <code>.to_json()</code> method, and you want to treat those objects uniformly in your code, you can create a <code>ToJsonable</code> protocol with <code>to_json(self) -&gt; str</code> and use that in your type hints. Any object from the library will satisfy the protocol if it has the method, without you needing to make it inherit from anything (Abstract Base Classes and Protocols: What Are They? When To Use Them?? Lets Find Out! - Justin A. Ellis). This decoupling is very powerful in a language as dynamic as Python, where often we \"duck type\" through frameworks \u2013 now you can put an actual type hint on it.</p> </li> <li> <p>You need generic interfaces or extension of existing ones. Protocols are useful for creating ad-hoc interfaces that might not have been foreseen initially. For instance, you might realize that two classes in different parts of your system happen to have similar methods for, say, resetting their state. You could retroactively define a <code>Resettable</code> protocol and update type hints to use it, without touching the classes themselves. If later you make those classes formally implement an ABC, fine \u2013 but the protocol gave you an immediate way to express the concept in types and check it. Additionally, if you\u2019re designing a library and want to allow users to plug in their own objects (as long as they have certain methods), providing a protocol in your public API documentation is a nice way to communicate that. Users can either implement that Protocol (statically) or just ensure their classes match the signature.</p> </li> </ul> <p>Pros and Cons Summary: Nominal typing (using concrete classes and ABCs) offers clarity in terms of design \u2013 it\u2019s very clear that ClassX is a kind of InterfaceY because it explicitly inherits it. It also allows enforcement: abstract base classes can ensure at runtime that certain methods are implemented (attempting to instantiate a subclass that hasn\u2019t implemented an abstract method will error out). They can also provide default behavior. However, nominal typing is less flexible \u2013 everything must be planned or adapted to fit the hierarchy. If you want an external class to be treated as an InterfaceY, you might have to write an adapter or subclass it, which could be clunky or impossible (if you don\u2019t control that class). Structural typing (using protocols) is extremely flexible and mirrors Python\u2019s dynamic nature \u2013 you get to \"write the interface after the fact.\" It encourages designing for capabilities rather than inheritance. The downside is that protocols are primarily static \u2013 they rely on the developer running a type checker. Python won\u2019t stop you from passing an object that doesn\u2019t fulfill the protocol (until you call a missing method and get an error at runtime, just like normal duck typing). So if you need guaranteed enforcement in a running program, protocols alone won\u2019t give you that (they are optional). That said, in a team or project using type checks as part of CI, protocols can prevent a lot of mistakes. Another minor con is that protocols, if overused, could make it less obvious which classes actually implement which interface; with nominal typing you can always search for subclasses of an ABC. In practice, a mix is often best: use protocols for the broad \"this is what we expect\" contracts especially for external boundaries and flexible APIs, and use concrete classes or ABCs internally when you want more structure or reuse.</p> <p>Best practices: It\u2019s not an either/or choice \u2013 you can use both in the same codebase. For example, you might define an ABC with some default methods for a complex interface, but also define a protocol for a subset of that interface for use in a more generic function. Choose structural typing when you want minimal coupling and maximum flexibility, especially at boundaries of your system or for \"pluggable\" functionality. Choose nominal typing when you want an explicit, enforced contract and possibly to leverage inheritance of code. Remember that protocols are most valuable when you are using static type checking; if your project doesn\u2019t use type checks, then a protocol is simply a <code>abc.ABC</code> with no abstract methods \u2013 it won\u2019t enforce anything by itself at runtime. In such cases, if enforcement is needed, an ABC with abstract methods (or even just documentation) might be better. However, even in purely dynamic contexts, many developers find protocols useful as documentation: by reading the Protocol class, you know what an object is expected to do.</p> <p>In Python\u2019s type system evolution, protocols were introduced to complement nominal typing, not to replace it (PEP 544 \u2013 Protocols: Structural subtyping (static duck typing) | peps.python.org). They give you the freedom to write code in the Pythonic duck-typed style while still reaping the benefits of static analysis. A good guideline is to use protocols to describe roles that can be played by objects of different class hierarchies, and use nominal typing for relationships within a class hierarchy. By following these practices, you can make your code both flexible and robust, leveraging the best of both worlds in Python\u2019s type system.</p>"},{"location":"11_Make_Illegal_Types_Unrepresentable/","title":"Make Illegal Types Unrepresentable","text":"<p>A common strategy for preventing problems is to check values after arguments are passed to functions. This spreads validation code across functions, producing maintenance problems. This chapter moves validation into custom types that make invalid data impossible. In addition, data is checked when you create an instance, rather than when data is passed to a function. With this approach, you:</p> <ol> <li>Discover problems sooner.</li> <li>Clarify the meaning of your code.</li> <li>Share custom type benefits across all functions that use those types.</li> <li>Eliminate duplicate validation checks and their associated maintenance.</li> <li>Make changes easier by localizing validation to a single point.</li> <li>Eliminate the need for techniques such as Design By Contract (DBC).</li> <li>Enable more focused testing with finer granularity.</li> </ol>"},{"location":"11_Make_Illegal_Types_Unrepresentable/#stringly-typed","title":"\"Stringly Typed\"","text":"<p>Years ago I came across some research looking at the way generic components like <code>List</code>, <code>Set</code> and <code>Map</code> were being used in Java. Only a tiny percentage of the code reviewed used anything except strings as type parameters. This study suggested that the vast majority of systems were using strings as their primary data type.</p> <p>Because you can put any characters in any format into a string, such \"stringly typed\" systems (an ironic play on \"strongly typed\") may be the worst of all possible worlds. Unless it's actually text, classifying something as a string doesn't tell you anything. When a function receives a string that is meant to represent a type, that function can assume precisely nothing about it. Every such function must start from scratch and analyze that string to see if it conforms to what that function needs.</p> <p>It is a daunting job to change the meaning of that stringly-typed item. You must look through every function that uses it and ensure that your change is reflected in the validations in every single function. Because the logic is distributed, it's highly likely you will miss some.</p> <p>Consider representing phone numbers as strings. Here are just a few of the different formats you might have to deal with:</p> <pre><code># string_phone_numbers.py\n# Some problematic formats\nphone_numbers: list[str] = [\n    \"5551234\",         # No formatting \u2013 unclear area code\n    \"555-1234\",        # US format, but without area code\n    \"(555) 123-4567\",  # US format with punctuation\n    \"555.123.4567\",    # Inconsistent punctuation\n    \"+1-555-123-4567\", # International format\n    \"+44 20 7946 0958\",# UK format \u2013 space-separated\n    \"5551234567\",      # No formatting at all\n    \"555 1234\",        # Ambiguous \u2013 local format?\n    \"555-12ab\",        # Invalid characters\n    \"CallMeMaybe\",     # Completely invalid\n    \"01234\",           # Leading zero \u2013 looks like a zip code\n    \"\",                # Empty string\n    \" 5551234 \",       # Whitespace issues\n]\n</code></pre> <p>Every time you write a function that takes a phone number represented as a string, you must first validate that number. Here's one of the worst approaches imaginable:</p> <pre><code># phone_number_functions.py\nfrom string_phone_numbers import phone_numbers\nimport re\n\ndef f1(phone: str):\n    VALID = re.compile(r\"^\\+?(\\d{1,3})?[\\s\\-.()]*([\\d\\s\\-.()]+)$\")\n    if not VALID.match(phone):\n        print(f\"Error {phone = }\")\n        return\n    ...\n\ndef f2(phone_num: str):\n    CHECK = re.compile(r\"^\\+?(\\d{1,3})?[\\s\\-.()]*([\\d\\s\\-.()]+)$\")\n    assert CHECK.match(phone_num), f\"Invalid {phone_num}\"\n    ...\n</code></pre> <p>Each function has its own custom code and reports errors differently. There might be many such functions spread throughout the system. If there's a bug or any change in the way phone numbers are validated, all validation code must be hunted down and corrected, and any tests must also be updated.</p> <p>Does anyone set out to write code like this? Probably not--it starts out seeming like \"the simplest thing\" and just continues to accumulate, one logical step at a time. Although you might not write code like this, systems like this exist, for phone numbers and for many other data items represented as strings. In this chapter we'll see how creating custom types can dramatically simplify validation and guarantee correctness throughout your system.</p>"},{"location":"11_Make_Illegal_Types_Unrepresentable/#design-by-contract","title":"Design by Contract","text":"<p>The argument-validation problem was observed by Bertrand Meyer and introduced as a core concept in his Eiffel programming language, described in the book Object-Oriented Software Construction (1988). Design By Contract (DbC) tried to reduce errors by treating the interaction between software components as a formal agreement:</p> <ul> <li>Preconditions: What must be true before a function/method runs.</li> <li>Postconditions: What must be true after the function completes.</li> <li>Invariants: What must always be true about the object state.</li> </ul> <p>Eiffel provided explicit keywords to make DbC a first-class citizen in the language:</p> Keyword Purpose <code>require</code> Preconditions <code>ensure</code> Postconditions <code>invariant</code> Class-wide conditions <code>old</code> Refers to previous state in postconditions <p>The idea was that each function you wrote would use these to ensure the correctness of the inputs and outputs of that function. In particular, <code>require</code> typically checks the argument values for correctness. For preconditions in Python, we can create a <code>requires</code> decorator to check argument values:</p> <pre><code># require.py\nfrom typing import Callable, NamedTuple\nfrom functools import wraps\n\n\nclass Condition(NamedTuple):\n    check: Callable[..., bool]\n    message: str\n\n\ndef requires(*conditions: Condition):\n    def decorator(func: Callable):\n        @wraps(func)\n        def wrapper(*args, **kwargs):\n            for condition in conditions:\n                if not condition.check(*args, **kwargs):\n                    raise ValueError(condition.message)\n            return func(*args, **kwargs)\n\n        return wrapper\n\n    return decorator\n</code></pre> <p>A <code>Condition</code> combines each <code>check</code> with a description of the failure condition. <code>check</code> is a <code>Callable</code> (usually a function) that takes the same arguments as the function being decorated and returns a <code>bool</code> indicating whether the condition is satisfied.</p> <p><code>requires</code> is a decorator factory; it returns a decorator that can be applied to any function.  It accepts any number of Condition instances.</p> <p>This inner function <code>decorator</code> is the actual decorator. It receives the target function func that\u2019s being wrapped.</p> <p><code>wrapper</code> is the new function that will replace <code>func</code>. <code>@wraps(func)</code> preserves metadata like the function name and docstring.</p> <p>Here's a basic example:</p> <pre><code># basic_requires.py\nfrom book_utils import Catch\nfrom require import requires, Condition\n\npositivity = Condition(\n    check=lambda x: x &gt; 0,\n    message=\"x must be positive\"\n)\n\n@requires(positivity)\ndef sqrt(x) -&gt; float:\n    return x ** 0.5\n\nprint(sqrt(4))\n## 2.0\nwith Catch():\n    sqrt(-2)\n## Error: x must be positive\n</code></pre> <p><code>positivity</code> defines an instance of <code>Condition</code>, which is then imposed on <code>sqrt</code> using <code>requires</code>.</p> <p><code>requires</code> produces an improved DbC for validating function arguments:</p> <pre><code># bank_account.py\nfrom dataclasses import dataclass\nfrom decimal import Decimal\n\nfrom book_utils import Catch\nfrom require import requires, Condition\nfrom amount import Amount\n\npositive_amount = Condition(\n    check=lambda self, amount: amount &gt;= Decimal(\"0\"),\n    message=\"Amount cannot be negative\",\n)\n\nsufficient_balance = Condition(\n    check=lambda self, amount: self.balance &gt;= amount,\n    message=\"Insufficient balance\"\n)\n\n\n@dataclass\nclass BankAccount:\n    balance: Decimal\n\n    @requires(positive_amount, sufficient_balance)\n    def withdraw(self, amount: Decimal) -&gt; str:\n        self.balance -= amount\n        return f\"Withdrew {amount}, balance: {self.balance}\"\n\n    @requires(positive_amount)\n    def deposit(self, amount: Decimal) -&gt; str:\n        self.balance += amount\n        return f\"Deposited {amount}, balance: {self.balance}\"\n\n\naccount = BankAccount(Decimal(100))\nprint(account.deposit(Decimal(50)))\n## Deposited 50, balance: 150\nprint(account.withdraw(Decimal(30)))\n## Withdrew 30, balance: 120\nwith Catch():\n    account.withdraw(Decimal(200))\n## Error: Insufficient balance\nwith Catch():\n    account.deposit(Decimal(-10))\n## Error: Amount cannot be negative\n</code></pre> <p>In this case the <code>Condition</code>s are being applied to methods, so their <code>lambda</code>s both include <code>self</code>. In <code>withdraw</code> you see multiple <code>Condition</code>s applied in one <code>requires</code> decorator.</p> <p>This is an improvement over placing the validation code at the beginning of each function body, as Eiffel does and as traditional Python functions do--assuming they check their arguments. The <code>@requires</code> clearly shows that constraints have been placed on the arguments, while <code>Condition</code> reduces duplicated code.</p> <p>DbC definitely helps, but it has limitations:</p> <ol> <li>A programmer can forget to use <code>requires</code>, or simply choose to perform argument checks by hand if DbC doesn't make sense to them.</li> <li>Validations are spread throughout your system. Using <code>Condition</code> centralizes the logic, but making changes still risks missing updates on functions.</li> </ol>"},{"location":"11_Make_Illegal_Types_Unrepresentable/#centralizing-validation-into-custom-types","title":"Centralizing Validation into Custom Types","text":"<p>Instead of DbC, we can encode validations into custom types. This way, incorrect objects of those types cannot successfully be created. In addition, the types are usually domain driven, that is, they represent a concept from the problem domain.</p> <p>For the bank example, we start by creating an <code>Amount</code>, which is a <code>Decimal</code> value with the fundamental property that it cannot be negative. If an <code>Amount</code> object exists, you know it cannot contain a negative value:</p> <pre><code># amount.py\nfrom dataclasses import dataclass\nfrom decimal import Decimal\n\n\n@dataclass(frozen=True)\nclass Amount:\n    value: Decimal\n\n    def __init__(self, value: int | float | str | Decimal) -&gt; None:\n        decimal_value = Decimal(str(value))\n        if decimal_value &lt; Decimal(\"0\"):\n            raise ValueError(f\"Amount({decimal_value}) cannot be negative\")\n        object.__setattr__(self, \"value\", decimal_value)\n\n    def __add__(self, other: \"Amount\") -&gt; \"Amount\":\n        return Amount(self.value + other.value)\n\n    def __sub__(self, other: \"Amount\") -&gt; \"Amount\":\n        return Amount(self.value - other.value)\n</code></pre> <p>Although <code>Amount</code> is a frozen <code>dataclass</code>, it is still possible to write an <code>__init__</code> method. Here, it allows <code>Amount</code> to convert multiple forms of input into a <code>Decimal</code>, then check that it is non-negative. It then modifies itself using <code>object.__setattr__</code>, but other than that we want it safely immutable. Thus, you can modify a frozen <code>dataclass</code> using <code>object.__setattr__</code>, but this is best only done during construction, as seen here. You can also call <code>object.__setattr__</code> in <code>__post_init__</code>, but if you find yourself doing it in other methods you should reconsider whether your type is really frozen. Requiring <code>object.__setattr__</code> to modify a frozen <code>dataclass</code> means you can easily discover all modifications.</p> <p>Note that <code>__add__</code> and <code>__sub__</code> simply return new <code>Amount</code> objects without worrying whether they are non-negative--the constructor takes care of that.</p> <p>If you provide an incorrect <code>value</code> to <code>Amount</code>, the <code>Decimal</code> constructor throws an exception:</p> <pre><code># bad_amount.py\nfrom amount import Amount\nfrom book_utils import Catch\n\nprint(Amount(123))\n## Amount(value=Decimal('123'))\nprint(Amount(\"123\"))\n## Amount(value=Decimal('123'))\nprint(Amount(1.23))\n## Amount(value=Decimal('1.23'))\nwith Catch():\n    Amount(\"not-a-number\")\n## Error: [&lt;class 'decimal.ConversionSyntax'&gt;]\n</code></pre> <p><code>Balance</code> contains an <code>Amount</code>, but it doesn't need any fancy construction behavior so we can produce an immutable using <code>NamedTuple</code>:</p> <pre><code># balance.py\nfrom typing import NamedTuple\nfrom amount import Amount\n\n\nclass Balance(NamedTuple):\n    amount: Amount\n\n    def deposit(self, deposit_amount: Amount) -&gt; \"Balance\":\n        return Balance(self.amount + deposit_amount)\n\n    def withdraw(self, withdrawal_amount: Amount) -&gt; \"Balance\":\n        return Balance(self.amount - withdrawal_amount)\n</code></pre> <p>Note that <code>Balance</code> simply produces new immutable objects when you <code>deposit</code> and <code>withdraw</code>. Because it uses <code>Amount</code>, it needs no special validation checks.</p> <p>In the new, improved <code>BankAccount</code>, the need for validation disappears because it is automatically enforced by the types:</p> <pre><code># typed_bank_account.py\nfrom dataclasses import dataclass\nfrom amount import Amount\nfrom balance import Balance\nfrom book_utils import Catch\n\n\n@dataclass\nclass BankAccount:\n    balance: Balance\n\n    def deposit(self, amount: Amount) -&gt; str:\n        self.balance = self.balance.deposit(amount)\n        return f\"Deposited {amount.value}, balance: {self.balance.amount.value}\"\n\n    def withdraw(self, amount: Amount) -&gt; str:\n        self.balance = self.balance.withdraw(amount)\n        return f\"Withdrew {amount.value}, balance: {self.balance.amount.value}\"\n\n\naccount = BankAccount(Balance(Amount(100)))\nprint(account.deposit(Amount(50)))\n## Deposited 50, balance: 150\nprint(account.withdraw(Amount(30)))\n## Withdrew 30, balance: 120\nwith Catch():\n    account.withdraw(Amount(200))\n## Error: Amount(-80) cannot be negative\nwith Catch():\n    account.deposit(Amount(-10))\n## Error: Amount(-10) cannot be negative\n</code></pre> <p>The code is significantly more straightforward to understand and change. If we need to modify the underlying representation of <code>Amount</code> we only do it in one place. Suppose, for example, we discover Python's implementation of <code>Decimal</code> is too slow. We can modify <code>Amount</code> to use, for example, a Rust implementation of decimal numbers. We only need to change the code for <code>Amount</code> because the rest of the code simply uses <code>Amount</code>.</p> <p>Possibly best of all, any new code we write using custom types transparently uses all the type validations built into those types. If we add more validations, they automatically propagate to each site where those types are used.</p>"},{"location":"11_Make_Illegal_Types_Unrepresentable/#a-phonenumber-type","title":"A <code>PhoneNumber</code> Type","text":"<p>Let's apply this approach to the stringly-typed phone number problem shown at the beginning of the chapter.</p> <pre><code># phone_number.py\nfrom dataclasses import dataclass\nfrom typing import Self\nimport re\n\n@dataclass(frozen=True)\nclass PhoneNumber:\n    \"\"\"Represents a validated and normalized phone number.\"\"\"\n    country_code: str\n    number: str  # Digits only, no formatting\n\n    PHONE_REGEX = re.compile(r\"^\\+?(\\d{1,3})?[\\s\\-.()]*([\\d\\s\\-.()]+)$\")\n\n    @classmethod\n    def parse(cls, raw: str) -&gt; Self:\n        \"\"\"Parses and validates a raw phone number string.\"\"\"\n        cleaned = raw.strip()\n        match = cls.PHONE_REGEX.match(cleaned)\n        if not match:\n            raise ValueError(f\"Invalid phone number: {raw!r}\")\n\n        cc, num = match.groups()\n        digits = re.sub(r\"\\D\", \"\", num)\n        if not digits:\n            raise ValueError(f\"No digits found in: {raw!r}\")\n\n        country_code = cc if cc else \"1\"  # default to US\n        return cls(country_code=country_code, number=digits)\n\n    def __str__(self) -&gt; str:\n        \"\"\"Formats the phone number as +&lt;country&gt; &lt;formatted number&gt;.\"\"\"\n        formatted = self.format_number()\n        return f\"+{self.country_code} {formatted}\"\n\n    def format_number(self) -&gt; str:\n        \"\"\"Applies simple formatting rules for 10-digit numbers.\"\"\"\n        if len(self.number) == 10:\n            return f\"({self.number[:3]}) {self.number[3:6]}-{self.number[6:]}\"\n        return self.number  # fallback: just the digits\n\n    def __eq__(self, other: object) -&gt; bool:\n        if not isinstance(other, PhoneNumber):\n            return NotImplemented\n        return (\n            self.country_code == other.country_code\n            and self.number == other.number\n        )\n</code></pre> <p>We can test this against the list in <code>string_phone_numbers.py</code>:</p> <pre><code># phone_numbers_as_types.py\nfrom phone_number import PhoneNumber\nfrom string_phone_numbers import phone_numbers\nfrom book_utils import Catch\n\nfor raw in phone_numbers:\n    with Catch():\n        pn = PhoneNumber.parse(raw)\n        print(f\"{raw!r} -&gt; {pn}\")\n## '5551234' -&gt; +555 1234\n## '555-1234' -&gt; +555 1234\n## '(555) 123-4567' -&gt; +1 (555) 123-4567\n## '555.123.4567' -&gt; +555 1234567\n## '+1-555-123-4567' -&gt; +1 (555) 123-4567\n## '+44 20 7946 0958' -&gt; +44 (207) 946-0958\n## '5551234567' -&gt; +555 1234567\n## '555 1234' -&gt; +555 1234\n## Error: Invalid phone number: '555-12ab'\n## Error: Invalid phone number: 'CallMeMaybe'\n## '01234' -&gt; +012 34\n## Error: Invalid phone number: ''\n## ' 5551234 ' -&gt; +555 1234\n</code></pre>"},{"location":"12_Errors_as_Values/","title":"Errors as Values","text":"<p>Most of what we've been working towards in programming\u2014whether we are aware of it or not\u2014is composability.</p> <p>Discovering the meaning of composability is part of this path--there are different definitions depending on the programming language paradigm under scrutiny. Here\u2019s my definition:</p> <p>The ability to assemble bigger pieces from smaller pieces.</p> <p>This is less precise than some definitions. For example, composition in object-oriented programming means \"putting objects inside other objects.\" When dealing with functions, composability means \"calling functions within other functions.\" Both definitions fit my overall definition; they achieve the same goal but in different specific ways.</p> <p>To enable the easy construction of programs, we need to be able to effortlessly assemble components in the same way that a child assembles Legos\u2014by simply sticking them together, without requiring extra activities. On top of that, such assemblages become their own components that can be stuck together just as easily. This composability scales up regardless of the size of the components.</p> <p>Over the years we have encountered numerous roadblocks to this goal.</p>"},{"location":"12_Errors_as_Values/#goto-considered-harmful","title":"Goto Considered Harmful","text":"<p>Djikstra\u2019s 1968 note had quite an impact on the programming community, which at the time consisted largely of assembly-language programmers. For these, the goto statement was foundational, and denigrating it was a shock. Although he never explicitly mentioned functions in his note, the effect was to push programmers towards functions. The creator of Structured Concurrency provides a clear description of this.</p> <p>Rather than jumping about within a limited program, functions present the caller with a single entry and exit point. This dramatically improves composability because you can no longer leave a section of code at any point using a goto. Within a function scope you cannot know what\u2019s outside that scope, thus you can\u2019t jump somewhere because you don\u2019t know a destination to jump to.</p> <p>My programming training was primarily as a computer engineer and I spent the first few years of my career programming in assembly. Assembly supports subroutine calls and returns, but not the loading of arguments on the stack and passing results back out\u2014the programmer must write this error-prone code by hand.</p> <p>Higher-level languages handle function arguments and returns for you, which made them a very desirable improvement as the size and complexity of programs grew beyond what the assembly programmer was able to hold in their head.</p>"},{"location":"12_Errors_as_Values/#modules","title":"Modules","text":"<p>Tim Peters\u2019 observation of the value of namespaces (see The Zen of Python) is the core of the idea of modules, which more modern languages incorporate (unfortunately C++ had to inherit C\u2019s messy system, for backwards compatibility). In Python, files are automatically modules, which is certainly one of the easiest solutions.</p> <p>It wasn\u2019t always this way. Breaking assembly-language programs into pieces was not easy, and early higher-level languages tended to be single-file programs and did not consider modularity. When the idea began to surface it was incorporated as a main feature of the Modula-2 language (a descendent of Pascal). The name tells you what a significant shift it was considered at the time.</p> <p>Modula-2 and similar languages required an explicit declaration of a module:</p> <pre><code>MODULE Hello;\nFROM STextIO IMPORT WriteString;\nBEGIN\n  WriteString(\"Hello World!\")\nEND Hello.\n</code></pre> <p>This allowed complete granularity independent of file organization; perhaps this was because programmers were used to thinking in terms of one big file-per-program. Python\u2019s merging of modules with files makes more sense in hindsight and has the benefit of eliminating the (significant) extra verbiage, only a portion of which is shown here.</p> <p>The main benefit of modules is name control\u2014each module creates a scope for names (a namespace) which allows programmers the freedom to choose any name at will within a module. This prevents name collisions across a project and reduces the cognitive load on the programmer. Prior to this, programs reached scaling limits as they grew larger. Program size in assembly language programs was limited by many different factors, so the need for modules was not seen until systems were able to grow larger because higher-level languages solved enough of these other factors.</p> <p>In modern languages, modularity is part of the background of a language and we don\u2019t think much about it. At one time, however, the lack of modularity was a significant roadblock to code composability.</p>"},{"location":"12_Errors_as_Values/#inheritance","title":"Inheritance","text":"<p>Object-oriented programming has a bit of a tortured history. Although the first OO language was Simula-67 (a compiled language), OO found its first real success with Smalltalk. But Smalltalk might be the most dynamic language you\u2019ll ever encounter\u2014literally everything is evaluated at runtime. While this worked well for the kinds of problems Smalltalk was good at solving, it turned out that taking the ideas of Smalltalk and imprinting them into a statically-typed language lost a lot in translation.</p>"},{"location":"12_Errors_as_Values/#error-handling","title":"Error Handling","text":"<p>Error reporting and handling has been a significant impediment to composability.</p>"},{"location":"12_Errors_as_Values/#history","title":"History","text":"<p>Original programs were small (by present-day standards), written in assembly language (machine code quickly became too unwieldy), and tightly coupled to the underlying hardware. If something went wrong, the only way to report it was to change the output on a wire, to turn on a light or a buzzer. If you had one, you put a message on the console\u2014this might as simple as a dot-matrix display. Such an error message probably wasn\u2019t friendly to the end-user of the system and usually required a tech support call to the manufacturer.</p> <p>Two of my first jobs were building embedded systems that controlled hardware. These systems had to work right. There was no point in reporting most errors because  an error normally meant the software was broken.</p> <p>For business and scientific programming, Fortran and Cobol were batch processed on punch cards. If something went wrong, either the compilation failed or the resulting data was bad. No real-time error-handling was necessary because the program didn\u2019t run in real time.</p> <p>As time-sharing operating systems like Unix became a common way to distribute computing resources, program execution became more immediate. Users began to expect more interactive experiences, so programmers had to begin thinking about how to report and handle errors during the execution of a program, and in ideal cases recovering from those errors so the program could continue without shutting down.</p> <p>Programmers produced a scattered collection of solutions to the reporting problem:</p> <ul> <li> <p>Indicate failure by returning a special value from a function call. This only works when the special value doesn't occur from an ordinary call to that function. For example, if your function returns any <code>int</code>, you can't use <code>0</code> or <code>-1</code> to report an error. A bigger problem is that you rely on the client programmer to pay attention to the return value and know what to do about errors.</p> </li> <li> <p>Indicate failure by setting a global flag. This is a single flag shared by all functions in the program. The client programmer must know to watch that flag. If the flag isn't checked right away, it might get overwritten by a different function call in which case the error is lost.</p> </li> <li> <p>Use signals if the operating system supports it.</p> </li> </ul> <p>The operating system was something that needed to be discovered. As programmers found themselves rewriting the same basic code over and over again, and much of that repeated code involved manipulating hardware and the attendant specialized knowledge required, it became clear that we needed a layer to eliminate this extra work, work that to some degree every program required.</p> <p>A fundamental question that designers were trying to understand during this evolution was:</p> <p>Who is responsible for error handling, the OS or the language?</p> <p>Since every program has the potential for errors, it initially seemed obvious that this activity should be the domain of the operating system. Some early operating systems allowed the program to invoke an error which would then jump to the operating system, and a few OSes even experimented with the ability to \"resume\" back to the point where the error occurred, so the handler could fix the problem and continue processing. Notably, these systems did not find success and resumption was removed.</p> <p>Further experiments eventually made it clear that the language needed primary responsibility for error reporting and handling (there are a few special cases, such as out-of-memory errors, which must still be handled by the OS). This is because an OS is designed to be general-purpose, and thus cannot know the specific situation that caused an error, whereas language code can be close to the problem. Customization is normally the domain of the language. You could imagine calling the OS to install custom error-handling routines, and you can also imagine how quickly that would become overwhelmingly messy.</p> <p>If errors are in the language domain, the next question is how to report and handle them.</p>"},{"location":"12_Errors_as_Values/#exceptions","title":"Exceptions","text":"<p>Unifying error reporting and recovery</p> <p>There were different language implementations of exceptions:</p> <ul> <li>Lisp (was this the origin of language-based exceptions?). Possibly ironic as Lisp is the first functional language.</li> <li>BASIC had \"On Error Go To\" (and \"resume\"?)</li> <li>Pascal</li> <li>C++</li> <li>Java created checked exceptions, which must be explicitly dealt with in your code, and runtime exceptions, which could be ignored.</li> <li>Python has exceptions but doesn\u2019t provide any type annotation or other mechanism to indicate what exceptions might emerge from a function call.</li> </ul> <p>Exceptions seemed like a great idea:</p> <ol> <li>A standardized way to correct problems so that an operation can recover and retry.</li> <li>There's only one way to report errors.</li> <li>Errors cannot be ignored\u2014they flow upward until caught or displayed on the console with program termination.</li> <li>Errors can be handled close to the origin, or generalized by catching them \"further out\" so that multiple error sources can be managed with a single handler.</li> <li>Exception hierarchies allow more general exception handlers to handle multiple exception subtypes.</li> </ol> <p>To be clear, exceptions were a big improvement over all of the previous (non) solutions to the error reporting problem. Exceptions moved us forward for awhile (and became entrenched in programming culture) until folks started discovering pain points. As is often the case, this happened as we tried to scale up to create larger and more complex systems. And once again, the underlying issue was composability.</p>"},{"location":"12_Errors_as_Values/#problems-with-exceptions","title":"Problems with Exceptions","text":"<p>In the small (and especially when teaching them), exceptions seem to work quite well. It's hard to prove during language design; things work in the small but don't scale. We only figure it out when scaling composability.</p>"},{"location":"12_Errors_as_Values/#1-the-two-kinds-of-errors-are-conflated","title":"1. The Two Kinds of Errors are Conflated","text":"<p>Recoverable vs panic (Recovering/Retrying requires programming) With exceptions, the two types are conflated. (Link to Error handling article)</p>"},{"location":"12_Errors_as_Values/#2-not-part-of-the-type-system","title":"2. Not Part of the Type System","text":"<p>If the type system doesn\u2019t include exceptions as part of a function signature, you can\u2019t know what exceptions you must handle when calling other functions (i.e.: composing). Even if you track down all the possible exceptions thrown explicitly in the code (by hunting for them in their source code!), built-in exceptions can still happen without evidence in the code: divide-by-zero is a great example of this.</p> <p>You can be using a library and handling all the exceptions from it (or perhaps just the ones you found in the documentation), and a newer version of that library can quietly add a new exception, and suddenly you are no longer detecting and/or handling all the exceptions. Even though you made no changes to your code.</p> <p>Languages like C++ and Java attempted to solve this problem by adding exception specifications, a notation that allows you to add the exception types that may be thrown, as part of the function\u2019s type signature.</p> <p>Object-oriented languages that enforce exception specifications (C++, Java) and create exception hierarchies introduce another problem. Exception hierarchies allow the library programmer to use an exception base type in the exception specification. This obscures important details; if the exception specification just uses a base type, there\u2019s no way for the compiler to enforce coverage of specific exceptions.</p> <p>When errors are included in the type system, you can know all the errors that can occur just by looking at the type information. If a library component adds a new error then that must be reflected in that component\u2019s type signature, which means that the code using it immediately knows that it is no longer covering all the error conditions, and will produce type errors until it is fixed.</p>"},{"location":"12_Errors_as_Values/#3-exception-specifications-create-a-shadow-type-system","title":"3. Exception Specifications Create a \"Shadow Type System\"","text":"<p>Languages like C++ and Java attempted to add notation indicating the exceptions that might emerge from a function call. This was well-intentioned and seems to produce the necessary information the client programmer needs to handle errors. The fundamental problem was that this created an alternate or \"shadow\" type system that doesn\u2019t follow the same rules as the primary type system. To make the shadow type system work, its rules were warped to the point where it became effectively useless (a discovery that has taken years to realize).</p> <p>C++ exception specifications were originally optional and not statically type-checked. After many years these were deprecated in favor of the statically-typed <code>expected</code> specification (which takes the functional approached described in this paper).</p> <p>Java created checked exceptions, which must be explicitly dealt with in your code, and runtime exceptions, which could be ignored. Eventually they added a feature that allows checked exceptions to be easily converted into runtime exceptions. Java functions can always return <code>null</code> without any warning.</p> <p>Both systems (the original C++ dynamic exception specifications, and Java exception specifications) had too many holes, and it was too difficult to effectively support both the main and shadow type systems.</p>"},{"location":"12_Errors_as_Values/#4-exceptions-destroy-partial-calculations","title":"4. Exceptions Destroy Partial Calculations","text":"<p>Let\u2019s start with a simple example where we populate a <code>List</code> with the results of a sequence of calls to the function <code>func_a</code>:</p> <pre><code># discarded_state.py\n# Exception throws everything away\nfrom book_utils import Catch\n\n\ndef func_a(i: int) -&gt; int:\n    if i == 1:\n        raise ValueError(f\"func_a({i})\")\n    return i\n\n\nwith Catch():\n    result = [func_a(i) for i in range(3)]\n    print(result)\n## Error: func_a(1)\n</code></pre> <p><code>func_a</code> throws a <code>ValueError</code> if its argument is <code>1</code>. The <code>range(3)</code> is 0, 1, and 2; only one of these values causes the exception. So <code>result</code> contains only one problem; the other two values are fine. However, we lose everything that we were calculating when the exception is thrown. This:</p> <ol> <li>Is computationally wasteful, especially with large calculations.</li> <li>Makes debugging harder. It would be quite valuable to see in <code>result</code> the parts that succeeded and those that failed.</li> </ol>"},{"location":"12_Errors_as_Values/#the-functional-solution","title":"The Functional Solution","text":"<p>Instead of creating a complex implementation to report and handle errors, the functional approach creates a \"return package\" containing the answer along with the (potential) error information. Instead of only returning the answer, we return this package from the function.</p> <p>This package is a new type, with operations that prevent the programmer from simply plucking the result from the package without dealing with error conditions (a failing of the Go language approach).</p> <p>A first attempt uses type unions to create a nameless return package:</p> <pre><code># return_union.py\n# Type union aka Sum Type\n# Success vs error is not clear\n\n\ndef func_a(i: int) -&gt; int | str:  # Sum type\n    if i == 1:\n        return f\"func_a({i})\"\n    return i\n\n\nprint(outputs := [(i, func_a(i)) for i in range(5)])\n## [(0, 0), (1, 'func_a(1)'), (2, 2), (3, 3), (4,\n## 4)]\n\nfor i, r in outputs:\n    match r:\n        case int(answer):\n            print(f\"{i}: {answer = }\")\n        case str(error):\n            print(f\"{i}: {error = }\")\n## 0: answer = 0\n## 1: error = 'func_a(1)'\n## 2: answer = 2\n## 3: answer = 3\n## 4: answer = 4\n</code></pre> <p><code>func_a</code> returns a <code>str</code> to indicate an error, and an <code>int</code> answer if there is no error. In the pattern match, we are forced to check the result type to determine whether an error occurs; we cannot just assume it is an <code>int</code>.</p> <p>An important problem with this approach is that it is not clear which type is the success value and which type represents the error condition\u2014because we are trying to repurpose existing built-in types to represent new meanings.</p> <p>In hindsight, it might seem like this \"return package\" approach is much more obvious than the elaborate exception-handling scheme that was adopted for C++, Java and other languages, but at the time the apparent overhead of returning extra bytes seemed unacceptable (I don\u2019t know of any comparisons between that and the overhead of exception-handling mechanisms, but I do know that the goal of C++ exception handling is to have zero execution overhead if no exceptions occur).</p> <p>Note that in the definition of <code>composed</code>, the type checker requires that you return <code>int | str</code> because <code>func_a</code> returns those types. Thus, when composing, type-safety is preserved. This means you won\u2019t lose error type information during composition, so composability automatically scales.</p>"},{"location":"12_Errors_as_Values/#creating-a-new-return-type","title":"Creating a New Return Type","text":"<p>We now have the unfortunate situation that <code>outputs</code> contains multiple types: both <code>int</code> and <code>str</code>. The solution is to create a new type that unifies the \"answer\" and \"error\" types. We\u2019ll call this <code>Result</code> and define it using generics to make it universally applicable:</p> <pre><code># result.py\n# Generic Result with Success &amp; Failure subtypes\n\nfrom dataclasses import dataclass\nfrom typing import Generic, TypeVar\n\nANSWER = TypeVar(\"ANSWER\")\nERROR = TypeVar(\"ERROR\")\n\n\nclass Result(Generic[ANSWER, ERROR]):\n    pass\n\n\n@dataclass(frozen=True)\nclass Success(Result[ANSWER, ERROR]):\n    answer: ANSWER  # Usage: return Success(answer)\n\n    def unwrap(self) -&gt; ANSWER:\n        return self.answer\n\n\n@dataclass(frozen=True)\nclass Failure(Result[ANSWER, ERROR]):\n    error: ERROR  # Usage: return Failure(error)\n</code></pre> <p>A <code>TypeVar</code> defines a generic parameter. We want <code>Result</code> to contain a type for an <code>ANSWER</code> when the function call is successful, and an <code>ERROR</code> to indicate how the function call failed. Each subtype of <code>Result</code> only holds one field: <code>answer</code> for a successful <code>Success</code> calculation, and <code>error</code> for a <code>Failure</code>. Thus, if a <code>Failure</code> is returned, the client programmer cannot simply reach in and grab the <code>answer</code> field because it doesn\u2019t exist. The client programmer is forced to properly analyze the <code>Result</code>.</p> <p>We could use a frozen <code>dataclass</code> instead of a <code>NamedTuple</code> here, but the latter is more concise.</p> <p>To use <code>Result</code>, you <code>return Success(answer)</code> when you\u2019ve successfully created an answer, and <code>return Failure(error)</code> to indicate a failure. <code>unwrap</code> is a convenience method which is only available for a <code>Success</code>.</p> <p>The modified version of the example using <code>Result</code> is now:</p> <pre><code># return_result.py\n# Result type returns Success/Failure\n# Using https://github.com/dry-python/returns\nfrom pprint import pprint\n\nfrom returns.result import Failure, Result, Success\n\n\ndef func_a(i: int) -&gt; Result[int, str]:\n    if i == 1:\n        return Failure(f\"func_a({i})\")\n    return Success(i)\n\n\npprint([(i, func_a(i)) for i in range(5)])\n## [(0, &lt;Success: 0&gt;),\n##  (1, &lt;Failure: func_a(1)&gt;),\n##  (2, &lt;Success: 2&gt;),\n##  (3, &lt;Success: 3&gt;),\n##  (4, &lt;Success: 4&gt;)]\n</code></pre> <p>Now <code>func_a</code> returns a single type, <code>Result</code>. The first type parameter to <code>Result</code> is the type returned by <code>Success</code> and the second type parameter is the type returned by <code>Failure</code>. The <code>outputs</code> from the comprehension are all of type <code>Result</code>, and we have preserved the successful calculations even though there is a failing call. We can also pattern-match on the outputs, and it is crystal-clear which match is for the success and which is for the failure.</p> <p>The <code>returns</code> library has been slipped in here, but its basic form is that of <code>result.py</code>.</p>"},{"location":"12_Errors_as_Values/#composing-with-result","title":"Composing with <code>Result</code>","text":"<p>The previous examples included very simple composition in the <code>composed</code> functions which just called a single other function. What if you need to compose a more complex function from multiple other functions? The <code>Result</code> type ensures that the <code>composed</code> function properly represents both the <code>Answer</code> type but also the various different errors that can occur:</p> <pre><code># composing_functions.py\nfrom pprint import pprint\n\nfrom return_result import func_a\n## [(0, &lt;Success: 0&gt;),\n##  (1, &lt;Failure: func_a(1)&gt;),\n##  (2, &lt;Success: 2&gt;),\n##  (3, &lt;Success: 3&gt;),\n##  (4, &lt;Success: 4&gt;)]\nfrom returns.result import Failure, Result, Success, safe\n\n\n# Use an exception as info (but don't raise it):\ndef func_b(i: int) -&gt; Result[int, ValueError]:\n    if i == 2:\n        return Failure(ValueError(f\"func_b({i})\"))\n    return Success(i)\n\n\n# Convert exception to Failure:\ndef func_c(i: int) -&gt; Result[int, ZeroDivisionError]:\n    try:\n        1 / (i - 3)\n    except ZeroDivisionError as e:\n        return Failure(ZeroDivisionError(f\"func_c({i}): {e}\"))\n    return Success(i)\n\n\n@safe  # Convert existing function\ndef func_d(i: int) -&gt; str:  # Result[str, ZeroDivisionError]\n    1 / i\n    return f\"func_d({i})\"\n\n\ndef composed(\n    i: int,\n) -&gt; Result[str, str | ValueError | ZeroDivisionError]:\n    result_a = func_a(i)\n    if isinstance(result_a, Failure):\n        return result_a\n\n    # unwrap() gets the answer from Success:\n    result_b = func_b(result_a.unwrap())\n    if isinstance(result_b, Failure):\n        return result_b\n\n    result_c = func_c(result_b.unwrap())\n    if isinstance(result_c, Failure):\n        return result_c\n\n    return func_d(result_c.unwrap())\n\n\npprint([(i, composed(i)) for i in range(5)])\n## [(0, &lt;Failure: division by zero&gt;),\n##  (1, &lt;Failure: func_a(1)&gt;),\n##  (2, &lt;Failure: func_b(2)&gt;),\n##  (3, &lt;Failure: func_c(3): division by zero&gt;),\n##  (4, &lt;Success: func_d(4)&gt;)]\n</code></pre> <p>The <code>a</code>, <code>b</code> and <code>c</code> functions each have argument values that are unacceptable. Notice that <code>b</code> and <code>c</code> both use built-in exception types as arguments to <code>Failure</code>, but those exceptions are never raised\u2014they are simply used to convey information, just like the <code>str</code> in <code>a</code>.</p> <p>In <code>composed</code>, we call <code>a</code>, <code>b</code> and <code>c</code> in sequence. After each call, we check to see if the result type is <code>Failure</code>. If so, the calculation has failed and we can\u2019t continue, so we return the current result, which is a <code>Failure</code> object containing the reason for the failure. If it succeeds, it is a <code>Success</code> which contains an <code>unwrap</code> method that is used to extract the answer from that calculation\u2014if you look back at <code>Result</code>, you\u2019ll see that it returns the <code>ANSWER</code> type so its use can be properly type-checked.</p> <p>This means that any failure during a sequence of composed function calls will short-circuit out of <code>composed</code>, returning a <code>Failure</code> that tells you exactly what happened, and that you must decide what to do with. You can\u2019t just ignore it and assume that it will \"bubble up\" until it finds an appropriate handler. You are forced to deal with it at the point of origin, which is typically when you know the most about an error.</p>"},{"location":"12_Errors_as_Values/#simplifying-composition-with-bind","title":"Simplifying Composition with <code>bind</code>","text":"<p>There\u2019s still a problem that impedes our ultimate goal of composability: every time you call a function within a composed function, you must write code to check the <code>Result</code> type and extract the <code>answer</code> with <code>unwrap</code>. This is extra repetitive work that interrupts the flow and readability of the program. We need some way to reduce or eliminate the extra code.</p> <p>Lets modify <code>Result</code> to add a new member function, <code>bind</code>:</p> <pre><code># result_with_bind.py\nfrom dataclasses import dataclass\nfrom typing import Callable, Generic, TypeVar\n\nANSWER = TypeVar(\"ANSWER\")\nERROR = TypeVar(\"ERROR\")\n\n\n@dataclass(frozen=True)\nclass Result(Generic[ANSWER, ERROR]):\n    def bind(self, func: Callable[[ANSWER], \"Result\"]) -&gt; \"Result[ANSWER, ERROR]\":\n        if isinstance(self, Success):\n            return func(self.unwrap())\n        return self  # Pass the Failure forward\n\n\n@dataclass(frozen=True)\nclass Success(Result[ANSWER, ERROR]):\n    answer: ANSWER\n\n    def unwrap(self) -&gt; ANSWER:\n        return self.answer\n\n\n@dataclass(frozen=True)\nclass Failure(Result[ANSWER, ERROR]):\n    error: ERROR\n</code></pre> <p><code>bind</code> removes the duplicated code:</p> <pre><code># composing_with_bind.py\nfrom pprint import pprint\n\nfrom composing_functions import func_a, func_b, func_c, func_d\n## [(0, &lt;Success: 0&gt;),\n##  (1, &lt;Failure: func_a(1)&gt;),\n##  (2, &lt;Success: 2&gt;),\n##  (3, &lt;Success: 3&gt;),\n##  (4, &lt;Success: 4&gt;)]\n## [(0, &lt;Failure: division by zero&gt;),\n##  (1, &lt;Failure: func_a(1)&gt;),\n##  (2, &lt;Failure: func_b(2)&gt;),\n##  (3, &lt;Failure: func_c(3): division by zero&gt;),\n##  (4, &lt;Success: func_d(4)&gt;)]\nfrom returns.result import Result\n\n\ndef composed(\n    i: int,\n) -&gt; Result[str, str | ZeroDivisionError | ValueError]:\n    # fmt: off\n    return (\n        func_a(i)\n        .bind(func_b)\n        .bind(func_c)\n        .bind(func_d)\n    )\n\n\npprint([(i, composed(i)) for i in range(5)])\n## [(0, &lt;Failure: division by zero&gt;),\n##  (1, &lt;Failure: func_a(1)&gt;),\n##  (2, &lt;Failure: func_b(2)&gt;),\n##  (3, &lt;Failure: func_c(3): division by zero&gt;),\n##  (4, &lt;Success: func_d(4)&gt;)]\n</code></pre> <p>In <code>composed</code>, we call <code>func_a(i)</code> which returns a <code>Result</code>. The <code>bind</code> method is called on that <code>Result</code>, passing it the next function we want to call (<code>func_b</code>) as an argument. The return value of <code>bind</code> is also a <code>Result</code>, so we can call <code>bind</code> again upon that <code>Result</code>, passing it the third function we want to call (<code>func_c</code>), and so on.</p> <p>At each \"chaining point\" in <code>func_a(i).bind(func_b).bind(func_c).bind(func_d)</code>, <code>bind</code> checks the <code>Result</code> type to see if it <code>Success</code>. If so, it passes the result <code>answer</code> from that call as the argument to the next function in the chain. If not, that means <code>self</code> is a <code>Failure</code> object (containing specific error information), so all it needs to do is <code>return self</code>. The next call in the chain sees that the returned type is <code>Failure</code>, so it doesn\u2019t try to apply the next function but just (again) returns the <code>Failure</code>. Once you produce a <code>Failure</code>, no more function calls occur (that is, it short-circuits) and the <code>Failure</code> result gets passed all the way out of the composed function so the caller can deal with that specific failure.</p>"},{"location":"12_Errors_as_Values/#handling-multiple-arguments","title":"Handling Multiple Arguments","text":"<p>We could continue adding features to our <code>Result</code> library until it becomes a complete solution. However, others have worked on this problem so it makes more sense to reuse their libraries. The most popular Python library that includes this extra functionality is Returns. <code>Returns</code> includes other features, but we will only focus on  <code>Result</code>.</p> <p>What if you need to create a <code>composed</code> function that takes multiple arguments? For this, we use something called \"do notation,\" which you access using <code>Result.do</code>:</p> <pre><code># multiple_arguments.py\nfrom pprint import pprint\n\nfrom composing_functions import func_a, func_b, func_c\n## [(0, &lt;Success: 0&gt;),\n##  (1, &lt;Failure: func_a(1)&gt;),\n##  (2, &lt;Success: 2&gt;),\n##  (3, &lt;Success: 3&gt;),\n##  (4, &lt;Success: 4&gt;)]\n## [(0, &lt;Failure: division by zero&gt;),\n##  (1, &lt;Failure: func_a(1)&gt;),\n##  (2, &lt;Failure: func_b(2)&gt;),\n##  (3, &lt;Failure: func_c(3): division by zero&gt;),\n##  (4, &lt;Success: func_d(4)&gt;)]\nfrom returns.result import Result\n\n\ndef add(first: int, second: int, third: int) -&gt; str:\n    return f\"add({first} + {second} + {third}):\" f\" {first + second + third}\"\n\n\ndef composed(i: int, j: int) -&gt; Result[str, str | ZeroDivisionError | ValueError]:\n    # fmt: off\n    return Result.do(\n        add(first, second, third)\n        for first in func_a(i)\n        for second in func_b(j)\n        for third in func_c(i + j)\n    )\n\n\ninputs = [(1, 5), (7, 2), (2, 1), (7, 5)]\npprint([(args, composed(*args)) for args in inputs])\n## [((1, 5), &lt;Failure: func_a(1)&gt;),\n##  ((7, 2), &lt;Failure: func_b(2)&gt;),\n##  ((2, 1), &lt;Failure: func_c(3): division by\n## zero&gt;),\n##  ((7, 5), &lt;Success: add(7 + 5 + 12): 24&gt;)]\n</code></pre> <p><code>Returns</code> provides a <code>@safe</code> decorator that you see applied to the \"plain\" function <code>func_b</code>. This changes the normal <code>int</code> return type into a <code>Result</code> that includes <code>int</code> for the <code>Success</code> type but is also somehow able to recognize that the division might produce a <code>ZeroDivisionError</code> and include that in the <code>Failure</code> type. In addition, <code>@safe</code> is apparently catching the exception and converting it to the <code>ZeroDivisionError</code> returned as the information object in the <code>Failure</code> object. <code>@safe</code> is a helpful tool when converting exception-throwing code into error-returning code.</p> <p><code>func_c</code> adds some variety by rejecting <code>-1</code> and producing a <code>str</code> result. We can now produce <code>composed</code> using a <code>pipe</code> and <code>bind</code>. All the previous error-checking and short-circuiting behaviors happen as before, but the syntax is now more straightforward and readable.</p> <p>Notice that when the <code>outputs</code> list is created, the output from <code>reject0</code> only happens for the values <code>-1</code> and <code>2</code>, because the other values cause errors in the <code>composed</code> chain of operations. The value <code>1</code> never gets to <code>func_b</code> because it is intercepted by the prior <code>composed</code> call to <code>func_a</code>. The value <code>0</code> causes <code>func_b</code> to produce a <code>ZeroDivisionError</code> when it tries to perform the division inside the <code>print</code>.</p> <p>[Explain rest of example]</p> <p>Note that there may be an issue with the <code>Returns</code> library, which is that for proper type checking it requires using a MyPy extension. So far I have been unable to get that extension to work (however, I have no experience with MyPy extensions).</p>"},{"location":"12_Errors_as_Values/#functional-error-handling-is-happening","title":"Functional Error Handling is Happening","text":"<p>Functional error handling has already appeared in languages like Rust, Kotlin, and recent versions of C++ support these combined answer-error result types, with associated unpacking operations. In these languages, errors become part of the type system and it is far more difficult for an error to \"slip through the cracks.\"</p> <p>Python has only been able to support functional error handling since the advent of typing and type checkers, and it doesn\u2019t provide any direct language or library constructs for this. The benefits of better error handling and robust composability make it worth adopting a library like <code>Results</code>.</p>"},{"location":"13_Uncategorized_Topics/","title":"Uncategorized Topics","text":"<p>These need to appear somewhere...</p>"},{"location":"13_Uncategorized_Topics/#annotated-for-metadata","title":"<code>Annotated</code> for Metadata","text":"<p>Demonstration using Cyclopts</p> <p><code>Annotated</code> provides metadata for types, useful in documentation, validation, or frameworks:</p> <pre><code># example_2.py\nfrom typing import Annotated\n\nUserID = Annotated[int, \"Database primary key\"]\n\n\ndef fetch_user(user_id: UserID) -&gt; dict:\n    return {\"id\": user_id, \"name\": \"Alice\"}\n</code></pre> <p>Metadata within <code>Annotated</code> helps convey additional context beyond simple type hints.</p>"},{"location":"13_Uncategorized_Topics/#type-narrowing","title":"Type Narrowing","text":"<p>Perhaps a short chapter?</p> <p>Type narrowing refines a variable's type within conditional checks:</p>"},{"location":"13_Uncategorized_Topics/#using-isinstance","title":"Using <code>isinstance</code>","text":"<pre><code># example_4.py\nfrom typing import Union\n\n\ndef process(value: Union[int, str]) -&gt; None:\n    if isinstance(value, int):\n        print(value + 1)\n    else:\n        print(value.upper())\n</code></pre>"},{"location":"13_Uncategorized_Topics/#using-assertions","title":"Using assertions","text":"<pre><code># example_5.py\nfrom typing import Optional\n\n\ndef greet(name: Optional[str]) -&gt; None:\n    assert name is not None, \"Name cannot be None\"\n    print(f\"Hello, {name}\")\n</code></pre> <p>Type narrowing helps write precise, safe, and understandable code.</p>"},{"location":"13_Uncategorized_Topics/#type-guards-isinstance-custom-type-guards-assertions","title":"Type Guards (<code>isinstance</code>, custom type guards, assertions)","text":"<p>Custom type guards offer explicit ways to narrow types more clearly:</p>"},{"location":"13_Uncategorized_Topics/#custom-type-guard-functions-python-310","title":"Custom type guard functions (Python 3.10+)","text":"<pre><code># example_6.py\nfrom typing import TypeGuard\n\n\nclass Cat:\n    def meow(self):\n        print(\"Meow!\")\n\n\ndef is_cat(animal: object) -&gt; TypeGuard[Cat]:\n    return hasattr(animal, \"meow\")\n\n\nanimal = Cat()\nif is_cat(animal):\n    animal.meow()  # Safe to call\n## Meow!\n</code></pre> <p>Type guards enhance type narrowing accuracy, making code safer and cleaner.</p>"},{"location":"A01_Annotation_Reference/","title":"Annotation Reference","text":"Annotation Description Example <code>int</code>, <code>str</code>, <code>float</code>, <code>bool</code> Basic built-in types <code>age: int = 25</code> <code>List[T]</code>, <code>list[T]</code> List containing items of type <code>T</code> <code>scores: list[int]</code> <code>Tuple[T, ...]</code>, <code>tuple[T, ...]</code> Tuple with specified item types <code>coords: tuple[float, float]</code> <code>Dict[K, V]</code>, <code>dict[K, V]</code> Dictionary with keys <code>K</code>, values <code>V</code> <code>user_data: dict[str, int]</code> <code>Set[T]</code>, <code>set[T]</code> Set containing items of type <code>T</code> <code>tags: set[str]</code> <code>Optional[T]</code> Type <code>T</code> or <code>None</code> <code>name: Optional[str]</code> <code>Union[T1, T2]</code> or <code>T1</code> | <code>T2</code> Either type <code>T1</code> or <code>T2</code> <code>value: int</code> | <code>str</code> <code>Callable[[Args], ReturnType]</code> Function types <code>adder: Callable[[int, int], int]</code> <code>Literal[\"value\"]</code> Specific literal values <code>mode: Literal[\"auto\", \"manual\"]</code> <code>Annotated[T, metadata]</code> Type <code>T</code> with additional metadata <code>UserID = Annotated[int, \"primary key\"]</code> <code>NewType('Name', T)</code> New distinct type based on type <code>T</code> <code>UserId = NewType('UserId', int)</code> <code>Protocol</code> Structural typing protocol <code>class Speaker(Protocol): ...</code>"},{"location":"A02_Glossary/","title":"Glossary","text":"<p>[[Add links to introductions in book]]</p> Term Definition Annotation Explicit type declaration for variables, functions, or classes. Duck Typing Determining an object's suitability based on presence of methods/attributes Generics Type annotations parameterized by type variables. Literal Types Types representing specific literal values. Protocol Interface defined by structural compatibility, rather than explicit inheritance. Stub Files Files (<code>.pyi</code>) containing type annotations without implementations. Type Alias Simplified or descriptive alias for complex type annotations. Type Checking Verification of type consistency either statically or at runtime. Type Narrowing Refining variable types within specific control-flow branches. Variance Rules describing subtype relationships between generic types (covariant, contravariant). Static Typing Types checked before execution (compile-time). Dynamic Typing Types determined and checked during execution (runtime). Covariance Generic type that accepts subtypes as substitutes for its type parameter. Contravariance Generic type that accepts supertypes as substitutes for its type parameter. Invariant Generic type that requires exact type matches for its type parameters."},{"location":"A03_Guidelines/","title":"Guidelines","text":"<p>[[Needs lots of work]]</p> <p>This placeholder text was generated by ChatGPT 4.5. It will be significantly rewritten as the book is developed. In the meantime you can add comments to either https://bsky.app/bruceeckel or Github Issues.</p>"},{"location":"A03_Guidelines/#effective-patterns-for-clear-and-maintainable-annotations","title":"Effective Patterns for Clear and Maintainable Annotations","text":"<p>Clear type annotations significantly improve code quality and maintainability:</p>"},{"location":"A03_Guidelines/#consistent-type-annotation-style","title":"Consistent Type Annotation Style","text":"<ul> <li>Standardize type annotations across your project.</li> <li>Clearly annotate function signatures, class attributes, and return types.</li> </ul> <pre><code># example_1.py\ndef calculate_area(width: float, height: float) -&gt; float:\n    return width * height\n</code></pre>"},{"location":"A03_Guidelines/#use-type-aliases-for-complex-types","title":"Use Type Aliases for Complex Types","text":"<p>Simplify repetitive or complex annotations:</p> <pre><code># example_2.py\nfrom typing import Dict, List\n\nUserData = Dict[str, List[int]]\n\n\ndef process_data(data: UserData) -&gt; None:\n    pass\n</code></pre> <p>Type aliases enhance readability, making complex types easier to understand.</p>"},{"location":"A03_Guidelines/#leverage-dataclasses-and-typeddicts","title":"Leverage Dataclasses and TypedDicts","text":"<ul> <li>Dataclasses simplify structured data definitions.</li> <li>TypedDicts clarify expected dictionary structures.</li> </ul> <pre><code># example_3.py\nfrom dataclasses import dataclass\n\n\n@dataclass\nclass User:\n    id: int\n    name: str\n</code></pre> <p>These patterns improve explicitness and reduce boilerplate code.</p>"},{"location":"A03_Guidelines/#common-pitfalls-and-how-to-avoid-them","title":"Common Pitfalls and How to Avoid Them","text":""},{"location":"A03_Guidelines/#overusing-any","title":"Overusing <code>Any</code>","text":"<p>Overuse of <code>Any</code> defeats the purpose of type annotations:</p> <ul> <li>Pitfall:</li> </ul> <pre><code># example_4.py\nfrom typing import Any\n\n\ndef process(data: Any) -&gt; Any:\n    pass\n</code></pre> <ul> <li>Solution:   Provide specific type annotations whenever possible.</li> </ul>"},{"location":"A03_Guidelines/#missing-or-inconsistent-annotations","title":"Missing or Inconsistent Annotations","text":"<p>Incomplete annotations lead to confusion:</p> <ul> <li>Always annotate public APIs clearly.</li> <li>Regularly review annotations during code reviews.</li> </ul>"},{"location":"A03_Guidelines/#complex-union-types","title":"Complex Union Types","text":"<p>Avoid overly complex union types:</p> <ul> <li>Pitfall:</li> </ul> <pre><code># example_5.py\nfrom typing import Union\n\n\ndef handle(value: Union[int, str, None, float]) -&gt; None:\n    pass\n</code></pre> <ul> <li>Solution:   Refactor to simplify or use custom types.</li> </ul>"},{"location":"A03_Guidelines/#balancing-simplicity-readability-and-explicitness","title":"Balancing Simplicity, Readability, and Explicitness","text":""},{"location":"A03_Guidelines/#simplicity","title":"Simplicity","text":"<ul> <li>Aim for the simplest annotation that accurately represents the type.</li> </ul>"},{"location":"A03_Guidelines/#readability","title":"Readability","text":"<ul> <li>Ensure annotations improve, rather than obscure, readability.</li> </ul>"},{"location":"A03_Guidelines/#explicitness","title":"Explicitness","text":"<ul> <li>Favor explicit annotations that clarify intent, especially at API boundaries.</li> </ul> <p>Striking the right balance ensures maintainable and understandable code.</p>"},{"location":"A03_Guidelines/#strategies-for-large-scale-typed-codebases","title":"Strategies for Large-Scale Typed Codebases","text":"<p>Managing large-scale typed codebases requires strategic approaches:</p>"},{"location":"A03_Guidelines/#incremental-adoption","title":"Incremental Adoption","text":"<ul> <li>Gradually introduce type annotations to existing codebases.</li> <li>Prioritize critical and frequently changed components.</li> </ul>"},{"location":"A03_Guidelines/#automate-type-checking","title":"Automate Type Checking","text":"<ul> <li>Integrate tools like <code>mypy</code> and <code>pyright</code> into CI/CD.</li> <li>Regularly enforce type checking to maintain standards.</li> </ul>"},{"location":"A03_Guidelines/#continuous-review-and-improvement","title":"Continuous Review and Improvement","text":"<ul> <li>Regularly review annotations during code reviews.</li> <li>Address inconsistencies and improve clarity over time.</li> </ul>"},{"location":"A03_Guidelines/#comprehensive-documentation","title":"Comprehensive Documentation","text":"<ul> <li>Document type annotation standards and best practices.</li> <li>Ensure all team members follow consistent annotation strategies.</li> </ul> <p>Implementing these strategies helps sustain clarity, maintainability, and robustness in large, typed Python projects.</p>"},{"location":"A04_Type_Checkers/","title":"Type Checkers","text":"<p>This placeholder text was generated by ChatGPT 4.5. It will be significantly rewritten as the book is developed. In the meantime you can add comments to either https://bsky.app/bruceeckel or Github Issues.</p>"},{"location":"A04_Type_Checkers/#getting-started-with-mypy-installation-and-basic-use","title":"Getting Started with <code>mypy</code>: Installation and Basic Use","text":"<p><code>mypy</code> is a popular static type checker for Python that validates type annotations:</p>"},{"location":"A04_Type_Checkers/#installation","title":"Installation","text":"<pre><code>pip install mypy\n</code></pre>"},{"location":"A04_Type_Checkers/#basic-use","title":"Basic Use","text":"<p>Run <code>mypy</code> on your script or module to identify type errors:</p> <pre><code>mypy your_script.py\n</code></pre> <p>Example:</p> <pre><code># script.py\n\ndef greet(name: str) -&gt; str:\n    print(f\"Hello, {name}!\")\n\ngreet(123)  # Incorrect type\n## Hello, 123!\n</code></pre> <p>Running <code>mypy script.py</code> outputs:</p> <pre><code>script.py:4: error: Argument 1 to \"greet\" has incompatible type \"int\"; expected \"str\"\n</code></pre>"},{"location":"A04_Type_Checkers/#advanced-configuration-and-fine-tuning-of-mypy","title":"Advanced Configuration and Fine-tuning of <code>mypy</code>","text":"<p>Customize <code>mypy</code> behavior using a <code>mypy.ini</code> or <code>pyproject.toml</code> file:</p>"},{"location":"A04_Type_Checkers/#example-mypyini","title":"Example <code>mypy.ini</code>","text":"<pre><code>[mypy]\nignore_missing_imports = True\nstrict = True\ncheck_untyped_defs = True\n</code></pre>"},{"location":"A04_Type_Checkers/#example-pyprojecttoml","title":"Example <code>pyproject.toml</code>","text":"<pre><code>[tool.mypy]\nignore_missing_imports = true\nstrict = true\n</code></pre> <p>Advanced configuration allows precise control over type-checking behavior and strictness levels.</p>"},{"location":"A04_Type_Checkers/#exploring-pyright-and-ide-integration-vscode-pycharm","title":"Exploring <code>pyright</code> and IDE Integration (VSCode, PyCharm)","text":"<p><code>pyright</code>, developed by Microsoft, offers high-performance static type checking, integrated seamlessly with popular IDEs.</p>"},{"location":"A04_Type_Checkers/#using-pyright-cli","title":"Using <code>pyright</code> (CLI)","text":"<p>Install globally using npm:</p> <pre><code>npm install -g pyright\npyright your_script.py\n</code></pre>"},{"location":"A04_Type_Checkers/#vscode-integration","title":"VSCode Integration","text":"<p><code>pyright</code> powers VSCode's built-in Python type checking, providing immediate feedback:</p> <ul> <li>Install the Python extension in VSCode.</li> <li>Real-time inline error highlighting and suggestions.</li> </ul>"},{"location":"A04_Type_Checkers/#pycharm-integration","title":"PyCharm Integration","text":"<p>PyCharm supports built-in type checking:</p> <ul> <li>Provides live error detection, highlighting, and quick-fix suggestions.</li> <li>Navigate to <code>Preferences &gt; Editor &gt; Inspections</code> to configure type-checking rules.</li> </ul>"},{"location":"A04_Type_Checkers/#incremental-typing-strategies-gradual-adoption","title":"Incremental Typing Strategies: Gradual Adoption","text":"<p>Adopt typing gradually, focusing first on critical paths:</p> <ul> <li>Annotate high-risk or frequently changing modules first.</li> <li>Enable type checking incrementally to avoid overwhelming your team:</li> </ul> <pre><code>[mypy]\nfiles = core/, utils/\n</code></pre> <p>Incremental typing balances immediate benefits with manageable adoption efforts.</p>"},{"location":"A04_Type_Checkers/#integrating-type-checking-into-continuous-integration","title":"Integrating Type Checking into Continuous Integration","text":"<p>Automate type checking within your CI/CD pipeline to enforce consistency and catch errors early:</p>"},{"location":"A04_Type_Checkers/#example-github-actions-workflow","title":"Example GitHub Actions Workflow","text":"<pre><code>name: Type Check\n\non: [push, pull_request]\n\njobs:\n  type-check:\n    runs-on: ubuntu-latest\n\n    steps:\n      - uses: actions/checkout@v3\n      - uses: actions/setup-python@v3\n        with:\n          python-version: '3.11'\n\n      - run: pip install mypy\n      - run: mypy .\n</code></pre> <p>Automated checks ensure ongoing compliance with typing standards and maintain high code quality.</p>"},{"location":"A04_Type_Checkers/#handling-and-resolving-common-errors","title":"Handling and Resolving Common Errors","text":"<p>Common type-checking errors and their resolutions:</p>"},{"location":"A04_Type_Checkers/#incorrect-type-annotation","title":"Incorrect Type Annotation","text":"<pre><code># example_2.py\n# Error: Incompatible types in assignment (expression has type \"int\", variable has type \"str\")\nname: str = 123  # fix: name = \"Alice\"\n</code></pre>"},{"location":"A04_Type_Checkers/#missing-imports","title":"Missing Imports","text":"<p>Use <code>ignore_missing_imports</code> or install type stubs:</p> <pre><code>[mypy]\nignore_missing_imports = True\n</code></pre> <p>Or install stubs:</p> <pre><code>pip install types-requests\n</code></pre>"},{"location":"A04_Type_Checkers/#union-and-optional-errors","title":"Union and Optional Errors","text":"<p>Resolve ambiguity clearly:</p> <pre><code># example_3.py\nfrom typing import Optional\n\n\n# Error: Incompatible return value type (got \"None\", expected \"int\")\ndef find_index(item: str, items: list[str]) -&gt; Optional[int]:\n    try:\n        return items.index(item)\n    except ValueError:\n        return None\n</code></pre> <p>Effectively handling and resolving these errors leads to clearer, more reliable, and maintainable codebases.</p>"},{"location":"A05_Automatic_Annotations/","title":"Automatic Annotations","text":"<p>[[Too specific to mypy -- should cover other tools]]</p> <p>This placeholder text was generated by ChatGPT 4.5. It will be significantly rewritten as the book is developed. In the meantime you can add comments to either https://bsky.app/bruceeckel or Github Issues.</p>"},{"location":"A05_Automatic_Annotations/#introduction-to-pyi-stub-files","title":"Introduction to <code>.pyi</code> Stub Files","text":"<p><code>.pyi</code> stub files provide type annotations for Python modules, especially useful when source code lacks annotations or is unavailable:</p> <ul> <li>Contains type definitions without actual implementations.</li> <li>Enables static type checking for third-party libraries.</li> </ul> <p>Example:</p> <pre><code># math.pyi\ndef sqrt(x: float) -&gt; float: ...\n</code></pre> <p>Stub files clearly document expected types, significantly improving interoperability.</p>"},{"location":"A05_Automatic_Annotations/#generating-stubs-automatically-with-stubgen","title":"Generating Stubs Automatically with <code>stubgen</code>","text":"<p><code>stubgen</code> is a tool included with <code>mypy</code> to automatically generate stub files from existing Python code:</p>"},{"location":"A05_Automatic_Annotations/#installation-and-basic-use","title":"Installation and Basic Use","text":"<pre><code>pip install mypy\nstubgen -m your_module\n</code></pre> <p>Generates a <code>.pyi</code> file with inferred annotations, saving manual effort:</p> <pre><code># generated_example.pyi\ndef greet(name: str) -&gt; str: ...\n</code></pre> <p>Auto-generated stubs provide a starting point for type annotations.</p>"},{"location":"A05_Automatic_Annotations/#writing-effective-stubs-manually","title":"Writing Effective Stubs Manually","text":"<p>Manual stub writing is essential when automatic inference is insufficient:</p>"},{"location":"A05_Automatic_Annotations/#example-stub-file","title":"Example Stub File","text":"<pre><code># custom_module.pyi\nclass User:\n    id: int\n    name: str\n\n\ndef fetch_user(user_id: int) -&gt; User: ...\n</code></pre>"},{"location":"A05_Automatic_Annotations/#best-practices","title":"Best Practices","text":"<ul> <li>Clearly annotate arguments and return types.</li> <li>Use ellipsis (<code>...</code>) to indicate stub implementation.</li> <li>Reflect original module's behavior accurately.</li> </ul> <p>Manual stub files enhance readability and ensure accurate type definitions.</p>"},{"location":"A05_Automatic_Annotations/#distributing-and-versioning-typing-stubs","title":"Distributing and Versioning Typing Stubs","text":"<p>Typing stubs can be distributed independently or alongside the original package:</p>"},{"location":"A05_Automatic_Annotations/#bundled-with-package","title":"Bundled with Package","text":"<p>Include stubs directly in your package:</p> <pre><code>your_package/\n\u251c\u2500\u2500 __init__.py\n\u2514\u2500\u2500 __init__.pyi\n</code></pre>"},{"location":"A05_Automatic_Annotations/#separate-distribution","title":"Separate Distribution","text":"<p>Publish stubs as standalone packages:</p> <pre><code>pip install types-requests\n</code></pre> <p>Use semantic versioning aligned with the original package for clarity and compatibility:</p> <pre><code>types-requests==2.25.1\n</code></pre> <p>Effective versioning ensures seamless integration and updates.</p>"},{"location":"A05_Automatic_Annotations/#typing-third-party-libraries-without-native-annotations","title":"Typing Third-party Libraries without Native Annotations","text":"<p>When third-party libraries lack native annotations:</p>"},{"location":"A05_Automatic_Annotations/#use-third-party-typing-packages","title":"Use Third-party Typing Packages","text":"<p>Install existing typing packages from PyPI:</p> <pre><code>pip install types-requests\n</code></pre>"},{"location":"A05_Automatic_Annotations/#custom-stubs","title":"Custom Stubs","text":"<p>Write custom stub files within your project:</p> <pre><code>stubs/\n\u251c\u2500\u2500 requests.pyi\n</code></pre>"},{"location":"A05_Automatic_Annotations/#ignoring-missing-annotations","title":"Ignoring Missing Annotations","text":"<p>Temporarily ignore missing annotations with <code>mypy</code> configuration:</p> <pre><code>[mypy-requests]\nignore_missing_imports = True\n</code></pre> <p>Using stubs significantly improves type checking for libraries without built-in annotations, maintaining robust and reliable codebases.</p>"},{"location":"A06_Class_Attributes/","title":"Class Attributes","text":"<p>A number of type tools use a syntax that hacks class attribute syntax; the most obvious is dataclasses but there are others. It's important to understand that this is special behavior created by the tool, and that ordinary classes do not behave this way.</p> <p>While contributing to an open-source project, I was stopped short by this (names have been changed):</p> <pre><code># data_point.py\nclass DataPoint:\n    measurement1 = None\n    measurement2 = None\n    measurement3 = None\n\n\nd = DataPoint()\nd.measurement1 = 100\nd.measurement2 = 200\nd.measurement3 = 300\n</code></pre> <p>Why give names and initialization values to <code>class</code> attributes, then when you make an object, immediately create and initialize instance variables with the same names as the class attributes? I began to suspect a misunderstanding about class attributes.</p> <p>I asked one of the coaches of the project (not the original author). They explained that this was the way you provide default values for Python objects. When I attempted to disagree, the effects were demonstrated using a debugger. The argument looked something like this:</p> <pre><code># like_default_values.py\n\n\nclass A:\n    x: int = 100\n\n\na = A()\nprint(f\"{a.x = }\")\n## a.x = 100\na.x = -1\nprint(f\"{a.x = }\")\n## a.x = -1\na2 = A()\nprint(f\"{a2.x = }\")\n## a2.x = 100\n</code></pre> <p>(<code>f\"{a.x = }\"</code> is an f-string feature that eliminates the redundancy of displaying a variable.)</p> <p>Sure enough, if I create an <code>A</code> object called <code>a</code> and ask for <code>a.x</code>, it looks like <code>x</code> has the \"default value\" of <code>100</code>. I can set <code>a.x</code> to <code>-1</code> and create a second <code>A</code> object <code>a2</code> which once again is given the \"default value\" of 100---separate storage appears to have been created and initialized for the <code>x</code> in both <code>a</code> and <code>a2</code>. Based on this simple example, Python class attributes seem to produce default value behavior.</p>"},{"location":"A06_Class_Attributes/#where-did-this-idea-come-from","title":"Where Did This Idea Come From?","text":"<p>Because of the way class attributes are defined, someone coming from either C++ or Java might assume they work the same as in C++ or Java: Storage for those variables is allocated and initialized before the constructor[^1] is called. Indeed, the first time I saw class attributes used for automated constructor generation (a trick we shall visit later in this article), I wondered if I had previously missed something magical about class attributes.</p> <p>Here's a Java example exploring the same ideas:</p> <pre><code>// DefaultValues.java\n// Java automatically initializes from defaults\n\nclass A {\n  int x = 100;\n  public A() {\n    // x is already initialized:\n    System.out.println(\"In A constructor: \" + this);\n  }\n  @Override\n  public String toString() {\n    return \"x = \" + x;\n  }\n}\n\nclass B {\n  static int x = 100;\n  @Override\n  public String toString() {\n    // Accessing static via instance:\n    return \"x = \" + x;\n    // Same as \"x = \" + this.x;\n  }\n  static public String statics() {\n    return \"B.statics(): B.x = \" + B.x;\n  }\n  // Cannot shadow identifier names:\n  // int x = -1;\n  // Variable 'x' is already defined in the scope\n}\n\npublic class DefaultValues {\n  public static void main(String[] args) {\n    A a = new A();\n    // In A constructor: x = 100\n    System.out.println(\"a: \" + a);\n    // a: x = 100\n    a.x = -1;\n    System.out.println(\"a: \" + a);\n    // a: x = -1\n    System.out.println(\"new A(): \" + new A());\n    // In A constructor: x = 100\n    // new A(): x = 100\n\n    B b = new B();\n    System.out.println(\"b: \" + b);\n    // b: x = 100\n    System.out.println(B.statics());\n    // B.statics(): B.x = 100\n    // Accessing static via class:\n    B.x = -1;\n    System.out.println(\"b: \" + b);\n    // b: x = -1\n    System.out.println(B.statics());\n    // B.statics(): B.x = -1\n    B b2 = new B();\n    System.out.println(\"b2: \" + b2);\n    // b2: x = -1\n  }\n}\n</code></pre> <p>Inside the constructor <code>A()</code>, the storage for <code>x</code> has already been allocated and initialized. Changing the value of <code>a.x</code> doesn't influence further new <code>A</code> objects, which are initialized to <code>100</code>.</p> <p>In <code>class B</code>, <code>x</code> is changed to a <code>static</code> variable. This means there is only a single piece of <code>x</code> storage for the class---no matter how many instances of that class you create. This is how Python class attributes work: they are <code>static</code> variables without using the <code>static</code> keyword.</p> <p>In <code>B</code>'s <code>toString()</code>, notice that <code>B</code>'s <code>x</code> is accessed the same way it is in <code>Class A</code>'s <code>toString()</code>: as if it were an ordinary object field rather than a <code>static</code> field. When you do this, Java automatically uses the <code>static</code> <code>x</code> even though you are syntactically treating it like the object's <code>x</code>.</p> <p>In <code>statics()</code>, <code>x</code> is accessed through the class by saying <code>B.x</code>. If <code>x</code> were not a <code>static</code> you couldn't do this.</p> <p>At the end of <code>class B</code>, notice that we cannot \"shadow\" an identifier name like we can in Python: we cannot have both an ordinary and a <code>static</code> variable of the same name. <code>main()</code> demonstrates that the <code>static x</code> in <code>B</code> is indeed associated with the class, and there's only one piece of storage shared by all objects of <code>class B</code>.</p> <p>C++ has virtually identical behavior, although <code>static</code> initialization syntax is different for variables:</p> <pre><code>// default_values.cpp\n// C++ automatically initializes from defaults\n// Tested on http://cpp.sh\n#include &lt;iostream&gt;\n\nclass A {\n    public:\n    int x = 100;\n    A() { // x is already initialized:\n        std::cout &lt;&lt; \"constructor: \" &lt;&lt; x &lt;&lt; std::endl;\n    }\n};\n\nclass B {\n    public:\n    static int x;\n    B() { // x has been initialized:\n        std::cout &lt;&lt; \"constructor: \" &lt;&lt; x &lt;&lt; std::endl;\n    }\n    // Cannot shadow identifier name:\n    // int x = 1;\n    // 'int B::x' conflicts with a previous declaration\n};\n\n// Static variables must be initialized outside the class:\nint B::x = 100;\n\n// Static consts are initialized inline:\nclass C {\n    public:\n    static const int x = 100;\n};\n\nint main() {\n    A a;\n    // constructor: 100\n    std::cout &lt;&lt; a.x &lt;&lt; std::endl;\n    // 100\n    a.x = -1;\n    std::cout &lt;&lt; a.x &lt;&lt; std::endl;\n    // -1\n\n    B b;\n    // constructor: 100\n    std::cout &lt;&lt; b.x &lt;&lt; std::endl;\n    // 100\n    // Accessing static via instance:\n    b.x = -1;\n    std::cout &lt;&lt; b.x &lt;&lt; std::endl;\n    // -1\n    // Accessing static via class:\n    B::x = -99;\n    std::cout &lt;&lt; b.x &lt;&lt; std::endl;\n    // -99\n\n    C c;\n    std::cout &lt;&lt; c.x &lt;&lt; std::endl;\n    // 100\n    // Cannot assign to const:\n    // c.x = -1;\n}\n</code></pre> <p>Just like Java, storage is allocated and initialized for <code>x</code> by the time the <code>A()</code> constructor is called.</p> <p>In <code>class B</code>, the <code>static int x</code> definition only indicates that <code>x</code> exists for <code>B</code>. To allocate and initialize static variable storage, the external definition <code>int B::x = 100</code> is required. If, however, the <code>static</code> is <code>const</code>, the initialization value is included in the definition as seen in <code>class C</code>. The compiler is able to inline <code>const</code> values where they are used, so no storage is required.</p> <p>In <code>class B</code>, you see that, like Java, C++ also disallows name shadowing. <code>main()</code> shows that <code>static x</code> can be accessed either through the class or using an instance of the class.</p> <p>Notice that both Java and C++ have explicit <code>static</code> keywords, whereas Python does not. This adds to the confusion, so when a Java or C++ programmer (who has not learned about class attributes) sees something of the form:</p> <pre><code># no_static_keyword.py\nclass X:\n    a = 1\n    b = 2\n    c = 3\n</code></pre> <p>It is quite reasonable to expect the same results as from similar-looking C++ or Java code. After doing a few simple experiments as in <code>like_default_values.py</code>, a C++ or Java programmer might well conclude that Python does indeed work that way. And, because a class attribute is a single variable that is \"global to the class,\" it can be mistaken for a default value.</p>"},{"location":"A06_Class_Attributes/#how-things-break","title":"How Things Break","text":"<p>The worst thing about this is that code written with the assumption that class attributes are just default initialization values seems to work most of the time for simple situations like the one I encountered. The code passes its tests, so how can I call it \"wrong?\"</p> <p>The problem occurs when you're least expecting it. Here is just one configuration that produces a surprise:</p> <pre><code># it_all_goes_wrong.py\n\n\nclass A:\n    x: int = 100\n    y: int = 200\n\n    @classmethod\n    def change_x(cls):\n        cls.x = 999\n\n    @classmethod\n    def change_y(cls):\n        cls.y = 313\n\n\ndef reset():\n    A.x = 100\n    A.y = 200\n\n\na1: A = None\na2: A = None\na3: A = None\n\n\ndef display(counter: int):\n    print(f\"display({counter})\")\n    if a1:\n        print(f\"{a1.x = }, {a1.y = }\")\n    if a2:\n        print(f\"{a2.x = }, {a2.y = }\")\n    if a3:\n        print(f\"{a3.x = }, {a3.y = }\")\n\n\na1 = A()\ndisplay(1)\n## display(1)\n## a1.x = 100, a1.y = 200\na1.x = -1\na1.y = -2\ndisplay(2)\n## display(2)\n## a1.x = -1, a1.y = -2\na1.change_x()\ndisplay(3)\n## display(3)\n## a1.x = -1, a1.y = -2\na2 = A()\ndisplay(4)\n## display(4)\n## a1.x = -1, a1.y = -2\n## a2.x = 999, a2.y = 200\na2.y = 17\ndisplay(5)\n## display(5)\n## a1.x = -1, a1.y = -2\n## a2.x = 999, a2.y = 17\nA.change_y()\na3 = A()\ndisplay(6)\n## display(6)\n## a1.x = -1, a1.y = -2\n## a2.x = 999, a2.y = 17\n## a3.x = 999, a3.y = 313\nreset()\ndisplay(7)\n## display(7)\n## a1.x = -1, a1.y = -2\n## a2.x = 100, a2.y = 17\n## a3.x = 100, a3.y = 200\n</code></pre> <p>Every object instance has its own dictionary. When you assign to an instance variable, you add a binding to the instance dictionary. But a class definition creates a (class) object, which also has its own dictionary. When you define a class attribute, you add a binding to the class dictionary.</p> <p>When Python looks up an attribute, it (generally) starts at the instance and if it doesn't find the attribute there, falls back to looking it up in the associated class/type dictionary (the same way that C++ and Java do).</p> <p><code>class A</code> contains two class attributes. <code>change_x()</code> and <code>change_y()</code> are \"class methods,\" which mean they operate on the class object, and not a particular instance of that class. The first parameter of a <code>classmethod</code> is thus not <code>self</code> (the instance reference) but instead <code>cls</code> (the class reference). <code>change_x()</code> and <code>change_y()</code> modify the class attributes, and <code>reset()</code> sets both class attributes back to their original values.</p> <p>The main code starts by creating three <code>A</code> references initialized to <code>None</code>, and a <code>display()</code> function that shows the <code>x</code> and <code>y</code> values for each non-<code>None</code> object.</p> <p>Everything looks like it exhibits \"default value\" behavior until we call <code>change_x()</code> and <code>change_y()</code>, then things get strange. The original <code>a1</code> produces the same results as before, but <code>a2</code> is partially affected (<code>x</code> changes but not <code>y</code>) and the new <code>a3</code> has different \"default values.\" Calling <code>reset()</code> modifies <code>a2</code> (partially) and <code>a3</code> (completely), but not <code>a1</code>.</p> <p><code>reset()</code> changes objects it has no direct connection with. The changes themselves are inconsistent across the different objects. Imagine these kinds of errors appearing in your code base, and trying to track them down based on the varying behavior of these so-called \"default values.\"</p>"},{"location":"A06_Class_Attributes/#class-attributes_1","title":"Class Attributes","text":"<p>The source of confusion is twofold:</p> <ol> <li> <p>Python's dynamic nature. Instance variables are not automatically created,    not even in the constructor. They are created the first time they are assigned to, which can happen just about anywhere.</p> </li> <li> <p>Unlike C++ and Java, Python allows instance variables to shadow (have the    same name as) class attributes. This feature gets significant use in    libraries that simplify configuration by using class attributes to    automatically generate constructors and other methods.</p> </li> </ol> <p>The two confusions compound, because if you ask for an uncreated instance variable with the same name as a class attribute, Python quietly returns the class attribute. If at some later point the instance variable of the same name is created (by assigning something to its identifier), the object will from then on produce the instance variable instead of the class attribute. The same behavior that makes a class attribute look like a default value can cause subtle bugs.</p> <p>To see this in action, we need a function that displays the inside of classes and objects:</p> <pre><code># look_inside.py\n\n\ndef attributes(d: object) -&gt; str:\n    return (\n        \", \".join([f\"{k}: {v}\" for k, v in vars(d).items() if not k.startswith(\"__\")])\n        or \"Empty\"\n    )\n\n\ndef show(obj: object, obj_name: str) -&gt; None:\n    klass: type = obj.__class__\n    print(f\"[Class {klass.__name__}] {attributes(klass)}\")\n    print(f\"[Object {obj_name}] {attributes(obj)}\")\n</code></pre> <p><code>attributes()</code> can be applied to either a class or an object. It uses the builtin <code>vars()</code> function to produce the dictionary, skips dunder functions, and produces names and values or <code>\"Empty\"</code> if there are none. <code>attributes()</code> is used in <code>show()</code> to display both the class and an object of that class. Now we can see the details when using class attributes:</p> <pre><code># class_attributes.py\nfrom look_inside import show\n\n\nclass A:\n    x: int = 100\n\n\nclass B:\n    x: int = 100\n\n    def __init__(self, x_init: int):\n        # Shadows the class attribute name:\n        self.x = x_init\n\n\na = A()\nshow(a, \"a\")\n## [Class A] x: 100\n## [Object a] Empty\na.x = 1\nshow(a, \"a\")\n## [Class A] x: 100\n## [Object a] x: 1\nb = B(-99)\nshow(b, \"b\")\n## [Class B] x: 100\n## [Object b] x: -99\n</code></pre> <p>Creating an <code>A</code> requires no constructor arguments (because there is no constructor). There are no instance variables for <code>a</code> until after the assignment <code>a.x = 1</code>. <code>B</code>'s constructor requires an argument and uses it to assign to an instance variable (thus creating it).</p> <p>Let's look at the original example using <code>show()</code>:</p> <pre><code># like_default_values_shown.py\nfrom look_inside import show\n\n\nclass A:\n    x: int = 100\n\n\na = A()\nshow(a, \"a\")\n## [Class A] x: 100\n## [Object a] Empty\nprint(f\"{a.x = }\")\n## a.x = 100\na.x = -1\nshow(a, \"a\")\n## [Class A] x: 100\n## [Object a] x: -1\nprint(f\"{a.x = }\")\n## a.x = -1\na2 = A()\nshow(a2, \"a2\")\n## [Class A] x: 100\n## [Object a2] Empty\nprint(f\"{a2.x = }\")\n## a2.x = 100\n</code></pre> <p>In the first <code>print()</code>, the instance variable <code>x</code> has not yet been created, so Python helpfully produces the class attribute of the same name. But the assignment <code>a.x = -1</code> creates an instance variable, and so the second <code>print()</code> sees that instance variable. When we create a new <code>A</code> for <code>a2</code>, we're back to a new object without an instance variable so it once again produces the class attribute, making it look like a default value.</p> <p>If you never do anything more complex than this, you won't know there are lurking problems.</p>"},{"location":"A06_Class_Attributes/#the-class-attribute-trick","title":"The Class Attribute Trick","text":"<p>Name shadowing is an intentional part of Python's design, and has become an integral part of the way some libraries provide easy class configuration. The first time I saw it was in Django:</p> <pre><code># example_9.py\n# class Blog(models.Model):\n#     name = models.CharField(max_length=100)\n#     tagline = models.TextField()\n# \n#     def __str__(self):\n#         return self.name\n</code></pre> <p>This seemed magical and confusing. There's no visible constructor but somehow <code>__str__</code> can access <code>self.name</code>. Presumably the base-class constructor creates the instance variables by using the class attributes as a template.</p> <p>Python's <code>dataclasses</code> use a decorator to generate code for the constructor and other methods using class attributes as a template. Simply adding <code>dataclasses</code> to <code>it_all_goes_wrong.py</code> fixes the problem:</p> <pre><code># example_10.py\nfrom dataclasses import dataclass\n\n\n@dataclass\nclass A:\n    x: int = 100\n    y: int = 200\n</code></pre> <p>I suspect that the use of class attributes as code-generation templates will continue.</p>"},{"location":"A06_Class_Attributes/#recommendations","title":"Recommendations","text":"<p>The solution is to not make class attributes seem like default values. Instead, write proper constructors with default arguments, as you see in <code>class A</code>:</p> <pre><code># choices.py\nfrom look_inside import show\nfrom dataclasses import dataclass\n\n\nclass A:\n    def __init__(self, x: int = 100, y: int = 200, z: int = 300):\n        self.x = x\n        self.y = y\n        self.z = z\n\n\n# OR:\n\n\n@dataclass\nclass AA:\n    x: int = 100\n    y: int = 200\n    z: int = 300\n\n\na = A()\nshow(a, \"a\")\n## [Class A] Empty\n## [Object a] x: 100, y: 200, z: 300\na.x = -1\na.y = -2\na.z = -3\nshow(a, \"a\")\n## [Class A] Empty\n## [Object a] x: -1, y: -2, z: -3\n\naa = AA()\nprint(aa)\n## AA(x=100, y=200, z=300)\nshow(aa, \"aa\")\n## [Class AA] x: 100, y: 200, z: 300\n## [Object aa] x: 100, y: 200, z: 300\naa.x = -1\naa.y = -2\naa.z = -3\nshow(aa, \"aa\")\n## [Class AA] x: 100, y: 200, z: 300\n## [Object aa] x: -1, y: -2, z: -3\naa2 = AA(-4, -5, -6)\nshow(aa2, \"aa2\")\n## [Class AA] x: 100, y: 200, z: 300\n## [Object aa2] x: -4, y: -5, z: -6\n\n# Even if we modify the class attributes, the\n# constructor default arguments stay the same:\nAA.x = 42\nAA.y = 74\nAA.z = 22\naa3 = AA()\nshow(aa3, \"aa3\")\n## [Class AA] x: 42, y: 74, z: 22\n## [Object aa3] x: 100, y: 200, z: 300\n</code></pre> <p>You can also use a <code>dataclass</code> as seen in <code>class AA</code>. Notice the result of <code>print(aa)</code> produces a useful description of the object because the <code>dataclass</code> automatically generates a <code>__repr__()</code>.</p> <p>The <code>dataclass</code> decorator generates a constructor with default arguments that match the class attributes. After that you can modify the class attributes and it has no effect on the constructed objects. It seems like <code>dataclasses</code> are what the original author of the code I encountered was hoping for.</p> <p>Although Python's syntax can make it look like other languages, its dynamic nature strongly influences the language's semantics. Assumptions that it works like C++ or Java will generally produce incorrect results.</p> <p>You can learn more about <code>dataclasses</code> from my Pycon 2022 presentation Making Dataclasses Work for You, on YouTube (not yet available at this writing).</p> <p>Thanks to Barry Warsaw for reviewing and giving feedback.</p> <p>[^1]: Languages like C++ and Java use constructor to mean \"activities performed after storage allocation and basic initialization.\" C++ also has a <code>new()</code> for controlling memory allocation, calling it \"operator new\" rather than \"constructor.\" In contrast, Python's constructor is usually defined as the <code>__new__()</code> function, and <code>__init__()</code> is called the initializer. C++'s operator <code>new()</code> and Python's <code>__new__()</code> are almost never overridden, and are rarely even mentioned (The common usage for Python's <code>__new__()</code> seems to be to create Factory functions). To keep things simple I just say \"constructor\" when referring to <code>__init__()</code>.</p>"},{"location":"A07_Tools/","title":"Tools","text":"<p>Useful tools</p> <ul> <li>Mkinit. Automatically generates <code>__init__.py</code> files.   Can solve import problems, but if it doesn't, try making all <code>__init__.py</code> files empty and perform full path imports.</li> </ul>"},{"location":"A08_Book_Utilities/","title":"Book Utilities","text":"<p>These are incorporated into book examples to make them easier to read and to reduce code duplication. They are placed in a subdirectory off the root of the project, named <code>book_utils</code>. Because the book examples are extracted into a flat layout in the examples repository, you can import directly from <code>book_utils</code>.</p>"},{"location":"A08_Book_Utilities/#exception-catcher","title":"Exception Catcher","text":"<p>When a function call is known to succeed, the ordinary <code>print()</code> can be used. If a function call can fail with an exception, <code>call_and_print()</code> will catch and display the error. In use, it is shortened to <code>cp</code> so it can also be used to make a code line a tiny bit shorter than <code>print()</code>.</p> <pre><code># book_utils/exception_catcher.py\n\"\"\"\nContext manager that catches exceptions and prints their error messages,\nand can be used as a callable via its __call__ method.\n\nWhen used as a callable, argument evaluation must be delayed until inside\nthe context manager in case argument evaluation raises an exception.\nTo do this the function should be provided as a zero-argument callable.\nIf the function takes arguments, it must be wrapped in a lambda to delay evaluation.\n\"\"\"\n\nfrom typing import Any, Callable, TypeVar\n\nR = TypeVar(\"R\")\n\n\nclass Catch:\n\n    def __enter__(self) -&gt; \"Catch\":\n        return self\n\n    def __exit__(self, exc_type: Any, exc_value: Any, traceback: Any) -&gt; bool:\n        # __exit__ is only called if an exception escapes the block.\n        if exc_type is not None:\n            print(f\"Error: {exc_value}\")\n        return True\n\n    def __call__(self, func: Callable[[], R]) -&gt; R:\n        \"\"\"\n        Execute a zero-argument callable, catching and\n        printing errors so that subsequent calls run.\n        \"\"\"\n        try:\n            result = func()\n            if result is not None:\n                print(result)\n            return result\n        except Exception as e:\n            print(f\"Error: {e}\")\n            return None\n</code></pre> <p>The <code>Catch</code> class serves two roles:</p> <ol> <li>Context Manager (<code>__enter__</code> and <code>__exit__</code> methods)</li> <li>Callable Object (<code>__call__</code> method)</li> </ol> <p>This combination allows it to handle exceptions and display meaningful error messages without stopping program execution.</p>"},{"location":"A08_Book_Utilities/#context-manager","title":"Context Manager","text":"<p>A context manager in Python is used with the <code>with</code> statement, typically to set up and tear down resources or to catch exceptions. The <code>Catch</code> class implements this using:</p> <ul> <li> <p><code>__enter__(self)</code>   When the context is entered, it returns the instance (<code>self</code>), making the methods of the class accessible within the block.</p> </li> <li> <p><code>__exit__(self, exc_type, exc_value, traceback)</code>   Automatically called when the context manager block (<code>with</code> statement) finishes execution.   It receives details about any exception raised inside the block:</p> </li> <li> <p><code>exc_type</code>: the type of exception raised (e.g., <code>ValueError</code>)</p> </li> <li><code>exc_value</code>: the actual exception object containing the message</li> <li><code>traceback</code>: the traceback object detailing where the exception occurred</li> </ul> <p>If an exception occurs (<code>exc_type is not None</code>), the <code>Catch</code> class prints the error message and returns <code>True</code> to indicate that the exception has been handled and should not propagate further.</p> <p>Example usage as a context manager:</p> <pre><code># simple_form.py\nfrom book_utils import Catch\n\nwith Catch():\n    1 / 0\n## Error: division by zero\n</code></pre>"},{"location":"A08_Book_Utilities/#callable-interface-__call__-method","title":"Callable Interface (<code>__call__</code> method)","text":"<p>The <code>Catch</code> class also defines a <code>__call__</code> method, allowing its instances to be called as functions. This lets you explicitly wrap a callable (like a lambda or zero-argument function) inside its own try-except block, capturing and handling exceptions raised during both argument evaluation and function execution.</p> <p>In the <code>__call__</code> method signature, <code>func</code> is a zero-argument callable. It executes this callable within a try-except block:</p> <ul> <li>If the callable succeeds, it prints and returns the result (if not <code>None</code>).</li> <li>If an exception is raised, it prints the error and returns <code>None</code>.</li> </ul> <p>Here's an example showing callables within a context manager:</p> <pre><code># simple_lambda_form.py\nfrom book_utils import Catch\n\nwith Catch() as catch:\n    catch(lambda: 1 / 0)\n    catch(lambda: 1 / 0)\n    catch(lambda: 1 / 0)\n    print(\"No lambda aborts the context:\")\n    1 / 0\n    print(\"This doesn't run:\")\n    catch(lambda: 1 / 0)\n## Error: division by zero\n## Error: division by zero\n## Error: division by zero\n## No lambda aborts the context:\n## Error: division by zero\n</code></pre> <p>Using lambdas here is essential because it delays the evaluation of arguments until inside the <code>Catch</code> context, ensuring that errors raised during argument construction are caught properly. Here's a more complex example with argument construction that throws exceptions:</p> <pre><code># demo_exception_checker.py\nfrom dataclasses import dataclass\n\nfrom book_utils import Catch\n\n\n@dataclass\nclass Fob:\n    x: int\n\n    def __post_init__(self) -&gt; None:\n        if self.x &lt; 0:\n            raise ValueError(f\"Fob arg {self.x} must be positive\")\n\n\ndef foo(a: int, b: Fob) -&gt; str:\n    if a &lt; 0:\n        raise ValueError(f\"foo arg {a} must be positive\")\n    return f\"foo({a}, {b}) succeeded\"\n\n\n# If you know it succeeds you can just run it without a context:\nprint(foo(0, Fob(0)))\n## foo(0, Fob(x=0)) succeeded\nwith Catch():  # Single-failure simple form\n    foo(1, Fob(-1))\n## Error: Fob arg -1 must be positive\n\n# In the simple form, success does NOT automatically display the result:\nwith Catch():\n    print(foo(42, Fob(42)))  # Must explicitly print\n## foo(42, Fob(x=42)) succeeded\nwith Catch() as catch:  # Lambda form displays successful result\n    catch(lambda: foo(42, Fob(42)))\n## foo(42, Fob(x=42)) succeeded\n\n# Multi-failure block requires lambda form:\nwith Catch() as catch:\n    catch(lambda: foo(1, Fob(1)))\n    catch(lambda: foo(0, Fob(0)))\n    catch(lambda: foo(-1, Fob(1)))\n    catch(lambda: foo(1, Fob(-1)))\n    catch(lambda: foo(-1, Fob(-1)))\n    catch(lambda: foo(10, Fob(11)))\n## foo(1, Fob(x=1)) succeeded\n## foo(0, Fob(x=0)) succeeded\n## Error: foo arg -1 must be positive\n## Error: Fob arg -1 must be positive\n## Error: Fob arg -1 must be positive\n## foo(10, Fob(x=11)) succeeded\n</code></pre>"},{"location":"A08_Book_Utilities/#book-utilities-__init__py","title":"Book Utilities <code>__init__.py</code>","text":"<p>To allow these utilities to be easily imported using <code>from book_utils</code>, we must set up the <code>__init__.py</code>:</p> <pre><code># book_utils/__init__.py\nfrom .exception_catcher import Catch\n__all__ = [\"Catch\"]\n</code></pre>"},{"location":"A09_Book_Notes/","title":"Book Notes","text":"<p>Resources and Ideas for eventual inclusion in the book.</p> <ul> <li>https://github.com/BruceEckel/RethinkingObjects (code from Pycon presentation, youtube video is not comprehensible)</li> <li>https://github.com/BruceEckel/RethinkingObjects-book</li> </ul>"},{"location":"A09_Book_Notes/#ai-generated-topic-list","title":"AI-Generated Topic List","text":"<p>Created by ChatGPT 4o.</p>"},{"location":"A09_Book_Notes/#part-i-the-basics-of-typing-in-python","title":"\ud83d\udcd8 Part I: The Basics of Typing in Python","text":""},{"location":"A09_Book_Notes/#introduction-to-static-typing","title":"Introduction to Static Typing","text":"<ul> <li>Why type your code?</li> <li>Benefits of types in Python (readability, tooling, correctness)</li> </ul>"},{"location":"A09_Book_Notes/#basic-type-annotations","title":"Basic Type Annotations","text":"<ul> <li>Built-in types: <code>int</code>, <code>str</code>, <code>float</code>, <code>bool</code></li> <li>Variable annotations</li> <li>Function argument and return types</li> </ul>"},{"location":"A09_Book_Notes/#optional-and-union-types","title":"Optional and Union Types","text":"<ul> <li><code>Optional[T]</code> / <code>T | None</code></li> <li><code>Union</code> / <code>T1 | T2</code></li> <li>When and why to use</li> </ul>"},{"location":"A09_Book_Notes/#any-and-noreturn","title":"Any and NoReturn","text":"<ul> <li>When to use <code>Any</code></li> <li>Risks of <code>Any</code></li> <li>Meaning and use of <code>NoReturn</code></li> </ul>"},{"location":"A09_Book_Notes/#type-aliases","title":"Type Aliases","text":"<ul> <li>Creating and using <code>type MyAlias = ...</code></li> <li>Organizing complex types</li> </ul>"},{"location":"A09_Book_Notes/#part-ii-collections-and-generics","title":"\ud83d\udcd8 Part II: Collections and Generics","text":""},{"location":"A09_Book_Notes/#typing-built-in-collections","title":"Typing Built-in Collections","text":"<ul> <li><code>List</code>, <code>Dict</code>, <code>Tuple</code>, <code>Set</code></li> <li>Homogeneous vs heterogeneous types</li> <li>Variadic tuples</li> </ul>"},{"location":"A09_Book_Notes/#generic-types","title":"Generic Types","text":"<ul> <li>Understanding <code>TypeVar</code> and generic functions</li> <li>Creating generic classes</li> </ul>"},{"location":"A09_Book_Notes/#callable-and-lambdas","title":"Callable and Lambdas","text":"<ul> <li>Typing functions as values</li> <li>Callable signatures</li> </ul>"},{"location":"A09_Book_Notes/#iterables-and-iterators","title":"Iterables and Iterators","text":"<ul> <li><code>Iterable</code>, <code>Iterator</code>, <code>Generator</code></li> <li>Typing generators and coroutines</li> </ul>"},{"location":"A09_Book_Notes/#literal-types","title":"Literal Types","text":"<ul> <li>Restricting to fixed string or numeric values</li> <li>Using <code>Literal</code> for flags and enums</li> </ul>"},{"location":"A09_Book_Notes/#part-iii-advanced-concepts","title":"\ud83d\udcd8 Part III: Advanced Concepts","text":""},{"location":"A09_Book_Notes/#protocols-and-structural-typing","title":"Protocols and Structural Typing","text":"<ul> <li>Introduction to duck typing</li> <li><code>Protocol</code> classes and <code>@runtime_checkable</code></li> </ul>"},{"location":"A09_Book_Notes/#new-in-python-10","title":"New in Python 10+","text":"<ul> <li><code>|</code> syntax for unions</li> <li><code>match</code> statement and typing with pattern matching</li> <li><code>ParamSpec</code> and <code>Concatenate</code></li> </ul>"},{"location":"A09_Book_Notes/#annotated-and-metadata-types","title":"Annotated and Metadata Types","text":"<ul> <li>Using <code>Annotated</code> for richer metadata</li> <li>Use in CLI tools, validation, etc.</li> </ul>"},{"location":"A09_Book_Notes/#self-type-and-recursive-types","title":"Self Type and Recursive Types","text":"<ul> <li>Typing methods that return <code>self</code></li> <li>Recursive types like nested JSON</li> </ul>"},{"location":"A09_Book_Notes/#dataclasses-and-typing","title":"Dataclasses and Typing","text":"<ul> <li>Typing fields with and without defaults</li> <li><code>InitVar</code>, <code>field</code>, <code>kw_only</code>, etc.</li> </ul>"},{"location":"A09_Book_Notes/#part-iv-runtime-typing-and-validation","title":"\ud83d\udcd8 Part IV: Runtime Typing and Validation","text":""},{"location":"A09_Book_Notes/#type-checking-at-runtime","title":"Type Checking at Runtime","text":"<ul> <li><code>isinstance</code> and <code>typing.get_type_hints()</code></li> <li>Runtime enforcement libraries (e.g. Pydantic, Enforce)</li> </ul>"},{"location":"A09_Book_Notes/#validating-with-decorators","title":"Validating with Decorators","text":"<ul> <li>Type validation decorators</li> <li>Enforcing types in dynamic code</li> </ul>"},{"location":"A09_Book_Notes/#typeddict-and-json-like-structures","title":"TypedDict and JSON-like Structures","text":"<ul> <li>Using <code>TypedDict</code> for structured data</li> <li>Migration from <code>dict[str, Any]</code></li> </ul>"},{"location":"A09_Book_Notes/#enums-and-custom-types","title":"Enums and Custom Types","text":"<ul> <li>Strongly typed enums</li> <li>Creating domain-specific types</li> </ul>"},{"location":"A09_Book_Notes/#dynamic-typing-interop","title":"Dynamic Typing Interop","text":"<ul> <li>Working with untyped or partially typed code</li> <li>Handling <code>Any</code> gracefully</li> </ul>"},{"location":"A09_Book_Notes/#part-v-tooling-and-practices","title":"\ud83d\udcd8 Part V: Tooling and Practices","text":""},{"location":"A09_Book_Notes/#static-type-checkers","title":"Static Type Checkers","text":"<ul> <li>Using <code>mypy</code>, <code>pyright</code>, <code>pyre</code>, <code>pytype</code></li> <li>Configuration and workflows</li> </ul>"},{"location":"A09_Book_Notes/#ide-and-editor-support","title":"IDE and Editor Support","text":"<ul> <li>VS Code, PyCharm, etc.</li> <li>Type hinting with LSPs and plugins</li> </ul>"},{"location":"A09_Book_Notes/#refactoring-with-types","title":"Refactoring with Types","text":"<ul> <li>Incremental typing strategies</li> <li>Using types to guide refactoring</li> </ul>"},{"location":"A09_Book_Notes/#testing-and-typing","title":"Testing and Typing","text":"<ul> <li>Typing test code</li> <li>Type-aware mocking and fixtures</li> </ul>"},{"location":"A09_Book_Notes/#types-in-documentation","title":"Types in Documentation","text":"<ul> <li>Sphinx and autodoc with type hints</li> <li>Docstrings vs annotations</li> </ul>"},{"location":"A09_Book_Notes/#part-vi-real-world-applications","title":"\ud83d\udcd8 Part VI: Real-World Applications","text":""},{"location":"A09_Book_Notes/#typing-apis-and-libraries","title":"Typing APIs and Libraries","text":"<ul> <li>Public API surfaces</li> <li>Library development with types</li> </ul>"},{"location":"A09_Book_Notes/#using-types-in-frameworks","title":"Using Types in Frameworks","text":"<ul> <li>Django/Pydantic/FastAPI with typing</li> <li>Typing decorators and middleware</li> </ul>"},{"location":"A09_Book_Notes/#typing-concurrency","title":"Typing Concurrency","text":"<ul> <li><code>async def</code>, <code>Awaitable</code>, <code>Coroutine</code></li> <li><code>Thread</code>, <code>Process</code>, <code>Queue</code></li> </ul>"},{"location":"A09_Book_Notes/#cross-version-compatibility","title":"Cross-Version Compatibility","text":"<ul> <li>Using <code>typing_extensions</code></li> <li>Supporting older Python versions</li> </ul>"},{"location":"A09_Book_Notes/#common-pitfalls-and-anti-patterns","title":"Common Pitfalls and Anti-Patterns","text":"<ul> <li>Misusing <code>Any</code></li> <li>Over-annotating</li> <li>Annotations that hinder readability</li> </ul>"},{"location":"A10_Topic_List/","title":"Topic List","text":"<p>Generated by ChatGPT 4o with \"Deep Research\"</p>"},{"location":"A10_Topic_List/#fundamentals-of-type-annotations-in-python","title":"Fundamentals of Type Annotations in Python","text":"<ul> <li>Purpose and Nature: Type annotations (or \u201ctype hints\u201d) allow developers to declare the expected data types of variables, function parameters, and return values. Python remains dynamically typed at runtime \u2013 these hints are not enforced by the interpreter and are mainly for static analysis and documentation (typing \u2014 Support for type hints \u2014 Python 3.13.2 documentation) (PEP 484 \u2013 Type Hints | peps.python.org). Tools like type checkers (e.g. mypy, Pyright) and IDEs use the hints to catch errors or suggest code completions (PEP 484 \u2013 Type Hints | peps.python.org). Python\u2019s core team has no plan to make type hints mandatory; they are optional aids to improve code quality (PEP 484 \u2013 Type Hints | peps.python.org).  </li> <li>Introduction via PEPs: Function annotation syntax was first introduced by PEP 3107 (Python 3.0) with no fixed semantics. PEP 484 (Python 3.5) later defined a standard for using these annotations as type hints, establishing a formal type hinting system (PEP 484 \u2013 Type Hints | peps.python.org). The <code>typing</code> module was added to provide a standard vocabulary of types. This enabled gradual typing \u2013 code can be partially or fully annotated, and type checkers will treat unannotated parts as dynamically typed (effectively type <code>Any</code>) (PEP 484 \u2013 Type Hints | peps.python.org) (PEP 484 \u2013 Type Hints | peps.python.org).  </li> </ul>"},{"location":"A10_Topic_List/#basic-annotation-syntax-and-usage","title":"Basic Annotation Syntax and Usage","text":"<ul> <li>Function Annotations (Parameters and Return): You can annotate function parameters and return types using the syntax introduced in PEP\u00a0484. For example: <pre><code>def greet(name: str, excited: bool = False) -&gt; str:\n    return f\"Hello, {'!' if excited else ''}{name}\"\n</code></pre>   In this example, <code>name: str</code> and <code>excited: bool = False</code> annotate the parameter types, and <code>-&gt; str</code> annotates the return type (typing \u2014 Support for type hints \u2014 Python 3.13.2 documentation). An unannotated parameter defaults to type <code>Any</code> in static analysis (PEP 484 \u2013 Type Hints | peps.python.org). If a function does not return a value (or returns <code>None</code>), it\u2019s good practice to annotate the return type as <code>None</code> (e.g. <code>-&gt; None</code>), especially for <code>__init__</code> methods (PEP 484 \u2013 Type Hints | peps.python.org).  </li> <li>Variable Annotations: Python 3.6 (PEP\u00a0526) introduced syntax for annotating variables and class attributes with types. For example: <code>age: int = 21</code> or <code>pi: float</code> (with or without initialization) (typing \u2014 Support for type hints \u2014 Python 3.13.2 documentation). These annotations can appear at the class or module level as well as inside functions. When annotating class variables (as opposed to instance variables), use <code>typing.ClassVar</code>. For instance: <pre><code>class Starship:\n    stats: ClassVar[dict[str, int]] = {}   # class variable  \n    damage: int = 10                       # instance variable  \n</code></pre>   Here <code>stats</code> is marked as a class-level attribute, whereas <code>damage</code> is an instance attribute (typing \u2014 Support for type hints \u2014 Python 3.13.2 documentation). ClassVar helps type checkers distinguish the two. (At runtime, annotations are stored in the <code>__annotations__</code> attribute of the function or class, but they don\u2019t affect execution (typing \u2014 Support for type hints \u2014 Python 3.13.2 documentation).)  </li> <li>Type Comments (Legacy): In older code or for compatibility, type hints can be given in comments (e.g. <code># type: int</code>) as described in PEP\u00a0484. This was mainly used for Python 2 or situations where inline annotation syntax was not available. Modern Python prefers explicit annotation syntax, but you might encounter type comments or stub files in some codebases.  </li> </ul>"},{"location":"A10_Topic_List/#core-built-in-types-and-collections-in-annotations","title":"Core Built-in Types and Collections in Annotations","text":"<ul> <li>Built-in Types: For simple types like <code>int</code>, <code>str</code>, <code>bool</code>, etc., you can use the type name directly as an annotation. For example, <code>x: int = 5</code> or <code>user: str</code>. The same goes for classes and custom types \u2013 you annotate with the class itself (e.g. <code>file: io.TextIOBase</code>).  </li> <li>Generic Collections (PEP\u00a0585): Modern Python allows using built-in container types directly as generics. For example, use <code>list[int]</code> instead of <code>typing.List[int]</code>, <code>dict[str, float]</code> instead of <code>typing.Dict[str, float]</code>, and so on (typing \u2014 Support for type hints \u2014 Python 3.13.2 documentation). PEP\u00a0585 (Python 3.9) enabled this, so the <code>typing</code> module\u2019s capitalized aliases (List, Dict, etc.) are no longer necessary in new code (Did You Know Some Types in Python's Typing Module Are Now ...). These generics let you specify element types: e.g. <code>list[int]</code> means \u201clist of ints\u201d. (Note: these annotations are for the benefit of type checkers; at runtime <code>list[int]</code> is mainly recognized by the interpreter for typing purposes but still behaves like a normal list). Tuples can also be annotated, e.g. <code>tuple[int, str]</code> for a fixed-length 2-tuple, or <code>tuple[int, ...]</code> for a variable-length tuple of ints.  </li> <li>Union Types and Optional (PEP\u00a0604): A union type means a value could be one of several types. You can write a union as <code>typing.Union[X, Y]</code> or, more readably in Python 3.10+, using the <code>|</code> operator: <code>X | Y</code> (typing \u2014 Support for type hints \u2014 Python 3.13.2 documentation) (typing \u2014 Support for type hints \u2014 Python 3.13.2 documentation). For example, <code>def parse(data: str | bytes) -&gt; None:</code> indicates <code>data</code> can be either a string or bytes. If one of the types is <code>None</code>, there\u2019s a shorthand: <code>Optional[T]</code> is equivalent to <code>T | None</code> (typing \u2014 Support for type hints \u2014 Python 3.13.2 documentation). For example, <code>Optional[int]</code> (or <code>int | None</code>) means the value can be an int or None. Important: \u201cOptional\u201d in type hinting refers to \"may be None\"; it does not mean an argument is optional in the sense of having a default. An argument with a default value isn\u2019t automatically <code>Optional</code> unless you explicitly want to allow <code>None</code> as a value (typing \u2014 Support for type hints \u2014 Python 3.13.2 documentation).  </li> <li>The <code>Any</code> Type: <code>typing.Any</code> is a special type that essentially disables type checking for that variable. A value of type <code>Any</code> is allowed to be passed or assigned to any type, and vice versa (typing \u2014 Support for type hints \u2014 Python 3.13.2 documentation). Every type is compatible with <code>Any</code>, and <code>Any</code> is compatible with every type (typing \u2014 Support for type hints \u2014 Python 3.13.2 documentation). You might use <code>Any</code> when you genuinely cannot predict the type (e.g. a function that can return any type depending on usage). However, overusing <code>Any</code> undermines the benefits of static typing, so it\u2019s best used sparingly when other typing features can\u2019t express the concept. (If a function can accept literally any object, a best practice is to annotate it as <code>object</code> rather than <code>Any</code> to signal that no specific behavior is assumed (Typing Best Practices \u2014 typing  documentation).)  </li> <li>NoReturn / Never: If a function never returns normally (for example, it always raises an exception or calls <code>sys.exit()</code>), you can annotate its return type as <code>NoReturn</code> (or <code>Never</code>, a synonymous alias introduced in Python 3.11) (typing \u2014 Support for type hints \u2014 Python 3.13.2 documentation) (typing \u2014 Support for type hints \u2014 Python 3.13.2 documentation). This signals to type checkers that the function doesn\u2019t produce a value at all. For instance: <pre><code>from typing import NoReturn  \ndef fatal_error(msg: str) -&gt; NoReturn:  \n    raise RuntimeError(msg)  \n</code></pre>   Here, callers can know that <code>fatal_error()</code> will not return normally. <code>Never</code>/<code>NoReturn</code> is the bottom type in the type system, meaning no value can ever have this type (except in a theoretical sense) (typing \u2014 Support for type hints \u2014 Python 3.13.2 documentation). Static analyzers use it to understand control flow (e.g. after a call to a NoReturn function, execution doesn\u2019t continue).  </li> </ul>"},{"location":"A10_Topic_List/#type-aliases-and-custom-types","title":"Type Aliases and Custom Types","text":"<ul> <li>Type Aliases: Sometimes you have a complex type and want to give it a short name (alias) for readability. You can create a type alias by simple assignment or using the new <code>type</code> statement. For example: <code>Address = tuple[str, int]</code> creates an alias <code>Address</code> for \u201ctuple of (str, int)\u201d. In Python 3.12+, you can declare aliases more explicitly with the <code>type</code> keyword (PEP\u00a0695): <pre><code>type Point = tuple[float, float]  \n</code></pre>   This creates a type alias <code>Point</code> that static checkers will treat exactly as <code>tuple[float, float]</code> (What\u2019s New In Python 3.12 \u2014 Python 3.13.2 documentation). Type aliases can also be generic, e.g. <code>type Response[T] = tuple[T, int]</code> to parameterize the alias (What\u2019s New In Python 3.12 \u2014 Python 3.13.2 documentation). In older versions, you might see <code>TypeAlias</code> from <code>typing</code> used as an annotation to mark an assignment as a type alias (typing \u2014 Support for type hints \u2014 Python 3.13.2 documentation), especially when forward references are involved (to hint to the checker that a string is meant to be a type name) (typing \u2014 Support for type hints \u2014 Python 3.13.2 documentation). PEP\u00a0695 deprecates the need for <code>TypeAlias</code> by introducing the explicit alias syntax.  </li> <li>NewType \u2013 Distinct Types Based on Existing Ones: The <code>typing.NewType</code> helper lets you define a distinct type that is interchangeable with some base type at runtime but treated as a separate type by type checkers. For example: <pre><code>from typing import NewType  \nUserId = NewType('UserId', int)  \n</code></pre>   This creates a new type <code>UserId</code> that behaves like an <code>int</code> at runtime (it\u2019s essentially an identity function that returns the int you give it) (typing \u2014 Support for type hints \u2014 Python 3.13.2 documentation) (typing \u2014 Support for type hints \u2014 Python 3.13.2 documentation), but static type checkers will consider <code>UserId</code> incompatible with plain <code>int</code> unless explicitly allowed. This is useful when you want to prevent mix-ups of semantically different values that share an underlying type (e.g. <code>UserId</code> vs <code>ProductId</code> both as ints). Using <code>NewType</code>, you can catch such mix-ups in static analysis. (Under the hood, calling <code>UserId(5)</code> just returns 5 at runtime, so there\u2019s no extra performance cost beyond a function call (typing \u2014 Support for type hints \u2014 Python 3.13.2 documentation) (typing \u2014 Support for type hints \u2014 Python 3.13.2 documentation). In Python 3.10+ <code>NewType</code> is implemented as a class for better performance (typing \u2014 Support for type hints \u2014 Python 3.13.2 documentation).)  </li> </ul>"},{"location":"A10_Topic_List/#generics-and-type-variables","title":"Generics and Type Variables","text":"<ul> <li>Generic Functions and TypeVar: Python supports parametric polymorphism (generics) in functions and classes. A Type Variable (created with <code>typing.TypeVar</code>) represents an unknown type that can vary between calls or instances. For example, to write a function that returns the same type as it receives, you can do: <pre><code>from typing import TypeVar  \nT = TypeVar('T')  \ndef identity(item: T) -&gt; T:  \n    return item  \n</code></pre>   Here <code>T</code> is a type variable that can stand for any type, and the function <code>identity</code> is generic \u2013 if you pass an <code>int</code>, it returns an <code>int</code>, if you pass a <code>str</code>, it returns a <code>str</code>, etc. As of Python 3.12, you can declare type parameters directly in the function signature (PEP\u00a0695) for brevity: <pre><code>def identity[T](item: T) -&gt; T:  \n    return item  \n</code></pre>   which is equivalent to the earlier definition (What\u2019s New In Python 3.12 \u2014 Python 3.13.2 documentation). Type variables can be given bounds or constraints to restrict what types they can represent. For instance, <code>U = TypeVar('U', bound=Number)</code> means U can be any subclass of <code>Number</code> (upper-bounded) while <code>V = TypeVar('V', int, str)</code> means V can only be <code>int</code> or <code>str</code> (union constraint) (What\u2019s New In Python 3.12 \u2014 Python 3.13.2 documentation). You can also mark a TypeVar as covariant or contravariant for class inheritance scenarios (useful when defining generic container classes that subclass built-in collections) (typing \u2014 Support for type hints \u2014 Python 3.13.2 documentation), though this is an advanced topic. In summary, type variables allow writing generic code that\u2019s checked for type consistency \u2013 a key feature of PEP\u00a0484\u2019s static typing.  </li> <li>Generic Classes: You can parameterize classes with types as well. For example: <pre><code>from typing import Generic, TypeVar  \nT = TypeVar('T')  \nclass Box(Generic[T]):  \n    def __init__(self, content: T):  \n        self.content = content  \n    def get_content(self) -&gt; T:  \n        return self.content  \n</code></pre> <code>Box[T]</code> is a generic class that can hold a value of type T. One can create <code>Box[int]</code>, <code>Box[str]</code>, etc., and the methods will be type-safe. In Python 3.12+, class definitions too support the simplified generic syntax: <code>class Box[T]: ...</code> (without needing to inherit <code>Generic[T]</code>) (What\u2019s New In Python 3.12 \u2014 Python 3.13.2 documentation). When subclassing generics or creating more complex hierarchies, you might need to be mindful of type variance, but for most user-defined generics, the default invariance (type must match exactly) is fine.  </li> <li><code>typing.Type</code> for Class Objects: When you want to hint that a function parameter or return is not an instance of a class but rather a class itself, use <code>Type[T]</code> (or <code>type[T]</code> in Python 3.9+) where T is a class. For example, <code>def factory(cls: type[T]) -&gt; T:</code> indicates that <code>factory</code> expects a class (subclass) of T and will return an instance of that class. If you want to accept specific subclasses, you can union them: e.g., <code>user_class: type[BasicUser]</code> means a class object inheriting from <code>BasicUser</code> (typing \u2014 Support for type hints \u2014 Python 3.13.2 documentation). In documentation, you may see <code>Type[Base]</code> to mean \u201cany subclass of Base\u201d. This is helpful for functions that need to work with class constructors or class methods.  </li> </ul>"},{"location":"A10_Topic_List/#structural-subtyping-with-protocols","title":"Structural Subtyping with Protocols","text":"<ul> <li>Protocols (PEP\u00a0544): Python\u2019s static typing supports structural typing via Protocol classes. A <code>Protocol</code> defines a set of methods and properties that a type must have to satisfy the protocol, without requiring inheritance. For example: <pre><code>from typing import Protocol  \nclass SupportsClose(Protocol):  \n    def close(self) -&gt; None: ...  \n</code></pre>   Any object with a <code>.close()</code> method returning None will be considered a <code>SupportsClose</code> for static typing purposes, even if it doesn\u2019t inherit from <code>SupportsClose</code>. This is akin to an interface or \u201cduck typing\u201d check. Protocols enable static type checking of duck-typed code. If you mark a protocol with <code>@typing.runtime_checkable</code>, you can even use <code>isinstance(obj, ProtocolName)</code> at runtime (which will just check for the presence of required attributes) (typing \u2014 Support for type hints \u2014 Python 3.13.2 documentation). Protocols can themselves be generic (e.g., an <code>Iterable[T]</code> protocol defines an <code>__iter__</code> that yields T) (typing \u2014 Support for type hints \u2014 Python 3.13.2 documentation). The standard library defines many protocols (e.g. <code>typing.Iterable</code>, <code>typing.Sized</code>) that correspond to common Python protocols. Using Protocols allows one to write functions that accept any object that \u201chas the right methods,\u201d enabling flexible, decoupled code with static checks (typing \u2014 Support for type hints \u2014 Python 3.13.2 documentation). (PEP\u00a0544 formalized this in Python 3.8; it\u2019s an extension of the idea of abstract base classes (ABCs) toward a more implicit structural approach.)  </li> </ul>"},{"location":"A10_Topic_List/#callable-types-and-function-overloading","title":"Callable Types and Function Overloading","text":"<ul> <li>Callable[[...], ReturnType]: Functions are first-class in Python, so you may want to annotate variables or parameters that are themselves functions (callables). The <code>typing.Callable</code> type is used to describe the signature of a callable. For example, <code>Callable[[int, str], bool]</code> means \u201ca callable that takes an <code>int</code> and a <code>str</code> and returns a <code>bool</code>.\u201d If you don\u2019t want to specify the parameters (accept any callable returning a specific type), you can use an ellipsis: <code>Callable[..., bool]</code> means any callable returning bool (typing \u2014 Support for type hints \u2014 Python 3.13.2 documentation). An example usage: <pre><code>def apply_to_ints(func: Callable[[int, int], int], a: int, b: int) -&gt; int:  \n    return func(a, b)  \n</code></pre>   This function takes another function <code>func</code> that adds or combines two ints and returns int. When you pass a lambda or function to <code>apply_to_ints</code>, a type checker will ensure it matches the described signature.  </li> <li>Overloaded Functions (PEP\u00a0484): Sometimes a function can be called with different argument types and behave differently (especially common in library stubs). The <code>@typing.overload</code> decorator allows you to declare multiple overload variants for a function for static typing purposes. For example: <pre><code>from typing import overload, Union  \n@overload  \ndef read(data: bytes) -&gt; str: ...  \n@overload  \ndef read(data: str) -&gt; str: ...  \ndef read(data: Union[str, bytes]) -&gt; str:  \n    # single implementation handling both  \n    return data.decode() if isinstance(data, bytes) else data  \n</code></pre>   Here two overloads declare that <code>read()</code> accepts either bytes or str and always returns str. The implementation (without @overload) handles both. Type checkers will resolve calls to the appropriate signature. Overloading is for the benefit of static analysis; at runtime only the final implementation exists (PEP 484 \u2013 Type Hints | peps.python.org).  </li> <li>Override decorator (PEP\u00a0698): In Python 3.12 a new <code>typing.override</code> decorator was added to improve correctness in class hierarchies. You place <code>@override</code> on a method that is supposed to override a method in the base class. This doesn\u2019t change runtime behavior, but a type checker will verify that you actually are overriding a base class method and that your method\u2019s signature is compatible with the base class version (What\u2019s New In Python 3.12 \u2014 Python 3.13.2 documentation). This helps catch errors where you intended to override a method but misspelled its name or got the signature wrong. Using <code>@override</code> can make code maintenance safer in large class hierarchies.  </li> </ul>"},{"location":"A10_Topic_List/#parameter-specifications-for-higher-order-functions-pep-612","title":"Parameter Specifications for Higher-Order Functions (PEP\u00a0612)","text":"<ul> <li>ParamSpec and Concatenate: PEP\u00a0612 introduced <code>ParamSpec</code> (Parameter Specification Variables) to support typing of higher-order functions \u2013 functions that accept or return other functions with arbitrary signatures. A ParamSpec, denoted typically as <code>P = ParamSpec(\"P\")</code>, captures a list of parameters (types and kinds) of a callable. For example, you might write: <pre><code>from typing import ParamSpec, Callable, Concatenate  \nP = ParamSpec(\"P\")  \ndef make_logged(func: Callable[P, int]) -&gt; Callable[Concatenate[str, P], int]:  \n    def wrapper(prefix: str, *args: P.args, **kwargs: P.kwargs) -&gt; int:  \n        print(prefix, \"Calling:\", func.__name__)  \n        result = func(*args, **kwargs)  \n        print(prefix, \"Result:\", result)  \n        return result  \n    return wrapper  \n</code></pre>   In this example, <code>make_logged</code> takes a function <code>func</code> that returns an int and has some parameters P. It returns a new function that adds a <code>prefix: str</code> in front of <code>func</code>\u2019s parameters. We use <code>Callable[P, int]</code> to represent the input function\u2019s signature and <code>Callable[Concatenate[str, P], int]</code> for the wrapper\u2019s signature. <code>Concatenate[str, P]</code> means we\u2019re prepending a <code>str</code> argument in front of the parameter list P (typing \u2014 Support for type hints \u2014 Python 3.13.2 documentation). ParamSpec allows the wrapper to perfectly forward the original function\u2019s parameters while adding new ones, preserving full type information. This technique is useful for decorators and wrapper functions that modify call signatures. Without ParamSpec, one might resort to <code>Callable[..., int]</code> which loses specific parameter types. ParamSpecs enable writing precise types for decorators like <code>@property</code>, context managers, function adapters, etc., making the static typing of these patterns much more powerful.  </li> </ul>"},{"location":"A10_Topic_List/#advanced-and-new-type-constructs","title":"Advanced and New Type Constructs","text":"<ul> <li>Literal Types (PEP\u00a0586 and PEP\u00a0675): A Literal type allows you to indicate that a value is not just of a general type, but a specific constant value (or one of a specific set of constants). For example, <code>Literal[\"GET\", \"POST\"]</code> can be used to type a variable that should only ever equal <code>\"GET\"</code> or <code>\"POST\"</code>. This is helpful for functions that behave differently based on constant string or numeric inputs. In Python 3.8, PEP\u00a0586 introduced <code>typing.Literal</code>. E.g. <code>def set_mode(mode: Literal[\"fast\", \"slow\"]) -&gt; None: ...</code> means mode must be one of those two strings (typing \u2014 Support for type hints \u2014 Python 3.13.2 documentation) (typing \u2014 Support for type hints \u2014 Python 3.13.2 documentation). More recently, PEP\u00a0675 (Python 3.11) added <code>LiteralString</code>, a special type to mark literal strings for security-sensitive APIs (What\u2019s New In Python 3.11 \u2014 Python 3.13.2 documentation). <code>LiteralString</code> is a subtype of <code>str</code> that static analyzers treat as strings that are either literal in the source or derived from other literal strings. The goal is to prevent untrusted or dynamic strings from flowing into places where they could cause injection attacks (SQL queries, shell commands, etc.) (What\u2019s New In Python 3.11 \u2014 Python 3.13.2 documentation) (What\u2019s New In Python 3.11 \u2014 Python 3.13.2 documentation). For example: <pre><code>def run_query(query: LiteralString): ...  \nrun_query(\"SELECT * FROM users\")           # OK, literal  \nq = \"DROP TABLE users\"  \nrun_query(q)                               # type checker error (q is not literal)  \n</code></pre>   Here, passing a non-literal string to <code>run_query</code> would be flagged by a type checker (What\u2019s New In Python 3.11 \u2014 Python 3.13.2 documentation). Literal types thus allow more precise typing for functions expecting fixed values or literal-derived values.  </li> <li>Final and Constants (PEP\u00a0591): To indicate that a name should not be reassigned (treated as a constant in type-checking), use the <code>Final</code> qualifier. For example, <code>MAX_SIZE: Final[int] = 100</code> tells the type checker that <code>MAX_SIZE</code> should never be re-bound to a different value or type (typing \u2014 Support for type hints \u2014 Python 3.13.2 documentation). Attempting to assign to it elsewhere would be a static error. You can also mark classes as <code>final</code> using <code>@typing.final</code> decorator, which means the class is not intended to be subclassed. Similarly, marking a method with <code>@final</code> means it should not be overridden in subclasses. This is purely for the type checker/linters; Python won\u2019t prevent subclassing or overriding at runtime, but it helps catch design violations in large projects. Using Final is useful for constants or to explicitly close off class hierarchies when appropriate.  </li> <li>Annotated Types (PEP\u00a0593): The <code>typing.Annotated</code> type was introduced to enrich type hints with additional metadata. Its syntax is <code>Annotated[T, X]</code> where T is a normal type and X is metadata (which can be any value, often a class or string). This metadata can be used by frameworks or tools at runtime or by linters for additional validation. For instance, one could annotate a type with a range: <code>Annotated[int, Between(0, 100)]</code> to indicate an int that should lie between 0 and 100. The Python interpreter and core type checkers mostly ignore the second argument of Annotated (they treat the variable as just type T), but specific libraries can inspect it. This was added in Python 3.9 to support use-cases like data validation, ORM field specifications, or units attached to values, all while keeping the primary type information. In short, <code>Annotated</code> wraps a base type with extra info that third-party consumers can use (typing \u2014 Support for type hints \u2014 Python 3.13.2 documentation).  </li> <li>Type Guards (PEP\u00a0647): A type guard is a special kind of function that informs the type checker of a type refinement. Introduced in Python 3.10, <code>typing.TypeGuard</code> is used as a return annotation on a boolean function to indicate that if the function returns True, its argument is of a certain type. For example: <pre><code>from typing import TypeGuard  \ndef is_str_list(vals: list[object]) -&gt; TypeGuard[list[str]]:  \n    return all(isinstance(x, str) for x in vals)  \n</code></pre>   Here, <code>is_str_list</code> returns a <code>bool</code>, but the <code>TypeGuard[list[str]]</code> annotation tells the checker that upon a True result, the input <code>vals</code> can be treated as <code>list[str]</code> (not just list of object). This enables writing custom <code>isinstance</code>-like helpers that narrow types. Python\u2019s <code>match</code> statement and <code>isinstance</code> checks also perform narrowing; TypeGuard extends this to user-defined predicates (typing \u2014 Support for type hints \u2014 Python 3.13.2 documentation). This concept helps make code with conditional type logic (like parsing JSON to specific shapes) more type-safe and clear to the type checker.  </li> <li><code>Self</code> Type (PEP\u00a0673): In class methods that return <code>self</code> (or class/instance attributes of the same class type), Python 3.11 introduced <code>typing.Self</code> to simplify the annotation (What\u2019s New In Python 3.11 \u2014 Python 3.13.2 documentation) (What\u2019s New In Python 3.11 \u2014 Python 3.13.2 documentation). Using <code>Self</code> in a method return type or parameter type means \u201cthe same type as the class in which this method is defined.\u201d For example: <pre><code>class MyBuilder:  \n    def set_name(self, name: str) -&gt; Self:  \n        self.name = name; return self  \n</code></pre>   The return type <code>Self</code> indicates that <code>set_name</code> returns the exact same class (<code>MyBuilder</code> in this case). In subclasses, it will correctly infer the subclass type (typing \u2014 Support for type hints \u2014 Python 3.13.2 documentation) (typing \u2014 Support for type hints \u2014 Python 3.13.2 documentation). Without <code>Self</code>, one would have to use a type variable bound to the class, or a string annotation of the class name \u2013 both less convenient. Common use cases for <code>Self</code> are fluent interfaces (where methods return <code>self</code>), alternative constructors (often classmethods that return an instance of <code>cls</code>), and methods like <code>__enter__</code> in context managers that conventionally return self (typing \u2014 Support for type hints \u2014 Python 3.13.2 documentation). <code>Self</code> ensures the return type is automatically updated in subclasses, preventing type checkers from thinking a subclass method returning <code>self</code> is returning the base class.  </li> <li> <p>TypedDicts (PEP\u00a0589 and extensions): A TypedDict is a way to describe the expected shape of dictionaries with specific string keys. Introduced in Python 3.8, TypedDict allows you to create a type that expects certain keys with certain value types, mimicking the behavior of JavaScript objects or dataclasses but for dicts. For example: <pre><code>from typing import TypedDict  \nclass Movie(TypedDict):  \n    title: str  \n    year: int  \n</code></pre>   This defines a type <code>Movie</code> that is a dict with keys <code>\"title\"</code> (str) and <code>\"year\"</code> (int) (typing \u2014 Support for type hints \u2014 Python 3.13.2 documentation). Any extra keys would be a type checker error, and missing required keys are also an error. At runtime, a <code>TypedDict</code> is just a plain <code>dict</code> (there\u2019s no special dictionary class) (typing \u2014 Support for type hints \u2014 Python 3.13.2 documentation), so this is a static construct only. You can also create TypedDict types using a functional syntax: <code>Movie = TypedDict('Movie', {'title': str, 'year': int})</code> (typing \u2014 Support for type hints \u2014 Python 3.13.2 documentation). By default all keys are required, but you can make some optional. Initially, you could specify <code>total=False</code> on the TypedDict to make all keys optional. Later, PEP\u00a0655 (Python 3.11) introduced <code>Required</code> and <code>NotRequired</code> markers to allow fine-grained control: you can mark individual keys as optional in an otherwise total TypedDict (What\u2019s New In Python 3.11 \u2014 Python 3.13.2 documentation) (What\u2019s New In Python 3.11 \u2014 Python 3.13.2 documentation). For example: <pre><code>class Movie(TypedDict, total=False):  \n    title: Required[str]   # must have title  \n    year: NotRequired[int] # may omit year  \n</code></pre>   This says <code>title</code> is always required, <code>year</code> can be omitted (What\u2019s New In Python 3.11 \u2014 Python 3.13.2 documentation). When using <code>total=False</code>, by default all keys are optional unless marked <code>Required</code>. Conversely, with <code>total=True</code> (default), all keys are required unless marked <code>NotRequired</code> (typing \u2014 Support for type hints \u2014 Python 3.13.2 documentation).   Another addition is PEP\u00a0705 (Python\u00a03.13) which introduced <code>typing.ReadOnly</code> for TypedDict. This lets you designate certain keys as read-only (cannot be changed once set) for static checking purposes (typing \u2014 Support for type hints \u2014 Python 3.13.2 documentation). Example: <code>class Config(TypedDict): host: ReadOnly[str]; port: int</code>. Changing <code>host</code> after creation would be flagged. This is helpful to model immutable data within dictionaries.   TypedDicts are particularly useful for structures like configuration dicts or JSON data, where you want static validation of keys. They are also used in kwargs type annotations: Python 3.11 allows \u201cspreading\u201d a TypedDict into function arguments with kwargs (PEP\u00a0692). For instance, <code>def create_movie(**kwargs: Unpack[Movie]) -&gt; None:</code> will ensure that the keyword arguments match the Movie TypedDict schema (typing \u2014 Support for type hints \u2014 Python 3.13.2 documentation) (typing \u2014 Support for type hints \u2014 Python 3.13.2 documentation). Here <code>typing.Unpack</code> is used to unpack the TypedDict type. This feature helps in writing functions that explicitly accept a set of keyword arguments without enumerating them in the function signature.  </p> </li> <li> <p>Data Class Transform (PEP\u00a0681): Python\u2019s <code>dataclasses</code> module and third-party libraries like Pydantic or attrs generate methods (like <code>__init__</code>, <code>__repr__</code>) automatically based on class attributes. PEP\u00a0681 introduced the <code>typing.dataclass_transform</code> decorator (Python\u00a03.11) which library authors can apply to their decorator or metaclass to hint to static type checkers that the decorator will produce certain dunder methods or behaviors similar to <code>dataclasses</code> (What\u2019s New In Python 3.11 \u2014 Python 3.13.2 documentation). For example, Pydantic\u2019s <code>BaseModel</code> or attrs\u2019 <code>@define</code> can use this so that type checkers know that after applying the decorator, the class has an <code>__init__</code> with parameters corresponding to the annotated fields. This is a more advanced feature primarily for library developers to improve user experience of static typing when using those libraries.  </p> </li> </ul>"},{"location":"A10_Topic_List/#forward-references-and-postponed-evaluation","title":"Forward References and Postponed Evaluation","text":"<ul> <li>Forward References: It\u2019s common to have types that refer to classes or types not yet defined (e.g., a method in class <code>A</code> that returns an instance of class <code>B</code> defined later in the file). To handle this, Python allows using string literals in annotations for forward references. For example: <pre><code>class Node:  \n    def add_child(self, child: \"Node\") -&gt; None: ...  \n</code></pre>   Without the quotes, <code>Node</code> wouldn\u2019t be defined at the time of evaluation of the annotation. Quoted annotations defer evaluation of that name. In Python 3.7+, an alternative to quoting every forward reference is to use <code>from __future__ import annotations</code>, which causes all annotations to be stored as strings by default (PEP\u00a0563). This \u201cpostponed evaluation\u201d was optional in 3.7\u20133.9 and was meant to become the default behavior in Python 3.10. However, that plan was revised: PEP\u00a0563\u2019s default activation was put on hold (What\u2019s New In Python 3.11 \u2014 Python 3.13.2 documentation). The Python steering council decided not to turn on the automatic stringification by default due to various issues it caused for runtime introspection and decided to explore a different approach (PEP\u00a0649).  </li> <li>PEP\u00a0649 (Deferred Annotations): PEP\u00a0649, accepted for Python\u2019s future (targeted for 3.13+), proposes a new mechanism where annotations are neither evaluated at function definition time nor simply stored as strings. Instead, annotations would be stored as code in a special function (<code>__annotate__</code>) that computes them on demand (PEP 649 \u2013 Deferred Evaluation Of Annotations Using Descriptors | peps.python.org) (PEP 649 \u2013 Deferred Evaluation Of Annotations Using Descriptors | peps.python.org). This aims to solve forward references and performance issues more elegantly: the evaluation of annotations is deferred until needed, without losing the actual object references or incurring the issues of stringified annotations. As of the latest Python (3.12), this is still in progress \u2013 by default, Python 3.12 still evaluates annotations normally (unless you use the future import). In practice, when writing modern code, you can rely on <code>from __future__ import annotations</code> to handle most forward references conveniently (or just use quotes for specific cases). Static type checkers themselves resolve forward references even if you leave them as raw names, so this is mostly a runtime concern for introspection via <code>inspect.get_annotations</code> or similar. The takeaway: forward references are supported via quoting or future imports, and the language is evolving to make annotation evaluation lazy by default in a robust way (What\u2019s New In Python 3.11 \u2014 Python 3.13.2 documentation).  </li> </ul>"},{"location":"A10_Topic_List/#tools-stubs-and-best-practices","title":"Tools, Stubs, and Best Practices","text":"<ul> <li>Type Checkers and IDE Support: To make the most of type annotations, use a static type checker (like mypy, pyright, Pyre) or an IDE with built-in checking (PyCharm, VS Code, etc.). These tools will read your annotations and warn you of type mismatches, missing return statements for functions declared to return non-<code>None</code>, improper overrides, etc. The type system is standardized enough that most checkers agree on core behavior (PEP 484 \u2013 Type Hints | peps.python.org). You can customize their strictness (for example, disallowing implicit <code>Any</code> types). Run these checkers as part of your development or CI process to catch bugs early.  </li> <li>Stub Files (PEP\u00a0484 &amp; PEP\u00a0561): If you are using a library that isn\u2019t annotated, or you cannot modify source code to add annotations (e.g. C extension modules or third-party code), you can use stub files (<code>.pyi</code> files) to provide type information. A stub file is a skeletal version of a module with only <code>pass</code> statements and type hints. PEP\u00a0561 describes how libraries can distribute these stubs so that your type checker picks them up (Distributing type information \u2014 typing documentation). For instance, popular libraries often ship a <code>py.typed</code> marker and include inline types or separate stub packages (e.g. <code>types-requests</code>). As a user, you typically don\u2019t need to write stub files unless you\u2019re providing types for an untyped library or doing something very dynamic. But it\u2019s good to know that the ecosystem supports them, enabling gradual adoption of typing even for older code.  </li> <li>General Best Practices: </li> <li>Adopt Gradually: You don\u2019t have to annotate everything at once. It\u2019s common to start by annotating function signatures of key modules or adding stubs for critical libraries. Unannotated code defaults to <code>Any</code> types, which type checkers will by default let pass (or you can configure them to be strict).  </li> <li>Be Comprehensive in Signatures: For a function that you\u2019re annotating, try to annotate all parameters and the return type. Partial annotations can sometimes mislead type inference. If a function returns nothing, use <code>-&gt; None</code> for clarity (PEP 484 \u2013 Type Hints | peps.python.org). If a parameter has a default, remember that doesn\u2019t automatically make it Optional unless you intend <code>None</code> as a valid value (typing \u2014 Support for type hints \u2014 Python 3.13.2 documentation).  </li> <li>Prefer Specific Types or Protocols: When annotating arguments, use the most general type that works for your function (Liskov substitution principle). For example, if your function only needs to read from a collection, annotate it as <code>Iterable[T]</code> or <code>Sequence[T]</code> instead of <code>list[T]</code>, to allow more types (like tuples, sets) (Typing Best Practices \u2014 typing  documentation). If a parameter can be any object with a certain method, consider using a Protocol instead of a concrete class. Conversely, for return types, it\u2019s usually best to be as specific as possible (don\u2019t return <code>Any</code> if you can return a concrete type).  </li> <li>Use Modern Syntax: Prefer the new concise annotation syntax that Python now supports. This means using built-in collection types (e.g. <code>list[int]</code> rather than <code>typing.List[int]</code>) (Typing Best Practices \u2014 typing  documentation), using <code>X | Y</code> for unions rather than <code>typing.Union[X, Y]</code> (typing \u2014 Support for type hints \u2014 Python 3.13.2 documentation), and <code>X | None</code> instead of <code>typing.Optional[X]</code>. These make annotations more readable. The older syntax is still accepted for compatibility, but the newer syntax is encouraged in current code.  </li> <li>Limit <code>Any</code> and Unsafe Casts: Try to avoid using <code>Any</code> unless absolutely necessary. If you find yourself needing to bypass the type system (via casts or <code># type: ignore</code> comments), consider if there\u2019s a better way \u2013 such as using Union types, overloading, or restructuring code. If you do use <code>Any</code> (for example, when interfacing with dynamically typed libraries), isolate it at the boundary of your code.  </li> <li>Leverage Type Narrowing: Write code in a type-friendly way. Use <code>isinstance</code> checks or guard functions (even custom TypeGuard functions) to narrow types, instead of, say, <code>assert isinstance(x, SomeType)</code> which some type checkers might not understand. Many checkers can infer that after <code>if isinstance(obj, str): ... else: ...</code>, in the else branch <code>obj</code> is not a str. This makes your code safer and your type checker happier.  </li> <li>Keep Types Up to Date: Treat type hints as part of the code documentation. If the code changes, update the annotations to match. Inconsistencies between code and annotations can be more confusing than no annotations. Running a type checker will catch these mismatches.  </li> <li>Performance Consideration: Annotations are designed to have minimal runtime overhead. They\u2019re stored as metadata and can be turned into strings with <code>from __future__ import annotations</code>. Unless you introspect them at runtime (with <code>typing.get_type_hints()</code>), they won\u2019t slow down your program. That said, using a type checker in development might slightly slow down your build/test cycle, but it\u2019s usually worth the trade-off for the bugs it prevents.  </li> </ul> <p>Each of these topics is elaborated in the official Python typing documentation and Python Enhancement Proposals. For further reading, the \u201cTyping Cheat Sheet\u201d for Python (typing \u2014 Support for type hints \u2014 Python 3.13.2 documentation) and the Static Typing section on Python\u2019s documentation site (typing \u2014 Support for type hints \u2014 Python 3.13.2 documentation) are excellent resources. They provide code examples and deeper explanations for advanced scenarios, helping you stay up-to-date with the evolving landscape of type annotations in modern Python.</p>"}]}